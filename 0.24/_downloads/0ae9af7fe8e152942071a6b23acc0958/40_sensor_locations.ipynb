{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with sensor locations\n\nThis tutorial describes how to read and plot sensor locations, and how\nMNE-Python handles physical locations of sensors.\n\nAs usual we'll start by importing the modules we need and loading some\n`example data <sample-dataset>`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n# the following import is required for matplotlib < 3.2:\nfrom mpl_toolkits.mplot3d import Axes3D  # noqa\nimport mne\n\nsample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n                                    'sample_audvis_raw.fif')\nraw = mne.io.read_raw_fif(sample_data_raw_file, preload=True, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About montages and layouts\n\n`Montages <mne.channels.DigMontage>` contain sensor positions in 3D (x, y, z\nin meters), which can be assigned to existing EEG/MEG data. By specifying the\nlocations of sensors relative to the brain,\n`Montages <mne.channels.DigMontage>` play an important role in computing the\nforward solution and inverse estimates.\n\nIn contrast, `Layouts <mne.channels.Layout>` are *idealized* 2D\nrepresentations of sensor positions. They are primarily used for arranging\nindividual sensor subplots in a topoplot or for showing the *approximate*\nrelative arrangement of sensors as seen from above.\n\n## Working with built-in montages\n\nThe 3D coordinates of MEG sensors are included in the raw recordings from MEG\nsystems. They are automatically stored in the ``info`` attribute of the\n`~mne.io.Raw` object upon loading. EEG electrode locations are much more\nvariable because of differences in head shape. Idealized montages for many\nEEG systems are included in MNE-Python; these files are stored in your\n``mne-python`` directory in the :file:`mne/channels/data/montages` folder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage_dir = os.path.join(os.path.dirname(mne.__file__),\n                           'channels', 'data', 'montages')\nprint('\\nBUILT-IN MONTAGE FILES')\nprint('======================')\nprint(sorted(os.listdir(montage_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. sidebar:: Computing sensor locations\n\n    If you are interested in how standard (idealized) EEG sensor positions\n    are computed on a spherical head model, make sure to check out the\n    `eeg_positions`_ repository.\n\nThese built-in EEG montages can be loaded with\n`mne.channels.make_standard_montage` (note that you need to provide the\nfilename *without* its extension):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\nprint(ten_twenty_montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once loaded, a montage can be applied to data with the\n`~mne.io.Raw.set_montage` method, for example\n`raw.set_montage <mne.io.Raw.set_montage>`. It is also possible to skip the\nloading step by passing the filename string directly to the\n`~mne.io.Raw.set_montage` method. This will not work with our sample\ndata, because its channel names do not match the channel names in the\nstandard 10\u201320 montage. Therefore, we do not run the following commands here:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# these will be equivalent:\n# raw_1020 = raw.copy().set_montage(ten_twenty_montage)\n# raw_1020 = raw.copy().set_montage('standard_1020')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Montage <mne.channels.DigMontage>` objects have a\n`~mne.channels.DigMontage.plot` method for visualizing the sensor locations\nin 2D or 3D:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ten_twenty_montage.plot(kind='3d')\nfig.gca().view_init(azim=70, elev=15)  # set view angle\nten_twenty_montage.plot(kind='topomap', show_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Controlling channel projection (MNE vs EEGLAB)\n\nChannel positions in 2D space are obtained by projecting their actual 3D\npositions onto a sphere, then projecting the sphere onto a plane. Because the\n``'standard_1020'`` montage contains realistic (as opposed to idealized\nspherical) channel positions, we will use a different montage to demonstrate\nhow channels are projected to 2D:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_montage = mne.channels.make_standard_montage('biosemi64')\nbiosemi_montage.plot(show_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, a sphere with origin at ``(0, 0, 0)`` (x, y, z coordinates) and\nradius of ``0.095`` meters (9.5 cm) is used. You can use a different sphere\nradius by passing a single value as the  ``sphere`` argument in any function\nthat plots channels in 2D (like `~mne.channels.DigMontage.plot` that we use\nhere, but also for example `mne.viz.plot_topomap`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_montage.plot(show_names=False, sphere=0.07)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To change not only the radius, but also the sphere origin, pass a\n``(x, y, z, radius)`` tuple as the ``sphere`` argument:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_montage.plot(show_names=False, sphere=(0.03, 0.02, 0.01, 0.075))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In MNE-Python, the head center and therefore the sphere center are calculated\nusing :term:`fiducial points <fiducial>`. This means that the head circle\nrepresents the head circumference at the nasion and ear level, and not where\nit is commonly measured in the 10\u201320 EEG system (above the nasion at T4/T8,\nT3/T7, Oz, and Fz). Notice below that by default T7 and Oz are placed\n*within* the head circle:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_montage.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you prefer to draw the head circle using 10\u201320 conventions (which are also\nused by EEGLAB), you can move the sphere origin a few centimeters up along\nthe z dimension:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_montage.plot(sphere=(0, 0, 0.035, 0.094))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can calculate the sphere origin from Oz, Fpz, T3/T7 or\nT4/T8 channels. This is easier once the montage has been applied to the data\nand channel positions are in the head space (see\n`this example <ex-topomap-eeglab-style>`).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Reading sensor digitization files\n\nIn the sample data, the sensor positions are already available in the\n``info`` attribute of the `~mne.io.Raw` object (see the documentation of the\nreading functions and `~mne.io.Raw.set_montage` for details on how that\nworks). Therefore, we can plot sensor locations directly from the\n`~mne.io.Raw` object using `~mne.io.Raw.plot_sensors`, which provides similar\nfunctionality to `montage.plot() <mne.channels.DigMontage.plot>`. In\naddition, `~mne.io.Raw.plot_sensors` supports channel selection by type,\ncolor-coding channels in various ways (by default, channels listed in\n``raw.info['bads']`` will be plotted in red), and drawing in an existing\nMatplotlib ``Axes`` object (so the channel positions can easily be added as a\nsubplot in a multi-panel figure):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\nax2d = fig.add_subplot(121)\nax3d = fig.add_subplot(122, projection='3d')\nraw.plot_sensors(ch_type='eeg', axes=ax2d)\nraw.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\nax3d.view_init(azim=70, elev=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous 2D topomap reveals irregularities in the EEG sensor positions in\nthe `sample dataset <sample-dataset>` \u2014 this is because the sensor\npositions in that dataset are digitizations of actual sensor positions on the\nhead rather than idealized sensor positions based on a spherical head model.\nDepending on the digitization device (e.g., a Polhemus Fastrak digitizer),\nyou need to use different montage reading functions (see `dig-formats`).\nThe resulting `montage <mne.channels.DigMontage>` can then be added to\n`~mne.io.Raw` objects by passing it as an argument to the\n`~mne.io.Raw.set_montage` method (just as we did before with the name of the\npredefined ``'standard_1020'`` montage). Once loaded, locations can be\nplotted with the `~mne.channels.DigMontage.plot` and saved with the\n`~mne.channels.DigMontage.save` methods of the\n`montage <mne.channels.DigMontage>` object.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>When setting a montage with `~mne.io.Raw.set_montage`, the measurement\n    info is updated in two places (both ``chs`` and ``dig`` entries are\n    updated) \u2013 see `tut-info-class` for more details. Note that ``dig``\n    may contain HPI, fiducial, or head shape points in addition to electrode\n    locations.</p></div>\n\n\n## Visualizing sensors in 3D surface renderings\n\nIt is also possible to render an image of an MEG sensor helmet using 3D\nsurface rendering instead of matplotlib. This works by calling\n`mne.viz.plot_alignment`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(raw.info, dig=False, eeg=False,\n                             surfaces=[], meg=['helmet', 'sensors'],\n                             coord_frame='meg')\nmne.viz.set_3d_view(fig, azimuth=50, elevation=90, distance=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that `~mne.viz.plot_alignment` requires an `~mne.Info` object, and can\nalso render MRI surfaces of the scalp, skull, and brain (by passing a dict\nwith keys like ``'head'``, ``'outer_skull'`` or ``'brain'`` to the\n``surfaces`` parameter). This makes the function useful for\n`assessing coordinate frame transformations <tut-source-alignment>`.\nFor examples of various uses of `~mne.viz.plot_alignment`, see\n`plot_montage`, `ex-eeg-on-scalp`, and `ex-plot-meg-sensors`.\n\n\n## Working with layout files\n\nSimilar to montages, many layout files are included with MNE-Python. They are\nstored in the :file:`mne/channels/data/layouts` folder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_dir = os.path.join(os.path.dirname(mne.__file__),\n                          'channels', 'data', 'layouts')\nprint('\\nBUILT-IN LAYOUT FILES')\nprint('=====================')\nprint(sorted(os.listdir(layout_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The file formats (and therefore file extensions) of the built-in layout and\nmontage files vary considerably (because manufacturers like to use different\nconventions). However, the montage and layout loading functions in MNE-Python\ntake the filename *without its extension* so you do not have to keep track of\nwhich file format is used by which manufacturer.\n\nTo load a layout file, use the `mne.channels.read_layout` function and\nprovide the filename *without* its file extension. You can then visualize the\nlayout using its `~mne.channels.Layout.plot` method or equivalently passing\nthe layout to `mne.viz.plot_layout`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_layout = mne.channels.read_layout('biosemi')\nbiosemi_layout.plot()  # same result as mne.viz.plot_layout(biosemi_layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the ``picks`` argument for selecting channels from `~mne.io.Raw`\nobjects, the `~mne.channels.Layout.plot` method of `~mne.channels.Layout`\nobjects also has a ``picks`` argument. However, because layouts only contain\ninformation about sensor name and location (not sensor type), the\n`~mne.channels.Layout.plot` method only supports picking channels by index\n(not by name or by type). In the following example, we find the desired\nindices using `numpy.where`; selection by name or type is possible with\n`mne.pick_channels` or `mne.pick_types`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "midline = np.where([name.endswith('z') for name in biosemi_layout.names])[0]\nbiosemi_layout.plot(picks=midline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have a `~mne.io.Raw` object that contains sensor positions, you can\ncreate a `~mne.channels.Layout` object with either\n`mne.channels.make_eeg_layout` or `mne.channels.find_layout`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_from_raw = mne.channels.make_eeg_layout(raw.info)\n# same result as mne.channels.find_layout(raw.info, ch_type='eeg')\nlayout_from_raw.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There is no corresponding ``make_meg_layout()`` function because sensor\n    locations are fixed in an MEG system (unlike in EEG, where sensor caps\n    deform to fit snugly on a specific head). Therefore, MEG layouts are\n    consistent (constant) for a given system and you can simply load them\n    with `mne.channels.read_layout` or use `mne.channels.find_layout` with\n    the ``ch_type`` parameter (as previously demonstrated for EEG).</p></div>\n\nAll `~mne.channels.Layout` objects have a `~mne.channels.Layout.save` method\nthat writes layouts to disk as either :file:`.lout` or :file:`.lay` formats\n(inferred from the file extension contained in the ``fname`` argument). The\nchoice between :file:`.lout` and :file:`.lay` format only matters if you need\nto load the layout file in some other application (MNE-Python can read both\nformats).\n\n\n.. LINKS\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}