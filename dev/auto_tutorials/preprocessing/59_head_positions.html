
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Extracting and visualizing subject head movement &#8212; MNE 1.1.dev0 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=19ec7dda39a41ce4efdb" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=19ec7dda39a41ce4efdb" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=19ec7dda39a41ce4efdb">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.google-analytics.com/analytics.js"></script>
    <script>
                    window.ga = window.ga || function () {
                        (ga.q = ga.q || []).push(arguments) };
                    ga.l = +new Date;
                    ga('create', 'UA-37225609-1', 'auto');
                    ga('set', 'anonymizeIp', true);
                    ga('send', 'pageview');
                </script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Signal-space separation (SSS) and Maxwell filtering" href="60_maxwell_filtering_sss.html" />
    <link rel="prev" title="Setting the EEG reference" href="55_setting_eeg_reference.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">

  <!-- checkbox to toggle primary sidebar -->
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  <!-- Checkboxes to toggle the secondary sidebar -->
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  <!-- A search field pop-up that will only show when the search button is clicked -->

  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  

  
  <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        dev  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables auto_tutorials/preprocessing/59_head_positions and {'json_url': 'https://mne.tools/dev/_static/versions.json', 'version_match': 'dev'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "auto_tutorials/preprocessing/59_head_positions.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://mne.tools/dev/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "auto_tutorials/preprocessing/59_head_positions.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const span = document.createElement("span");
            span.textContent = `${entry.name}`;

            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            node.appendChild(span);

            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's 1.1 variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "dev") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Discourse" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
      </ul>
      </div>
      
    </div>

  </div>

</div>

<script>
// Adds the `shown` class to the parent so that we can trigger overflow
// behavior that depends on whether we're expanded
$('#navbar-collapsible').on('show.bs.collapse', function () {
  $(".bd-header").addClass("shown");
});
$('#navbar-collapsible').on('hide.bs.collapse', function () {
  $(".bd-header").removeClass("shown");
});
</script>
  </nav>
  

  <div class="bd-container container-xl">
    <div class="bd-container__inner row">
      



<div class="bd-sidebar-primary bd-sidebar">
  <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../intro/index.html">
     Introductory tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/10_overview.html">
       Overview of MEG/EEG analysis with MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/15_inplace.html">
       Modifying data in-place
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/20_events_from_raw.html">
       Parsing events from raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/30_info.html">
       The Info data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/40_sensor_locations.html">
       Working with sensor locations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/50_configure_mne.html">
       Configuring MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../intro/70_report.html">
       Getting started with mne.Report
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../io/index.html">
     Reading data for different recording systems
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/10_reading_meg_data.html">
       Importing data from MEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/20_reading_eeg_data.html">
       Importing data from EEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/30_reading_fnirs_data.html">
       Importing data from fNIRS devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/60_ctf_bst_auditory.html">
       Working with CTF data: the Brainstorm auditory dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../raw/index.html">
     Working with continuous data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../raw/10_raw_overview.html">
       The Raw data structure: continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../raw/20_event_arrays.html">
       Working with events
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../raw/30_annotate_raw.html">
       Annotating continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../raw/40_visualize_raw.html">
       Built-in plotting methods for Raw objects
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Preprocessing
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="10_preprocessing_overview.html">
       Overview of artifact detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="15_handling_bad_channels.html">
       Handling bad channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="20_rejecting_bad_data.html">
       Rejecting bad data spans and breaks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="25_background_filtering.html">
       Background information on filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="30_filtering_resampling.html">
       Filtering and resampling data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="35_artifact_correction_regression.html">
       Repairing artifacts with regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="40_artifact_correction_ica.html">
       Repairing artifacts with ICA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="45_projectors_background.html">
       Background on projectors and projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="50_artifact_correction_ssp.html">
       Repairing artifacts with SSP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="55_setting_eeg_reference.html">
       Setting the EEG reference
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Extracting and visualizing subject head movement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="60_maxwell_filtering_sss.html">
       Signal-space separation (SSS) and Maxwell filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="70_fnirs_processing.html">
       Preprocessing functional near-infrared spectroscopy (fNIRS) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../epochs/index.html">
     Segmenting continuous data into epochs
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/10_epochs_overview.html">
       The Epochs data structure: discontinuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/15_baseline_regression.html">
       Regression-based baseline correction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/20_visualize_epochs.html">
       Visualizing epoched data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/30_epochs_metadata.html">
       Working with Epoch metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/40_autogenerate_metadata.html">
       Auto-generating Epochs metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">
       Exporting Epochs to Pandas DataFrames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">
       Divide continuous data into equally-spaced epochs
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../evoked/index.html">
     Estimating evoked responses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../evoked/10_evoked_overview.html">
       The Evoked data structure: evoked/averaged data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../evoked/20_visualize_evoked.html">
       Visualizing Evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../evoked/30_eeg_erp.html">
       EEG analysis - Event-Related Potentials (ERPs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../evoked/40_whitened.html">
       Plotting whitened data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../time-freq/index.html">
     Time-frequency analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">
       Frequency and time-frequency sensor analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time-freq/50_ssvep.html">
       Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../forward/index.html">
     Forward models and source spaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/10_background_freesurfer.html">
       FreeSurfer MRI reconstruction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/20_source_alignment.html">
       Source alignment and coordinate frames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/25_automated_coreg.html">
       Using an automated approach to coregistration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/30_forward.html">
       Head model and forward computation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/35_eeg_no_mri.html">
       EEG forward operator with a template MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/50_background_freesurfer_mne.html">
       How MNE uses FreeSurferâ€™s outputs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/80_fix_bem_in_blender.html">
       Fixing BEM and head surfaces
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/90_compute_covariance.html">
       Computing a covariance matrix
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../inverse/index.html">
     Source localization and inverses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/10_stc_class.html">
       The SourceEstimate data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/20_dipole_fit.html">
       Source localization with equivalent current dipole (ECD) fit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/30_mne_dspm_loreta.html">
       Source localization with MNE, dSPM, sLORETA, and eLORETA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/35_dipole_orientations.html">
       The role of dipole orientations in distributed source localization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/40_mne_fixed_free.html">
       Computing various MNE solutions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/50_beamformer_lcmv.html">
       Source reconstruction using an LCMV beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/60_visualize_stc.html">
       Visualize source time courses (stcs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/70_eeg_mri_coords.html">
       EEG source localization given electrode locations on an MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/80_brainstorm_phantom_elekta.html">
       Brainstorm Elekta phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/85_brainstorm_phantom_ctf.html">
       Brainstorm CTF phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/90_phantom_4DBTi.html">
       4D Neuroimaging/BTi phantom dataset tutorial
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../stats-sensor-space/index.html">
     Statistical analysis of sensor data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/10_background_stats.html">
       Statistical inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">
       Visualising statistical significance thresholds on EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">
       Non-parametric 1 sample cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">
       Non-parametric between conditions cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/70_cluster_rmANOVA_time_freq.html">
       Mass-univariate twoway repeated measures ANOVA on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
       Spatiotemporal permutation F-test on full sensor data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../stats-source-space/index.html">
     Statistical analysis of source estimates
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">
       Permutation t-test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">
       2 samples permutation test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
       Repeated measures ANOVA on source data with spatio-temporal clustering
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../machine-learning/index.html">
     Machine learning models of neural activity
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../machine-learning/30_strf.html">
       Spectro-temporal receptive field (STRF) estimation on continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../machine-learning/50_decoding.html">
       Decoding (MVPA)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../clinical/index.html">
     Clinical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../clinical/10_ieeg_localize.html">
       Locating intracranial electrode contacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../clinical/20_seeg.html">
       Working with sEEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../clinical/30_ecog.html">
       Working with ECoG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../clinical/60_sleep.html">
       Sleep stage classification from polysomnography (PSG) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../simulation/index.html">
     Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/10_array_objs.html">
       Creating MNE-Python data structures from scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/70_point_spread.html">
       Corrupt known signal with point spread
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/80_dics.html">
       DICS for power mapping
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/io/index.html">
     Input/Output
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">
       Getting averaging info from .fif files
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/io/read_neo_format.html">
       How to use data in neural ensemble (NEO) format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">
       Reading/Writing a noise covariance matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/io/read_xdf.html">
       Reading XDF EEG data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/simulation/index.html">
     Data Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">
       Generate simulated evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">
       Generate simulated raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
       Simulate raw data using subject anatomy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">
       Generate simulated source data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/preprocessing/index.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/css.html">
       Cortical Signal Suppression (CSS) for removal of cortical signals
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">
       Define target events based on time lag, plot evoked response
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/eeg_bridging.html">
       Identify EEG Electrodes Bridged by too much Gel
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">
       Transform EEG data using current source density (CSD)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">
       Show EOG artifact timing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">
       Find MEG reference channel artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">
       Visualise NIRS artifact correction methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">
       Compare the different ICA algorithms in MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">
       Interpolate bad channels for MEG/EEG channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">
       Maxwell filter data with movement compensation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">
       Annotate movement artifacts and reestimate dev_head_t
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">
       Annotate muscle artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/muscle_ica.html">
       Removing muscle ICA components
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/otp.html">
       Plot sensor denoising using oversampled temporal projection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">
       Shifting time-scale in evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">
       Remap MEG channel types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">
       XDAWN Denoising
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/visualization/index.html">
     Visualization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">
       How to convert 3D electrode positions to a 2D image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/brain.html">
       Plotting with
       <code class="docutils literal notranslate">
        <span class="pre">
         mne.viz.Brain
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">
       Visualize channel over epochs as an image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">
       Plotting EEG sensors on the scalp
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">
       Plotting topographic arrowmaps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">
       Plotting topographic maps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">
       Whitening evoked data with a noise covariance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">
       Plotting sensor layouts of MEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">
       Plot the MNE brain and helmet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">
       Plotting sensor layouts of EEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/parcellation.html">
       Plot a cortical parcellation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/publication_figure.html">
       Make figures more publication ready
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">
       Plot single trial activity, grouped by ROI and sorted by RT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/sensor_noise_level.html">
       Show noise levels from empty room data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">
       Sensitivity map of SSP projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">
       Compare evoked responses for different conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">
       Plot custom topographies for MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/visualization/xhemi.html">
       Cross-hemisphere comparison
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/time_frequency/index.html">
     Time-Frequency Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">
       Compute a cross-spectral density (CSD) matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">
       Compute Power Spectral Density of inverse solution from single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">
       Compute power and phase lock in label of the source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">
       Compute source power spectral density (PSD) in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">
       Compute source power spectral density (PSD) of VectorView and OPM data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">
       Compute induced power in the source space with dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">
       Temporal whitening with AR model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">
       Compute and visualize ERDS maps
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">
       Explore event-related dynamics for specific frequency bands
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">
       Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/stats/index.html">
     Statistics Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">
       Permutation F-test on sensor data with 1D cluster level
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">
       FDR correction on T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">
       Regression on continuous data (rER[P/F])
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">
       Permutation T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">
       Analysing continuous features with binning and regression in sensor space
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/decoding/index.html">
     Machine Learning (Decoding, Encoding, and MVPA)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">
       Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">
       Decoding in time-frequency space using Common Spatial Patterns (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">
       Representational Similarity Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">
       Decoding source space data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">
       Continuous Target Decoding with SPoC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">
       Decoding sensor space data with generalization across time and conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
       Analysis of evoked response using ICA and PCA reduction techniques
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">
       XDAWN Decoding From EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">
       Compute effect-matched-spatial filtering (EMS)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">
       Linear classifier on sensor data with plot patterns and filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">
       Receptive Field Estimation and Prediction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">
       Compute Spectro-Spatial Decomposition (SSD) spatial filters
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/index.html">
     Connectivity Analysis Examples
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/forward/index.html">
     Forward modeling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">
       Display sensitivity maps for EEG and MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">
       Generate a left cerebellum volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">
       Use source space morphing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/inverse/index.html">
     Inverse problem and source analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
       Compute MNE-dSPM inverse solution on single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
       Compute sLORETA inverse solution on raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">
       Compute MNE-dSPM inverse solution on evoked data in volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">
       Source localization with a custom inverse solver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">
       Compute source power using DICS beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">
       Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">
       Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">
       Extracting time course from source_estimate object
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">
       Generate a functional label from source estimates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">
       Extracting the time series of activations in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">
       Compute sparse inverse solution with mixed norm: MxNE and irMxNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">
       Compute MNE inverse solution on evoked data with a mixed source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">
       Compute source power estimate by projecting the covariance with MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">
       Morph surface source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">
       Morph volumetric source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/multi_dipole_model.html">
       Computing source timecourses with an XFit-like multi-dipole model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">
       Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">
       Visualize source leakage among labels using a circular graph
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">
       Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">
       Compute cross-talk functions for LCMV beamformers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/rap_music.html">
       Compute Rap-Music on evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">
       Reading an inverse operator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/read_stc.html">
       Reading an STC file
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">
       Compute spatial resolution metrics in source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">
       Compute spatial resolution metrics to compare MEG with EEG+MEG
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">
       Estimate data SNR using an inverse
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">
       Computing source space SNR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
       Compute MxNE with time-frequency sparse prior
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">
       Plotting the full vector-valued MNE solution
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_examples/datasets/index.html">
     Examples on open datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
    <label for="toctree-checkbox-26">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">
       Brainstorm raw (median nerve) dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">
       HF-SEF dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/datasets/limo_data.html">
       Single trial linear regression analysis with the LIMO dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/datasets/opm_data.html">
       Optically pumped magnetometer (OPM) data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset_sgskip.html">
       From raw data to dSPM on SPM Faces dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


      <!-- â†“â†“â†“â†“â†“ this chunk is customized â†“â†“â†“â†“â†“ -->
      
        

<div class="bd-sidebar-secondary bd-toc">
    
    <div class="toc-item">
      
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hpi-frequencies">
   HPI frequencies
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimating-continuous-head-position">
   Estimating continuous head position
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualizing-continuous-head-position">
   Visualizing continuous head position
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-snr-of-the-hpi-signal">
   Computing SNR of the HPI signal
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
    <div class="toc-item">
      
    </div>
    
</div>


      
      <!-- â†‘â†‘â†‘ this chunk is customized â†‘â†‘â†‘ -->

      
      <div class="bd-content col">

        <div class="bd-header-article">
            <div class="bd-header-article__inner">
    <div class="bd-header-article__start">
        
        <label class="sidebar-toggle primary-toggle" for="__primary">
            <span class="fas fa-outdent"></span>
        </label>
        
    </div>

    <div class="bd-header-article__end">
        
        <label class="sidebar-toggle secondary-toggle" for="__secondary">
            <span class="fas fa-outdent"></span>
        </label>
        
    </div>
</div>
        </div>

        <!-- â†“â†“â†“â†“â†“ this chunk is customized â†“â†“â†“â†“â†“ -->
        
          <div>
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-preprocessing-59-head-positions-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="extracting-and-visualizing-subject-head-movement">
<span id="tut-head-pos"></span><span id="sphx-glr-auto-tutorials-preprocessing-59-head-positions-py"></span><h1>Extracting and visualizing subject head movement<a class="headerlink" href="#extracting-and-visualizing-subject-head-movement" title="Permalink to this heading">#</a></h1>
<p>Continuous head movement can be encoded during MEG recordings by use of
HPI coils that continuously emit sinusoidal signals. These signals can then be
extracted from the recording and used to estimate head position as a function
of time. Here we show an example of how to do this, and how to visualize
the result.</p>
<section id="hpi-frequencies">
<h2>HPI frequencies<a class="headerlink" href="#hpi-frequencies" title="Permalink to this heading">#</a></h2>
<p>First letâ€™s load a short bit of raw data where the subject intentionally moved
their head during the recording. Its power spectral density shows five peaks
(most clearly visible in the gradiometers) corresponding to the HPI coil
frequencies, plus other peaks related to power line interference (60 Hz and
harmonics).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Eric Larson &lt;larson.eric.d@gmail.com&gt;</span>
<span class="c1">#          Richard HÃ¶chenberger &lt;richard.hoechenberger@gmail.com&gt;</span>
<span class="c1">#          Daniel McCloy &lt;dan@mccloy.info&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">path</span> <span class="k">as</span> <span class="n">op</span>
<span class="kn">import</span> <span class="nn">mne</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">op</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="s1">&#39;SSS&#39;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_raw</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">op</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a><span class="p">,</span> <span class="s1">&#39;test_move_anon_raw.fif&#39;</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_raw</span></a><span class="p">,</span> <span class="n">allow_maxshield</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.plot_psd" title="mne.io.Raw.plot_psd" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">plot_psd</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_59_head_positions_001.png" srcset="../../_images/sphx_glr_59_head_positions_001.png" alt="EEG, Gradiometers, Magnetometers" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-testing-data/SSS/test_move_anon_raw.fif...
    Read a total of 12 projection items:
        mag.fif : PCA-v1 (1 x 306)  idle
        mag.fif : PCA-v2 (1 x 306)  idle
        mag.fif : PCA-v3 (1 x 306)  idle
        mag.fif : PCA-v4 (1 x 306)  idle
        mag.fif : PCA-v5 (1 x 306)  idle
        mag.fif : PCA-v6 (1 x 306)  idle
        mag.fif : PCA-v7 (1 x 306)  idle
        grad.fif : PCA-v1 (1 x 306)  idle
        grad.fif : PCA-v2 (1 x 306)  idle
        grad.fif : PCA-v3 (1 x 306)  idle
        grad.fif : PCA-v4 (1 x 306)  idle
        Average EEG reference (1 x 60)  idle
    Range : 10800 ... 31199 =      9.000 ...    25.999 secs
Ready.
Reading 0 ... 20399  =      0.000 ...    16.999 secs...
Effective window size : 1.707 (s)
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished
Effective window size : 1.707 (s)
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished
Effective window size : 1.707 (s)
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished
</pre></div>
</div>
<p>We can use <a class="reference internal" href="../../generated/mne.chpi.get_chpi_info.html#mne.chpi.get_chpi_info" title="mne.chpi.get_chpi_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.chpi.get_chpi_info</span></code></a> to retrieve the coil frequencies,
the index of the channel indicating when which coil was switched on, and the
respective â€œevent codesâ€ associated with each coilâ€™s activity.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_freqs</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">ch_idx</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_codes</span></a> <span class="o">=</span> <a href="../../generated/mne.chpi.get_chpi_info.html#mne.chpi.get_chpi_info" title="mne.chpi.get_chpi_info" class="sphx-glr-backref-module-mne-chpi sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">chpi</span><span class="o">.</span><span class="n">get_chpi_info</span></a><span class="p">(</span><span class="n">info</span><span class="o">=</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cHPI coil frequencies extracted from raw: </span><span class="si">{</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_freqs</span></a><span class="si">}</span><span class="s1"> Hz&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using 5 HPI coils: 83 143 203 263 323 Hz
cHPI coil frequencies extracted from raw: [ 83. 143. 203. 263. 323.] Hz
</pre></div>
</div>
</section>
<section id="estimating-continuous-head-position">
<h2>Estimating continuous head position<a class="headerlink" href="#estimating-continuous-head-position" title="Permalink to this heading">#</a></h2>
<p>First, letâ€™s extract the HPI coil amplitudes as a function of time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_amplitudes</span></a> <span class="o">=</span> <a href="../../generated/mne.chpi.compute_chpi_amplitudes.html#mne.chpi.compute_chpi_amplitudes" title="mne.chpi.compute_chpi_amplitudes" class="sphx-glr-backref-module-mne-chpi sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">chpi</span><span class="o">.</span><span class="n">compute_chpi_amplitudes</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using 5 HPI coils: 83 143 203 263 323 Hz
Line interference frequencies: 60 120 180 240 300 360 Hz
Using time window: 83.3 ms
Fitting 5 HPI coil locations at up to 1696 time points (17.0 sec duration)

  0%|          | cHPI amplitudes : 0/1696 [00:00&lt;?,       ?it/s]
  0%|          | cHPI amplitudes : 1/1696 [00:02&lt;1:14:45,    2.65s/it]
  1%|1         | cHPI amplitudes : 18/1696 [00:02&lt;03:56,    7.09it/s]
  2%|2         | cHPI amplitudes : 38/1696 [00:02&lt;01:48,   15.31it/s]
  3%|3         | cHPI amplitudes : 58/1696 [00:02&lt;01:08,   23.83it/s]
  4%|4         | cHPI amplitudes : 71/1696 [00:02&lt;00:55,   29.52it/s]
  5%|5         | cHPI amplitudes : 91/1696 [00:02&lt;00:41,   38.72it/s]
  7%|6         | cHPI amplitudes : 112/1696 [00:02&lt;00:32,   48.74it/s]
  8%|7         | cHPI amplitudes : 133/1696 [00:02&lt;00:26,   59.13it/s]
  9%|9         | cHPI amplitudes : 154/1696 [00:02&lt;00:22,   69.87it/s]
 10%|#         | cHPI amplitudes : 171/1696 [00:02&lt;00:19,   78.75it/s]
 11%|#1        | cHPI amplitudes : 190/1696 [00:02&lt;00:16,   89.05it/s]
 12%|#2        | cHPI amplitudes : 209/1696 [00:02&lt;00:14,   99.68it/s]
 13%|#3        | cHPI amplitudes : 226/1696 [00:02&lt;00:13,  109.42it/s]
 14%|#4        | cHPI amplitudes : 242/1696 [00:02&lt;00:12,  118.75it/s]
 15%|#5        | cHPI amplitudes : 257/1696 [00:02&lt;00:11,  127.65it/s]
 16%|#5        | cHPI amplitudes : 271/1696 [00:02&lt;00:10,  136.18it/s]
 17%|#6        | cHPI amplitudes : 287/1696 [00:02&lt;00:09,  146.40it/s]
 18%|#8        | cHPI amplitudes : 306/1696 [00:02&lt;00:08,  159.21it/s]
 19%|#9        | cHPI amplitudes : 326/1696 [00:02&lt;00:07,  173.15it/s]
 20%|##        | cHPI amplitudes : 345/1696 [00:02&lt;00:07,  186.57it/s]
 21%|##1       | cHPI amplitudes : 363/1696 [00:02&lt;00:06,  199.44it/s]
 23%|##2       | cHPI amplitudes : 384/1696 [00:02&lt;00:06,  215.24it/s]
 24%|##3       | cHPI amplitudes : 403/1696 [00:03&lt;00:05,  229.64it/s]
 25%|##5       | cHPI amplitudes : 424/1696 [00:03&lt;00:05,  246.17it/s]
 26%|##6       | cHPI amplitudes : 443/1696 [00:03&lt;00:04,  261.15it/s]
 27%|##7       | cHPI amplitudes : 464/1696 [00:03&lt;00:04,  278.38it/s]
 29%|##8       | cHPI amplitudes : 485/1696 [00:03&lt;00:04,  295.79it/s]
 30%|##9       | cHPI amplitudes : 506/1696 [00:03&lt;00:03,  313.55it/s]
 31%|###1      | cHPI amplitudes : 527/1696 [00:03&lt;00:03,  331.60it/s]
 32%|###2      | cHPI amplitudes : 547/1696 [00:03&lt;00:03,  348.75it/s]
 33%|###3      | cHPI amplitudes : 568/1696 [00:03&lt;00:03,  367.18it/s]
 35%|###4      | cHPI amplitudes : 588/1696 [00:03&lt;00:02,  384.79it/s]
 36%|###5      | cHPI amplitudes : 609/1696 [00:03&lt;00:02,  403.83it/s]
 37%|###7      | cHPI amplitudes : 631/1696 [00:03&lt;00:02,  424.04it/s]
 38%|###8      | cHPI amplitudes : 652/1696 [00:03&lt;00:02,  443.37it/s]
 40%|###9      | cHPI amplitudes : 673/1696 [00:03&lt;00:02,  462.44it/s]
 41%|####      | cHPI amplitudes : 694/1696 [00:03&lt;00:02,  481.97it/s]
 42%|####2     | cHPI amplitudes : 715/1696 [00:03&lt;00:01,  501.34it/s]
 43%|####3     | cHPI amplitudes : 737/1696 [00:03&lt;00:01,  522.09it/s]
 45%|####4     | cHPI amplitudes : 759/1696 [00:03&lt;00:01,  542.91it/s]
 46%|####5     | cHPI amplitudes : 779/1696 [00:03&lt;00:01,  560.29it/s]
 47%|####7     | cHPI amplitudes : 798/1696 [00:03&lt;00:01,  575.79it/s]
 48%|####8     | cHPI amplitudes : 819/1696 [00:03&lt;00:01,  594.92it/s]
 49%|####9     | cHPI amplitudes : 839/1696 [00:03&lt;00:01,  612.38it/s]
 51%|#####     | cHPI amplitudes : 858/1696 [00:03&lt;00:01,  627.72it/s]
 52%|#####1    | cHPI amplitudes : 877/1696 [00:03&lt;00:01,  643.70it/s]
 53%|#####2    | cHPI amplitudes : 896/1696 [00:03&lt;00:01,  659.51it/s]
 54%|#####4    | cHPI amplitudes : 916/1696 [00:03&lt;00:01,  676.39it/s]
 55%|#####5    | cHPI amplitudes : 937/1696 [00:03&lt;00:01,  695.12it/s]
 56%|#####6    | cHPI amplitudes : 958/1696 [00:03&lt;00:01,  713.48it/s]
 58%|#####7    | cHPI amplitudes : 977/1696 [00:03&lt;00:00,  727.95it/s]
 59%|#####8    | cHPI amplitudes : 998/1696 [00:03&lt;00:00,  746.63it/s]
 60%|######    | cHPI amplitudes : 1019/1696 [00:03&lt;00:00,  764.22it/s]
 61%|######1   | cHPI amplitudes : 1038/1696 [00:03&lt;00:00,  777.27it/s]
 62%|######2   | cHPI amplitudes : 1058/1696 [00:03&lt;00:00,  792.28it/s]
 64%|######3   | cHPI amplitudes : 1079/1696 [00:03&lt;00:00,  810.01it/s]
 65%|######4   | cHPI amplitudes : 1101/1696 [00:03&lt;00:00,  828.37it/s]
 66%|######6   | cHPI amplitudes : 1121/1696 [00:03&lt;00:00,  843.09it/s]
 67%|######7   | cHPI amplitudes : 1143/1696 [00:03&lt;00:00,  861.07it/s]
 69%|######8   | cHPI amplitudes : 1165/1696 [00:03&lt;00:00,  878.45it/s]
 70%|######9   | cHPI amplitudes : 1185/1696 [00:03&lt;00:00,  891.95it/s]
 71%|#######1  | cHPI amplitudes : 1206/1696 [00:03&lt;00:00,  907.26it/s]
 72%|#######2  | cHPI amplitudes : 1227/1696 [00:03&lt;00:00,  922.50it/s]
 74%|#######3  | cHPI amplitudes : 1247/1696 [00:03&lt;00:00,  934.57it/s]
 75%|#######4  | cHPI amplitudes : 1268/1696 [00:03&lt;00:00,  948.58it/s]
 76%|#######5  | cHPI amplitudes : 1287/1696 [00:03&lt;00:00,  957.10it/s]
 77%|#######7  | cHPI amplitudes : 1308/1696 [00:03&lt;00:00,  970.77it/s]
 78%|#######8  | cHPI amplitudes : 1326/1696 [00:03&lt;00:00,  975.04it/s]
 79%|#######9  | cHPI amplitudes : 1346/1696 [00:03&lt;00:00,  985.45it/s]
 80%|########  | cHPI amplitudes : 1363/1696 [00:03&lt;00:00,  988.31it/s]
 81%|########1 | cHPI amplitudes : 1378/1696 [00:03&lt;00:00,  984.42it/s]
 82%|########2 | cHPI amplitudes : 1395/1696 [00:03&lt;00:00,  986.83it/s]
 83%|########3 | cHPI amplitudes : 1416/1696 [00:03&lt;00:00,  999.32it/s]
 85%|########4 | cHPI amplitudes : 1437/1696 [00:03&lt;00:00, 1011.81it/s]
 86%|########5 | cHPI amplitudes : 1458/1696 [00:03&lt;00:00, 1022.89it/s]
 87%|########7 | cHPI amplitudes : 1479/1696 [00:03&lt;00:00, 1033.75it/s]
 88%|########8 | cHPI amplitudes : 1499/1696 [00:03&lt;00:00, 1042.41it/s]
 89%|########9 | cHPI amplitudes : 1517/1696 [00:03&lt;00:00, 1045.93it/s]
 91%|######### | cHPI amplitudes : 1537/1696 [00:03&lt;00:00, 1054.13it/s]
 92%|#########1| cHPI amplitudes : 1554/1696 [00:03&lt;00:00, 1053.59it/s]
 93%|#########2| cHPI amplitudes : 1575/1696 [00:03&lt;00:00, 1063.21it/s]
 94%|#########4| cHPI amplitudes : 1596/1696 [00:03&lt;00:00, 1073.42it/s]
 95%|#########5| cHPI amplitudes : 1612/1696 [00:03&lt;00:00, 1068.93it/s]
 96%|#########5| cHPI amplitudes : 1627/1696 [00:04&lt;00:00, 1062.45it/s]
 97%|#########6| cHPI amplitudes : 1641/1696 [00:04&lt;00:00, 1052.12it/s]
 98%|#########7| cHPI amplitudes : 1659/1696 [00:04&lt;00:00, 1053.62it/s]
 99%|#########8| cHPI amplitudes : 1678/1696 [00:04&lt;00:00, 1059.09it/s]
100%|##########| cHPI amplitudes : 1696/1696 [00:04&lt;00:00, 1057.66it/s]
100%|##########| cHPI amplitudes : 1696/1696 [00:04&lt;00:00,  416.26it/s]
</pre></div>
</div>
<p>Second, letâ€™s compute time-varying HPI coil locations from these:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_locs</span></a> <span class="o">=</span> <a href="../../generated/mne.chpi.compute_chpi_locs.html#mne.chpi.compute_chpi_locs" title="mne.chpi.compute_chpi_locs" class="sphx-glr-backref-module-mne-chpi sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">chpi</span><span class="o">.</span><span class="n">compute_chpi_locs</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_amplitudes</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing 4385 HPI location guesses (1 cm grid in a 10.7 cm sphere)
HPIFIT: 5 coils digitized in order 5 1 4 3 2
HPI consistency of isotrak and hpifit is OK.

  0%|          | cHPI locations  : 0/1696 [00:00&lt;?,       ?it/s]
  0%|          | cHPI locations  : 1/1696 [00:00&lt;21:08,    1.34it/s]
  2%|2         | cHPI locations  : 37/1696 [00:00&lt;00:32,   50.81it/s]
  4%|4         | cHPI locations  : 70/1696 [00:00&lt;00:16,   96.27it/s]
  5%|5         | cHPI locations  : 93/1696 [00:00&lt;00:12,  127.38it/s]
  6%|5         | cHPI locations  : 101/1696 [00:00&lt;00:12,  126.04it/s]
  8%|7         | cHPI locations  : 131/1696 [00:00&lt;00:09,  165.63it/s]
  9%|9         | cHPI locations  : 155/1696 [00:00&lt;00:07,  196.65it/s]
 11%|#1        | cHPI locations  : 187/1696 [00:00&lt;00:06,  239.85it/s]
 12%|#1        | cHPI locations  : 201/1696 [00:01&lt;00:06,  230.30it/s]
 14%|#3        | cHPI locations  : 229/1696 [00:01&lt;00:05,  264.95it/s]
 16%|#5        | cHPI locations  : 266/1696 [00:01&lt;00:04,  312.94it/s]
 18%|#7        | cHPI locations  : 301/1696 [00:01&lt;00:04,  325.86it/s]
 20%|#9        | cHPI locations  : 336/1696 [00:01&lt;00:03,  367.82it/s]
 22%|##1       | cHPI locations  : 372/1696 [00:01&lt;00:03,  411.44it/s]
 24%|##3       | cHPI locations  : 401/1696 [00:01&lt;00:03,  404.28it/s]
 25%|##4       | cHPI locations  : 422/1696 [00:01&lt;00:03,  424.17it/s]
 26%|##6       | cHPI locations  : 442/1696 [00:01&lt;00:02,  442.80it/s]
 27%|##7       | cHPI locations  : 466/1696 [00:01&lt;00:02,  467.31it/s]
 29%|##8       | cHPI locations  : 490/1696 [00:01&lt;00:02,  492.02it/s]
 30%|##9       | cHPI locations  : 501/1696 [00:01&lt;00:02,  449.06it/s]
 31%|###1      | cHPI locations  : 526/1696 [00:01&lt;00:02,  474.36it/s]
 33%|###2      | cHPI locations  : 559/1696 [00:01&lt;00:02,  442.33it/s]
 33%|###3      | cHPI locations  : 568/1696 [00:01&lt;00:02,  406.41it/s]
 34%|###3      | cHPI locations  : 573/1696 [00:01&lt;00:03,  373.09it/s]
 34%|###4      | cHPI locations  : 577/1696 [00:01&lt;00:03,  344.58it/s]
 34%|###4      | cHPI locations  : 581/1696 [00:01&lt;00:03,  316.55it/s]
 35%|###4      | cHPI locations  : 587/1696 [00:01&lt;00:03,  291.32it/s]
 35%|###5      | cHPI locations  : 600/1696 [00:02&lt;00:03,  275.93it/s]
 37%|###6      | cHPI locations  : 626/1696 [00:02&lt;00:03,  297.08it/s]
 39%|###8      | cHPI locations  : 653/1696 [00:02&lt;00:03,  319.57it/s]
 40%|####      | cHPI locations  : 679/1696 [00:02&lt;00:02,  341.45it/s]
 41%|####1     | cHPI locations  : 700/1696 [00:02&lt;00:03,  330.43it/s]
 43%|####3     | cHPI locations  : 736/1696 [00:02&lt;00:02,  362.13it/s]
 45%|####5     | cHPI locations  : 766/1696 [00:02&lt;00:02,  388.01it/s]
 47%|####6     | cHPI locations  : 789/1696 [00:02&lt;00:02,  369.75it/s]
 47%|####6     | cHPI locations  : 794/1696 [00:02&lt;00:02,  341.72it/s]
 47%|####7     | cHPI locations  : 800/1696 [00:02&lt;00:02,  316.73it/s]
 47%|####7     | cHPI locations  : 805/1696 [00:02&lt;00:03,  287.73it/s]
 48%|####7     | cHPI locations  : 810/1696 [00:02&lt;00:03,  264.44it/s]
 48%|####8     | cHPI locations  : 815/1696 [00:02&lt;00:03,  245.70it/s]
 48%|####8     | cHPI locations  : 819/1696 [00:02&lt;00:03,  230.62it/s]
 49%|####8     | cHPI locations  : 823/1696 [00:03&lt;00:04,  216.70it/s]
 49%|####8     | cHPI locations  : 827/1696 [00:03&lt;00:04,  205.55it/s]
 49%|####9     | cHPI locations  : 833/1696 [00:03&lt;00:04,  193.46it/s]
 50%|#####     | cHPI locations  : 848/1696 [00:03&lt;00:04,  187.78it/s]
 52%|#####2    | cHPI locations  : 885/1696 [00:03&lt;00:03,  212.45it/s]
 54%|#####4    | cHPI locations  : 922/1696 [00:03&lt;00:03,  237.80it/s]
 56%|#####5    | cHPI locations  : 948/1696 [00:03&lt;00:03,  239.28it/s]
 58%|#####8    | cHPI locations  : 985/1696 [00:03&lt;00:02,  264.62it/s]
 60%|######    | cHPI locations  : 1018/1696 [00:03&lt;00:02,  287.48it/s]
 61%|######1   | cHPI locations  : 1040/1696 [00:03&lt;00:02,  277.57it/s]
 62%|######1   | cHPI locations  : 1051/1696 [00:03&lt;00:02,  263.79it/s]
 63%|######2   | cHPI locations  : 1062/1696 [00:03&lt;00:02,  248.49it/s]
 63%|######3   | cHPI locations  : 1072/1696 [00:04&lt;00:02,  238.07it/s]
 64%|######4   | cHPI locations  : 1086/1696 [00:04&lt;00:02,  233.17it/s]
 66%|######5   | cHPI locations  : 1113/1696 [00:04&lt;00:02,  249.71it/s]
 67%|######7   | cHPI locations  : 1139/1696 [00:04&lt;00:02,  265.91it/s]
 69%|######8   | cHPI locations  : 1168/1696 [00:04&lt;00:01,  284.88it/s]
 70%|######9   | cHPI locations  : 1186/1696 [00:04&lt;00:01,  274.15it/s]
 72%|#######2  | cHPI locations  : 1223/1696 [00:04&lt;00:01,  299.25it/s]
 74%|#######4  | cHPI locations  : 1257/1696 [00:04&lt;00:01,  322.64it/s]
 76%|#######5  | cHPI locations  : 1286/1696 [00:04&lt;00:01,  320.06it/s]
 76%|#######6  | cHPI locations  : 1296/1696 [00:04&lt;00:01,  306.37it/s]
 77%|#######6  | cHPI locations  : 1301/1696 [00:04&lt;00:01,  285.35it/s]
 77%|#######7  | cHPI locations  : 1306/1696 [00:04&lt;00:01,  270.56it/s]
 77%|#######7  | cHPI locations  : 1311/1696 [00:04&lt;00:01,  250.59it/s]
 78%|#######7  | cHPI locations  : 1315/1696 [00:04&lt;00:01,  236.05it/s]
 78%|#######7  | cHPI locations  : 1319/1696 [00:04&lt;00:01,  223.03it/s]
 78%|#######8  | cHPI locations  : 1325/1696 [00:05&lt;00:01,  211.60it/s]
 78%|#######8  | cHPI locations  : 1331/1696 [00:05&lt;00:01,  200.23it/s]
 79%|#######9  | cHPI locations  : 1341/1696 [00:05&lt;00:01,  191.10it/s]
 81%|########1 | cHPI locations  : 1376/1696 [00:05&lt;00:01,  211.91it/s]
 83%|########3 | cHPI locations  : 1412/1696 [00:05&lt;00:01,  234.05it/s]
 85%|########4 | cHPI locations  : 1441/1696 [00:05&lt;00:01,  237.04it/s]
 86%|########6 | cHPI locations  : 1464/1696 [00:05&lt;00:00,  250.31it/s]
 88%|########7 | cHPI locations  : 1486/1696 [00:05&lt;00:00,  263.23it/s]
 89%|########8 | cHPI locations  : 1508/1696 [00:05&lt;00:00,  276.54it/s]
 91%|######### | cHPI locations  : 1537/1696 [00:05&lt;00:00,  295.68it/s]
 91%|######### | cHPI locations  : 1541/1696 [00:05&lt;00:00,  274.84it/s]
 92%|#########2| cHPI locations  : 1565/1696 [00:05&lt;00:00,  265.15it/s]
 93%|#########2| cHPI locations  : 1573/1696 [00:05&lt;00:00,  245.61it/s]
 93%|#########3| cHPI locations  : 1580/1696 [00:06&lt;00:00,  229.08it/s]
 94%|#########3| cHPI locations  : 1586/1696 [00:06&lt;00:00,  216.35it/s]
 94%|#########3| cHPI locations  : 1590/1696 [00:06&lt;00:00,  201.89it/s]
 94%|#########3| cHPI locations  : 1594/1696 [00:06&lt;00:00,  189.75it/s]
 94%|#########4| cHPI locations  : 1599/1696 [00:06&lt;00:00,  178.91it/s]
 95%|#########4| cHPI locations  : 1609/1696 [00:06&lt;00:00,  170.52it/s]
 96%|#########6| cHPI locations  : 1629/1696 [00:06&lt;00:00,  180.81it/s]
 97%|#########7| cHPI locations  : 1652/1696 [00:06&lt;00:00,  178.56it/s]
 99%|#########8| cHPI locations  : 1677/1696 [00:06&lt;00:00,  191.82it/s]
100%|##########| cHPI locations  : 1696/1696 [00:06&lt;00:00,  247.20it/s]
</pre></div>
</div>
<p>Lastly, compute head positions from the coil locations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">head_pos</span></a> <span class="o">=</span> <a href="../../generated/mne.chpi.compute_head_pos.html#mne.chpi.compute_head_pos" title="mne.chpi.compute_head_pos" class="sphx-glr-backref-module-mne-chpi sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">chpi</span><span class="o">.</span><span class="n">compute_head_pos</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chpi_locs</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>t=9.000:     5/5 good HPI fits, movements [mm/s] =      0.1 /      0.2 /      0.5 /      0.2 /      0.3
t=10.000:    5/5 good HPI fits, movements [mm/s] =      0.1 /      0.2 /      0.0 /      0.2 /      0.1
t=11.000:    5/5 good HPI fits, movements [mm/s] =      0.0 /      0.1 /      0.1 /      0.0 /      0.1
t=12.000:    5/5 good HPI fits, movements [mm/s] =      0.0 /      0.0 /      0.0 /      0.0 /      0.0
t=13.000:    5/5 good HPI fits, movements [mm/s] =      0.0 /      0.1 /      0.0 /      0.0 /      0.1
t=14.000:    5/5 good HPI fits, movements [mm/s] =      0.1 /      0.1 /      0.1 /      0.1 /      0.1
t=14.580:    5/5 good HPI fits, movements [mm/s] =      5.0 /      4.8 /      6.1 /      5.5 /      4.9
t=14.670:    5/5 good HPI fits, movements [mm/s] =     33.4 /     34.5 /     39.9 /     37.9 /     30.3
t=14.720:    5/5 good HPI fits, movements [mm/s] =     49.4 /     47.3 /     60.2 /     59.5 /     44.6
t=14.760:    5/5 good HPI fits, movements [mm/s] =     65.2 /     63.0 /     72.9 /     70.8 /     56.3
t=14.800:    5/5 good HPI fits, movements [mm/s] =     66.1 /     59.2 /     83.1 /     78.0 /     60.8
t=14.860:    5/5 good HPI fits, movements [mm/s] =     55.3 /     52.4 /     57.8 /     62.0 /     47.1
t=14.990:    5/5 good HPI fits, movements [mm/s] =     23.0 /     22.6 /     24.0 /     27.1 /     19.9
t=15.990:    5/5 good HPI fits, movements [mm/s] =      0.7 /      0.9 /      0.8 /      0.8 /      0.9
t=16.880:    5/5 good HPI fits, movements [mm/s] =      2.5 /      3.4 /      2.9 /      3.8 /      3.3
t=16.930:    5/5 good HPI fits, movements [mm/s] =     52.5 /     55.1 /     58.5 /     67.0 /     59.4
t=16.990:    5/5 good HPI fits, movements [mm/s] =     56.4 /     53.9 /     61.9 /     65.0 /     57.5
t=17.040:    5/5 good HPI fits, movements [mm/s] =     54.3 /     49.8 /     60.0 /     62.0 /     49.3
t=17.090:    5/5 good HPI fits, movements [mm/s] =     57.6 /     50.5 /     66.6 /     64.9 /     51.6
t=17.140:    5/5 good HPI fits, movements [mm/s] =     60.2 /     54.5 /     72.9 /     67.0 /     57.7
t=17.180:    5/5 good HPI fits, movements [mm/s] =     63.3 /     60.3 /     74.5 /     72.5 /     61.7
t=17.220:    5/5 good HPI fits, movements [mm/s] =     61.5 /     57.0 /     75.0 /     71.2 /     63.1
t=17.260:    5/5 good HPI fits, movements [mm/s] =     67.9 /     67.1 /     72.9 /     68.8 /     69.5
t=17.320:    5/5 good HPI fits, movements [mm/s] =     49.3 /     50.9 /     55.3 /     54.9 /     52.3
t=17.470:    5/5 good HPI fits, movements [mm/s] =     18.5 /     21.2 /     19.2 /     20.5 /     17.4
t=18.470:    5/5 good HPI fits, movements [mm/s] =      1.9 /      2.6 /      2.0 /      2.4 /      1.9
t=19.390:    5/5 good HPI fits, movements [mm/s] =      2.5 /      2.7 /      1.9 /      2.9 /      2.5
t=19.500:    5/5 good HPI fits, movements [mm/s] =     22.9 /     25.0 /     19.3 /     28.9 /     27.7
t=19.610:    5/5 good HPI fits, movements [mm/s] =     21.3 /     25.8 /     21.8 /     31.7 /     31.3
t=19.710:    5/5 good HPI fits, movements [mm/s] =     21.6 /     20.5 /     23.1 /     29.7 /     27.8
t=19.850:    5/5 good HPI fits, movements [mm/s] =     16.5 /     14.7 /     18.6 /     21.8 /     20.1
t=20.850:    5/5 good HPI fits, movements [mm/s] =      2.3 /      1.9 /      2.0 /      2.5 /      2.2
t=21.850:    5/5 good HPI fits, movements [mm/s] =      0.6 /      1.7 /      1.7 /      2.0 /      1.9
t=21.950:    5/5 good HPI fits, movements [mm/s] =     25.8 /     27.1 /     24.1 /     31.9 /     26.5
t=22.000:    5/5 good HPI fits, movements [mm/s] =     65.7 /     59.1 /     46.4 /     64.2 /     52.1
t=22.050:    5/5 good HPI fits, movements [mm/s] =     59.9 /     62.3 /     51.3 /     70.0 /     57.8
t=22.100:    5/5 good HPI fits, movements [mm/s] =     61.3 /     65.4 /     58.5 /     74.4 /     64.3
t=22.140:    5/5 good HPI fits, movements [mm/s] =     74.8 /     73.8 /     62.4 /     80.3 /     68.3
t=22.180:    5/5 good HPI fits, movements [mm/s] =     63.5 /     59.5 /     53.3 /     67.5 /     53.8
t=22.240:    5/5 good HPI fits, movements [mm/s] =     38.6 /     39.6 /     36.7 /     47.9 /     42.0
t=22.300:    5/5 good HPI fits, movements [mm/s] =     41.9 /     40.1 /     33.4 /     47.5 /     39.2
t=22.400:    5/5 good HPI fits, movements [mm/s] =     32.0 /     28.4 /     22.1 /     30.8 /     25.0
t=23.400:    5/5 good HPI fits, movements [mm/s] =      1.8 /      1.8 /      1.1 /      1.5 /      1.2
t=24.400:    5/5 good HPI fits, movements [mm/s] =      1.3 /      0.8 /      0.7 /      0.8 /      0.7
t=24.640:    5/5 good HPI fits, movements [mm/s] =     12.6 /     11.5 /     11.6 /     13.1 /     11.0
t=24.720:    5/5 good HPI fits, movements [mm/s] =     30.4 /     33.3 /     31.5 /     38.8 /     35.0
t=24.790:    5/5 good HPI fits, movements [mm/s] =     30.9 /     35.7 /     33.1 /     43.0 /     41.0
t=24.850:    5/5 good HPI fits, movements [mm/s] =     37.7 /     41.1 /     35.6 /     45.3 /     42.1
t=24.890:    5/5 good HPI fits, movements [mm/s] =     50.4 /     52.1 /     49.5 /     59.6 /     52.7
t=24.930:    5/5 good HPI fits, movements [mm/s] =     55.6 /     55.2 /     59.3 /     68.6 /     62.2
t=24.980:    5/5 good HPI fits, movements [mm/s] =     47.3 /     47.4 /     51.0 /     58.5 /     53.8
t=25.080:    5/5 good HPI fits, movements [mm/s] =     23.8 /     19.1 /     23.3 /     28.1 /     26.2
t=25.510:    5/5 good HPI fits, movements [mm/s] =      2.5 /      6.6 /      7.4 /      6.5 /      7.8
</pre></div>
</div>
<p>Note that these can then be written to disk or read from disk with
<a class="reference internal" href="../../generated/mne.chpi.write_head_pos.html#mne.chpi.write_head_pos" title="mne.chpi.write_head_pos"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.chpi.write_head_pos()</span></code></a> and <a class="reference internal" href="../../generated/mne.chpi.read_head_pos.html#mne.chpi.read_head_pos" title="mne.chpi.read_head_pos"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.chpi.read_head_pos()</span></code></a>,
respectively.</p>
</section>
<section id="visualizing-continuous-head-position">
<h2>Visualizing continuous head position<a class="headerlink" href="#visualizing-continuous-head-position" title="Permalink to this heading">#</a></h2>
<p>We can plot as traces, which is especially useful for long recordings:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.plot_head_positions.html#mne.viz.plot_head_positions" title="mne.viz.plot_head_positions" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_head_positions</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">head_pos</span></a><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;traces&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_59_head_positions_002.png" srcset="../../_images/sphx_glr_59_head_positions_002.png" alt="Position (mm), Rotation (quat)" class = "sphx-glr-single-img"/><p>Or we can visualize them as a continuous field (with the vectors pointing
in the head-upward direction):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.plot_head_positions.html#mne.viz.plot_head_positions" title="mne.viz.plot_head_positions" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_head_positions</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">head_pos</span></a><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;field&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_59_head_positions_003.png" srcset="../../_images/sphx_glr_59_head_positions_003.png" alt="59 head positions" class = "sphx-glr-single-img"/><p>These head positions can then be used with
<a class="reference internal" href="../../generated/mne.preprocessing.maxwell_filter.html#mne.preprocessing.maxwell_filter" title="mne.preprocessing.maxwell_filter"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.preprocessing.maxwell_filter()</span></code></a> to compensate for movement,
or with <a class="reference internal" href="../../generated/mne.preprocessing.annotate_movement.html#mne.preprocessing.annotate_movement" title="mne.preprocessing.annotate_movement"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.preprocessing.annotate_movement()</span></code></a> to mark segments as
bad that deviate too much from the average head position.</p>
</section>
<section id="computing-snr-of-the-hpi-signal">
<h2>Computing SNR of the HPI signal<a class="headerlink" href="#computing-snr-of-the-hpi-signal" title="Permalink to this heading">#</a></h2>
<p>It is also possible to compute the SNR of the continuous HPI measurements.
This can be a useful proxy for head position along the vertical dimension,
i.e., it can indicate the distance between the HPI coils and the MEG sensors.
Using <a class="reference internal" href="../../generated/mne.chpi.compute_chpi_snr.html#mne.chpi.compute_chpi_snr" title="mne.chpi.compute_chpi_snr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_chpi_snr</span></code></a>, the HPI power and SNR are computed
separately for each MEG sensor type and each HPI coil (frequency), along with
the residual power for each sensor type. The results can then be visualized
with <a class="reference internal" href="../../generated/mne.viz.plot_chpi_snr.html#mne.viz.plot_chpi_snr" title="mne.viz.plot_chpi_snr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_chpi_snr</span></code></a>. Here weâ€™ll just show a few seconds, for speed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.io.Raw.html#mne.io.Raw.crop" title="mne.io.Raw.crop" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">crop</span></a><span class="p">(</span><span class="n">tmin</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">snr_dict</span></a> <span class="o">=</span> <a href="../../generated/mne.chpi.compute_chpi_snr.html#mne.chpi.compute_chpi_snr" title="mne.chpi.compute_chpi_snr" class="sphx-glr-backref-module-mne-chpi sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">chpi</span><span class="o">.</span><span class="n">compute_chpi_snr</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="../../generated/mne.viz.plot_chpi_snr.html#mne.viz.plot_chpi_snr" title="mne.viz.plot_chpi_snr" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_chpi_snr</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">snr_dict</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_59_head_positions_004.png" srcset="../../_images/sphx_glr_59_head_positions_004.png" alt="SNR, magnetometers, cHPI power, magnetometers, Residual variance, magnetometers, SNR, gradiometers, cHPI power, gradiometers, Residual variance, gradiometers" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using 5 HPI coils: 83 143 203 263 323 Hz
Line interference frequencies: 60 120 180 240 300 360 Hz
Using time window: 83.3 ms
Fitting 5 HPI coil locations at up to 496 time points (5.0 sec duration)

  0%|          | cHPI SNRs : 0/496 [00:00&lt;?,       ?it/s]
  0%|          | cHPI SNRs : 1/496 [00:04&lt;37:46,    4.58s/it]
  3%|2         | cHPI SNRs : 14/496 [00:04&lt;02:30,    3.19it/s]
  6%|5         | cHPI SNRs : 28/496 [00:04&lt;01:11,    6.54it/s]
  8%|8         | cHPI SNRs : 42/496 [00:04&lt;00:45,   10.04it/s]
 11%|#1        | cHPI SNRs : 56/496 [00:04&lt;00:32,   13.69it/s]
 14%|#4        | cHPI SNRs : 70/496 [00:04&lt;00:24,   17.50it/s]
 17%|#6        | cHPI SNRs : 84/496 [00:04&lt;00:19,   21.47it/s]
 20%|#9        | cHPI SNRs : 98/496 [00:04&lt;00:15,   25.60it/s]
 23%|##2       | cHPI SNRs : 112/496 [00:04&lt;00:12,   29.92it/s]
 25%|##5       | cHPI SNRs : 126/496 [00:04&lt;00:10,   34.41it/s]
 28%|##8       | cHPI SNRs : 140/496 [00:04&lt;00:09,   39.08it/s]
 31%|###1      | cHPI SNRs : 154/496 [00:04&lt;00:07,   43.94it/s]
 34%|###3      | cHPI SNRs : 168/496 [00:04&lt;00:06,   49.00it/s]
 37%|###6      | cHPI SNRs : 182/496 [00:04&lt;00:05,   54.26it/s]
 40%|###9      | cHPI SNRs : 196/496 [00:04&lt;00:05,   59.72it/s]
 42%|####2     | cHPI SNRs : 210/496 [00:04&lt;00:04,   65.38it/s]
 45%|####5     | cHPI SNRs : 224/496 [00:04&lt;00:03,   71.26it/s]
 48%|####7     | cHPI SNRs : 238/496 [00:04&lt;00:03,   77.36it/s]
 51%|#####     | cHPI SNRs : 252/496 [00:04&lt;00:02,   83.67it/s]
 54%|#####3    | cHPI SNRs : 266/496 [00:04&lt;00:02,   90.20it/s]
 56%|#####6    | cHPI SNRs : 280/496 [00:04&lt;00:02,   96.94it/s]
 59%|#####9    | cHPI SNRs : 293/496 [00:04&lt;00:01,  103.33it/s]
 62%|######1   | cHPI SNRs : 306/496 [00:04&lt;00:01,  109.98it/s]
 65%|######4   | cHPI SNRs : 320/496 [00:04&lt;00:01,  117.36it/s]
 67%|######7   | cHPI SNRs : 333/496 [00:04&lt;00:01,  124.42it/s]
 70%|######9   | cHPI SNRs : 347/496 [00:04&lt;00:01,  132.34it/s]
 73%|#######2  | cHPI SNRs : 361/496 [00:05&lt;00:00,  140.51it/s]
 76%|#######5  | cHPI SNRs : 375/496 [00:05&lt;00:00,  148.91it/s]
 78%|#######8  | cHPI SNRs : 389/496 [00:05&lt;00:00,  157.55it/s]
 81%|########1 | cHPI SNRs : 403/496 [00:05&lt;00:00,  166.41it/s]
 84%|########4 | cHPI SNRs : 417/496 [00:05&lt;00:00,  175.51it/s]
 87%|########6 | cHPI SNRs : 431/496 [00:05&lt;00:00,  184.86it/s]
 90%|########9 | cHPI SNRs : 445/496 [00:05&lt;00:00,  194.42it/s]
 93%|#########2| cHPI SNRs : 459/496 [00:05&lt;00:00,  204.11it/s]
 95%|#########5| cHPI SNRs : 473/496 [00:05&lt;00:00,  213.94it/s]
 98%|#########8| cHPI SNRs : 487/496 [00:05&lt;00:00,  224.04it/s]
100%|##########| cHPI SNRs : 496/496 [00:05&lt;00:00,   95.99it/s]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  35.888 seconds)</p>
<p><strong>Estimated memory usage:</strong>  123 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-preprocessing-59-head-positions-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4d0dcc2a86878ce85a64142c4b4be583/59_head_positions.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">59_head_positions.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9bd293f49554a21d68d4f2a842cc6cc2/59_head_positions.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">59_head_positions.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


            
          </div>
        
        <!-- â†‘â†‘â†‘ this chunk is customized â†‘â†‘â†‘ -->

        
        <footer class="bd-footer-article">
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="55_setting_eeg_reference.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Setting the EEG reference</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="60_maxwell_filtering_sss.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Signal-space separation (SSS) and Maxwell filtering</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
        </footer>
        
      </div>
      
    </div>
  </div>

  
  <!-- â†“â†“â†“â†“â†“ this chunk is customized â†“â†“â†“â†“â†“ -->
    <script src="https://mne.tools/versionwarning.js"></script>
    
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=19ec7dda39a41ce4efdb"></script>

  <!-- â†‘â†‘â†‘ this chunk is customized â†‘â†‘â†‘ -->
  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="text-center text-muted small">&copy; Copyright 2012â€“2022, MNE Developers. Last updated <time datetime="2022-07-31T20:02:57.032736+00:00" class="localized">2022-07-31 20:02 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
  </div>
  
</div>
  </footer>
  </body>
</html>