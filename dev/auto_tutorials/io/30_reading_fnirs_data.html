
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Importing data from fNIRS devices &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Working with CTF data: the Brainstorm auditory dataset" href="60_ctf_bst_auditory.html" />
    <link rel="prev" title="Importing data from EEG devices" href="20_reading_eeg_data.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardized-data">
   Standardized data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#snirf-snirf">
     SNIRF (.snirf)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continuous-wave-devices">
   Continuous Wave Devices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nirx-directory-or-hdr">
     NIRx (directory or hdr)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hitachi-csv">
     Hitachi (.csv)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequency-domain-devices">
   Frequency Domain Devices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#boxy-txt">
     BOXY (.txt)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-data-import">
   Custom Data Import
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loading-legacy-data-in-csv-or-tsv-format">
     Loading legacy data in CSV or TSV format
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#applying-standard-sensor-locations-to-imported-data">
       Applying standard sensor locations to imported data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-io-30-reading-fnirs-data-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="importing-data-from-fnirs-devices">
<span id="tut-importing-fnirs-data"></span><span id="sphx-glr-auto-tutorials-io-30-reading-fnirs-data-py"></span><h1>Importing data from fNIRS devices<a class="headerlink" href="#importing-data-from-fnirs-devices" title="Permalink to this headline">¶</a></h1>
<p>fNIRS devices consist of two kinds of optodes: light sources (AKA “emitters” or
“transmitters”) and light detectors (AKA “receivers”). Channels are defined as
source-detector pairs, and channel locations are defined as the midpoint
between source and detector.</p>
<p>MNE-Python provides functions for reading fNIRS data and optode locations from
several file formats. Regardless of the device manufacturer or file format,
MNE-Python’s fNIRS functions will internally store the measurement data and its
metadata in the same way (e.g., data values are always converted into SI
units). Supported measurement types include amplitude, optical density,
oxyhaemoglobin concentration, and deoxyhemoglobin concentration (for continuous
wave fNIRS), and additionally AC amplitude and phase (for
frequency domain fNIRS).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>MNE-Python stores metadata internally with a specific structure,
and internal functions expect specific naming conventions.
Manual modification of channel names and metadata
is not recommended.</p>
</div>
<div class="section" id="standardized-data">
<span id="import-snirf"></span><h2>Standardized data<a class="headerlink" href="#standardized-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="snirf-snirf">
<h3>SNIRF (.snirf)<a class="headerlink" href="#snirf-snirf" title="Permalink to this headline">¶</a></h3>
<p>The Shared Near Infrared Spectroscopy Format
(<a class="reference external" href="https://github.com/fNIRS/snirf/blob/master/snirf_specification.md">SNIRF</a>)
is designed by the fNIRS community in an effort to facilitate
sharing and analysis of fNIRS data. And is the official format of the
Society for functional near-infrared spectroscopy (SfNIRS).
SNIRF is the preferred format for reading data in to MNE-Python.
Data stored in the SNIRF format can be read in
using <a class="reference internal" href="../../generated/mne.io.read_raw_snirf.html#mne.io.read_raw_snirf" title="mne.io.read_raw_snirf"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_snirf()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The SNIRF format has provisions for many different types of fNIRS
recordings. MNE-Python currently only supports reading continuous
wave data stored in the .snirf format.</p>
</div>
</div>
</div>
<div class="section" id="continuous-wave-devices">
<h2>Continuous Wave Devices<a class="headerlink" href="#continuous-wave-devices" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nirx-directory-or-hdr">
<span id="import-nirx"></span><h3>NIRx (directory or hdr)<a class="headerlink" href="#nirx-directory-or-hdr" title="Permalink to this headline">¶</a></h3>
<p>NIRx produce continuous wave fNIRS devices.
NIRx recordings can be read in using <a class="reference internal" href="../../generated/mne.io.read_raw_nirx.html#mne.io.read_raw_nirx" title="mne.io.read_raw_nirx"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_nirx()</span></code></a>.
The NIRx device stores data directly to a directory with multiple file types,
MNE-Python extracts the appropriate information from each file.
MNE-Python only supports NIRx files recorded with NIRStar
version 15.0 and above.
MNE-Python supports reading data from NIRScout and NIRSport 1 devices.</p>
</div>
<div class="section" id="hitachi-csv">
<span id="import-hitachi"></span><h3>Hitachi (.csv)<a class="headerlink" href="#hitachi-csv" title="Permalink to this headline">¶</a></h3>
<p>Hitachi produce continuous wave fNIRS devices.
Hitachi fNIRS recordings can be read using <a class="reference internal" href="../../generated/mne.io.read_raw_hitachi.html#mne.io.read_raw_hitachi" title="mne.io.read_raw_hitachi"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_hitachi()</span></code></a>.
No optode information is stored so you’ll need to set the montage manually,
see the Notes section of <a class="reference internal" href="../../generated/mne.io.read_raw_hitachi.html#mne.io.read_raw_hitachi" title="mne.io.read_raw_hitachi"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_hitachi()</span></code></a>.</p>
</div>
</div>
<div class="section" id="frequency-domain-devices">
<h2>Frequency Domain Devices<a class="headerlink" href="#frequency-domain-devices" title="Permalink to this headline">¶</a></h2>
<div class="section" id="boxy-txt">
<span id="import-boxy"></span><h3>BOXY (.txt)<a class="headerlink" href="#boxy-txt" title="Permalink to this headline">¶</a></h3>
<p>BOXY recordings can be read in using <a class="reference internal" href="../../generated/mne.io.read_raw_boxy.html#mne.io.read_raw_boxy" title="mne.io.read_raw_boxy"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_boxy()</span></code></a>.
The BOXY software and ISS Imagent I and II devices are frequency domain
systems that store data in a single <code class="docutils literal notranslate"><span class="pre">.txt</span></code> file containing what they call
(with MNE-Python’s name for that type of data in parens):</p>
<ul class="simple">
<li><dl class="simple">
<dt>DC</dt><dd><p>All light collected by the detector (<code class="docutils literal notranslate"><span class="pre">fnirs_cw_amplitude</span></code>)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>AC</dt><dd><p>High-frequency modulated light intensity (<code class="docutils literal notranslate"><span class="pre">fnirs_fd_ac_amplitude</span></code>)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Phase</dt><dd><p>Phase of the modulated light (<code class="docutils literal notranslate"><span class="pre">fnirs_fd_phase</span></code>)</p>
</dd>
</dl>
</li>
</ul>
<p>DC data is stored as the type <code class="docutils literal notranslate"><span class="pre">fnirs_cw_amplitude</span></code> because it
collects both the modulated and any unmodulated light, and hence is analogous
to what is collected by continuous wave systems such as NIRx. This helps with
conformance to SNIRF standard types.</p>
<p>These raw data files can be saved by the acquisition devices as parsed or
unparsed <code class="docutils literal notranslate"><span class="pre">.txt</span></code> files, which affects how the data in the file is organised.
MNE-Python will read either file type and extract the raw DC, AC,
and Phase data. If triggers are sent using the <code class="docutils literal notranslate"><span class="pre">digaux</span></code> port of the
recording hardware, MNE-Python will also read the <code class="docutils literal notranslate"><span class="pre">digaux</span></code> data and
create annotations for any triggers.</p>
</div>
</div>
<div class="section" id="custom-data-import">
<h2>Custom Data Import<a class="headerlink" href="#custom-data-import" title="Permalink to this headline">¶</a></h2>
<div class="section" id="loading-legacy-data-in-csv-or-tsv-format">
<h3>Loading legacy data in CSV or TSV format<a class="headerlink" href="#loading-legacy-data-in-csv-or-tsv-format" title="Permalink to this headline">¶</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This method is not supported and users are discoraged to use it.
You should convert your data to the
<a class="reference external" href="https://github.com/fNIRS/snirf">SNIRF</a> format using the tools
provided by the Society for functional Near-Infrared Spectroscopy,
and then load it using <a class="reference internal" href="../../generated/mne.io.read_raw_snirf.html#mne.io.read_raw_snirf" title="mne.io.read_raw_snirf"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.io.read_raw_snirf()</span></code></a>.</p>
</div>
<p>fNIRS measurements may be stored in a non-standardised format that is not
supported by MNE-Python and cannot be converted easily into SNIRF.
This legacy data is often in CSV or TSV format,
we show here a way to load it even though it is not officially supported by
MNE-Python due to the lack of standardisation of the file format (the
naming and ordering of channels, the type and scaling of data, and
specification of sensor positions varies between each vendor). You will likely
have to adapt this depending on the system from which your CSV originated.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">mne</span>
</pre></div>
</div>
<p>First, we generate an example CSV file which will then be loaded in to
MNE-Python. This step would be skipped if you have actual data you wish to
load. We simulate 16 channels with 100 samples of data and save this to a
file called fnirs.csv.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal" class="sphx-glr-backref-module-numpy-random sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">100</span><span class="p">)))</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;fnirs.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The channels must be ordered in haemoglobin pairs, such that for
a single channel all the types are in subsequent indices. The
type order must be ‘hbo’ then ‘hbr’.
The data below is already in the correct order and may be
used as a template for how data must be stored.
If the order that your data is stored is different to the
mandatory formatting, then you must first read the data with
channel naming according to the data structure, then reorder
the channels to match the required format.</p>
</div>
<p>Next, we will load the example CSV file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv" title="pandas.read_csv" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-function"><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span></a><span class="p">(</span><span class="s1">&#39;fnirs.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, the metadata must be specified manually as the CSV file does not
contain information about channel names, types, sample rate etc.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In MNE-Python the naming of channels MUST follow the structure
<code class="docutils literal notranslate"><span class="pre">S#_D#</span> <span class="pre">type</span></code> where # is replaced by the appropriate source and
detector numbers and type is either <code class="docutils literal notranslate"><span class="pre">hbo</span></code>, <code class="docutils literal notranslate"><span class="pre">hbr</span></code> or the
wavelength.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_names</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;S1_D1 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S1_D1 hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;S2_D1 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S2_D1 hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;S3_D1 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S3_D1 hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;S4_D1 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S4_D1 hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;S5_D2 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S5_D2 hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;S6_D2 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S6_D2 hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;S7_D2 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S7_D2 hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;S8_D2 hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;S8_D2 hbr&#39;</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_types</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span>
            <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">,</span> <span class="s1">&#39;hbo&#39;</span><span class="p">,</span> <span class="s1">&#39;hbr&#39;</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a> <span class="o">=</span> <span class="mf">10.</span>  <span class="c1"># in Hz</span>
</pre></div>
</div>
<p>Finally, the data can be converted in to an MNE-Python data structure.
The metadata above is used to create an <a class="reference internal" href="../../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Info</span></code></a> data structure,
and this is combined with the data to create an MNE-Python
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> object. For more details on the info structure
see <a class="reference internal" href="../intro/30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a>, and for additional details on how continuous data
is stored in MNE-Python see <a class="reference internal" href="../raw/10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a>.
For a more extensive description of how to create MNE-Python data structures
from raw array data see <a class="reference internal" href="../simulation/10_array_objs.html#tut-creating-data-structures"><span class="std std-ref">Creating MNE-Python data structures from scratch</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">info</span></a> <span class="o">=</span> <a href="../../generated/mne.create_info.html#mne.create_info" title="mne.create_info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">create_info</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_names</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_names</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_types</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ch_types</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a><span class="p">)</span>
<a href="../../generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">RawArray</span></a><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.DataFrame" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">,</span> <a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">info</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=16, n_times=101
    Range : 0 ... 100 =      0.000 ...    10.000 secs
Ready.
</pre></div>
</div>
<div class="section" id="applying-standard-sensor-locations-to-imported-data">
<h4>Applying standard sensor locations to imported data<a class="headerlink" href="#applying-standard-sensor-locations-to-imported-data" title="Permalink to this headline">¶</a></h4>
<p>Having information about optode locations may assist in your analysis.
Beyond the general benefits this provides (e.g. creating regions of interest,
etc), this is may be particularly important for fNIRS as information about
the optode locations is required to convert the optical density data in to an
estimate of the haemoglobin concentrations.
MNE-Python provides methods to load standard sensor configurations
(montages) from some vendors, and this is demonstrated below.
Some handy tutorials for understanding sensor locations, coordinate systems,
and how to store and view this information in MNE-Python are:
<a class="reference internal" href="../intro/40_sensor_locations.html#tut-sensor-locations"><span class="std std-ref">Working with sensor locations</span></a>, <a class="reference internal" href="../forward/20_source_alignment.html#plot-source-alignment"><span class="std std-ref">Source alignment and coordinate frames</span></a>, and
<a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html#ex-eeg-on-scalp"><span class="std std-ref">Plotting EEG sensors on the scalp</span></a>.</p>
<p>Below is an example of how to load the optode positions for an Artinis
OctaMon device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is also possible to create a custom montage from a file for
fNIRS with <a class="reference internal" href="../../generated/mne.channels.read_custom_montage.html#mne.channels.read_custom_montage" title="mne.channels.read_custom_montage"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.read_custom_montage()</span></code></a> by setting
<code class="docutils literal notranslate"><span class="pre">coord_frame</span></code> to <code class="docutils literal notranslate"><span class="pre">'mri'</span></code>.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a> <span class="o">=</span> <a href="../../generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">make_standard_montage</span></a><span class="p">(</span><span class="s1">&#39;artinis-octamon&#39;</span><span class="p">)</span>
<a href="../../generated/mne.io.RawArray.html#mne.io.RawArray.set_montage" title="mne.io.RawArray.set_montage" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">set_montage</span></a><span class="p">(</span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a><span class="p">)</span>

<span class="c1"># View the position of optodes in 2D to confirm the positions are correct.</span>
<a href="../../generated/mne.io.RawArray.html#mne.io.RawArray.plot_sensors" title="mne.io.RawArray.plot_sensors" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">plot_sensors</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_30_reading_fnirs_data_001.png" srcset="../../_images/sphx_glr_30_reading_fnirs_data_001.png" alt="30 reading fnirs data" class = "sphx-glr-single-img"/><p>To validate the positions were loaded correctly it is also possible to view
the location of the sources (red), detectors (black), and channels (white
lines and orange dots) in a 3D representation.
The ficiduals are marked in blue, green and red.
See <a class="reference internal" href="../forward/20_source_alignment.html#plot-source-alignment"><span class="std std-ref">Source alignment and coordinate frames</span></a> for more details.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;/subjects&#39;</span>
<a href="../../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fetch_fsaverage</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">)</span>

<span class="n">trans</span> <span class="o">=</span> <a href="../../generated/mne.channels.compute_native_head_t.html#mne.channels.compute_native_head_t" title="mne.channels.compute_native_head_t" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">compute_native_head_t</span></a><span class="p">(</span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <a href="../../generated/mne.viz.create_3d_figure.html#mne.viz.create_3d_figure" title="mne.viz.create_3d_figure" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">create_3d_figure</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span> <span class="n">bgcolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <a href="../../generated/mne.viz.plot_alignment.html#mne.viz.plot_alignment" title="mne.viz.plot_alignment" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_alignment</span></a><span class="p">(</span>
    <a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">subject</span><span class="o">=</span><span class="s1">&#39;fsaverage&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
    <span class="n">surfaces</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;brain&#39;</span><span class="p">,</span> <span class="s1">&#39;head&#39;</span><span class="p">],</span> <span class="n">coord_frame</span><span class="o">=</span><span class="s1">&#39;mri&#39;</span><span class="p">,</span> <span class="n">dig</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_axes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fnirs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;channels&#39;</span><span class="p">,</span> <span class="s1">&#39;pairs&#39;</span><span class="p">,</span> <span class="s1">&#39;sources&#39;</span><span class="p">,</span> <span class="s1">&#39;detectors&#39;</span><span class="p">],</span> <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
<a href="../../generated/mne.viz.set_3d_view.html#mne.viz.set_3d_view" title="mne.viz.set_3d_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">set_3d_view</span></a><span class="p">(</span><span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">azimuth</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">elevation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                    <span class="n">focalpoint</span><span class="o">=</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">))</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_30_reading_fnirs_data_002.png" srcset="../../_images/sphx_glr_30_reading_fnirs_data_002.png" alt="30 reading fnirs data" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0 files missing from root.txt in /home/circleci/mne_data/MNE-sample-data/subjects
0 files missing from bem.txt in /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage
Using outer_skin.surf for head surface.
Plotting 16 fNIRS locations
Plotting 16 fNIRS sources
Plotting 16 fNIRS detectors
Plotting 16 fNIRS pairs
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.791 seconds)</p>
<p><strong>Estimated memory usage:</strong>  22 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-io-30-reading-fnirs-data-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e68832206dbbb6f92ef843fcd5de9d98/30_reading_fnirs_data.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">30_reading_fnirs_data.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/d8a6d02146c5c075611a652218e020ad/30_reading_fnirs_data.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">30_reading_fnirs_data.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="20_reading_eeg_data.html" title="previous page">Importing data from EEG devices</a>
    <a class='right-next' id="next-link" href="60_ctf_bst_auditory.html" title="next page">Working with CTF data: the Brainstorm auditory dataset</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-06-17T18:19:14.954041+00:00" class="localized">2021-06-17 18:19 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>