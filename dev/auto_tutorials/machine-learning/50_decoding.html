
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Decoding (MVPA) &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Working with sEEG data" href="../clinical/20_seeg.html" />
    <link rel="prev" title="Spectro-temporal receptive field (STRF) estimation on continuous data" href="30_strf.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurferâ€™s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#design-philosophy">
   Design philosophy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformation-classes">
   Transformation classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scaler">
     Scaler
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizer">
     Vectorizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#psdestimator">
     PSDEstimator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filterestimator">
     FilterEstimator
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spatial-filters">
   Spatial filters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#common-spatial-pattern">
     Common spatial pattern
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#source-power-comodulation-spoc">
     Source power comodulation (SPoC)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xdawn">
     xDAWN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#effect-matched-spatial-filtering">
     Effect-matched spatial filtering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#patterns-vs-filters">
     Patterns vs. filters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decoding-over-time">
   Decoding over time
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#temporal-decoding">
     Temporal decoding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#temporal-generalization">
     Temporal generalization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projecting-sensor-space-patterns-to-source-space">
   Projecting sensor-space patterns to source space
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#source-space-decoding">
   Source-space decoding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-machine-learning-50-decoding-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="decoding-mvpa">
<span id="sphx-glr-auto-tutorials-machine-learning-50-decoding-py"></span><h1>Decoding (MVPA)<a class="headerlink" href="#decoding-mvpa" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="design-philosophy">
<h2>Design philosophy<a class="headerlink" href="#design-philosophy" title="Permalink to this headline">Â¶</a></h2>
<p>Decoding (a.k.a. MVPA) in MNE largely follows the machine
learning API of the scikit-learn package.
Each estimator implements <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">transform</span></code>, <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>, and
(optionally) <code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code> methods. For more details on this design,
visit <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>. For additional theoretical insights into the decoding
framework in MNE <a class="footnote-reference brackets" href="#kingetal2018" id="id1">1</a>.</p>
<p>For ease of comprehension, we will denote instantiations of the class using
the same name as the class but in small caps instead of camel cases.</p>
<p>Letâ€™s start by loading data for a simple two-class problem:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="kn">import</span> <span class="p">(</span><a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">SlidingEstimator</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">Scaler</span></a><span class="p">,</span>
                          <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="mne.decoding.cross_val_multiscore" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">cross_val_multiscore</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.LinearModel.html#mne.decoding.LinearModel" title="mne.decoding.LinearModel" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">LinearModel</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.get_coef.html#mne.decoding.get_coef" title="mne.decoding.get_coef" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">get_coef</span></a><span class="p">,</span>
                          <a href="../../generated/mne.decoding.Vectorizer.html#mne.decoding.Vectorizer" title="mne.decoding.Vectorizer" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">Vectorizer</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">CSP</span></a><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/subjects&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_raw.fif&#39;</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.200</span><span class="p">,</span> <span class="mf">0.500</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Auditory/Left&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Visual/Left&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>  <span class="c1"># just use two</span>
<span class="n">raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># The subsequent decoding analyses only capture evoked responses, so we can</span>
<span class="c1"># low-pass the MEG data. Usually a value more like 40 Hz would be used,</span>
<span class="c1"># but here low-pass at 20 so we can more heavily decimate, and allow</span>
<span class="c1"># the examlpe to run faster. The 2 Hz high-pass helps improve CSP.</span>
<span class="n">raw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="s1">&#39;STI 014&#39;</span><span class="p">)</span>

<span class="c1"># Set up pick list: EEG + MEG - bad channels (modify to your needs)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;bads&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;MEG 2443&#39;</span><span class="p">,</span> <span class="s1">&#39;EEG 053&#39;</span><span class="p">]</span>  <span class="c1"># bads + 2 more</span>

<span class="c1"># Read epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span> <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">picks</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;grad&#39;</span><span class="p">,</span> <span class="s1">&#39;eog&#39;</span><span class="p">),</span> <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.</span><span class="p">),</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="mf">4000e-13</span><span class="p">,</span> <span class="n">eog</span><span class="o">=</span><span class="mf">150e-6</span><span class="p">),</span> <span class="n">decim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">epochs</span><span class="o">.</span><span class="n">pick_types</span><span class="p">(</span><span class="n">meg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;bads&#39;</span><span class="p">)</span>  <span class="c1"># remove stim and EOG</span>
<span class="k">del</span> <span class="n">raw</span>

<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>  <span class="c1"># MEG signals: n_epochs, n_meg_channels, n_times</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># target: auditory left vs visual left</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
    Read a total of 3 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
    Range : 25800 ... 192599 =     42.956 ...   320.670 secs
Ready.
Reading 0 ... 166799  =      0.000 ...   277.714 secs...
Filtering raw data in 1 contiguous segment
Setting up band-pass filter from 2 - 20 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 2.00
- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)
- Upper passband edge: 20.00 Hz
- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)
- Filter length: 993 samples (1.653 sec)

320 events found
Event IDs: [ 1  2  3  4  5 32]
Not setting metadata
Not setting metadata
145 matching events found
Setting baseline interval to [-0.19979521315838786, 0.0] sec
Applying baseline correction (mode: mean)
3 projection items activated
Loading data for 145 events and 421 original time points ...
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
22 bad epochs dropped
Removing projector &lt;Projection | PCA-v1, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v2, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v3, active : True, n_channels : 102&gt;
</pre></div>
</div>
</div>
<div class="section" id="transformation-classes">
<h2>Transformation classes<a class="headerlink" href="#transformation-classes" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="scaler">
<h3>Scaler<a class="headerlink" href="#scaler" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.Scaler</span></code></a> will standardize the data based on channel
scales. In the simplest modes <code class="docutils literal notranslate"><span class="pre">scalings=None</span></code> or <code class="docutils literal notranslate"><span class="pre">scalings=dict(...)</span></code>,
each data channel type (e.g., mag, grad, eeg) is treated separately and
scaled by a constant. This is the approach used by e.g.,
<a class="reference internal" href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.compute_covariance()</span></code></a> to standardize channel scales.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">scalings='mean'</span></code> or <code class="docutils literal notranslate"><span class="pre">scalings='median'</span></code>, each channel is scaled using
empirical measures. Each channel is scaled independently by the mean and
standand deviation, or median and interquartile range, respectively, across
all epochs and time points during <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit" title="mne.decoding.Scaler.fit"><code class="xref py py-class docutils literal notranslate"><span class="pre">fit</span></code></a>
(during training). The <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.transform" title="mne.decoding.Scaler.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transform()</span></code></a> method is
called to transform data (training or test set) by scaling all time points
and epochs on a channel-by-channel basis. To perform both the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and
<code class="docutils literal notranslate"><span class="pre">transform</span></code> operations in a single call, the
<a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit_transform" title="mne.decoding.Scaler.fit_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit_transform()</span></code></a> method may be used. To invert the
transform, <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.inverse_transform" title="mne.decoding.Scaler.inverse_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">inverse_transform()</span></code></a> can be used. For
<code class="docutils literal notranslate"><span class="pre">scalings='median'</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> version 0.17+ is required.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using this class is different from directly applying
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code></a> or
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.RobustScaler</span></code></a> offered by
<a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>. These scale each <em>classification feature</em>, e.g.
each time point for each channel, with mean and standard
deviation computed across epochs, whereas
<a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.Scaler</span></code></a> scales each <em>channel</em> using mean and
standard deviation computed across all of its time points
and epochs.</p>
</div>
</div>
<div class="section" id="vectorizer">
<h3>Vectorizer<a class="headerlink" href="#vectorizer" title="Permalink to this headline">Â¶</a></h3>
<p>Scikit-learn API provides functionality to chain transformers and estimators
by using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a>. We can construct decoding
pipelines and perform cross-validation and grid-search. However scikit-learn
transformers and estimators generally expect 2D data
(n_samples * n_features), whereas MNE transformers typically output data
with a higher dimensionality
(e.g. n_samples * n_channels * n_frequencies * n_times). A Vectorizer
therefore needs to be applied between the MNE and the scikit-learn steps
like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uses all MEG sensors and time points as separate classification</span>
<span class="c1"># features, so the resulting filters used are spatio-temporal</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">Scaler</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">),</span>
                    <a href="../../generated/mne.decoding.Vectorizer.html#mne.decoding.Vectorizer" title="mne.decoding.Vectorizer" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">Vectorizer</span></a><span class="p">(),</span>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>

<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="mne.decoding.cross_val_multiscore" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">score</span></a> <span class="o">=</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Spatio-temporal: </span><span class="si">%0.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">score</span></a><span class="p">,))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Spatio-temporal: 99.2%
</pre></div>
</div>
</div>
<div class="section" id="psdestimator">
<h3>PSDEstimator<a class="headerlink" href="#psdestimator" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.PSDEstimator.html#mne.decoding.PSDEstimator" title="mne.decoding.PSDEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.PSDEstimator</span></code></a>
computes the power spectral density (PSD) using the multitaper
method. It takes a 3D array as input, converts it into 2D and computes the
PSD.</p>
</div>
<div class="section" id="filterestimator">
<h3>FilterEstimator<a class="headerlink" href="#filterestimator" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.FilterEstimator.html#mne.decoding.FilterEstimator" title="mne.decoding.FilterEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.FilterEstimator</span></code></a> filters the 3D epochs data.</p>
</div>
</div>
<div class="section" id="spatial-filters">
<h2>Spatial filters<a class="headerlink" href="#spatial-filters" title="Permalink to this headline">Â¶</a></h2>
<p>Just like temporal filters, spatial filters provide weights to modify the
data along the sensor dimension. They are popular in the BCI community
because of their simplicity and ability to distinguish spatially-separated
neural activity.</p>
<div class="section" id="common-spatial-pattern">
<h3>Common spatial pattern<a class="headerlink" href="#common-spatial-pattern" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.CSP</span></code></a> is a technique to analyze multichannel data based
on recordings from two classes <a class="footnote-reference brackets" href="#koles1991" id="id2">2</a> (see also
<a class="reference external" href="https://en.wikipedia.org/wiki/Common_spatial_pattern">https://en.wikipedia.org/wiki/Common_spatial_pattern</a>).</p>
<p>Let <span class="math notranslate nohighlight">\(X \in R^{C\times T}\)</span> be a segment of data with
<span class="math notranslate nohighlight">\(C\)</span> channels and <span class="math notranslate nohighlight">\(T\)</span> time points. The data at a single time point
is denoted by <span class="math notranslate nohighlight">\(x(t)\)</span> such that <span class="math notranslate nohighlight">\(X=[x(t), x(t+1), ..., x(t+T-1)]\)</span>.
Common spatial pattern (CSP) finds a decomposition that projects the signal
in the original sensor space to CSP space using the following transformation:</p>
<div class="math notranslate nohighlight" id="equation-csp">
<span class="eqno">(1)<a class="headerlink" href="#equation-csp" title="Permalink to this equation">Â¶</a></span>\[x_{CSP}(t) = W^{T}x(t)\]</div>
<p>where each column of <span class="math notranslate nohighlight">\(W \in R^{C\times C}\)</span> is a spatial filter and each
row of <span class="math notranslate nohighlight">\(x_{CSP}\)</span> is a CSP component. The matrix <span class="math notranslate nohighlight">\(W\)</span> is also
called the de-mixing matrix in other contexts. Let
<span class="math notranslate nohighlight">\(\Sigma^{+} \in R^{C\times C}\)</span> and <span class="math notranslate nohighlight">\(\Sigma^{-} \in R^{C\times C}\)</span>
be the estimates of the covariance matrices of the two conditions.
CSP analysis is given by the simultaneous diagonalization of the two
covariance matrices</p>
<div class="math notranslate nohighlight" id="equation-diagonalize-p">
<span class="eqno">(2)<a class="headerlink" href="#equation-diagonalize-p" title="Permalink to this equation">Â¶</a></span>\[W^{T}\Sigma^{+}W = \lambda^{+}\]</div>
<div class="math notranslate nohighlight" id="equation-diagonalize-n">
<span class="eqno">(3)<a class="headerlink" href="#equation-diagonalize-n" title="Permalink to this equation">Â¶</a></span>\[W^{T}\Sigma^{-}W = \lambda^{-}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda^{C}\)</span> is a diagonal matrix whose entries are the
eigenvalues of the following generalized eigenvalue problem</p>
<div class="math notranslate nohighlight" id="equation-eigen-problem">
<span class="eqno">(4)<a class="headerlink" href="#equation-eigen-problem" title="Permalink to this equation">Â¶</a></span>\[\Sigma^{+}w = \lambda \Sigma^{-}w\]</div>
<p>Large entries in the diagonal matrix corresponds to a spatial filter which
gives high variance in one class but low variance in the other. Thus, the
filter facilitates discrimination between the two classes.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html#ex-decoding-csp-eeg"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></p></li>
<li><p><a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html#ex-decoding-csp-eeg-timefreq"><span class="std std-ref">Decoding in time-frequency space using Common Spatial Patterns (CSP)</span></a></p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The winning entry of the Grasp-and-lift EEG competition in Kaggle used
the <a class="reference internal" href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP"><code class="xref py py-class docutils literal notranslate"><span class="pre">CSP</span></code></a> implementation in MNE and was featured as
a <a class="reference external" href="http://blog.kaggle.com/2015/08/12/july-2015-scripts-of-the-week/">script of the week</a>.</p>
</div>
<p>We can use CSP with these data with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">csp</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">CSP</span></a><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf_csp</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">csp</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.LinearModel.html#mne.decoding.LinearModel" title="mne.decoding.LinearModel" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">LinearModel</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)))</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="mne.decoding.cross_val_multiscore" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf_csp</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CSP: </span><span class="si">%0.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="o">.</span><span class="n">mean</span><span class="p">(),))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from data with rank=None
    Using tolerance 4.4e-11 (2.2e-16 eps * 203 dim * 9.7e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.3e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.2e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.4e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.4e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.3e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
CSP: 87.0%
</pre></div>
</div>
</div>
<div class="section" id="source-power-comodulation-spoc">
<h3>Source power comodulation (SPoC)<a class="headerlink" href="#source-power-comodulation-spoc" title="Permalink to this headline">Â¶</a></h3>
<p>Source Power Comodulation (<a class="reference internal" href="../../generated/mne.decoding.SPoC.html#mne.decoding.SPoC" title="mne.decoding.SPoC"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.SPoC</span></code></a>)
<a class="footnote-reference brackets" href="#dahneetal2014" id="id3">3</a> identifies the composition of
orthogonal spatial filters that maximally correlate with a continuous target.</p>
<p>SPoC can be seen as an extension of the CSP where the target is driven by a
continuous variable rather than a discrete variable. Typical applications
include extraction of motor patterns using EMG power or audio patterns using
sound envelope.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html#ex-spoc-cmc"><span class="std std-ref">Continuous Target Decoding with SPoC</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="xdawn">
<h3>xDAWN<a class="headerlink" href="#xdawn" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../../generated/mne.preprocessing.Xdawn.html#mne.preprocessing.Xdawn" title="mne.preprocessing.Xdawn"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.preprocessing.Xdawn</span></code></a> is a spatial filtering method designed to
improve the signal to signal + noise ratio (SSNR) of the ERP responses
<a class="footnote-reference brackets" href="#rivetetal2009" id="id4">4</a>. Xdawn was originally
designed for P300 evoked potential by enhancing the target response with
respect to the non-target response. The implementation in MNE-Python is a
generalization to any type of ERP.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html#ex-xdawn-denoising"><span class="std std-ref">XDAWN Denoising</span></a></p></li>
<li><p><a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html#ex-xdawn-decoding"><span class="std std-ref">XDAWN Decoding From EEG data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="effect-matched-spatial-filtering">
<h3>Effect-matched spatial filtering<a class="headerlink" href="#effect-matched-spatial-filtering" title="Permalink to this headline">Â¶</a></h3>
<p>The result of <a class="reference internal" href="../../generated/mne.decoding.EMS.html#mne.decoding.EMS" title="mne.decoding.EMS"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.EMS</span></code></a> is a spatial filter at each time
point and a corresponding time course <a class="footnote-reference brackets" href="#schurgeretal2013" id="id5">5</a>.
Intuitively, the result gives the similarity between the filter at
each time point and the data vector (sensors) at that time point.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html#ex-ems-filtering"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="patterns-vs-filters">
<h3>Patterns vs. filters<a class="headerlink" href="#patterns-vs-filters" title="Permalink to this headline">Â¶</a></h3>
<p>When interpreting the components of the CSP (or spatial filters in general),
it is often more intuitive to think about how <span class="math notranslate nohighlight">\(x(t)\)</span> is composed of
the different CSP components <span class="math notranslate nohighlight">\(x_{CSP}(t)\)</span>. In other words, we can
rewrite Equation <a class="reference internal" href="#equation-csp">(1)</a> as follows:</p>
<div class="math notranslate nohighlight" id="equation-patterns">
<span class="eqno">(5)<a class="headerlink" href="#equation-patterns" title="Permalink to this equation">Â¶</a></span>\[x(t) = (W^{-1})^{T}x_{CSP}(t)\]</div>
<p>The columns of the matrix <span class="math notranslate nohighlight">\((W^{-1})^T\)</span> are called spatial patterns.
This is also called the mixing matrix. The example <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html#ex-linear-patterns"><span class="std std-ref">Linear classifier on sensor data with plot patterns and filters</span></a>
discusses the difference between patterns and filters.</p>
<p>These can be plotted with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit CSP on full data and plot</span>
<a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP.fit" title="mne.decoding.CSP.fit" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">csp</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">)</span>
<a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP.plot_patterns" title="mne.decoding.CSP.plot_patterns" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">csp</span><span class="o">.</span><span class="n">plot_patterns</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
<a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP.plot_filters" title="mne.decoding.CSP.plot_filters" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">csp</span><span class="o">.</span><span class="n">plot_filters</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> <span class="n">scalings</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="CSP0, CSP1, CSP2, a.u." class="sphx-glr-multi-img" src="../../_images/sphx_glr_50_decoding_001.png" />
</li>
<li><img alt="CSP0, CSP1, CSP2, a.u." class="sphx-glr-multi-img" src="../../_images/sphx_glr_50_decoding_002.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from data with rank=None
    Using tolerance 4.8e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing rank from data with rank=None
    Using tolerance 5.7e-11 (2.2e-16 eps * 203 dim * 1.3e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
</pre></div>
</div>
</div>
</div>
<div class="section" id="decoding-over-time">
<h2>Decoding over time<a class="headerlink" href="#decoding-over-time" title="Permalink to this headline">Â¶</a></h2>
<p>This strategy consists in fitting a multivariate predictive model on each
time instant and evaluating its performance at the same instant on new
epochs. The <a class="reference internal" href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.SlidingEstimator</span></code></a> will take as input a
pair of features <span class="math notranslate nohighlight">\(X\)</span> and targets <span class="math notranslate nohighlight">\(y\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> has
more than 2 dimensions. For decoding over time the data <span class="math notranslate nohighlight">\(X\)</span>
is the epochs data of shape n_epochs x n_channels x n_times. As the
last dimension of <span class="math notranslate nohighlight">\(X\)</span> is the time, an estimator will be fit
on every time instant.</p>
<p>This approach is analogous to SlidingEstimator-based approaches in fMRI,
where here we are interested in when one can discriminate experimental
conditions and therefore figure out when the effect of interest happens.</p>
<p>When working with linear models as estimators, this approach boils
down to estimating a discriminative spatial filter for each time instant.</p>
<div class="section" id="temporal-decoding">
<h3>Temporal decoding<a class="headerlink" href="#temporal-decoding" title="Permalink to this headline">Â¶</a></h3>
<p>Weâ€™ll use a Logistic Regression for a binary classification as machine
learning model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We will train the classifier on all left visual vs auditory trials on MEG</span>

<a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a><span class="p">(),</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>

<a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_decod</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">SlidingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="mne.decoding.cross_val_multiscore" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_decod</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot</span>
<a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;score&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Times&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;AUC&#39;</span><span class="p">)</span>  <span class="c1"># Area Under the Curve</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.legend.html#matplotlib.axes.Axes.legend" title="matplotlib.axes.Axes.legend" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">legend</span></a><span class="p">()</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Sensor space decoding&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Sensor space decoding" class="sphx-glr-single-img" src="../../_images/sphx_glr_50_decoding_003.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  5%|4         | Fitting SlidingEstimator : 2/43 [00:00&lt;00:00,   58.61it/s]
  7%|6         | Fitting SlidingEstimator : 3/43 [00:00&lt;00:01,   31.51it/s]
 12%|#1        | Fitting SlidingEstimator : 5/43 [00:00&lt;00:00,   39.19it/s]
 16%|#6        | Fitting SlidingEstimator : 7/43 [00:00&lt;00:01,   35.93it/s]
 21%|##        | Fitting SlidingEstimator : 9/43 [00:00&lt;00:00,   39.21it/s]
 23%|##3       | Fitting SlidingEstimator : 10/43 [00:00&lt;00:00,   33.53it/s]
 30%|###       | Fitting SlidingEstimator : 13/43 [00:00&lt;00:00,   39.14it/s]
 33%|###2      | Fitting SlidingEstimator : 14/43 [00:00&lt;00:00,   35.22it/s]
 42%|####1     | Fitting SlidingEstimator : 18/43 [00:00&lt;00:00,   42.79it/s]
 44%|####4     | Fitting SlidingEstimator : 19/43 [00:00&lt;00:00,   38.59it/s]
 56%|#####5    | Fitting SlidingEstimator : 24/43 [00:00&lt;00:00,   47.01it/s]
 58%|#####8    | Fitting SlidingEstimator : 25/43 [00:00&lt;00:00,   42.87it/s]
 65%|######5   | Fitting SlidingEstimator : 28/43 [00:00&lt;00:00,   45.54it/s]
 67%|######7   | Fitting SlidingEstimator : 29/43 [00:00&lt;00:00,   42.19it/s]
 74%|#######4  | Fitting SlidingEstimator : 32/43 [00:00&lt;00:00,   44.82it/s]
 77%|#######6  | Fitting SlidingEstimator : 33/43 [00:00&lt;00:00,   41.68it/s]
 86%|########6 | Fitting SlidingEstimator : 37/43 [00:00&lt;00:00,   46.16it/s]
 88%|########8 | Fitting SlidingEstimator : 38/43 [00:00&lt;00:00,   42.84it/s]
 95%|#########5| Fitting SlidingEstimator : 41/43 [00:00&lt;00:00,   45.40it/s]
 98%|#########7| Fitting SlidingEstimator : 42/43 [00:00&lt;00:00,   42.28it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:01&lt;00:00,   42.98it/s]

  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  7%|6         | Fitting SlidingEstimator : 3/43 [00:00&lt;00:00,   82.85it/s]
 16%|#6        | Fitting SlidingEstimator : 7/43 [00:00&lt;00:00,   58.39it/s]
 23%|##3       | Fitting SlidingEstimator : 10/43 [00:00&lt;00:00,   46.68it/s]
 26%|##5       | Fitting SlidingEstimator : 11/43 [00:00&lt;00:00,   38.60it/s]
 33%|###2      | Fitting SlidingEstimator : 14/43 [00:00&lt;00:00,   44.62it/s]
 35%|###4      | Fitting SlidingEstimator : 15/43 [00:00&lt;00:00,   38.77it/s]
 44%|####4     | Fitting SlidingEstimator : 19/43 [00:00&lt;00:00,   46.45it/s]
 47%|####6     | Fitting SlidingEstimator : 20/43 [00:00&lt;00:00,   41.24it/s]
 58%|#####8    | Fitting SlidingEstimator : 25/43 [00:00&lt;00:00,   49.73it/s]
 60%|######    | Fitting SlidingEstimator : 26/43 [00:00&lt;00:00,   44.95it/s]
 67%|######7   | Fitting SlidingEstimator : 29/43 [00:00&lt;00:00,   47.17it/s]
 70%|######9   | Fitting SlidingEstimator : 30/43 [00:00&lt;00:00,   43.89it/s]
 74%|#######4  | Fitting SlidingEstimator : 32/43 [00:00&lt;00:00,   44.88it/s]
 84%|########3 | Fitting SlidingEstimator : 36/43 [00:00&lt;00:00,   44.07it/s]
 86%|########6 | Fitting SlidingEstimator : 37/43 [00:00&lt;00:00,   40.96it/s]
 93%|#########3| Fitting SlidingEstimator : 40/43 [00:00&lt;00:00,   43.51it/s]
 95%|#########5| Fitting SlidingEstimator : 41/43 [00:00&lt;00:00,   40.74it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:00&lt;00:00,   42.62it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:00&lt;00:00,   43.12it/s]

  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  7%|6         | Fitting SlidingEstimator : 3/43 [00:00&lt;00:00,   82.28it/s]
 14%|#3        | Fitting SlidingEstimator : 6/43 [00:00&lt;00:00,   54.66it/s]
 16%|#6        | Fitting SlidingEstimator : 7/43 [00:00&lt;00:00,   39.54it/s]
 23%|##3       | Fitting SlidingEstimator : 10/43 [00:00&lt;00:00,   47.60it/s]
 33%|###2      | Fitting SlidingEstimator : 14/43 [00:00&lt;00:00,   44.67it/s]
 42%|####1     | Fitting SlidingEstimator : 18/43 [00:00&lt;00:00,   43.90it/s]
 47%|####6     | Fitting SlidingEstimator : 20/43 [00:00&lt;00:00,   41.73it/s]
 56%|#####5    | Fitting SlidingEstimator : 24/43 [00:00&lt;00:00,   47.73it/s]
 58%|#####8    | Fitting SlidingEstimator : 25/43 [00:00&lt;00:00,   43.21it/s]
 65%|######5   | Fitting SlidingEstimator : 28/43 [00:00&lt;00:00,   46.11it/s]
 70%|######9   | Fitting SlidingEstimator : 30/43 [00:00&lt;00:00,   44.37it/s]
 77%|#######6  | Fitting SlidingEstimator : 33/43 [00:00&lt;00:00,   47.17it/s]
 79%|#######9  | Fitting SlidingEstimator : 34/43 [00:00&lt;00:00,   43.48it/s]
 88%|########8 | Fitting SlidingEstimator : 38/43 [00:00&lt;00:00,   47.18it/s]
 98%|#########7| Fitting SlidingEstimator : 42/43 [00:00&lt;00:00,   46.48it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:00&lt;00:00,   46.71it/s]

  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  2%|2         | Fitting SlidingEstimator : 1/43 [00:00&lt;00:01,   29.56it/s]
  5%|4         | Fitting SlidingEstimator : 2/43 [00:00&lt;00:01,   28.36it/s]
  9%|9         | Fitting SlidingEstimator : 4/43 [00:00&lt;00:01,   38.14it/s]
 12%|#1        | Fitting SlidingEstimator : 5/43 [00:00&lt;00:01,   31.61it/s]
 16%|#6        | Fitting SlidingEstimator : 7/43 [00:00&lt;00:00,   36.48it/s]
 19%|#8        | Fitting SlidingEstimator : 8/43 [00:00&lt;00:01,   30.73it/s]
 28%|##7       | Fitting SlidingEstimator : 12/43 [00:00&lt;00:00,   41.70it/s]
 30%|###       | Fitting SlidingEstimator : 13/43 [00:00&lt;00:00,   36.55it/s]
 35%|###4      | Fitting SlidingEstimator : 15/43 [00:00&lt;00:00,   38.83it/s]
 40%|###9      | Fitting SlidingEstimator : 17/43 [00:00&lt;00:00,   37.37it/s]
 51%|#####1    | Fitting SlidingEstimator : 22/43 [00:00&lt;00:00,   46.50it/s]
 53%|#####3    | Fitting SlidingEstimator : 23/43 [00:00&lt;00:00,   42.15it/s]
 60%|######    | Fitting SlidingEstimator : 26/43 [00:00&lt;00:00,   45.55it/s]
 65%|######5   | Fitting SlidingEstimator : 28/43 [00:00&lt;00:00,   43.59it/s]
 74%|#######4  | Fitting SlidingEstimator : 32/43 [00:00&lt;00:00,   47.99it/s]
 81%|########1 | Fitting SlidingEstimator : 35/43 [00:00&lt;00:00,   45.11it/s]
 84%|########3 | Fitting SlidingEstimator : 36/43 [00:00&lt;00:00,   42.16it/s]
 91%|######### | Fitting SlidingEstimator : 39/43 [00:00&lt;00:00,   44.42it/s]
 93%|#########3| Fitting SlidingEstimator : 40/43 [00:00&lt;00:00,   41.72it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:00&lt;00:00,   44.53it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:00&lt;00:00,   43.60it/s]

  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  5%|4         | Fitting SlidingEstimator : 2/43 [00:00&lt;00:01,   26.96it/s]
 12%|#1        | Fitting SlidingEstimator : 5/43 [00:00&lt;00:00,   46.94it/s]
 14%|#3        | Fitting SlidingEstimator : 6/43 [00:00&lt;00:01,   34.22it/s]
 21%|##        | Fitting SlidingEstimator : 9/43 [00:00&lt;00:00,   43.77it/s]
 23%|##3       | Fitting SlidingEstimator : 10/43 [00:00&lt;00:00,   36.19it/s]
 30%|###       | Fitting SlidingEstimator : 13/43 [00:00&lt;00:00,   42.79it/s]
 33%|###2      | Fitting SlidingEstimator : 14/43 [00:00&lt;00:00,   37.10it/s]
 40%|###9      | Fitting SlidingEstimator : 17/43 [00:00&lt;00:00,   42.17it/s]
 44%|####4     | Fitting SlidingEstimator : 19/43 [00:00&lt;00:00,   40.20it/s]
 56%|#####5    | Fitting SlidingEstimator : 24/43 [00:00&lt;00:00,   48.24it/s]
 63%|######2   | Fitting SlidingEstimator : 27/43 [00:00&lt;00:00,   45.12it/s]
 67%|######7   | Fitting SlidingEstimator : 29/43 [00:00&lt;00:00,   40.68it/s]
 72%|#######2  | Fitting SlidingEstimator : 31/43 [00:00&lt;00:00,   39.59it/s]
 77%|#######6  | Fitting SlidingEstimator : 33/43 [00:00&lt;00:00,   40.67it/s]
 79%|#######9  | Fitting SlidingEstimator : 34/43 [00:00&lt;00:00,   38.04it/s]
 86%|########6 | Fitting SlidingEstimator : 37/43 [00:00&lt;00:00,   40.59it/s]
 88%|########8 | Fitting SlidingEstimator : 38/43 [00:00&lt;00:00,   38.21it/s]
 98%|#########7| Fitting SlidingEstimator : 42/43 [00:01&lt;00:00,   41.70it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:01&lt;00:00,   39.18it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:01&lt;00:00,   39.66it/s]
</pre></div>
</div>
<p>You can retrieve the spatial filters and spatial patterns if you explicitly
use a LinearModel</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a><span class="p">(),</span>
                    <a href="../../generated/mne.decoding.LinearModel.html#mne.decoding.LinearModel" title="mne.decoding.LinearModel" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">LinearModel</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)))</span>
<a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_decod</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">SlidingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator.fit" title="mne.decoding.SlidingEstimator.fit" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_decod</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">)</span>

<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">coef</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.get_coef.html#mne.decoding.get_coef" title="mne.decoding.get_coef" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">get_coef</span></a><span class="p">(</span><a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_decod</span></a><span class="p">,</span> <span class="s1">&#39;patterns_&#39;</span><span class="p">,</span> <span class="n">inverse_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked_time_gen</span></a> <span class="o">=</span> <a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">EvokedArray</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">coef</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">joint_kwargs</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">ts_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">),</span>
                    <span class="n">topomap_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">))</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_joint" title="mne.EvokedArray.plot_joint" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">evoked_time_gen</span><span class="o">.</span><span class="n">plot_joint</span></a><span class="p">(</span><span class="n">times</span><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="o">.</span><span class="mi">500</span><span class="p">,</span> <span class="o">.</span><span class="mi">100</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;patterns&#39;</span><span class="p">,</span>
                           <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">joint_kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="0.000 s, 0.100 s, 0.200 s, 0.300 s, 0.400 s" class="sphx-glr-single-img" src="../../_images/sphx_glr_50_decoding_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting SlidingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  2%|2         | Fitting SlidingEstimator : 1/43 [00:00&lt;00:01,   28.10it/s]
  7%|6         | Fitting SlidingEstimator : 3/43 [00:00&lt;00:00,   40.86it/s]
  9%|9         | Fitting SlidingEstimator : 4/43 [00:00&lt;00:01,   29.19it/s]
 14%|#3        | Fitting SlidingEstimator : 6/43 [00:00&lt;00:01,   35.59it/s]
 19%|#8        | Fitting SlidingEstimator : 8/43 [00:00&lt;00:01,   29.21it/s]
 21%|##        | Fitting SlidingEstimator : 9/43 [00:00&lt;00:01,   26.26it/s]
 26%|##5       | Fitting SlidingEstimator : 11/43 [00:00&lt;00:01,   29.69it/s]
 28%|##7       | Fitting SlidingEstimator : 12/43 [00:00&lt;00:01,   27.10it/s]
 33%|###2      | Fitting SlidingEstimator : 14/43 [00:00&lt;00:00,   29.88it/s]
 37%|###7      | Fitting SlidingEstimator : 16/43 [00:00&lt;00:00,   29.96it/s]
 44%|####4     | Fitting SlidingEstimator : 19/43 [00:00&lt;00:00,   34.16it/s]
 47%|####6     | Fitting SlidingEstimator : 20/43 [00:00&lt;00:00,   31.82it/s]
 56%|#####5    | Fitting SlidingEstimator : 24/43 [00:00&lt;00:00,   37.31it/s]
 58%|#####8    | Fitting SlidingEstimator : 25/43 [00:00&lt;00:00,   34.93it/s]
 63%|######2   | Fitting SlidingEstimator : 27/43 [00:00&lt;00:00,   36.20it/s]
 65%|######5   | Fitting SlidingEstimator : 28/43 [00:00&lt;00:00,   34.03it/s]
 70%|######9   | Fitting SlidingEstimator : 30/43 [00:00&lt;00:00,   35.40it/s]
 74%|#######4  | Fitting SlidingEstimator : 32/43 [00:00&lt;00:00,   33.15it/s]
 79%|#######9  | Fitting SlidingEstimator : 34/43 [00:01&lt;00:00,   31.33it/s]
 81%|########1 | Fitting SlidingEstimator : 35/43 [00:01&lt;00:00,   29.85it/s]
 84%|########3 | Fitting SlidingEstimator : 36/43 [00:01&lt;00:00,   29.62it/s]
 86%|########6 | Fitting SlidingEstimator : 37/43 [00:01&lt;00:00,   28.66it/s]
 91%|######### | Fitting SlidingEstimator : 39/43 [00:01&lt;00:00,   29.92it/s]
 93%|#########3| Fitting SlidingEstimator : 40/43 [00:01&lt;00:00,   28.76it/s]
 98%|#########7| Fitting SlidingEstimator : 42/43 [00:01&lt;00:00,   29.89it/s]
100%|##########| Fitting SlidingEstimator : 43/43 [00:01&lt;00:00,   31.28it/s]
No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
</div>
<div class="section" id="temporal-generalization">
<h3>Temporal generalization<a class="headerlink" href="#temporal-generalization" title="Permalink to this headline">Â¶</a></h3>
<p>Temporal generalization is an extension of the decoding over time approach.
It consists in evaluating whether the model estimated at a particular
time instant accurately predicts any other time instant. It is analogous to
transferring a trained model to a distinct learning problem, where the
problems correspond to decoding the patterns of brain activity recorded at
distinct time instants.</p>
<p>The object to for Temporal generalization is
<a class="reference internal" href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.GeneralizingEstimator</span></code></a>. It expects as input <span class="math notranslate nohighlight">\(X\)</span>
and <span class="math notranslate nohighlight">\(y\)</span> (similarly to <a class="reference internal" href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">SlidingEstimator</span></code></a>) but
generates predictions from each model for all time instants. The class
<a class="reference internal" href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">GeneralizingEstimator</span></code></a> is generic and will treat the
last dimension as the one to be used for generalization testing. For
convenience, here, we refer to it as different tasks. If <span class="math notranslate nohighlight">\(X\)</span>
corresponds to epochs data then the last dimension is time.</p>
<p>This runs the analysis used in <a class="footnote-reference brackets" href="#kingetal2014" id="id6">6</a> and further detailed
in <a class="footnote-reference brackets" href="#kingdehaene2014" id="id7">7</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the Temporal generalization object</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_gen</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="mne.decoding.cross_val_multiscore" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-function"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_gen</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">X</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot the diagonal (it&#39;s exactly the same as the time-by-time decoding above)</span>
<a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.diag.html#numpy.diag" title="numpy.diag" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">diag</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;score&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Times&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;AUC&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.legend.html#matplotlib.axes.Axes.legend" title="matplotlib.axes.Axes.legend" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">legend</span></a><span class="p">()</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Decoding MEG sensors over time&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Decoding MEG sensors over time" class="sphx-glr-single-img" src="../../_images/sphx_glr_50_decoding_005.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting GeneralizingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  2%|2         | Fitting GeneralizingEstimator : 1/43 [00:00&lt;00:03,   13.68it/s]
  7%|6         | Fitting GeneralizingEstimator : 3/43 [00:00&lt;00:01,   25.99it/s]
  9%|9         | Fitting GeneralizingEstimator : 4/43 [00:00&lt;00:01,   23.80it/s]
 12%|#1        | Fitting GeneralizingEstimator : 5/43 [00:00&lt;00:01,   24.66it/s]
 14%|#3        | Fitting GeneralizingEstimator : 6/43 [00:00&lt;00:01,   22.20it/s]
 19%|#8        | Fitting GeneralizingEstimator : 8/43 [00:00&lt;00:01,   26.31it/s]
 21%|##        | Fitting GeneralizingEstimator : 9/43 [00:00&lt;00:01,   24.47it/s]
 26%|##5       | Fitting GeneralizingEstimator : 11/43 [00:00&lt;00:01,   27.27it/s]
 28%|##7       | Fitting GeneralizingEstimator : 12/43 [00:00&lt;00:01,   25.80it/s]
 33%|###2      | Fitting GeneralizingEstimator : 14/43 [00:00&lt;00:01,   28.51it/s]
 37%|###7      | Fitting GeneralizingEstimator : 16/43 [00:00&lt;00:00,   28.87it/s]
 44%|####4     | Fitting GeneralizingEstimator : 19/43 [00:00&lt;00:00,   33.31it/s]
 49%|####8     | Fitting GeneralizingEstimator : 21/43 [00:00&lt;00:00,   32.90it/s]
 56%|#####5    | Fitting GeneralizingEstimator : 24/43 [00:00&lt;00:00,   36.07it/s]
 58%|#####8    | Fitting GeneralizingEstimator : 25/43 [00:00&lt;00:00,   34.05it/s]
 65%|######5   | Fitting GeneralizingEstimator : 28/43 [00:00&lt;00:00,   37.33it/s]
 67%|######7   | Fitting GeneralizingEstimator : 29/43 [00:00&lt;00:00,   34.89it/s]
 72%|#######2  | Fitting GeneralizingEstimator : 31/43 [00:00&lt;00:00,   36.00it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 32/43 [00:00&lt;00:00,   34.07it/s]
 79%|#######9  | Fitting GeneralizingEstimator : 34/43 [00:01&lt;00:00,   34.99it/s]
 81%|########1 | Fitting GeneralizingEstimator : 35/43 [00:01&lt;00:00,   33.42it/s]
 86%|########6 | Fitting GeneralizingEstimator : 37/43 [00:01&lt;00:00,   34.71it/s]
 93%|#########3| Fitting GeneralizingEstimator : 40/43 [00:01&lt;00:00,   33.74it/s]
 95%|#########5| Fitting GeneralizingEstimator : 41/43 [00:01&lt;00:00,   32.23it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   33.39it/s]

  0%|          | Scoring GeneralizingEstimator : 0/1849 [00:00&lt;?,       ?it/s]
  1%|          | Scoring GeneralizingEstimator : 10/1849 [00:00&lt;00:11,  166.73it/s]
  2%|1         | Scoring GeneralizingEstimator : 32/1849 [00:00&lt;00:05,  343.84it/s]
  3%|2         | Scoring GeneralizingEstimator : 54/1849 [00:00&lt;00:04,  428.21it/s]
  5%|4         | Scoring GeneralizingEstimator : 91/1849 [00:00&lt;00:03,  578.86it/s]
  7%|6         | Scoring GeneralizingEstimator : 128/1849 [00:00&lt;00:02,  677.07it/s]
  9%|8         | Scoring GeneralizingEstimator : 165/1849 [00:00&lt;00:02,  746.80it/s]
 11%|#         | Scoring GeneralizingEstimator : 197/1849 [00:00&lt;00:02,  775.82it/s]
 13%|#2        | Scoring GeneralizingEstimator : 234/1849 [00:00&lt;00:01,  818.02it/s]
 15%|#4        | Scoring GeneralizingEstimator : 272/1849 [00:00&lt;00:01,  856.20it/s]
 17%|#6        | Scoring GeneralizingEstimator : 309/1849 [00:00&lt;00:01,  883.13it/s]
 19%|#8        | Scoring GeneralizingEstimator : 346/1849 [00:00&lt;00:01,  905.54it/s]
 21%|##        | Scoring GeneralizingEstimator : 383/1849 [00:00&lt;00:01,  924.74it/s]
 23%|##2       | Scoring GeneralizingEstimator : 421/1849 [00:00&lt;00:01,  943.94it/s]
 25%|##4       | Scoring GeneralizingEstimator : 457/1849 [00:00&lt;00:01,  954.95it/s]
 26%|##6       | Scoring GeneralizingEstimator : 482/1849 [00:00&lt;00:01,  935.40it/s]
 27%|##7       | Scoring GeneralizingEstimator : 503/1849 [00:00&lt;00:01,  908.49it/s]
 28%|##8       | Scoring GeneralizingEstimator : 526/1849 [00:00&lt;00:01,  889.47it/s]
 30%|###       | Scoring GeneralizingEstimator : 557/1849 [00:00&lt;00:01,  890.08it/s]
 32%|###1      | Scoring GeneralizingEstimator : 588/1849 [00:00&lt;00:01,  891.88it/s]
 33%|###3      | Scoring GeneralizingEstimator : 619/1849 [00:00&lt;00:01,  893.38it/s]
 35%|###5      | Scoring GeneralizingEstimator : 654/1849 [00:00&lt;00:01,  903.46it/s]
 37%|###7      | Scoring GeneralizingEstimator : 691/1849 [00:00&lt;00:01,  916.75it/s]
 39%|###9      | Scoring GeneralizingEstimator : 726/1849 [00:00&lt;00:01,  923.67it/s]
 41%|####1     | Scoring GeneralizingEstimator : 759/1849 [00:00&lt;00:01,  926.82it/s]
 43%|####3     | Scoring GeneralizingEstimator : 796/1849 [00:00&lt;00:01,  937.61it/s]
 45%|####4     | Scoring GeneralizingEstimator : 830/1849 [00:00&lt;00:01,  941.16it/s]
 47%|####6     | Scoring GeneralizingEstimator : 868/1849 [00:00&lt;00:01,  953.08it/s]
 49%|####8     | Scoring GeneralizingEstimator : 905/1849 [00:00&lt;00:00,  961.29it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 943/1849 [00:01&lt;00:00,  971.19it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 980/1849 [00:01&lt;00:00,  978.24it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 1018/1849 [00:01&lt;00:00,  987.28it/s]
 57%|#####7    | Scoring GeneralizingEstimator : 1054/1849 [00:01&lt;00:00,  990.94it/s]
 59%|#####9    | Scoring GeneralizingEstimator : 1094/1849 [00:01&lt;00:00,  997.25it/s]
 61%|######1   | Scoring GeneralizingEstimator : 1132/1849 [00:01&lt;00:00, 1004.70it/s]
 63%|######3   | Scoring GeneralizingEstimator : 1170/1849 [00:01&lt;00:00, 1011.63it/s]
 65%|######5   | Scoring GeneralizingEstimator : 1207/1849 [00:01&lt;00:00, 1015.45it/s]
 67%|######7   | Scoring GeneralizingEstimator : 1244/1849 [00:01&lt;00:00, 1018.93it/s]
 69%|######9   | Scoring GeneralizingEstimator : 1282/1849 [00:01&lt;00:00, 1025.01it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 1316/1849 [00:01&lt;00:00, 1023.72it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 1350/1849 [00:01&lt;00:00, 1022.70it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 1388/1849 [00:01&lt;00:00, 1028.33it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 1426/1849 [00:01&lt;00:00, 1033.03it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 1464/1849 [00:01&lt;00:00, 1038.14it/s]
 81%|########1 | Scoring GeneralizingEstimator : 1502/1849 [00:01&lt;00:00, 1042.43it/s]
 83%|########3 | Scoring GeneralizingEstimator : 1540/1849 [00:01&lt;00:00, 1046.78it/s]
 85%|########5 | Scoring GeneralizingEstimator : 1578/1849 [00:01&lt;00:00, 1050.91it/s]
 87%|########7 | Scoring GeneralizingEstimator : 1616/1849 [00:01&lt;00:00, 1054.59it/s]
 89%|########9 | Scoring GeneralizingEstimator : 1654/1849 [00:01&lt;00:00, 1057.86it/s]
 91%|#########1| Scoring GeneralizingEstimator : 1691/1849 [00:01&lt;00:00, 1059.78it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1729/1849 [00:01&lt;00:00, 1062.81it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1766/1849 [00:01&lt;00:00, 1064.39it/s]
 98%|#########7| Scoring GeneralizingEstimator : 1803/1849 [00:01&lt;00:00, 1065.34it/s]
100%|#########9| Scoring GeneralizingEstimator : 1841/1849 [00:01&lt;00:00, 1068.12it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1004.62it/s]

  0%|          | Fitting GeneralizingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  5%|4         | Fitting GeneralizingEstimator : 2/43 [00:00&lt;00:00,   52.29it/s]
  7%|6         | Fitting GeneralizingEstimator : 3/43 [00:00&lt;00:01,   33.48it/s]
 14%|#3        | Fitting GeneralizingEstimator : 6/43 [00:00&lt;00:00,   49.57it/s]
 16%|#6        | Fitting GeneralizingEstimator : 7/43 [00:00&lt;00:00,   36.64it/s]
 21%|##        | Fitting GeneralizingEstimator : 9/43 [00:00&lt;00:00,   39.40it/s]
 23%|##3       | Fitting GeneralizingEstimator : 10/43 [00:00&lt;00:00,   33.94it/s]
 30%|###       | Fitting GeneralizingEstimator : 13/43 [00:00&lt;00:00,   40.59it/s]
 33%|###2      | Fitting GeneralizingEstimator : 14/43 [00:00&lt;00:00,   35.50it/s]
 40%|###9      | Fitting GeneralizingEstimator : 17/43 [00:00&lt;00:00,   40.17it/s]
 44%|####4     | Fitting GeneralizingEstimator : 19/43 [00:00&lt;00:00,   38.96it/s]
 51%|#####1    | Fitting GeneralizingEstimator : 22/43 [00:00&lt;00:00,   43.05it/s]
 56%|#####5    | Fitting GeneralizingEstimator : 24/43 [00:00&lt;00:00,   41.19it/s]
 63%|######2   | Fitting GeneralizingEstimator : 27/43 [00:00&lt;00:00,   44.16it/s]
 65%|######5   | Fitting GeneralizingEstimator : 28/43 [00:00&lt;00:00,   40.82it/s]
 72%|#######2  | Fitting GeneralizingEstimator : 31/43 [00:00&lt;00:00,   43.56it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 32/43 [00:00&lt;00:00,   40.54it/s]
 81%|########1 | Fitting GeneralizingEstimator : 35/43 [00:00&lt;00:00,   43.29it/s]
 86%|########6 | Fitting GeneralizingEstimator : 37/43 [00:00&lt;00:00,   41.99it/s]
 91%|######### | Fitting GeneralizingEstimator : 39/43 [00:00&lt;00:00,   42.93it/s]
 93%|#########3| Fitting GeneralizingEstimator : 40/43 [00:00&lt;00:00,   42.18it/s]
 95%|#########5| Fitting GeneralizingEstimator : 41/43 [00:00&lt;00:00,   41.48it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   43.29it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   42.46it/s]

  0%|          | Scoring GeneralizingEstimator : 0/1849 [00:00&lt;?,       ?it/s]
  1%|1         | Scoring GeneralizingEstimator : 19/1849 [00:00&lt;00:06,  300.73it/s]
  3%|2         | Scoring GeneralizingEstimator : 55/1849 [00:00&lt;00:03,  572.51it/s]
  5%|5         | Scoring GeneralizingEstimator : 93/1849 [00:00&lt;00:02,  722.45it/s]
  7%|7         | Scoring GeneralizingEstimator : 131/1849 [00:00&lt;00:02,  810.50it/s]
  9%|9         | Scoring GeneralizingEstimator : 169/1849 [00:00&lt;00:01,  869.55it/s]
 11%|#1        | Scoring GeneralizingEstimator : 207/1849 [00:00&lt;00:01,  911.48it/s]
 13%|#3        | Scoring GeneralizingEstimator : 245/1849 [00:00&lt;00:01,  942.56it/s]
 15%|#5        | Scoring GeneralizingEstimator : 284/1849 [00:00&lt;00:01,  969.88it/s]
 17%|#7        | Scoring GeneralizingEstimator : 322/1849 [00:00&lt;00:01,  988.74it/s]
 19%|#9        | Scoring GeneralizingEstimator : 360/1849 [00:00&lt;00:01, 1003.57it/s]
 21%|##1       | Scoring GeneralizingEstimator : 397/1849 [00:00&lt;00:01, 1012.99it/s]
 24%|##3       | Scoring GeneralizingEstimator : 435/1849 [00:00&lt;00:01, 1023.49it/s]
 26%|##5       | Scoring GeneralizingEstimator : 473/1849 [00:00&lt;00:01, 1033.00it/s]
 28%|##7       | Scoring GeneralizingEstimator : 511/1849 [00:00&lt;00:01, 1040.98it/s]
 30%|##9       | Scoring GeneralizingEstimator : 550/1849 [00:00&lt;00:01, 1050.27it/s]
 32%|###1      | Scoring GeneralizingEstimator : 588/1849 [00:00&lt;00:01, 1056.39it/s]
 34%|###3      | Scoring GeneralizingEstimator : 626/1849 [00:00&lt;00:01, 1061.58it/s]
 36%|###5      | Scoring GeneralizingEstimator : 664/1849 [00:00&lt;00:01, 1066.42it/s]
 38%|###7      | Scoring GeneralizingEstimator : 701/1849 [00:00&lt;00:01, 1068.67it/s]
 40%|###9      | Scoring GeneralizingEstimator : 739/1849 [00:00&lt;00:01, 1071.48it/s]
 42%|####2     | Scoring GeneralizingEstimator : 777/1849 [00:00&lt;00:00, 1075.35it/s]
 44%|####4     | Scoring GeneralizingEstimator : 815/1849 [00:00&lt;00:00, 1078.75it/s]
 46%|####6     | Scoring GeneralizingEstimator : 853/1849 [00:00&lt;00:00, 1082.06it/s]
 48%|####8     | Scoring GeneralizingEstimator : 891/1849 [00:00&lt;00:00, 1084.78it/s]
 50%|#####     | Scoring GeneralizingEstimator : 928/1849 [00:00&lt;00:00, 1084.72it/s]
 52%|#####2    | Scoring GeneralizingEstimator : 965/1849 [00:00&lt;00:00, 1085.21it/s]
 54%|#####4    | Scoring GeneralizingEstimator : 1003/1849 [00:00&lt;00:00, 1087.49it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 1041/1849 [00:00&lt;00:00, 1089.25it/s]
 58%|#####8    | Scoring GeneralizingEstimator : 1079/1849 [00:01&lt;00:00, 1091.03it/s]
 60%|######    | Scoring GeneralizingEstimator : 1117/1849 [00:01&lt;00:00, 1092.87it/s]
 62%|######2   | Scoring GeneralizingEstimator : 1154/1849 [00:01&lt;00:00, 1092.80it/s]
 64%|######4   | Scoring GeneralizingEstimator : 1190/1849 [00:01&lt;00:00, 1090.66it/s]
 66%|######6   | Scoring GeneralizingEstimator : 1227/1849 [00:01&lt;00:00, 1090.46it/s]
 68%|######7   | Scoring GeneralizingEstimator : 1256/1849 [00:01&lt;00:00, 1076.23it/s]
 70%|######9   | Scoring GeneralizingEstimator : 1287/1849 [00:01&lt;00:00, 1066.86it/s]
 72%|#######1  | Scoring GeneralizingEstimator : 1325/1849 [00:01&lt;00:00, 1069.84it/s]
 74%|#######3  | Scoring GeneralizingEstimator : 1362/1849 [00:01&lt;00:00, 1070.55it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 1390/1849 [00:01&lt;00:00, 1056.75it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 1428/1849 [00:01&lt;00:00, 1059.96it/s]
 79%|#######8  | Scoring GeneralizingEstimator : 1457/1849 [00:01&lt;00:00, 1048.22it/s]
 81%|########  | Scoring GeneralizingEstimator : 1494/1849 [00:01&lt;00:00, 1050.63it/s]
 83%|########2 | Scoring GeneralizingEstimator : 1532/1849 [00:01&lt;00:00, 1054.77it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1570/1849 [00:01&lt;00:00, 1058.26it/s]
 87%|########6 | Scoring GeneralizingEstimator : 1608/1849 [00:01&lt;00:00, 1061.86it/s]
 89%|########8 | Scoring GeneralizingEstimator : 1645/1849 [00:01&lt;00:00, 1063.37it/s]
 91%|######### | Scoring GeneralizingEstimator : 1682/1849 [00:01&lt;00:00, 1065.15it/s]
 93%|#########3| Scoring GeneralizingEstimator : 1720/1849 [00:01&lt;00:00, 1067.47it/s]
 95%|#########4| Scoring GeneralizingEstimator : 1756/1849 [00:01&lt;00:00, 1067.41it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1794/1849 [00:01&lt;00:00, 1069.92it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1832/1849 [00:01&lt;00:00, 1072.50it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1060.95it/s]

  0%|          | Fitting GeneralizingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  5%|4         | Fitting GeneralizingEstimator : 2/43 [00:00&lt;00:00,   52.52it/s]
  7%|6         | Fitting GeneralizingEstimator : 3/43 [00:00&lt;00:01,   30.51it/s]
 14%|#3        | Fitting GeneralizingEstimator : 6/43 [00:00&lt;00:00,   43.91it/s]
 16%|#6        | Fitting GeneralizingEstimator : 7/43 [00:00&lt;00:01,   35.21it/s]
 21%|##        | Fitting GeneralizingEstimator : 9/43 [00:00&lt;00:00,   37.62it/s]
 23%|##3       | Fitting GeneralizingEstimator : 10/43 [00:00&lt;00:00,   33.13it/s]
 28%|##7       | Fitting GeneralizingEstimator : 12/43 [00:00&lt;00:00,   36.22it/s]
 30%|###       | Fitting GeneralizingEstimator : 13/43 [00:00&lt;00:00,   32.08it/s]
 37%|###7      | Fitting GeneralizingEstimator : 16/43 [00:00&lt;00:00,   37.06it/s]
 42%|####1     | Fitting GeneralizingEstimator : 18/43 [00:00&lt;00:00,   36.31it/s]
 51%|#####1    | Fitting GeneralizingEstimator : 22/43 [00:00&lt;00:00,   42.53it/s]
 56%|#####5    | Fitting GeneralizingEstimator : 24/43 [00:00&lt;00:00,   41.17it/s]
 63%|######2   | Fitting GeneralizingEstimator : 27/43 [00:00&lt;00:00,   44.23it/s]
 67%|######7   | Fitting GeneralizingEstimator : 29/43 [00:00&lt;00:00,   42.76it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 32/43 [00:00&lt;00:00,   45.74it/s]
 77%|#######6  | Fitting GeneralizingEstimator : 33/43 [00:00&lt;00:00,   42.12it/s]
 84%|########3 | Fitting GeneralizingEstimator : 36/43 [00:00&lt;00:00,   44.14it/s]
 86%|########6 | Fitting GeneralizingEstimator : 37/43 [00:00&lt;00:00,   41.68it/s]
 93%|#########3| Fitting GeneralizingEstimator : 40/43 [00:00&lt;00:00,   44.25it/s]
 95%|#########5| Fitting GeneralizingEstimator : 41/43 [00:00&lt;00:00,   41.29it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   43.19it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   42.29it/s]

  0%|          | Scoring GeneralizingEstimator : 0/1849 [00:00&lt;?,       ?it/s]
  1%|1         | Scoring GeneralizingEstimator : 21/1849 [00:00&lt;00:05,  323.28it/s]
  3%|3         | Scoring GeneralizingEstimator : 57/1849 [00:00&lt;00:03,  584.75it/s]
  5%|5         | Scoring GeneralizingEstimator : 94/1849 [00:00&lt;00:02,  720.97it/s]
  7%|7         | Scoring GeneralizingEstimator : 132/1849 [00:00&lt;00:02,  810.49it/s]
  9%|9         | Scoring GeneralizingEstimator : 169/1849 [00:00&lt;00:01,  863.04it/s]
 11%|#1        | Scoring GeneralizingEstimator : 206/1849 [00:00&lt;00:01,  901.35it/s]
 13%|#3        | Scoring GeneralizingEstimator : 243/1849 [00:00&lt;00:01,  930.17it/s]
 15%|#5        | Scoring GeneralizingEstimator : 280/1849 [00:00&lt;00:01,  951.68it/s]
 17%|#7        | Scoring GeneralizingEstimator : 317/1849 [00:00&lt;00:01,  968.79it/s]
 19%|#9        | Scoring GeneralizingEstimator : 355/1849 [00:00&lt;00:01,  985.15it/s]
 21%|##1       | Scoring GeneralizingEstimator : 391/1849 [00:00&lt;00:01,  993.60it/s]
 23%|##3       | Scoring GeneralizingEstimator : 428/1849 [00:00&lt;00:01, 1004.01it/s]
 25%|##5       | Scoring GeneralizingEstimator : 466/1849 [00:00&lt;00:01, 1015.16it/s]
 27%|##7       | Scoring GeneralizingEstimator : 503/1849 [00:00&lt;00:01, 1021.50it/s]
 29%|##9       | Scoring GeneralizingEstimator : 540/1849 [00:00&lt;00:01, 1028.10it/s]
 31%|###1      | Scoring GeneralizingEstimator : 578/1849 [00:00&lt;00:01, 1035.98it/s]
 33%|###3      | Scoring GeneralizingEstimator : 615/1849 [00:00&lt;00:01, 1040.85it/s]
 35%|###5      | Scoring GeneralizingEstimator : 652/1849 [00:00&lt;00:01, 1044.17it/s]
 37%|###7      | Scoring GeneralizingEstimator : 689/1849 [00:00&lt;00:01, 1048.10it/s]
 39%|###9      | Scoring GeneralizingEstimator : 726/1849 [00:00&lt;00:01, 1051.72it/s]
 41%|####1     | Scoring GeneralizingEstimator : 763/1849 [00:00&lt;00:01, 1054.51it/s]
 43%|####3     | Scoring GeneralizingEstimator : 800/1849 [00:00&lt;00:00, 1056.97it/s]
 45%|####5     | Scoring GeneralizingEstimator : 837/1849 [00:00&lt;00:00, 1058.67it/s]
 47%|####7     | Scoring GeneralizingEstimator : 874/1849 [00:00&lt;00:00, 1060.96it/s]
 49%|####9     | Scoring GeneralizingEstimator : 911/1849 [00:00&lt;00:00, 1062.76it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 943/1849 [00:00&lt;00:00, 1054.28it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 980/1849 [00:00&lt;00:00, 1056.58it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 1017/1849 [00:00&lt;00:00, 1057.95it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 1044/1849 [00:01&lt;00:00, 1041.24it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 1065/1849 [00:01&lt;00:00, 1013.71it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 1087/1849 [00:01&lt;00:00,  989.68it/s]
 61%|######    | Scoring GeneralizingEstimator : 1120/1849 [00:01&lt;00:00,  988.71it/s]
 63%|######2   | Scoring GeneralizingEstimator : 1158/1849 [00:01&lt;00:00,  996.65it/s]
 65%|######4   | Scoring GeneralizingEstimator : 1193/1849 [00:01&lt;00:00,  998.74it/s]
 66%|######5   | Scoring GeneralizingEstimator : 1219/1849 [00:01&lt;00:00,  985.01it/s]
 68%|######7   | Scoring GeneralizingEstimator : 1257/1849 [00:01&lt;00:00,  992.31it/s]
 70%|######9   | Scoring GeneralizingEstimator : 1290/1849 [00:01&lt;00:00,  991.23it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 1317/1849 [00:01&lt;00:00,  978.34it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 1352/1849 [00:01&lt;00:00,  981.52it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 1389/1849 [00:01&lt;00:00,  987.65it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 1424/1849 [00:01&lt;00:00,  990.07it/s]
 79%|#######8  | Scoring GeneralizingEstimator : 1459/1849 [00:01&lt;00:00,  991.58it/s]
 81%|########  | Scoring GeneralizingEstimator : 1493/1849 [00:01&lt;00:00,  992.40it/s]
 83%|########2 | Scoring GeneralizingEstimator : 1527/1849 [00:01&lt;00:00,  992.48it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1563/1849 [00:01&lt;00:00,  996.24it/s]
 86%|########6 | Scoring GeneralizingEstimator : 1598/1849 [00:01&lt;00:00,  997.22it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1633/1849 [00:01&lt;00:00,  998.92it/s]
 90%|########9 | Scoring GeneralizingEstimator : 1663/1849 [00:01&lt;00:00,  992.77it/s]
 92%|#########1| Scoring GeneralizingEstimator : 1697/1849 [00:01&lt;00:00,  993.55it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1731/1849 [00:01&lt;00:00,  994.10it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1766/1849 [00:01&lt;00:00,  995.90it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1801/1849 [00:01&lt;00:00,  997.14it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1836/1849 [00:01&lt;00:00,  998.90it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1000.85it/s]

  0%|          | Fitting GeneralizingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  2%|2         | Fitting GeneralizingEstimator : 1/43 [00:00&lt;00:01,   21.50it/s]
  5%|4         | Fitting GeneralizingEstimator : 2/43 [00:00&lt;00:01,   21.75it/s]
  7%|6         | Fitting GeneralizingEstimator : 3/43 [00:00&lt;00:01,   23.77it/s]
  9%|9         | Fitting GeneralizingEstimator : 4/43 [00:00&lt;00:01,   20.70it/s]
 14%|#3        | Fitting GeneralizingEstimator : 6/43 [00:00&lt;00:01,   26.75it/s]
 16%|#6        | Fitting GeneralizingEstimator : 7/43 [00:00&lt;00:01,   27.17it/s]
 19%|#8        | Fitting GeneralizingEstimator : 8/43 [00:00&lt;00:01,   26.39it/s]
 26%|##5       | Fitting GeneralizingEstimator : 11/43 [00:00&lt;00:01,   28.60it/s]
 33%|###2      | Fitting GeneralizingEstimator : 14/43 [00:00&lt;00:00,   33.46it/s]
 35%|###4      | Fitting GeneralizingEstimator : 15/43 [00:00&lt;00:00,   31.23it/s]
 40%|###9      | Fitting GeneralizingEstimator : 17/43 [00:00&lt;00:00,   33.50it/s]
 42%|####1     | Fitting GeneralizingEstimator : 18/43 [00:00&lt;00:00,   30.86it/s]
 47%|####6     | Fitting GeneralizingEstimator : 20/43 [00:00&lt;00:00,   32.73it/s]
 49%|####8     | Fitting GeneralizingEstimator : 21/43 [00:00&lt;00:00,   30.60it/s]
 56%|#####5    | Fitting GeneralizingEstimator : 24/43 [00:00&lt;00:00,   33.98it/s]
 58%|#####8    | Fitting GeneralizingEstimator : 25/43 [00:00&lt;00:00,   32.12it/s]
 63%|######2   | Fitting GeneralizingEstimator : 27/43 [00:00&lt;00:00,   33.34it/s]
 65%|######5   | Fitting GeneralizingEstimator : 28/43 [00:00&lt;00:00,   31.71it/s]
 70%|######9   | Fitting GeneralizingEstimator : 30/43 [00:00&lt;00:00,   32.67it/s]
 72%|#######2  | Fitting GeneralizingEstimator : 31/43 [00:00&lt;00:00,   31.40it/s]
 77%|#######6  | Fitting GeneralizingEstimator : 33/43 [00:01&lt;00:00,   32.80it/s]
 81%|########1 | Fitting GeneralizingEstimator : 35/43 [00:01&lt;00:00,   32.60it/s]
 88%|########8 | Fitting GeneralizingEstimator : 38/43 [00:01&lt;00:00,   35.40it/s]
 91%|######### | Fitting GeneralizingEstimator : 39/43 [00:01&lt;00:00,   33.51it/s]
 98%|#########7| Fitting GeneralizingEstimator : 42/43 [00:01&lt;00:00,   35.74it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   34.83it/s]

  0%|          | Scoring GeneralizingEstimator : 0/1849 [00:00&lt;?,       ?it/s]
  2%|2         | Scoring GeneralizingEstimator : 37/1849 [00:00&lt;00:01, 1089.34it/s]
  4%|4         | Scoring GeneralizingEstimator : 74/1849 [00:00&lt;00:01, 1080.83it/s]
  6%|6         | Scoring GeneralizingEstimator : 112/1849 [00:00&lt;00:01, 1085.32it/s]
  7%|7         | Scoring GeneralizingEstimator : 136/1849 [00:00&lt;00:01,  982.46it/s]
  9%|8         | Scoring GeneralizingEstimator : 161/1849 [00:00&lt;00:01,  929.86it/s]
 10%|#         | Scoring GeneralizingEstimator : 189/1849 [00:00&lt;00:01,  908.13it/s]
 12%|#2        | Scoring GeneralizingEstimator : 227/1849 [00:00&lt;00:01,  942.80it/s]
 14%|#4        | Scoring GeneralizingEstimator : 266/1849 [00:00&lt;00:01,  973.20it/s]
 16%|#6        | Scoring GeneralizingEstimator : 303/1849 [00:00&lt;00:01,  989.48it/s]
 18%|#8        | Scoring GeneralizingEstimator : 342/1849 [00:00&lt;00:01, 1008.67it/s]
 20%|##        | Scoring GeneralizingEstimator : 378/1849 [00:00&lt;00:01, 1013.57it/s]
 22%|##2       | Scoring GeneralizingEstimator : 416/1849 [00:00&lt;00:01, 1023.99it/s]
 25%|##4       | Scoring GeneralizingEstimator : 455/1849 [00:00&lt;00:01, 1036.87it/s]
 27%|##6       | Scoring GeneralizingEstimator : 494/1849 [00:00&lt;00:01, 1047.02it/s]
 29%|##8       | Scoring GeneralizingEstimator : 531/1849 [00:00&lt;00:01, 1049.65it/s]
 31%|###       | Scoring GeneralizingEstimator : 570/1849 [00:00&lt;00:01, 1058.45it/s]
 33%|###2      | Scoring GeneralizingEstimator : 608/1849 [00:00&lt;00:01, 1063.69it/s]
 35%|###4      | Scoring GeneralizingEstimator : 646/1849 [00:00&lt;00:01, 1067.53it/s]
 37%|###6      | Scoring GeneralizingEstimator : 684/1849 [00:00&lt;00:01, 1072.10it/s]
 39%|###9      | Scoring GeneralizingEstimator : 722/1849 [00:00&lt;00:01, 1075.77it/s]
 41%|####      | Scoring GeneralizingEstimator : 757/1849 [00:00&lt;00:01, 1072.82it/s]
 43%|####3     | Scoring GeneralizingEstimator : 796/1849 [00:00&lt;00:00, 1078.45it/s]
 45%|####5     | Scoring GeneralizingEstimator : 834/1849 [00:00&lt;00:00, 1081.18it/s]
 47%|####7     | Scoring GeneralizingEstimator : 872/1849 [00:00&lt;00:00, 1083.85it/s]
 49%|####9     | Scoring GeneralizingEstimator : 909/1849 [00:00&lt;00:00, 1084.51it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 948/1849 [00:00&lt;00:00, 1089.10it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 985/1849 [00:00&lt;00:00, 1088.21it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 1019/1849 [00:00&lt;00:00, 1082.05it/s]
 57%|#####7    | Scoring GeneralizingEstimator : 1058/1849 [00:00&lt;00:00, 1085.22it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 1090/1849 [00:01&lt;00:00, 1075.53it/s]
 61%|######1   | Scoring GeneralizingEstimator : 1128/1849 [00:01&lt;00:00, 1078.65it/s]
 63%|######3   | Scoring GeneralizingEstimator : 1167/1849 [00:01&lt;00:00, 1082.91it/s]
 65%|######5   | Scoring GeneralizingEstimator : 1206/1849 [00:01&lt;00:00, 1086.62it/s]
 67%|######7   | Scoring GeneralizingEstimator : 1243/1849 [00:01&lt;00:00, 1087.24it/s]
 69%|######9   | Scoring GeneralizingEstimator : 1282/1849 [00:01&lt;00:00, 1091.07it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 1320/1849 [00:01&lt;00:00, 1093.01it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 1359/1849 [00:01&lt;00:00, 1096.49it/s]
 76%|#######5  | Scoring GeneralizingEstimator : 1397/1849 [00:01&lt;00:00, 1097.50it/s]
 78%|#######7  | Scoring GeneralizingEstimator : 1436/1849 [00:01&lt;00:00, 1100.23it/s]
 80%|#######9  | Scoring GeneralizingEstimator : 1475/1849 [00:01&lt;00:00, 1103.04it/s]
 82%|########1 | Scoring GeneralizingEstimator : 1508/1849 [00:01&lt;00:00, 1095.62it/s]
 83%|########3 | Scoring GeneralizingEstimator : 1539/1849 [00:01&lt;00:00, 1084.74it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1566/1849 [00:01&lt;00:00, 1068.75it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1590/1849 [00:01&lt;00:00, 1048.98it/s]
 87%|########7 | Scoring GeneralizingEstimator : 1612/1849 [00:01&lt;00:00, 1025.39it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1634/1849 [00:01&lt;00:00, 1003.58it/s]
 90%|########9 | Scoring GeneralizingEstimator : 1656/1849 [00:01&lt;00:00,  983.83it/s]
 91%|######### | Scoring GeneralizingEstimator : 1682/1849 [00:01&lt;00:00,  971.98it/s]
 93%|#########2| Scoring GeneralizingEstimator : 1718/1849 [00:01&lt;00:00,  976.81it/s]
 95%|#########4| Scoring GeneralizingEstimator : 1756/1849 [00:01&lt;00:00,  984.79it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1781/1849 [00:01&lt;00:00,  971.49it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1814/1849 [00:01&lt;00:00,  971.14it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00,  979.83it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1026.14it/s]

  0%|          | Fitting GeneralizingEstimator : 0/43 [00:00&lt;?,       ?it/s]
  5%|4         | Fitting GeneralizingEstimator : 2/43 [00:00&lt;00:00,   57.38it/s]
  7%|6         | Fitting GeneralizingEstimator : 3/43 [00:00&lt;00:00,   43.29it/s]
  9%|9         | Fitting GeneralizingEstimator : 4/43 [00:00&lt;00:01,   38.09it/s]
 16%|#6        | Fitting GeneralizingEstimator : 7/43 [00:00&lt;00:00,   36.40it/s]
 23%|##3       | Fitting GeneralizingEstimator : 10/43 [00:00&lt;00:00,   43.05it/s]
 26%|##5       | Fitting GeneralizingEstimator : 11/43 [00:00&lt;00:00,   37.51it/s]
 30%|###       | Fitting GeneralizingEstimator : 13/43 [00:00&lt;00:00,   39.77it/s]
 33%|###2      | Fitting GeneralizingEstimator : 14/43 [00:00&lt;00:00,   38.62it/s]
 35%|###4      | Fitting GeneralizingEstimator : 15/43 [00:00&lt;00:00,   36.80it/s]
 44%|####4     | Fitting GeneralizingEstimator : 19/43 [00:00&lt;00:00,   44.55it/s]
 49%|####8     | Fitting GeneralizingEstimator : 21/43 [00:00&lt;00:00,   41.72it/s]
 58%|#####8    | Fitting GeneralizingEstimator : 25/43 [00:00&lt;00:00,   42.91it/s]
 65%|######5   | Fitting GeneralizingEstimator : 28/43 [00:00&lt;00:00,   45.40it/s]
 67%|######7   | Fitting GeneralizingEstimator : 29/43 [00:00&lt;00:00,   42.23it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 32/43 [00:00&lt;00:00,   44.47it/s]
 77%|#######6  | Fitting GeneralizingEstimator : 33/43 [00:00&lt;00:00,   41.18it/s]
 84%|########3 | Fitting GeneralizingEstimator : 36/43 [00:00&lt;00:00,   43.44it/s]
 88%|########8 | Fitting GeneralizingEstimator : 38/43 [00:00&lt;00:00,   41.91it/s]
 93%|#########3| Fitting GeneralizingEstimator : 40/43 [00:00&lt;00:00,   39.68it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   42.52it/s]
100%|##########| Fitting GeneralizingEstimator : 43/43 [00:01&lt;00:00,   42.22it/s]

  0%|          | Scoring GeneralizingEstimator : 0/1849 [00:00&lt;?,       ?it/s]
  1%|1         | Scoring GeneralizingEstimator : 20/1849 [00:00&lt;00:05,  307.07it/s]
  3%|3         | Scoring GeneralizingEstimator : 57/1849 [00:00&lt;00:03,  584.91it/s]
  5%|5         | Scoring GeneralizingEstimator : 94/1849 [00:00&lt;00:02,  721.83it/s]
  7%|7         | Scoring GeneralizingEstimator : 131/1849 [00:00&lt;00:02,  803.69it/s]
  9%|9         | Scoring GeneralizingEstimator : 168/1849 [00:00&lt;00:01,  858.70it/s]
 11%|#1        | Scoring GeneralizingEstimator : 204/1849 [00:00&lt;00:01,  891.03it/s]
 13%|#3        | Scoring GeneralizingEstimator : 242/1849 [00:00&lt;00:01,  925.70it/s]
 15%|#5        | Scoring GeneralizingEstimator : 279/1849 [00:00&lt;00:01,  947.94it/s]
 17%|#7        | Scoring GeneralizingEstimator : 317/1849 [00:00&lt;00:01,  967.47it/s]
 19%|#9        | Scoring GeneralizingEstimator : 355/1849 [00:00&lt;00:01,  983.75it/s]
 21%|##1       | Scoring GeneralizingEstimator : 392/1849 [00:00&lt;00:01,  994.76it/s]
 23%|##3       | Scoring GeneralizingEstimator : 430/1849 [00:00&lt;00:01, 1007.68it/s]
 25%|##5       | Scoring GeneralizingEstimator : 467/1849 [00:00&lt;00:01, 1016.06it/s]
 27%|##7       | Scoring GeneralizingEstimator : 505/1849 [00:00&lt;00:01, 1025.98it/s]
 29%|##9       | Scoring GeneralizingEstimator : 542/1849 [00:00&lt;00:01, 1031.13it/s]
 31%|###1      | Scoring GeneralizingEstimator : 579/1849 [00:00&lt;00:01, 1036.16it/s]
 33%|###3      | Scoring GeneralizingEstimator : 617/1849 [00:00&lt;00:01, 1043.23it/s]
 35%|###5      | Scoring GeneralizingEstimator : 654/1849 [00:00&lt;00:01, 1046.72it/s]
 37%|###7      | Scoring GeneralizingEstimator : 693/1849 [00:00&lt;00:01, 1054.26it/s]
 40%|###9      | Scoring GeneralizingEstimator : 731/1849 [00:00&lt;00:01, 1059.39it/s]
 42%|####1     | Scoring GeneralizingEstimator : 768/1849 [00:00&lt;00:01, 1061.95it/s]
 44%|####3     | Scoring GeneralizingEstimator : 806/1849 [00:00&lt;00:00, 1065.93it/s]
 46%|####5     | Scoring GeneralizingEstimator : 844/1849 [00:00&lt;00:00, 1069.36it/s]
 48%|####7     | Scoring GeneralizingEstimator : 882/1849 [00:00&lt;00:00, 1072.74it/s]
 50%|####9     | Scoring GeneralizingEstimator : 919/1849 [00:00&lt;00:00, 1073.14it/s]
 52%|#####1    | Scoring GeneralizingEstimator : 957/1849 [00:00&lt;00:00, 1075.76it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 995/1849 [00:00&lt;00:00, 1078.56it/s]
 56%|#####5    | Scoring GeneralizingEstimator : 1034/1849 [00:00&lt;00:00, 1083.22it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 1070/1849 [00:01&lt;00:00, 1082.07it/s]
 60%|#####9    | Scoring GeneralizingEstimator : 1108/1849 [00:01&lt;00:00, 1083.54it/s]
 62%|######1   | Scoring GeneralizingEstimator : 1146/1849 [00:01&lt;00:00, 1085.83it/s]
 64%|######4   | Scoring GeneralizingEstimator : 1184/1849 [00:01&lt;00:00, 1087.83it/s]
 66%|######6   | Scoring GeneralizingEstimator : 1222/1849 [00:01&lt;00:00, 1089.97it/s]
 68%|######8   | Scoring GeneralizingEstimator : 1260/1849 [00:01&lt;00:00, 1091.14it/s]
 70%|#######   | Scoring GeneralizingEstimator : 1298/1849 [00:01&lt;00:00, 1092.91it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 1336/1849 [00:01&lt;00:00, 1094.62it/s]
 74%|#######4  | Scoring GeneralizingEstimator : 1374/1849 [00:01&lt;00:00, 1095.20it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 1410/1849 [00:01&lt;00:00, 1093.48it/s]
 78%|#######8  | Scoring GeneralizingEstimator : 1447/1849 [00:01&lt;00:00, 1093.61it/s]
 80%|########  | Scoring GeneralizingEstimator : 1484/1849 [00:01&lt;00:00, 1093.11it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1522/1849 [00:01&lt;00:00, 1094.27it/s]
 84%|########4 | Scoring GeneralizingEstimator : 1560/1849 [00:01&lt;00:00, 1095.87it/s]
 86%|########6 | Scoring GeneralizingEstimator : 1597/1849 [00:01&lt;00:00, 1095.73it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1635/1849 [00:01&lt;00:00, 1097.16it/s]
 90%|######### | Scoring GeneralizingEstimator : 1672/1849 [00:01&lt;00:00, 1096.80it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1710/1849 [00:01&lt;00:00, 1098.26it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1737/1849 [00:01&lt;00:00, 1080.69it/s]
 95%|#########5| Scoring GeneralizingEstimator : 1761/1849 [00:01&lt;00:00, 1060.72it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1783/1849 [00:01&lt;00:00, 1038.63it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1820/1849 [00:01&lt;00:00, 1041.50it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1044.62it/s]
100%|##########| Scoring GeneralizingEstimator : 1849/1849 [00:01&lt;00:00, 1052.16it/s]
</pre></div>
</div>
<p>Plot the full (generalization) matrix:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow" title="matplotlib.axes.Axes.imshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;lanczos&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span>
               <span class="n">extent</span><span class="o">=</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Testing Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Temporal generalization&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html#matplotlib.pyplot.colorbar" title="matplotlib.pyplot.colorbar" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span></a><span class="p">(</span><a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Temporal generalization" class="sphx-glr-single-img" src="../../_images/sphx_glr_50_decoding_006.png" />
</div>
</div>
<div class="section" id="projecting-sensor-space-patterns-to-source-space">
<h2>Projecting sensor-space patterns to source space<a class="headerlink" href="#projecting-sensor-space-patterns-to-source-space" title="Permalink to this headline">Â¶</a></h2>
<p>If you use a linear classifier (or regressor) for your data, you can also
project these to source space. For example, using our <code class="docutils literal notranslate"><span class="pre">evoked_time_gen</span></code>
from before:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cov</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span></a><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
<span class="k">del</span> <span class="n">epochs</span>
<span class="n">fwd</span> <span class="o">=</span> <a href="../../generated/mne.read_forward_solution.html#mne.read_forward_solution" title="mne.read_forward_solution" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_forward_solution</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif&#39;</span><span class="p">)</span>
<span class="n">inv</span> <span class="o">=</span> <a href="../../generated/mne.minimum_norm.make_inverse_operator.html#mne.minimum_norm.make_inverse_operator" title="mne.minimum_norm.make_inverse_operator" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">minimum_norm</span><span class="o">.</span><span class="n">make_inverse_operator</span></a><span class="p">(</span>
    <a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked_time_gen</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">fwd</span><span class="p">,</span> <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cov</span></a><span class="p">,</span> <span class="n">loose</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
<a href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stc</span></a> <span class="o">=</span> <a href="../../generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">minimum_norm</span><span class="o">.</span><span class="n">apply_inverse</span></a><span class="p">(</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked_time_gen</span></a><span class="p">,</span> <span class="n">inv</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="mf">9.</span><span class="p">,</span> <span class="s1">&#39;dSPM&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">fwd</span><span class="p">,</span> <span class="n">inv</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from data with rank=None
    Using tolerance 3.4e-10 (2.2e-16 eps * 203 dim * 7.6e+03  max singular value)
    Estimated rank (grad): 203
    GRAD: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 1599
[done]
Reading forward solution from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif...
    Reading a source space...
    Computing patch statistics...
    Patch information added...
    Distance information added...
    [done]
    Reading a source space...
    Computing patch statistics...
    Patch information added...
    Distance information added...
    [done]
    2 source spaces read
    Desired named matrix (kind = 3523) not available
    Read MEG forward solution (7498 sources, 306 channels, free orientations)
    Desired named matrix (kind = 3523) not available
    Read EEG forward solution (7498 sources, 60 channels, free orientations)
    MEG and EEG forward solutions combined
    Source spaces transformed to the forward solution coordinate frame
Computing inverse operator with 203 channels.
    203 out of 366 channels remain after picking
Selected 203 channels
Creating the depth weighting matrix...
    203 planar channels
    limit = 7262/7498 = 10.020866
    scale = 2.58122e-08 exp = 0.8
    Picked elements from a free-orientation depth-weighting prior into the fixed-orientation one
    Average patch normals will be employed in the rotation to the local surface coordinates....
    Converting to surface-based source orientations...
    [done]
Whitening the forward solution.
Computing rank from covariance with rank=None
    Using tolerance 1.6e-13 (2.2e-16 eps * 203 dim * 3.6  max singular value)
    Estimated rank (grad): 203
    GRAD: rank 203 computed from 203 data channels with 0 projectors
    Setting small GRAD eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing SVD of whitened and weighted lead field matrix.
    largest singular value = 3.91789
    scaling factor to adjust the trace = 6.28301e+18 (nchan = 203 nzero = 0)
Preparing the inverse operator for use...
    Scaled noise and source covariance from nave = 1 to nave = 1
    Created the regularized inverter
    The projection vectors do not apply to these channels.
    Created the whitener using a noise covariance matrix with rank 203 (0 small eigenvalues omitted)
    Computing noise-normalization factors (dSPM)...
[done]
Applying inverse operator to &quot;&quot;...
    Picked 203 channels from the data
    Computing inverse...
    Eigenleads need to be weighted ...
    Computing residual...
    Explained  76.6% variance
    dSPM...
[done]
</pre></div>
</div>
<p>And this can be visualized using <a class="reference internal" href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate.plot" title="mne.SourceEstimate.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">stc.plot</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <a href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate.plot" title="mne.SourceEstimate.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">stc</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">views</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="s1">&#39;med&#39;</span><span class="p">),</span> <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="50 decoding" class="sphx-glr-single-img" src="../../_images/sphx_glr_50_decoding_007.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using control points [2.03727704 2.4722366  8.19426193]
</pre></div>
</div>
</div>
<div class="section" id="source-space-decoding">
<h2>Source-space decoding<a class="headerlink" href="#source-space-decoding" title="Permalink to this headline">Â¶</a></h2>
<p>Source space decoding is also possible, but because the number of features
can be much larger than in the sensor space, univariate feature selection
using ANOVA f-test (or some other metric) can be done to reduce the feature
dimension. Interpreting decoding results might be easier in source space as
compared to sensor space.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html#tut-dec-st-source"><span class="std std-ref">Decoding source space data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">Â¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Explore other datasets from MNE (e.g. Face dataset from SPM to predict
Face vs. Scrambled)</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="kingetal2018"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jean-RÃ©mi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, and Alexandre Gramfort. Encoding and decoding neuronal dynamics: methodological framework to uncover the algorithms of cognition. hal-01848442, 2018. URL: <a class="reference external" href="https://hal.archives-ouvertes.fr/hal-01848442">https://hal.archives-ouvertes.fr/hal-01848442</a>.</p>
</dd>
<dt class="label" id="koles1991"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>ZoltanÂ J. Koles. The quantitative extraction and topographic mapping of the abnormal components in the clinical EEG. <em>Electroencephalography and Clinical Neurophysiology</em>, 79(6):440â€“447, 1991. <a class="reference external" href="https://doi.org/10.1016/0013-4694(91)90163-X">doi:10.1016/0013-4694(91)90163-X</a>.</p>
</dd>
<dt class="label" id="dahneetal2014"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Sven DÃ¤hne, FrankÂ C. Meinecke, Stefan Haufe, Johannes HÃ¶hne, Michael Tangermann, Klaus-Robert MÃ¼ller, and VadimÂ V. Nikulin. SPoC: a novel framework for relating the amplitude of neuronal oscillations to behaviorally relevant parameters. <em>NeuroImage</em>, 86:111â€“122, 2014. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2013.07.079">doi:10.1016/j.neuroimage.2013.07.079</a>.</p>
</dd>
<dt class="label" id="rivetetal2009"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Bertrand Rivet, Antoine Souloumiac, Virginie Attina, and Guillaume Gibert. xDAWN algorithm to enhance evoked potentials: application to brainâ€“computer interface. <em>IEEE Transactions on Biomedical Engineering</em>, 56(8):2035â€“2043, 2009. <a class="reference external" href="https://doi.org/10.1109/TBME.2009.2012869">doi:10.1109/TBME.2009.2012869</a>.</p>
</dd>
<dt class="label" id="schurgeretal2013"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Aaron Schurger, Sebastien Marti, and Stanislas Dehaene. Reducing multi-sensor data to a single time course that reveals experimental effects. <em>BMC Neuroscience</em>, 2013. <a class="reference external" href="https://doi.org/10.1186/1471-2202-14-122">doi:10.1186/1471-2202-14-122</a>.</p>
</dd>
<dt class="label" id="kingetal2014"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Jean-RÃ©mi King, Alexandre Gramfort, Aaron Schurger, Lionel Naccache, and Stanislas Dehaene. Two distinct dynamic modes subtend the detection of unexpected sounds. <em>PLoS ONE</em>, 9(1):e85791, 2014. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0085791">doi:10.1371/journal.pone.0085791</a>.</p>
</dd>
<dt class="label" id="kingdehaene2014"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p>Jean-RÃ©mi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. <em>Trends in Cognitive Sciences</em>, 18(4):203â€“210, 2014. <a class="reference external" href="https://doi.org/10.1016/j.tics.2014.01.002">doi:10.1016/j.tics.2014.01.002</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  50.833 seconds)</p>
<p><strong>Estimated memory usage:</strong>  487 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-machine-learning-50-decoding-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/911f82913fdceaf692d2bd4584358dcd/50_decoding.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">50_decoding.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e1c3654f77f904db443b548e9d93b8f9/50_decoding.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">50_decoding.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="30_strf.html" title="previous page">Spectro-temporal receptive field (STRF) estimation on continuous data</a>
    <a class='right-next' id="next-link" href="../clinical/20_seeg.html" title="next page">Working with sEEG data</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012â€“2021, MNE Developers. Last updated <time datetime="2021-05-18T12:20:53.616965+00:00" class="localized">2021-05-18 12:20 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>