
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Source reconstruction using an LCMV beamformer &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Visualize source time courses (stcs)" href="60_visualize_stc.html" />
    <link rel="prev" title="Computing various MNE solutions" href="40_mne_fixed_free.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/10_ieeg_localize.html">
     Locating Intracranial Electrode Contacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-to-beamformers">
   Introduction to beamformers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-processing">
   Data processing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-the-covariance-matrices">
   Computing the covariance matrices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-forward-model">
   The forward model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#handling-depth-bias">
   Handling depth bias
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compute-the-spatial-filter">
   Compute the spatial filter
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apply-the-spatial-filter">
   Apply the spatial filter
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-the-reconstructed-source-activity">
   Visualize the reconstructed source activity
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#on-mri-slices-orthoview-2d">
     On MRI slices (orthoview; 2D)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#on-mni-glass-brain-orthoview-2d">
     On MNI glass brain (orthoview; 2D)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#volumetric-rendering-3d-with-vectors">
     Volumetric rendering (3D) with vectors
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-the-activity-of-the-maximum-voxel-with-all-three-components">
   Visualize the activity of the maximum voxel with all three components
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#morph-the-output-to-fsaverage">
   Morph the output to fsaverage
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-inverse-50-beamformer-lcmv-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="source-reconstruction-using-an-lcmv-beamformer">
<span id="sphx-glr-auto-tutorials-inverse-50-beamformer-lcmv-py"></span><h1>Source reconstruction using an LCMV beamformer<a class="headerlink" href="#source-reconstruction-using-an-lcmv-beamformer" title="Permalink to this headline">¶</a></h1>
<p>This tutorial gives an overview of the beamformer method
and shows how to reconstruct source activity using an LCMV beamformer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Britta Westner &lt;britta.wstnr@gmail.com&gt;</span>
<span class="c1">#          Eric Larson &lt;larson.eric.d@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span><span class="p">,</span> <a href="../../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a>
<span class="kn">from</span> <span class="nn">mne.beamformer</span> <span class="kn">import</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">,</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a>
</pre></div>
</div>
<div class="section" id="introduction-to-beamformers">
<h2>Introduction to beamformers<a class="headerlink" href="#introduction-to-beamformers" title="Permalink to this headline">¶</a></h2>
<p>A beamformer is a spatial filter that reconstructs source activity by
scanning through a grid of pre-defined source points and estimating activity
at each of those source points independently. A set of weights is
constructed for each defined source location which defines the contribution
of each sensor to this source.
Beamformers are often used for their focal reconstructions and their ability
to reconstruct deeper sources. They can also suppress external noise sources.
The beamforming method applied in this tutorial is the linearly constrained
minimum variance (LCMV) beamformer <a class="footnote-reference brackets" href="#vanveenetal1997" id="id1">1</a> operates on
time series.
Frequency-resolved data can be reconstructed with the dynamic imaging of
coherent sources (DICS) beamforming method <a class="footnote-reference brackets" href="#grossetal2001" id="id2">2</a>.
As we will see in the following, the spatial filter is computed from two
ingredients: the forward model solution and the covariance matrix of the
data.</p>
</div>
<div class="section" id="data-processing">
<h2>Data processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">¶</a></h2>
<p>We will use the sample data set for this tutorial and reconstruct source
activity on the trials with left auditory stimulation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/subjects&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw.fif&#39;</span>

<span class="c1"># Read the raw data</span>
<span class="n">raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;bads&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;MEG 2443&#39;</span><span class="p">]</span>  <span class="c1"># bad MEG channel</span>

<span class="c1"># Set up the epoching</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># those are the trials with left-ear auditory stimuli</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

<span class="c1"># pick relevant channels</span>
<span class="n">raw</span><span class="o">.</span><span class="n">pick</span><span class="p">([</span><span class="s1">&#39;meg&#39;</span><span class="p">,</span> <span class="s1">&#39;eog&#39;</span><span class="p">])</span>  <span class="c1"># pick channels of interest</span>

<span class="c1"># Create epochs</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># already applied</span>
<span class="n">epochs</span> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span>
                    <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="mf">4000e-13</span><span class="p">,</span> <span class="n">mag</span><span class="o">=</span><span class="mf">4e-12</span><span class="p">,</span> <span class="n">eog</span><span class="o">=</span><span class="mf">150e-6</span><span class="p">))</span>

<span class="c1"># for speed purposes, cut to a window of interest</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">average</span><span class="p">()</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>

<span class="c1"># Visualize averaged sensor space data</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_joint" title="mne.EvokedArray.plot_joint" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">evoked</span><span class="o">.</span><span class="n">plot_joint</span></a><span class="p">()</span>

<span class="k">del</span> <span class="n">raw</span>  <span class="c1"># save memory</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_50_beamformer_lcmv_001.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_001.png" alt="0.093 s" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_50_beamformer_lcmv_002.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_002.png" alt="0.093 s" class = "sphx-glr-multi-img"/></li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
319 events found
Event IDs: [ 1  2  3  4  5 32]
Removing projector &lt;Projection | Average EEG reference, active : False, n_channels : 60&gt;
Not setting metadata
Not setting metadata
72 matching events found
Setting baseline interval to [-0.19979521315838786, 0.0] sec
Applying baseline correction (mode: mean)
Created an SSP operator (subspace dimension = 3)
Loading data for 72 events and 106 original time points ...
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on MAG : [&#39;MEG 1711&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
17 bad epochs dropped
Created an SSP operator (subspace dimension = 3)
3 projection items activated
SSP projectors applied...
Removing projector &lt;Projection | PCA-v1, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v2, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v3, active : True, n_channels : 102&gt;
</pre></div>
</div>
</div>
<div class="section" id="computing-the-covariance-matrices">
<h2>Computing the covariance matrices<a class="headerlink" href="#computing-the-covariance-matrices" title="Permalink to this headline">¶</a></h2>
<p>Spatial filters use the data covariance to estimate the filter
weights. The data covariance matrix will be <a class="reference external" href="https://en.wikipedia.org/wiki/Invertible_matrix">inverted</a> during the spatial
filter computation, so it is valuable to plot the covariance matrix and its
eigenvalues to gauge whether matrix inversion will be possible.
Also, because we want to combine different channel types (magnetometers and
gradiometers), we need to account for the different amplitude scales of these
channel types. To do this we will supply a noise covariance matrix to the
beamformer, which will be used for whitening.
The data covariance matrix should be estimated from a time window that
includes the brain signal of interest,
and incorporate enough samples for a stable estimate. A rule of thumb is to
use more samples than there are channels in the data set; see
<a class="footnote-reference brackets" href="#brookesetal2008" id="id3">3</a> for more detailed advice on covariance estimation
for beamformers. Here, we use a time
window incorporating the expected auditory response at around 100 ms post
stimulus and extend the period to account for a low number of trials (72) and
low sampling rate of 150 Hz.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span></a><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                                  <span class="n">method</span><span class="o">=</span><span class="s1">&#39;empirical&#39;</span><span class="p">)</span>
<a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span></a><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                   <span class="n">method</span><span class="o">=</span><span class="s1">&#39;empirical&#39;</span><span class="p">)</span>
<a href="../../generated/mne.Covariance.html#mne.Covariance.plot" title="mne.Covariance.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">data_cov</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
<span class="k">del</span> <span class="n">epochs</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_50_beamformer_lcmv_003.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_003.png" alt="Magnetometers covariance, Gradiometers covariance" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_50_beamformer_lcmv_004.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_004.png" alt="Magnetometers covariance, Gradiometers covariance" class = "sphx-glr-multi-img"/></li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from data with rank=None
    Using tolerance 4.1e-09 (2.2e-16 eps * 305 dim * 6.1e+04  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
    Created an SSP operator (subspace dimension = 3)
    Setting small MEG eigenvalues to zero (without PCA)
Reducing data rank from 305 -&gt; 302
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 2035
[done]
Computing rank from data with rank=None
    Using tolerance 2.8e-09 (2.2e-16 eps * 305 dim * 4.2e+04  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
    Created an SSP operator (subspace dimension = 3)
    Setting small MEG eigenvalues to zero (without PCA)
Reducing data rank from 305 -&gt; 302
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 1705
[done]
Computing rank from covariance with rank=None
    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)
    Estimated rank (mag): 99
    MAG: rank 99 computed from 102 data channels with 0 projectors
Computing rank from covariance with rank=None
    Using tolerance 4.3e-13 (2.2e-16 eps * 203 dim * 9.4  max singular value)
    Estimated rank (grad): 203
    GRAD: rank 203 computed from 203 data channels with 0 projectors
</pre></div>
</div>
<p>When looking at the covariance matrix plots, we can see that our data is
slightly rank-deficient as the rank is not equal to the number of channels.
Thus, we will have to regularize the covariance matrix before inverting it
in the beamformer calculation. This can be achieved by setting the parameter
<code class="docutils literal notranslate"><span class="pre">reg=0.05</span></code> when calculating the spatial filter with
<a class="reference internal" href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_lcmv()</span></code></a>. This corresponds to loading the diagonal
of the covariance matrix with 5% of the sensor power.</p>
</div>
<div class="section" id="the-forward-model">
<h2>The forward model<a class="headerlink" href="#the-forward-model" title="Permalink to this headline">¶</a></h2>
<p>The forward model is the other important ingredient for the computation of a
spatial filter. Here, we will load the forward model from disk; more
information on how to create a forward model can be found in this tutorial:
<a class="reference internal" href="../forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>.
Note that beamformers are usually computed in a <a class="reference internal" href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">volume</span> <span class="pre">source</span> <span class="pre">space</span></code></a>, because estimating only cortical surface
activation can misrepresent the data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read forward model</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fwd_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis-meg-vol-7-fwd.fif&#39;</span>
<span class="n">forward</span> <span class="o">=</span> <a href="../../generated/mne.read_forward_solution.html#mne.read_forward_solution" title="mne.read_forward_solution" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_forward_solution</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fwd_fname</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading forward solution from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-vol-7-fwd.fif...
    Reading a source space...
    [done]
    1 source spaces read
    Desired named matrix (kind = 3523) not available
    Read MEG forward solution (3757 sources, 306 channels, free orientations)
    Source spaces transformed to the forward solution coordinate frame
</pre></div>
</div>
</div>
<div class="section" id="handling-depth-bias">
<h2>Handling depth bias<a class="headerlink" href="#handling-depth-bias" title="Permalink to this headline">¶</a></h2>
<p>The forward model solution is inherently biased toward superficial sources.
When analyzing single conditions it is best to mitigate the depth bias
somehow. There are several ways to do this:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.beamformer.make_lcmv()</span></code></a> has a <code class="docutils literal notranslate"><span class="pre">depth</span></code> parameter that normalizes
the forward model prior to computing the spatial filters. See the docstring
for details.</p></li>
<li><p>Unit-noise gain beamformers handle depth bias by normalizing the
weights of the spatial filter. Choose this by setting
<code class="docutils literal notranslate"><span class="pre">weight_norm='unit-noise-gain'</span></code>.</p></li>
<li><p>When computing the Neural activity index, the depth bias is handled by
normalizing both the weights and the estimated noise (see
<a class="footnote-reference brackets" href="#vanveenetal1997" id="id4">1</a>). Choose this by setting <code class="docutils literal notranslate"><span class="pre">weight_norm='nai'</span></code>.</p></li>
</ul>
<p>Note that when comparing conditions, the depth bias will cancel out and it is
possible to set both parameters to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</div>
<div class="section" id="compute-the-spatial-filter">
<h2>Compute the spatial filter<a class="headerlink" href="#compute-the-spatial-filter" title="Permalink to this headline">¶</a></h2>
<p>Now we can compute the spatial filter. We’ll use a unit-noise gain beamformer
to deal with depth bias, and will also optimize the orientation of the
sources such that output power is maximized.
This is achieved by setting <code class="docutils literal notranslate"><span class="pre">pick_ori='max-power'</span></code>.
This gives us one source estimate per source (i.e., voxel), which is known
as a scalar beamformer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filters</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                    <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="o">=</span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="p">,</span> <span class="n">pick_ori</span><span class="o">=</span><span class="s1">&#39;max-power&#39;</span><span class="p">,</span>
                    <span class="n">weight_norm</span><span class="o">=</span><span class="s1">&#39;unit-noise-gain&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># You can save the filter for later use with:</span>
<span class="c1"># filters.save(&#39;filters-lcmv.h5&#39;)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from covariance with rank=None
    Using tolerance 7.1e-13 (2.2e-16 eps * 305 dim * 10  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Computing rank from covariance with rank=None
    Using tolerance 2.9e-13 (2.2e-16 eps * 305 dim * 4.3  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Making LCMV beamformer with rank {&#39;meg&#39;: 302}
Computing inverse operator with 305 channels.
    305 out of 306 channels remain after picking
Selected 305 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 3)
Computing rank from covariance with rank={&#39;meg&#39;: 302}
    Setting small MEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 3757 sources
Filter computation complete
</pre></div>
</div>
<p>It is also possible to compute a vector beamformer, which gives back three
estimates per voxel, corresponding to the three direction components of the
source. This can be achieved by setting
<code class="docutils literal notranslate"><span class="pre">pick_ori='vector'</span></code> and will yield a <a class="reference internal" href="../../generated/mne.VolVectorSourceEstimate.html#mne.VolVectorSourceEstimate" title="mne.VolVectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">volume</span> <span class="pre">vector</span> <span class="pre">source</span> <span class="pre">estimate</span></code></a>. So we will compute another set of filters
using the vector beamformer approach:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filters_vec</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                        <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="o">=</span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="p">,</span> <span class="n">pick_ori</span><span class="o">=</span><span class="s1">&#39;vector&#39;</span><span class="p">,</span>
                        <span class="n">weight_norm</span><span class="o">=</span><span class="s1">&#39;unit-noise-gain&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># save a bit of memory</span>
<a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a> <span class="o">=</span> <span class="n">forward</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span>
<span class="k">del</span> <span class="n">forward</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from covariance with rank=None
    Using tolerance 7.1e-13 (2.2e-16 eps * 305 dim * 10  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Computing rank from covariance with rank=None
    Using tolerance 2.9e-13 (2.2e-16 eps * 305 dim * 4.3  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Making LCMV beamformer with rank {&#39;meg&#39;: 302}
Computing inverse operator with 305 channels.
    305 out of 306 channels remain after picking
Selected 305 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 3)
Computing rank from covariance with rank={&#39;meg&#39;: 302}
    Setting small MEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 3757 sources
Filter computation complete
</pre></div>
</div>
</div>
<div class="section" id="apply-the-spatial-filter">
<h2>Apply the spatial filter<a class="headerlink" href="#apply-the-spatial-filter" title="Permalink to this headline">¶</a></h2>
<p>The spatial filter can be applied to different data types: raw, epochs,
evoked data or the data covariance matrix to gain a static image of power.
The function to apply the spatial filter to <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a> data is
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv()</span></code></a> which is
what we will use here. The other functions are
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_raw.html#mne.beamformer.apply_lcmv_raw" title="mne.beamformer.apply_lcmv_raw"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_raw()</span></code></a>,
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_epochs.html#mne.beamformer.apply_lcmv_epochs" title="mne.beamformer.apply_lcmv_epochs"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_epochs()</span></code></a>, and
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_cov.html#mne.beamformer.apply_lcmv_cov" title="mne.beamformer.apply_lcmv_cov"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_cov()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">max_ori_out</span><span class="o">=</span><span class="s1">&#39;signed&#39;</span><span class="p">)</span>
<span class="n">stc_vec</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a><span class="p">,</span> <span class="n">filters_vec</span><span class="p">,</span> <span class="n">max_ori_out</span><span class="o">=</span><span class="s1">&#39;signed&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">filters</span><span class="p">,</span> <span class="n">filters_vec</span>
</pre></div>
</div>
</div>
<div class="section" id="visualize-the-reconstructed-source-activity">
<h2>Visualize the reconstructed source activity<a class="headerlink" href="#visualize-the-reconstructed-source-activity" title="Permalink to this headline">¶</a></h2>
<p>We can visualize the source estimate in different ways, e.g. as a volume
rendering, an overlay onto the MRI, or as an overlay onto a glass brain.</p>
<p>The plots for the scalar beamformer show brain activity in the right temporal
lobe around 100 ms post stimulus. This is expected given the left-ear
auditory stimulation of the experiment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="p">,</span> <span class="n">subject</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
              <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.087</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="on-mri-slices-orthoview-2d">
<h3>On MRI slices (orthoview; 2D)<a class="headerlink" href="#on-mri-slices-orthoview-2d" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;stat_map&#39;</span><span class="p">,</span> <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">pos_lims</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_50_beamformer_lcmv_005.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_005.png" alt="50 beamformer lcmv" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Fixing initial time: 0.087 sec
Showing: t = 0.087 s, (50.7, 2.0, -13.3) mm, [18, 12, 9] vox, 5184 vertex
</pre></div>
</div>
</div>
<div class="section" id="on-mni-glass-brain-orthoview-2d">
<h3>On MNI glass brain (orthoview; 2D)<a class="headerlink" href="#on-mni-glass-brain-orthoview-2d" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;glass_brain&#39;</span><span class="p">,</span> <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_50_beamformer_lcmv_006.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_006.png" alt="50 beamformer lcmv" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Transforming subject RAS (non-zero origin) -&gt; MNI Talairach
     1.022485 -0.008449 -0.036217       5.60 mm
     0.071071  0.914866  0.406098     -19.82 mm
     0.008756 -0.433700  1.028119      -1.55 mm
     0.000000  0.000000  0.000000       1.00

Fixing initial time: 0.087 sec
Showing: t = 0.087 s, (57.9, -19.7, -15.6) mm, [18, 12, 9] vox, 5184 vertex
</pre></div>
</div>
</div>
<div class="section" id="volumetric-rendering-3d-with-vectors">
<h3>Volumetric rendering (3D) with vectors<a class="headerlink" href="#volumetric-rendering-3d-with-vectors" title="Permalink to this headline">¶</a></h3>
<p>These plots can also be shown using a volumetric rendering via
<a class="reference internal" href="../../generated/mne.VolVectorSourceEstimate.html#mne.VolVectorSourceEstimate.plot_3d" title="mne.VolVectorSourceEstimate.plot_3d"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_3d()</span></code></a>. Let’s try visualizing the
vector beamformer case. Here we get three source time courses out per voxel
(one for each component of the dipole moment: x, y, and z), which appear
as small vectors in the visualization (in the 2D plotters, only the
magnitude can be shown):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <span class="n">stc_vec</span><span class="o">.</span><span class="n">plot_3d</span><span class="p">(</span>
    <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span>
    <span class="n">views</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;coronal&#39;</span><span class="p">,</span> <span class="s1">&#39;sagittal&#39;</span><span class="p">,</span> <span class="s1">&#39;axial&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>
    <span class="n">view_layout</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span> <span class="n">show_traces</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
    <span class="n">brain_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">silhouette</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_50_beamformer_lcmv_007.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_007.png" alt="50 beamformer lcmv" class = "sphx-glr-single-img"/></div>
</div>
<div class="section" id="visualize-the-activity-of-the-maximum-voxel-with-all-three-components">
<h2>Visualize the activity of the maximum voxel with all three components<a class="headerlink" href="#visualize-the-activity-of-the-maximum-voxel-with-all-three-components" title="Permalink to this headline">¶</a></h2>
<p>We can also visualize all three components in the peak voxel. For this, we
will first find the peak voxel and then plot the time courses of this voxel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">peak_vox</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">_</span></a> <span class="o">=</span> <span class="n">stc_vec</span><span class="o">.</span><span class="n">get_peak</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><span class="mf">0.08</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">vert_as_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori_labels</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">]</span>
<a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">stc_vec</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">peak_vox</span></a><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori_labels</span></a><span class="p">):</span>
    <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">stc_vec</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> component&#39;</span> <span class="o">%</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.legend.html#matplotlib.axes.Axes.legend" title="matplotlib.axes.Axes.legend" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">legend</span></a><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.artist.Artist.set.html#matplotlib.artist.Artist.set" title="matplotlib.artist.Artist.set" class="sphx-glr-backref-module-matplotlib-artist sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set</span></a><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Activity per orientation in the peak voxel&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Time (s)&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Amplitude (a. u.)&#39;</span><span class="p">)</span>
<span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plt_show</span><span class="p">()</span>
<span class="k">del</span> <span class="n">stc_vec</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_50_beamformer_lcmv_008.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_008.png" alt="Activity per orientation in the peak voxel" class = "sphx-glr-single-img"/></div>
<div class="section" id="morph-the-output-to-fsaverage">
<h2>Morph the output to fsaverage<a class="headerlink" href="#morph-the-output-to-fsaverage" title="Permalink to this headline">¶</a></h2>
<p>We can also use volumetric morphing to get the data to fsaverage space. This
is for example necessary when comparing activity across subjects. Here, we
will use the scalar beamformer example.
We pass a <a class="reference internal" href="../../generated/mne.SourceMorph.html#mne.SourceMorph" title="mne.SourceMorph"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.SourceMorph</span></code></a> as the <code class="docutils literal notranslate"><span class="pre">src</span></code> argument to
<a class="reference internal" href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate.plot" title="mne.VolSourceEstimate.plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.VolSourceEstimate.plot</span></code></a>. To save some computational load when applying
the morph, we will crop the <code class="docutils literal notranslate"><span class="pre">stc</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">)</span>  <span class="c1"># ensure fsaverage src exists</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_fs_src</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">+</span> <span class="s1">&#39;/fsaverage/bem/fsaverage-vol-5-src.fif&#39;</span>

<a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a> <span class="o">=</span> <a href="../../generated/mne.read_source_spaces.html#mne.read_source_spaces" title="mne.read_source_spaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_source_spaces</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_fs_src</span></a><span class="p">)</span>
<a href="../../generated/mne.SourceMorph.html#mne.SourceMorph" title="mne.SourceMorph" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">morph</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_source_morph.html#mne.compute_source_morph" title="mne.compute_source_morph" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_source_morph</span></a><span class="p">(</span>
    <a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="p">,</span> <span class="n">subject_from</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span><span class="p">,</span> <span class="n">src_to</span><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
    <span class="n">niter_sdr</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">niter_affine</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>  <span class="c1"># just for speed</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stc_fs</span></a> <span class="o">=</span> <a href="../../generated/mne.SourceMorph.html#mne.SourceMorph.apply" title="mne.SourceMorph.apply" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">morph</span><span class="o">.</span><span class="n">apply</span></a><span class="p">(</span><span class="n">stc</span><span class="p">)</span>
<span class="k">del</span> <span class="n">stc</span>

<a href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate.plot" title="mne.VolSourceEstimate.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">stc_fs</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span>
    <a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;stat_map&#39;</span><span class="p">,</span> <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.085</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
    <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">pos_lims</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_50_beamformer_lcmv_009.png" srcset="../../_images/sphx_glr_50_beamformer_lcmv_009.png" alt="50 beamformer lcmv" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0 files missing from root.txt in /home/circleci/mne_data/MNE-sample-data/subjects
0 files missing from bem.txt in /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage
    Reading a source space...
    [done]
    1 source spaces read
Volume source space(s) present...
    Loading /home/circleci/mne_data/MNE-sample-data/subjects/sample/mri/brain.mgz as &quot;from&quot; volume
    Loading /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage/mri/brain.mgz as &quot;to&quot; volume
Computing registration...
Reslicing to zooms=(4.999999888241291, 4.999999888241291, 4.999999888241291) for translation ...
Optimizing translation:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
    Translation:   22.7 mm
    R²:            92.5%
Optimizing rigid:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
    Translation:    1.0 mm
    Rotation:      12.8°
    R²:            94.4%
Optimizing affine:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
    R²:            94.5%
Optimizing sdr:
    R²:            98.7%
[done]

  0%|          | Time : 0/16 [00:00&lt;?,       ?it/s]
  6%|6         | Time : 1/16 [00:00&lt;00:03,    4.78it/s]
 12%|#2        | Time : 2/16 [00:00&lt;00:03,    4.19it/s]
 19%|#8        | Time : 3/16 [00:00&lt;00:02,    4.71it/s]
 25%|##5       | Time : 4/16 [00:00&lt;00:02,    4.95it/s]
 31%|###1      | Time : 5/16 [00:00&lt;00:02,    5.06it/s]
 38%|###7      | Time : 6/16 [00:01&lt;00:01,    5.08it/s]
 44%|####3     | Time : 7/16 [00:01&lt;00:01,    5.11it/s]
 50%|#####     | Time : 8/16 [00:01&lt;00:01,    5.14it/s]
 56%|#####6    | Time : 9/16 [00:01&lt;00:01,    5.22it/s]
 62%|######2   | Time : 10/16 [00:01&lt;00:01,    5.29it/s]
 69%|######8   | Time : 11/16 [00:02&lt;00:00,    5.30it/s]
 75%|#######5  | Time : 12/16 [00:02&lt;00:00,    5.30it/s]
 81%|########1 | Time : 13/16 [00:02&lt;00:00,    5.33it/s]
 88%|########7 | Time : 14/16 [00:02&lt;00:00,    5.39it/s]
 94%|#########3| Time : 15/16 [00:02&lt;00:00,    5.42it/s]
100%|##########| Time : 16/16 [00:02&lt;00:00,    5.41it/s]
100%|##########| Time : 16/16 [00:02&lt;00:00,    5.34it/s]
Fixing initial time: 0.085 sec
Showing: t = 0.087 s, (50.0, -20.0, -15.0) mm, [26, 19, 12] vox, 16097 vertex
</pre></div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="vanveenetal1997"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Barry D. Van Veen, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki. Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. <em>IEEE Transactions on Biomedical Engineering</em>, 44(9):867–880, 1997. <a class="reference external" href="https://doi.org/10.1109/10.623056">doi:10.1109/10.623056</a>.</p>
</dd>
<dt class="label" id="grossetal2001"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Joachim Groß, Jan Kujala, Matti S. Hämäläinen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. <em>Proceedings of the National Academy of Sciences</em>, 98(2):694–699, 2001. <a class="reference external" href="https://doi.org/10.1073/pnas.98.2.694">doi:10.1073/pnas.98.2.694</a>.</p>
</dd>
<dt class="label" id="brookesetal2008"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Matthew J. Brookes, Jiri Vrba, Stephen E. Robinson, Claire M. Stevenson, Andrew M. Peters, Gareth R. Barnes, Arjan Hillebrand, and Peter G. Morris. Optimising experimental design for MEG beamformer imaging. <em>NeuroImage</em>, 39(4):1788–1802, 2008. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2007.09.050">doi:10.1016/j.neuroimage.2007.09.050</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 3 minutes  18.379 seconds)</p>
<p><strong>Estimated memory usage:</strong>  809 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-inverse-50-beamformer-lcmv-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ae471c67517152eafd903dfe6cd64f17/50_beamformer_lcmv.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">50_beamformer_lcmv.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c6baf7c1a2f53fda44e93271b91f45b8/50_beamformer_lcmv.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">50_beamformer_lcmv.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="40_mne_fixed_free.html" title="previous page">Computing various MNE solutions</a>
    <a class='right-next' id="next-link" href="60_visualize_stc.html" title="next page">Visualize source time courses (stcs)</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-07-27T09:25:20.429767+00:00" class="localized">2021-07-27 09:25 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>