
<!DOCTYPE html>


<html lang="en" data-content_root="../../" data-theme="auto">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Overview of MEG/EEG analysis with MNE-Python &#8212; MNE 1.12.0.dev8+g97cc9e90c documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "auto";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=4c2284e1" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=9de10e95"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=fd10adb8"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-5TBCPCRB6X"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_tutorials/intro/10_overview';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://mne.tools/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <script defer="defer" src="../../_static/js/custom-icons.js?v=8bbd8100"></script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Modifying data in-place" href="15_inplace.html" />
    <link rel="prev" title="Introductory tutorials" href="index.html" />
    <link rel="canonical" href="https://mne.tools/stable/auto_tutorials/intro/10_overview.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.12" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="auto">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-light" alt="MNE 1.12.0.dev8+g97cc9e90c documentation - Home"/>
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-dark pst-js-only" alt="MNE 1.12.0.dev8+g97cc9e90c documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../help/index.html">
    Get Help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord (office hours)" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord (office hours)</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Q&A Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Q&A Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="Code Repository" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Code Repository</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sponsors/mne-tools" title="Sponsor us on GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-regular fa-heart fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Sponsor us on GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://opencollective.com/mne-python" title="Donate via OpenCollective" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-opencollective fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Donate via OpenCollective</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../help/index.html">
    Get Help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord (office hours)" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord (office hours)</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Q&A Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Q&A Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="Code Repository" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Code Repository</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/sponsors/mne-tools" title="Sponsor us on GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-regular fa-heart fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Sponsor us on GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://opencollective.com/mne-python" title="Donate via OpenCollective" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-opencollective fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Donate via OpenCollective</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="index.html">Introductory tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Overview of MEG/EEG analysis with MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="15_inplace.html">Modifying data in-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="20_events_from_raw.html">Parsing events from raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="30_info.html">The Info data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="40_sensor_locations.html">Working with sensor locations</a></li>
<li class="toctree-l3"><a class="reference internal" href="50_configure_mne.html">Configuring MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="70_report.html">Getting started with mne.Report</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../io/index.html">Reading data for different recording systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../io/10_reading_meg_data.html">Importing data from MEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../io/20_reading_eeg_data.html">Importing data from EEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../io/30_reading_fnirs_data.html">Importing data from fNIRS devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../io/60_ctf_bst_auditory.html">Working with CTF data: the Brainstorm auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../io/70_reading_eyetracking_data.html">Importing Data from Eyetracking devices</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../raw/index.html">Working with continuous data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../raw/10_raw_overview.html">The Raw data structure: continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../raw/20_event_arrays.html">Working with events</a></li>
<li class="toctree-l3"><a class="reference internal" href="../raw/30_annotate_raw.html">Annotating continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../raw/40_visualize_raw.html">Built-in plotting methods for Raw objects</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/10_preprocessing_overview.html">Overview of artifact detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/15_handling_bad_channels.html">Handling bad channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/20_rejecting_bad_data.html">Rejecting bad data spans and breaks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/25_background_filtering.html">Background information on filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/30_filtering_resampling.html">Filtering and resampling data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/35_artifact_correction_regression.html">Repairing artifacts with regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html">Repairing artifacts with ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/45_projectors_background.html">Background on projectors and projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/50_artifact_correction_ssp.html">Repairing artifacts with SSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/55_setting_eeg_reference.html">Setting the EEG reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/59_head_positions.html">Extracting and visualizing subject head movement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/60_maxwell_filtering_sss.html">Signal-space separation (SSS) and Maxwell filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/70_fnirs_processing.html">Preprocessing functional near-infrared spectroscopy (fNIRS) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/80_opm_processing.html">Preprocessing optically pumped magnetometer (OPM) MEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../preprocessing/90_eyetracking_data.html">Working with eye tracker data in MNE-Python</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../epochs/index.html">Segmenting continuous data into epochs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../epochs/10_epochs_overview.html">The Epochs data structure: discontinuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/15_baseline_regression.html">Regression-based baseline correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/20_visualize_epochs.html">Visualizing epoched data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/30_epochs_metadata.html">Working with Epoch metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/40_autogenerate_metadata.html">Auto-generating Epochs metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">Exporting Epochs to Pandas DataFrames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">Divide continuous data into equally-spaced epochs</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../evoked/index.html">Estimating evoked responses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../evoked/10_evoked_overview.html">The Evoked data structure: evoked/averaged data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../evoked/20_visualize_evoked.html">Visualizing Evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../evoked/30_eeg_erp.html">EEG analysis - Event-Related Potentials (ERPs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../evoked/40_whitened.html">Plotting whitened data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../time-freq/index.html">Time-frequency analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../time-freq/10_spectrum_class.html">The Spectrum and EpochsSpectrum classes: frequency-domain data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">Frequency and time-frequency sensor analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../time-freq/50_ssvep.html">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../forward/index.html">Forward models and source spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../forward/10_background_freesurfer.html">FreeSurfer MRI reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/20_source_alignment.html">Source alignment and coordinate frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/25_automated_coreg.html">Using an automated approach to coregistration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/30_forward.html">Head model and forward computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/35_eeg_no_mri.html">EEG forward operator with a template MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/50_background_freesurfer_mne.html">How MNE uses FreeSurferâ€™s outputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/80_fix_bem_in_blender.html">Fixing BEM and head surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../forward/90_compute_covariance.html">Computing a covariance matrix</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../inverse/index.html">Source localization and inverses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../inverse/10_stc_class.html">The SourceEstimate data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/20_dipole_fit.html">Source localization with equivalent current dipole (ECD) fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/30_mne_dspm_loreta.html">Source localization with MNE, dSPM, sLORETA, and eLORETA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/35_dipole_orientations.html">The role of dipole orientations in distributed source localization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/40_mne_fixed_free.html">Computing various MNE solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/50_beamformer_lcmv.html">Source reconstruction using an LCMV beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/60_visualize_stc.html">Visualize source time courses (stcs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/70_eeg_mri_coords.html">EEG source localization given electrode locations on an MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/80_brainstorm_phantom_elekta.html">Brainstorm Elekta phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/85_brainstorm_phantom_ctf.html">Brainstorm CTF phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/90_phantom_4DBTi.html">4D Neuroimaging/BTi phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../inverse/95_phantom_KIT.html">KIT phantom dataset tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../stats-sensor-space/index.html">Statistical analysis of sensor data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/10_background_stats.html">Statistical inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">Visualising statistical significance thresholds on EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">Non-parametric 1 sample cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">Non-parametric between conditions cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/70_cluster_rmANOVA_time_freq.html">Mass-univariate twoway repeated measures ANOVA on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">Spatiotemporal permutation F-test on full sensor data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../stats-source-space/index.html">Statistical analysis of source estimates</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">Permutation t-test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">2 samples permutation test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">Repeated measures ANOVA on source data with spatio-temporal clustering</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../machine-learning/index.html">Machine learning models of neural activity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../machine-learning/30_strf.html">Spectro-temporal receptive field (STRF) estimation on continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../machine-learning/50_decoding.html">Decoding (MVPA)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../clinical/index.html">Clinical applications</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../clinical/20_seeg.html">Working with sEEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../clinical/30_ecog.html">Working with ECoG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../clinical/60_sleep.html">Sleep stage classification from polysomnography (PSG) data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../simulation/index.html">Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../simulation/10_array_objs.html">Creating MNE-Python data structures from scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../simulation/70_point_spread.html">Corrupt known signal with point spread</a></li>
<li class="toctree-l3"><a class="reference internal" href="../simulation/80_dics.html">DICS for power mapping</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../visualization/index.html">Visualization tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../visualization/10_publication_figure.html">Make figures more publication ready</a></li>
<li class="toctree-l3"><a class="reference internal" href="../visualization/20_ui_events.html">Using the event system to link figures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../auto_examples/index.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/io/index.html">Input/Output</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">Getting averaging info from .fif files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/io/read_impedances.html">Getting impedances from raw files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/io/read_neo_format.html">How to use data in neural ensemble (NEO) format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">Reading/Writing a noise covariance matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/io/read_xdf.html">Reading XDF EEG data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/simulation/index.html">Data Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/simulation/plot_stc_metrics.html">Compare simulated and estimated source activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">Generate simulated evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">Generate simulated raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">Simulate raw data using subject anatomy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">Generate simulated source data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/contralateral_referencing.html">Using contralateral referencing for EEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/css.html">Cortical Signal Suppression (CSS) for removal of cortical signals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">Define target events based on time lag, plot evoked response</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/eeg_bridging.html">Identify EEG Electrodes Bridged by too much Gel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">Transform EEG data using current source density (CSD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">Show EOG artifact timing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/eog_regression.html">Reduce EOG artifacts through regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/epochs_metadata.html">Automated epochs metadata generation with variable time windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/esg_rm_heart_artefact_pcaobs.html">Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">Find MEG reference channel artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">Visualise NIRS artifact correction methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">Compare the different ICA algorithms in MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">Interpolate bad channels for MEG/EEG channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/interpolate_to.html">Interpolate EEG data to any montage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">Maxwell filter data with movement compensation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">Annotate movement artifacts and reestimate dev_head_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">Annotate muscle artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/muscle_ica.html">Removing muscle ICA components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/otp.html">Plot sensor denoising using oversampled temporal projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">Shifting time-scale in evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">Remap MEG channel types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">XDAWN Denoising</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/visualization/index.html">Visualization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">How to convert 3D electrode positions to a 2D image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/brain.html">Plotting with <code class="docutils literal notranslate"><span class="pre">mne.viz.Brain</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">Visualize channel over epochs as an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">Plotting EEG sensors on the scalp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">Plotting topographic arrowmaps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">Plotting topographic maps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">Whitening evoked data with a noise covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/eyetracking_plot_heatmap.html">Plotting eye-tracking heatmaps in MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">Plotting sensor layouts of MEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">Plot the MNE brain and helmet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">Plotting sensor layouts of EEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/parcellation.html">Plot a cortical parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">Plot single trial activity, grouped by ROI and sorted by RT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">Sensitivity map of SSP projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">Compare evoked responses for different conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">Plot custom topographies for MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/visualization/xhemi.html">Cross-hemisphere comparison</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/time_frequency/index.html">Time-Frequency Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">Compute a cross-spectral density (CSD) matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">Compute Power Spectral Density of inverse solution from single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">Compute power and phase lock in label of the source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">Compute source power spectral density (PSD) in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">Compute source power spectral density (PSD) of VectorView and OPM data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">Compute induced power in the source space with dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">Temporal whitening with AR model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">Compute and visualize ERDS maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">Explore event-related dynamics for specific frequency bands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/stats/index.html">Statistics Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">Permutation F-test on sensor data with 1D cluster level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">FDR correction on T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">Regression on continuous data (rER[P/F])</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">Permutation T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">Analysing continuous features with binning and regression in sensor space</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/decoding/index.html">Machine Learning (Decoding, Encoding, and MVPA)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">Decoding in time-frequency space using Common Spatial Patterns (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">Representational Similarity Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">Decoding source space data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">Continuous Target Decoding with SPoC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">Decoding sensor space data with generalization across time and conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">Analysis of evoked response using ICA and PCA reduction techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">XDAWN Decoding From EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">Compute effect-matched-spatial filtering (EMS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">Linear classifier on sensor data with plot patterns and filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">Receptive Field Estimation and Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">Compute spatial filters with Spatio-Spectral Decomposition (SSD)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../auto_examples/connectivity/index.html">Connectivity Analysis Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/forward/index.html">Forward modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">Display sensitivity maps for EEG and MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">Generate a left cerebellum volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">Use source space morphing</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/inverse/index.html">Inverse problem and source analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">Compute MNE-dSPM inverse solution on single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">Compute sLORETA inverse solution on raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">Compute MNE-dSPM inverse solution on evoked data in volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">Source localization with a custom inverse solver</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/dics_epochs.html">Compute source level time-frequency timecourses using a DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">Compute source power using DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">Extracting time course from source_estimate object</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">Generate a functional label from source estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">Extracting the time series of activations in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">Compute MNE inverse solution on evoked data with a mixed source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">Compute source power estimate by projecting the covariance with MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">Morph surface source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">Morph volumetric source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/multi_dipole_model.html">Computing source timecourses with an XFit-like multi-dipole model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">Visualize source leakage among labels using a circular graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">Compute cross-talk functions for LCMV beamformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/psf_volume.html">Plot point-spread functions (PSFs) for a volume</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/rap_music.html">Compute Rap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">Reading an inverse operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/read_stc.html">Reading an STC file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">Compute spatial resolution metrics in source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">Compute spatial resolution metrics to compare MEG with EEG+MEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">Estimate data SNR using an inverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">Computing source space SNR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">Compute MxNE with time-frequency sparse prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/trap_music.html">Compute Trap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">Plotting the full vector-valued MNE solution</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../auto_examples/datasets/index.html">Examples on open datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">Brainstorm raw (median nerve) dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">HF-SEF dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/kernel_phantom.html">Kernel OPM phantom data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/limo_data.html">Single trial linear regression analysis with the LIMO dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/opm_data.html">Optically pumped magnetometer (OPM) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset.html">From raw data to dSPM on SPM Faces dataset</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/implementation.html">Implementation details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/design_philosophy.html">Design philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/datasets.html">Example datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generated/commands.html">Command-line tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../help/migrating.html">Migrating from other analysis software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/cookbook.html">The typical M/EEG workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/cite.html">How to cite MNE-Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../documentation/cited.html">Papers citing MNE-Python</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-tutorials-intro-10-overview-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="overview-of-meg-eeg-analysis-with-mne-python">
<span id="tut-overview"></span><span id="sphx-glr-auto-tutorials-intro-10-overview-py"></span><h1>Overview of MEG/EEG analysis with MNE-Python<a class="headerlink" href="#overview-of-meg-eeg-analysis-with-mne-python" title="Link to this heading">#</a></h1>
<p>This tutorial covers the basic EEG/MEG pipeline for event-related analysis: loading
data, epoching, averaging, plotting, and estimating cortical activity from sensor data.
It introduces the core MNE-Python data structures <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a>,
<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Evoked</span></code></a>, and <a class="reference internal" href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, and covers a lot of ground fairly quickly (at
the expense of depth). Subsequent tutorials address each of these topics in greater
detail.</p>
<p>We begin by importing the necessary Python modules:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: The MNE-Python contributors.</span>
<span class="c1"># License: BSD-3-Clause</span>
<span class="c1"># Copyright the MNE-Python contributors.</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">mne</span>
</pre></div>
</div>
<section id="loading-data">
<h2>Loading data<a class="headerlink" href="#loading-data" title="Link to this heading">#</a></h2>
<p>MNE-Python data structures are based around the FIF file format from
Neuromag, but there are reader functions for <a class="reference internal" href="../../documentation/implementation.html#data-formats"><span class="std std-ref">a wide variety of other
data formats</span></a>. MNE-Python also has interfaces to a
variety of <a class="reference internal" href="../../documentation/datasets.html#datasets"><span class="std std-ref">publicly available datasets</span></a>, which MNE-Python
can download and manage for you.</p>
<p>Weâ€™ll start this tutorial by loading one of the example datasets (called
â€œ<a class="reference internal" href="../../documentation/datasets.html#sample-dataset"><span class="std std-ref">Sample</span></a>â€), which contains EEG and MEG data from one subject
performing an audiovisual experiment, along with structural MRI scans for
that subject. The <a class="reference internal" href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.datasets.sample.data_path</span></code></a> function will automatically
download the dataset if it isnâ€™t found in one of the expected locations, then
return the directory path to the dataset (see the documentation of
<a class="reference internal" href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">data_path</span></code></a> for a list of places it checks before
downloading). Note also that for this tutorial to run smoothly on our
servers, weâ€™re using a filtered and downsampled version of the data
(<code class="file docutils literal notranslate"><span class="pre">sample_audvis_filt-0-40_raw.fif</span></code>), but an unfiltered version
(<code class="file docutils literal notranslate"><span class="pre">sample_audvis_raw.fif</span></code>) is also included in the sample dataset and
could be substituted here when running the tutorial locally.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a> <span class="o">=</span> <span class="p">(</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">/</span> <span class="s2">&quot;MEG&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_audvis_filt-0-40_raw.fif&quot;</span>
<span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
</pre></div>
</div>
<p>By default, <a class="reference internal" href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read_raw_fif</span></code></a> displays some information about the file
itâ€™s loading; for example, here it tells us that there are four â€œprojection
itemsâ€ in the file along with the recorded data; those are <a class="reference internal" href="../../documentation/glossary.html#term-projector"><span class="xref std std-term">SSP
projectors</span></a> calculated to remove environmental noise from the MEG
signals, plus a projector to mean-reference the EEG channels; these are
discussed in the tutorial <a class="reference internal" href="../preprocessing/45_projectors_background.html#tut-projectors-background"><span class="std std-ref">Background on projectors and projections</span></a>. In addition to
the information displayed during loading, you can get a glimpse of the basic
details of a <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object by printing it; even more is available by
printing its <code class="docutils literal notranslate"><span class="pre">info</span></code> attribute (a <a class="reference internal" href="../../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dictionary-like</span> <span class="pre">object</span></code></a> that
is preserved across <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a>, and <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Evoked</span></code></a> objects).
The <code class="docutils literal notranslate"><span class="pre">info</span></code> data structure keeps track of channel locations, applied
filters, projectors, etc. Notice especially the <code class="docutils literal notranslate"><span class="pre">chs</span></code> entry, showing that
MNE-Python detects different sensor types and handles each appropriately. See
<a class="reference internal" href="30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for more on the <a class="reference internal" href="../../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Info</span></code></a> class.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;Raw | sample_audvis_filt-0-40_raw.fif, 376 x 41700 (277.7 s), ~3.2 MiB, data not loaded&gt;
&lt;Info | 15 non-empty values
 bads: 2 items (MEG 2443, EEG 053)
 ch_names: MEG 0113, MEG 0112, MEG 0111, MEG 0122, MEG 0123, MEG 0121, MEG ...
 chs: 204 Gradiometers, 102 Magnetometers, 9 Stimulus, 60 EEG, 1 EOG
 custom_ref_applied: False
 dev_head_t: MEG device -&gt; head transform
 dig: 146 items (3 Cardinal, 4 HPI, 61 EEG, 78 Extra)
 file_id: 4 items (dict)
 highpass: 0.1 Hz
 hpi_meas: 1 item (list)
 hpi_results: 1 item (list)
 lowpass: 40.0 Hz
 meas_date: 2002-12-03 19:01:10 UTC
 meas_id: 4 items (dict)
 nchan: 376
 projs: PCA-v1: off, PCA-v2: off, PCA-v3: off, Average EEG reference: off
 sfreq: 150.2 Hz
&gt;
</pre></div>
</div>
<p><a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects also have several built-in plotting methods; here we
show the power spectral density (PSD) for each sensor type with
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.compute_psd" title="mne.io.Raw.compute_psd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_psd</span></code></a>, as well as a plot of the raw sensor traces with
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.plot" title="mne.io.Raw.plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code></a>. In the PSD plot, weâ€™ll only plot frequencies below 50 Hz
(since our data are low-pass filtered at 40 Hz). In interactive Python
sessions, <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.plot" title="mne.io.Raw.plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code></a> is interactive and allows scrolling, scaling,
bad channel marking, annotations, projector toggling, etc.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">raw</span><span class="o">.</span><span class="n">compute_psd</span><span class="p">(</span><span class="n">fmax</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">picks</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s2">&quot;bads&quot;</span><span class="p">,</span> <span class="n">amplitude</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_channels</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_10_overview_001.png" srcset="../../_images/sphx_glr_10_overview_001.png" alt="EEG, Gradiometers, Magnetometers" class = "sphx-glr-single-img"/><img src="../../_images/sphx_glr_10_overview_002.png" srcset="../../_images/sphx_glr_10_overview_002.png" alt="Raw plot" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Effective window size : 13.639 (s)
Plotting power spectral density (dB=True).
Using qt as 2D backend.
</pre></div>
</div>
</section>
<section id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Link to this heading">#</a></h2>
<p>MNE-Python supports a variety of preprocessing approaches and techniques
(maxwell filtering, signal-space projection, independent components analysis,
filtering, downsampling, etc); see the full list of capabilities in the
<a class="reference internal" href="../../api/preprocessing.html#module-mne.preprocessing" title="mne.preprocessing"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.preprocessing</span></code></a> and <a class="reference internal" href="../../api/preprocessing.html#module-mne.filter" title="mne.filter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.filter</span></code></a> submodules. Here weâ€™ll clean
up our data by performing independent components analysis
(<a class="reference internal" href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA" title="mne.preprocessing.ICA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ICA</span></code></a>); for brevity weâ€™ll skip the steps that helped us
determined which components best capture the artifacts (see
<a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html#tut-artifact-ica"><span class="std std-ref">Repairing artifacts with ICA</span></a> for a detailed walk-through of that process).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up and fit the ICA</span>
<a href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA" title="mne.preprocessing.ICA" class="sphx-glr-backref-module-mne-preprocessing sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ica</span></a> <span class="o">=</span> <a href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA" title="mne.preprocessing.ICA" class="sphx-glr-backref-module-mne-preprocessing sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">ICA</span></a><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">97</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<a href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.fit" title="mne.preprocessing.ICA.fit" class="sphx-glr-backref-module-mne-preprocessing sphx-glr-backref-type-py-method"><span class="n">ica</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><span class="n">raw</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ica</span><span class="o">.</span><span class="n">exclude</span></a> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># details on how we picked these are omitted here</span>
<a href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.plot_properties" title="mne.preprocessing.ICA.plot_properties" class="sphx-glr-backref-module-mne-preprocessing sphx-glr-backref-type-py-method"><span class="n">ica</span><span class="o">.</span><span class="n">plot_properties</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="n">picks</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ica</span><span class="o">.</span><span class="n">exclude</span></a><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_10_overview_003.png" srcset="../../_images/sphx_glr_10_overview_003.png" alt="ICA001 (mag), Segment image and ERP/ERF, Spectrum, Dropped segments: 0.00 %" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_004.png" srcset="../../_images/sphx_glr_10_overview_004.png" alt="ICA002 (mag), Segment image and ERP/ERF, Spectrum, Dropped segments: 0.00 %" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Fitting ICA to data using 364 channels (please be patient, this may take a while)
Selecting by number: 20 components
Fitting ICA took 2.4s.
    Using multitaper spectrum estimation with 7 DPSS windows
Not setting metadata
138 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
138 matching events found
No baseline correction applied
0 projection items activated
</pre></div>
</div>
<p>Once weâ€™re confident about which component(s) we want to remove, we pass them
as the <code class="docutils literal notranslate"><span class="pre">exclude</span></code> parameter and then apply the ICA to the raw signal. The
<a class="reference internal" href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.apply" title="mne.preprocessing.ICA.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a> method requires the raw data to be loaded into
memory (by default itâ€™s only read from disk as-needed), so weâ€™ll use
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.load_data" title="mne.io.Raw.load_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_data</span></code></a> first. Weâ€™ll also make a copy of the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a>
object so we can compare the signal before and after artifact removal
side-by-side:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">orig_raw</span></a> <span class="o">=</span> <span class="n">raw</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">raw</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<a href="../../generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.apply" title="mne.preprocessing.ICA.apply" class="sphx-glr-backref-module-mne-preprocessing sphx-glr-backref-type-py-method"><span class="n">ica</span><span class="o">.</span><span class="n">apply</span></a><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

<span class="c1"># show some frontal channels to clearly illustrate the artifact removal</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;MEG 0111&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0121&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0131&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0211&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0221&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0231&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0311&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0321&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 0331&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 1511&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 1521&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MEG 1531&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 001&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 002&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 003&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 004&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 005&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 006&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 007&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EEG 008&quot;</span><span class="p">,</span>
<span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chan_idxs</span></a> <span class="o">=</span> <span class="p">[</span><span class="n">raw</span><span class="o">.</span><span class="n">ch_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs</span></a><span class="p">]</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.plot" title="mne.io.Raw.plot" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">orig_raw</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">order</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chan_idxs</span></a><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chan_idxs</span></a><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_10_overview_005.png" srcset="../../_images/sphx_glr_10_overview_005.png" alt="Raw plots" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_006.png" srcset="../../_images/sphx_glr_10_overview_006.png" alt="Raw plots" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading 0 ... 41699  =      0.000 ...   277.709 secs...
Applying ICA to Raw instance
    Transforming to ICA space (20 components)
    Zeroing out 2 ICA components
    Projecting back using 364 PCA components
</pre></div>
</div>
</section>
<section id="detecting-experimental-events">
<span id="overview-tut-events-section"></span><h2>Detecting experimental events<a class="headerlink" href="#detecting-experimental-events" title="Link to this heading">#</a></h2>
<p>The sample dataset includes several <a class="reference internal" href="../../documentation/glossary.html#term-stim-channel"><span class="xref std std-term">â€œSTIMâ€ channels</span></a>
that recorded electrical signals sent from the stimulus delivery computer (as
brief DC shifts / squarewave pulses). These pulses (often called â€œtriggersâ€)
are used in this dataset to mark experimental events: stimulus onset,
stimulus type, and participant response (button press). The individual STIM
channels are combined onto a single channel, in such a way that voltage
levels on that channel can be unambiguously decoded as a particular event
type. On older Neuromag systems (such as that used to record the sample data)
this summation channel was called <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code>, so we can pass that channel
name to the <a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.find_events</span></code></a> function to recover the timing and identity of
the stimulus events.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="n">stim_channel</span><span class="o">=</span><span class="s2">&quot;STI 014&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>  <span class="c1"># show the first 5</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Finding events on: STI 014
319 events found on stim channel STI 014
Event IDs: [ 1  2  3  4  5 32]
[[6994    0    2]
 [7086    0    3]
 [7192    0    1]
 [7304    0    4]
 [7413    0    2]]
</pre></div>
</div>
<p>The resulting events array is an ordinary 3-column <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NumPy</span> <span class="pre">array</span></code></a>, with sample number in the first column and integer event ID
in the last column; the middle column is usually ignored. Rather than keeping
track of integer event IDs, we can provide an <em>event dictionary</em> that maps
the integer IDs to experimental conditions or events. In this dataset, the
mapping looks like this:</p>
<div class="pst-scrollable-table-container"><table class="table" id="sample-data-event-dict-table">
<thead>
<tr class="row-odd"><th class="head"><p>Event ID</p></th>
<th class="head"><p>Condition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>auditory stimulus (tone) to the left ear</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>auditory stimulus (tone) to the right ear</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>visual stimulus (checkerboard) to the left visual field</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>visual stimulus (checkerboard) to the right visual field</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>smiley face (catch trial)</p></td>
</tr>
<tr class="row-odd"><td><p>32</p></td>
<td><p>subject button press</p></td>
</tr>
</tbody>
</table>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;auditory/left&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;auditory/right&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;visual/left&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s2">&quot;visual/right&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;smiley&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;buttonpress&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Event dictionaries like this one are used when extracting epochs from
continuous data; the <code class="docutils literal notranslate"><span class="pre">/</span></code> character in the dictionary keys allows pooling
across conditions by requesting partial condition descriptors (i.e.,
requesting <code class="docutils literal notranslate"><span class="pre">'auditory'</span></code> will select all epochs with Event IDs 1 and 2;
requesting <code class="docutils literal notranslate"><span class="pre">'left'</span></code> will select all epochs with Event IDs 1 and 3). An
example of this is shown in the next section. There is also a convenient
<a class="reference internal" href="../../generated/mne.viz.plot_events.html#mne.viz.plot_events" title="mne.viz.plot_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_events</span></code></a> function for visualizing the distribution of events
across the duration of the recording (to make sure event detection worked as
expected). Here we will also make use of the <a class="reference internal" href="../../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Info</span></code></a> attribute to get the
sampling frequency of the recording (so our x-axis will be in seconds instead
of in samples).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="../../generated/mne.viz.plot_events.html#mne.viz.plot_events" title="mne.viz.plot_events" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_events</span></a><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <span class="n">event_id</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a><span class="p">,</span> <span class="n">sfreq</span><span class="o">=</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;sfreq&quot;</span><span class="p">],</span> <span class="n">first_samp</span><span class="o">=</span><span class="n">raw</span><span class="o">.</span><span class="n">first_samp</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_10_overview_007.png" srcset="../../_images/sphx_glr_10_overview_007.png" alt="10 overview" class = "sphx-glr-single-img"/><p>For paradigms that are not event-related (e.g., analysis of resting-state
data), you can extract regularly spaced (possibly overlapping) spans of data
by creating events using <a class="reference internal" href="../../generated/mne.make_fixed_length_events.html#mne.make_fixed_length_events" title="mne.make_fixed_length_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.make_fixed_length_events</span></code></a> and then proceeding
with epoching as described in the next section.</p>
</section>
<section id="epoching-continuous-data">
<span id="tut-section-overview-epoching"></span><h2>Epoching continuous data<a class="headerlink" href="#epoching-continuous-data" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object and the events array are the bare minimum needed to
create an <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> object, which we create with the <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> class
constructor. Here weâ€™ll also specify some data quality constraints: weâ€™ll
reject any epoch where peak-to-peak signal amplitude is beyond reasonable
limits for that channel type. This is done with a <em>rejection dictionary</em>; you
may include or omit thresholds for any of the channel types present in your
data. The values given here are reasonable for this particular dataset, but
may need to be adapted for different hardware or recording conditions. For a
more automated approach, consider using the <a class="reference external" href="http://autoreject.github.io/">autoreject package</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reject_criteria</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">mag</span><span class="o">=</span><span class="mf">4000e-15</span><span class="p">,</span>  <span class="c1"># 4000 fT</span>
    <span class="n">grad</span><span class="o">=</span><span class="mf">4000e-13</span><span class="p">,</span>  <span class="c1"># 4000 fT/cm</span>
    <span class="n">eeg</span><span class="o">=</span><span class="mf">150e-6</span><span class="p">,</span>  <span class="c1"># 150 ÂµV</span>
    <span class="n">eog</span><span class="o">=</span><span class="mf">250e-6</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># 250 ÂµV</span>
</pre></div>
</div>
<p>Weâ€™ll also pass the event dictionary as the <code class="docutils literal notranslate"><span class="pre">event_id</span></code> parameter (so we can
work with easy-to-pool event labels instead of the integer event IDs), and
specify <code class="docutils literal notranslate"><span class="pre">tmin</span></code> and <code class="docutils literal notranslate"><span class="pre">tmax</span></code> (the time relative to each event at which to
start and end each epoch). As mentioned above, by default <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> and
<a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> data arenâ€™t loaded into memory (theyâ€™re accessed from disk only
when needed), but here weâ€™ll force loading into memory using the
<code class="docutils literal notranslate"><span class="pre">preload=True</span></code> parameter so that we can see the results of the rejection
criteria being applied:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span>
    <span class="n">raw</span><span class="p">,</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span>
    <span class="n">event_id</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a><span class="p">,</span>
    <span class="n">tmin</span><span class="o">=-</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">tmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">reject</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reject_criteria</span></a><span class="p">,</span>
    <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Not setting metadata
319 matching events found
Setting baseline interval to [-0.19979521315838786, 0.0] s
Applying baseline correction (mode: mean)
Created an SSP operator (subspace dimension = 4)
4 projection items activated
Using data from preloaded Raw for 319 events and 106 original time points ...
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on MAG : [&#39;MEG 1711&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on MAG : [&#39;MEG 1711&#39;]
    Rejecting  epoch based on EEG : [&#39;EEG 008&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
10 bad epochs dropped
</pre></div>
</div>
<p>Next weâ€™ll pool across left/right stimulus presentations so we can compare
auditory versus visual responses. To avoid biasing our signals to the left or
right, weâ€™ll use <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs.equalize_event_counts" title="mne.Epochs.equalize_event_counts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">equalize_event_counts</span></code></a> first to randomly sample
epochs from each condition to match the number of epochs present in the
condition with the fewest good epochs.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conds_we_care_about</span></a> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;auditory/left&quot;</span><span class="p">,</span> <span class="s2">&quot;auditory/right&quot;</span><span class="p">,</span> <span class="s2">&quot;visual/left&quot;</span><span class="p">,</span> <span class="s2">&quot;visual/right&quot;</span><span class="p">]</span>
<span class="n">epochs</span><span class="o">.</span><span class="n">equalize_event_counts</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conds_we_care_about</span></a><span class="p">)</span>  <span class="c1"># this operates in-place</span>
<a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">aud_epochs</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="p">[</span><span class="s2">&quot;auditory&quot;</span><span class="p">]</span>
<a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vis_epochs</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="p">[</span><span class="s2">&quot;visual&quot;</span><span class="p">]</span>
<span class="k">del</span> <span class="n">raw</span><span class="p">,</span> <span class="n">epochs</span>  <span class="c1"># free up memory</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Dropped 7 epochs: 121, 195, 258, 271, 273, 274, 275
</pre></div>
</div>
<p>Like <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects, <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> objects also have a number of
built-in plotting methods. One is <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs.plot_image" title="mne.Epochs.plot_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_image</span></code></a>, which shows each
epoch as one row of an image map, with color representing signal magnitude;
the average evoked response and the sensor location are shown below the
image:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.Epochs.html#mne.Epochs.plot_image" title="mne.Epochs.plot_image" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">aud_epochs</span><span class="o">.</span><span class="n">plot_image</span></a><span class="p">(</span><span class="n">picks</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;MEG 1332&quot;</span><span class="p">,</span> <span class="s2">&quot;EEG 021&quot;</span><span class="p">])</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_10_overview_008.png" srcset="../../_images/sphx_glr_10_overview_008.png" alt="MEG 1332, fT/cm" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_009.png" srcset="../../_images/sphx_glr_10_overview_009.png" alt="EEG 021, ÂµV" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Not setting metadata
136 matching events found
No baseline correction applied
0 projection items activated
Not setting metadata
136 matching events found
No baseline correction applied
0 projection items activated
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> and <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> objects have <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs.get_data" title="mne.Epochs.get_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_data</span></code></a>
methods that return the underlying data as a
<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NumPy</span> <span class="pre">array</span></code></a>. Both methods have a <code class="docutils literal notranslate"><span class="pre">picks</span></code>
parameter for subselecting which channel(s) to return; <code class="docutils literal notranslate"><span class="pre">raw.get_data()</span></code>
has additional parameters for restricting the time domain. The resulting
matrices have dimension <code class="docutils literal notranslate"><span class="pre">(n_channels,</span> <span class="pre">n_times)</span></code> for <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> and
<code class="docutils literal notranslate"><span class="pre">(n_epochs,</span> <span class="pre">n_channels,</span> <span class="pre">n_times)</span></code> for <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a>.</p>
</div>
</section>
<section id="time-frequency-analysis">
<h2>Time-frequency analysis<a class="headerlink" href="#time-frequency-analysis" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="../../api/time_frequency.html#module-mne.time_frequency" title="mne.time_frequency"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.time_frequency</span></code></a> submodule provides implementations of several
algorithms to compute time-frequency representations, power spectral density,
and cross-spectral density. Here, for example, weâ€™ll compute for the auditory
epochs the induced power at different frequencies and times, using Morlet
wavelets. On this dataset the result is not especially informative (it just
shows the evoked â€œauditory N100â€ response); see <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html#inter-trial-coherence"><span class="std std-ref">here</span></a> for a more extended example on a dataset with richer
frequency content.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frequencies</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a href="../../generated/mne.time_frequency.AverageTFR.html#mne.time_frequency.AverageTFR" title="mne.time_frequency.AverageTFR" class="sphx-glr-backref-module-mne-time_frequency sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">power</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs.compute_tfr" title="mne.Epochs.compute_tfr" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">aud_epochs</span><span class="o">.</span><span class="n">compute_tfr</span></a><span class="p">(</span>
    <span class="s2">&quot;morlet&quot;</span><span class="p">,</span> <span class="n">n_cycles</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_itc</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">freqs</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frequencies</span></a><span class="p">,</span> <span class="n">decim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<a href="../../generated/mne.time_frequency.AverageTFR.html#mne.time_frequency.AverageTFR.plot" title="mne.time_frequency.AverageTFR.plot" class="sphx-glr-backref-module-mne-time_frequency sphx-glr-backref-type-py-method"><span class="n">power</span><span class="o">.</span><span class="n">plot</span></a><span class="p">([</span><span class="s2">&quot;MEG 1332&quot;</span><span class="p">])</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_10_overview_010.png" srcset="../../_images/sphx_glr_10_overview_010.png" alt="10 overview" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No baseline correction applied
</pre></div>
</div>
</section>
<section id="estimating-evoked-responses">
<h2>Estimating evoked responses<a class="headerlink" href="#estimating-evoked-responses" title="Link to this heading">#</a></h2>
<p>Now that we have our conditions in <code class="docutils literal notranslate"><span class="pre">aud_epochs</span></code> and <code class="docutils literal notranslate"><span class="pre">vis_epochs</span></code>, we can
get an estimate of evoked responses to auditory versus visual stimuli by
averaging together the epochs in each condition. This is as simple as calling
the <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs.average" title="mne.Epochs.average"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average</span></code></a> method on the <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> object, and then using
a function from the <a class="reference internal" href="../../api/visualization.html#module-mne.viz" title="mne.viz"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.viz</span></code></a> module to compare the global field power
for each sensor type of the two <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Evoked</span></code></a> objects:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">aud_evoked</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs.average" title="mne.Epochs.average" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">aud_epochs</span><span class="o">.</span><span class="n">average</span></a><span class="p">()</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vis_evoked</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs.average" title="mne.Epochs.average" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">vis_epochs</span><span class="o">.</span><span class="n">average</span></a><span class="p">()</span>

<a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_compare_evokeds</span></a><span class="p">(</span>
    <span class="nb">dict</span><span class="p">(</span><span class="n">auditory</span><span class="o">=</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">aud_evoked</span></a><span class="p">,</span> <span class="n">visual</span><span class="o">=</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vis_evoked</span></a><span class="p">),</span>
    <span class="n">legend</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">,</span>
    <span class="n">show_sensors</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_10_overview_011.png" srcset="../../_images/sphx_glr_10_overview_011.png" alt="Gradiometers (RMS)" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_012.png" srcset="../../_images/sphx_glr_10_overview_012.png" alt="Magnetometers (RMS)" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_013.png" srcset="../../_images/sphx_glr_10_overview_013.png" alt="EEG (GFP)" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Multiple channel types selected, returning one figure per type.
combining channels using RMS (grad channels)
combining channels using RMS (grad channels)
combining channels using RMS (mag channels)
combining channels using RMS (mag channels)
combining channels using GFP (eeg channels)
combining channels using GFP (eeg channels)
</pre></div>
</div>
<p>We can also get a more detailed view of each <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Evoked</span></code></a> object using other
plotting methods such as <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_joint" title="mne.Evoked.plot_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_joint</span></code></a> or
<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_topomap" title="mne.Evoked.plot_topomap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_topomap</span></code></a>. Here weâ€™ll examine just the EEG channels, and see
the classic auditory evoked N100-P200 pattern over dorso-frontal electrodes,
then plot scalp topographies at some additional arbitrary times:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_joint" title="mne.EvokedArray.plot_joint" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">aud_evoked</span><span class="o">.</span><span class="n">plot_joint</span></a><span class="p">(</span><span class="n">picks</span><span class="o">=</span><span class="s2">&quot;eeg&quot;</span><span class="p">)</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_topomap" title="mne.EvokedArray.plot_topomap" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">aud_evoked</span><span class="o">.</span><span class="n">plot_topomap</span></a><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">ch_type</span><span class="o">=</span><span class="s2">&quot;eeg&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_10_overview_014.png" srcset="../../_images/sphx_glr_10_overview_014.png" alt="EEG (59 channels), 0.093 s, 0.206 s, 0.233 s" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_10_overview_015.png" srcset="../../_images/sphx_glr_10_overview_015.png" alt="0.000 s, 0.080 s, 0.100 s, 0.120 s, 0.200 s, ÂµV" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Projections have already been applied. Setting proj attribute to True.
</pre></div>
</div>
<p>Evoked objects can also be combined to show contrasts between conditions,
using the <a class="reference internal" href="../../generated/mne.combine_evoked.html#mne.combine_evoked" title="mne.combine_evoked"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.combine_evoked</span></code></a> function. A simple difference can be
generated by passing <code class="docutils literal notranslate"><span class="pre">weights=[1,</span> <span class="pre">-1]</span></code>. Weâ€™ll then plot the difference wave
at each sensor using <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_topo" title="mne.Evoked.plot_topo"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_topo</span></code></a>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked_diff</span></a> <span class="o">=</span> <a href="../../generated/mne.combine_evoked.html#mne.combine_evoked" title="mne.combine_evoked" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">combine_evoked</span></a><span class="p">([</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">aud_evoked</span></a><span class="p">,</span> <a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vis_evoked</span></a><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.pick" title="mne.EvokedArray.pick" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">evoked_diff</span><span class="o">.</span><span class="n">pick</span></a><span class="p">(</span><span class="n">picks</span><span class="o">=</span><span class="s2">&quot;mag&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">plot_topo</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_10_overview_016.png" srcset="../../_images/sphx_glr_10_overview_016.png" alt="10 overview" class = "sphx-glr-single-img"/></section>
<section id="inverse-modeling">
<h2>Inverse modeling<a class="headerlink" href="#inverse-modeling" title="Link to this heading">#</a></h2>
<p>Finally, we can estimate the origins of the evoked activity by projecting the
sensor data into this subjectâ€™s <a class="reference internal" href="../../documentation/glossary.html#term-source-space"><span class="xref std std-term">source space</span></a> (a set of points either
on the cortical surface or within the cortical volume of that subject, as
estimated by structural MRI scans). MNE-Python supports lots of ways of doing
this (dynamic statistical parametric mapping, dipole fitting, beamformers,
etc.); here weâ€™ll use minimum-norm estimation (MNE) to generate a continuous
map of activation constrained to the cortical surface. MNE uses a linear
<a class="reference internal" href="../../documentation/glossary.html#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project EEG+MEG sensor measurements into the
source space. The inverse operator is computed from the
<a class="reference internal" href="../../documentation/glossary.html#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for this subject and an estimate of <a class="reference internal" href="../forward/90_compute_covariance.html#tut-compute-covariance"><span class="std std-ref">the
covariance of sensor measurements</span></a>. For this
tutorial weâ€™ll skip those computational steps and load a pre-computed inverse
operator from disk (itâ€™s included with the <a class="reference internal" href="../../documentation/datasets.html#sample-dataset"><span class="std std-ref">sample data</span></a>). Because this â€œinverse problemâ€ is underdetermined (there
is no unique solution), here we further constrain the solution by providing a
regularization parameter specifying the relative smoothness of the current
estimates in terms of a signal-to-noise ratio (where â€œnoiseâ€ here is akin to
baseline activity level across all of cortex).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load inverse operator</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inverse_operator_file</span></a> <span class="o">=</span> <span class="p">(</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">/</span> <span class="s2">&quot;MEG&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_audvis-meg-oct-6-meg-inv.fif&quot;</span>
<span class="p">)</span>
<a href="../../generated/mne.minimum_norm.InverseOperator.html#mne.minimum_norm.InverseOperator" title="mne.minimum_norm.InverseOperator" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inv_operator</span></a> <span class="o">=</span> <a href="../../generated/mne.minimum_norm.read_inverse_operator.html#mne.minimum_norm.read_inverse_operator" title="mne.minimum_norm.read_inverse_operator" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">minimum_norm</span><span class="o">.</span><span class="n">read_inverse_operator</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inverse_operator_file</span></a><span class="p">)</span>
<span class="c1"># set signal-to-noise ratio (SNR) to compute regularization parameter (Î»Â²)</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">snr</span></a> <span class="o">=</span> <span class="mf">3.0</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lambda2</span></a> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">snr</span></a><span class="o">**</span><span class="mi">2</span>
<span class="c1"># generate the source time course (STC)</span>
<a href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stc</span></a> <span class="o">=</span> <a href="../../generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">minimum_norm</span><span class="o">.</span><span class="n">apply_inverse</span></a><span class="p">(</span>
    <a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vis_evoked</span></a><span class="p">,</span> <a href="../../generated/mne.minimum_norm.InverseOperator.html#mne.minimum_norm.InverseOperator" title="mne.minimum_norm.InverseOperator" class="sphx-glr-backref-module-mne-minimum_norm sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inv_operator</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lambda2</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lambda2</span></a><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;MNE&quot;</span>
<span class="p">)</span>  <span class="c1"># or dSPM, sLORETA, eLORETA</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading inverse operator decomposition from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif...
    Reading inverse operator info...
    [done]
    Reading inverse operator decomposition...
    [done]
    305 x 305 full covariance (kind = 1) found.
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Noise covariance matrix read.
    22494 x 22494 diagonal covariance (kind = 2) found.
    Source covariance matrix read.
    22494 x 22494 diagonal covariance (kind = 6) found.
    Orientation priors read.
    22494 x 22494 diagonal covariance (kind = 5) found.
    Depth priors read.
    Did not find the desired covariance matrix (kind = 3)
    Reading a source space...
    Computing patch statistics...
    Patch information added...
    Distance information added...
    [done]
    Reading a source space...
    Computing patch statistics...
    Patch information added...
    Distance information added...
    [done]
    2 source spaces read
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Source spaces transformed to the inverse solution coordinate frame
Preparing the inverse operator for use...
    Scaled noise and source covariance from nave = 1 to nave = 136
    Created the regularized inverter
    Created an SSP operator (subspace dimension = 3)
    Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)
Applying inverse operator to &quot;0.50 Ã— visual/left + 0.50 Ã— visual/right&quot;...
    Picked 305 channels from the data
    Computing inverse...
    Eigenleads need to be weighted ...
    Computing residual...
    Explained  70.2% variance
    Combining the current components...
[done]
</pre></div>
</div>
<p>Finally, in order to plot the source estimate on the subjectâ€™s cortical
surface weâ€™ll also need the path to the sample subjectâ€™s structural MRI files
(the <code class="docutils literal notranslate"><span class="pre">subjects_dir</span></code>):</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># path to subjects&#39; MRI files</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">/</span> <span class="s2">&quot;subjects&quot;</span>
<span class="c1"># plot the STC</span>
<a href="../../generated/mne.SourceEstimate.html#mne.SourceEstimate.plot" title="mne.SourceEstimate.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">stc</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span>
    <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hemi</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">,</span> <span class="n">views</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lat&quot;</span><span class="p">,</span> <span class="s2">&quot;med&quot;</span><span class="p">],</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a>
<span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_10_overview_017.png" srcset="../../_images/sphx_glr_10_overview_017.png" alt="10 overview" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using control points [8.61922423e-11 1.06837855e-10 4.49139511e-10]
</pre></div>
</div>
<p>The remaining tutorials have <em>much more detail</em> on each of these topics (as
well as many other capabilities of MNE-Python not mentioned here:
connectivity analysis, encoding/decoding models, lots more visualization
options, etc). Read on to learn more!</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 30.461 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-intro-10-overview-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e23ed246a9a354f899dfb3ce3b06e194/10_overview.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">10_overview.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/642494b64bd51f58d66c30234acc9e13/10_overview.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">10_overview.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4b971c508ae67cd8f7c494b209000e0e/10_overview.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">10_overview.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introductory tutorials</p>
      </div>
    </a>
    <a class="right-next"
       href="15_inplace.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modifying data in-place</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-data">Loading data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detecting-experimental-events">Detecting experimental events</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epoching-continuous-data">Epoching continuous data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-frequency-analysis">Time-frequency analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-evoked-responses">Estimating evoked responses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inverse-modeling">Inverse modeling</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://mne.tools/versionwarning.js"></script>
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center small">&copy; Copyright 2012â€“2025, MNE Developers. Last updated <time datetime="2025-11-26T06:32:59.315712+00:00" class="localized">2025-11-26 06:32 UTC</time>.
<script type="text/javascript">
function formatTimestamp() {
    document.querySelectorAll("time.localized").forEach(el => {
        const d = new Date(el.getAttribute("datetime"));
        el.textContent = d.toLocaleString("sv-SE", { "timeZoneName": "short" });
    });
}
if (document.readyState !== "loading") {
    formatTimestamp();
} else {
    document.addEventListener("DOMContentLoaded", formatTimestamp);
}
</script></p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>