
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Working with sensor locations &#8212; MNE 0.23.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.951c8c8e3af89de180a2f03968e0e7cb.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
    <!-- add `style` or `link` tags with your CSS `@font-face` declarations here -->
    <!-- ... and a `style` tag with setting `font-family` in `body` and `.header-style` -->
    <!-- ... and optionally preload the `woff2` for snappier page loads -->
    <!-- or add a `style` tag with a font fallback chain with good cross-platform coverage -->
    <style>
        body,.header-style {font-family: 'Source Sans Pro', sans-serif;}
        code,kbd,pre,samp {font-family: 'Source Code Pro', monospace;}
    </style>

    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/font-source-sans-pro.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/font-source-code-pro.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.014cad6f3a039303089e.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Configuring MNE-Python" href="plot_50_configure_mne.html" />
    <link rel="prev" title="The Info data structure" href="plot_30_info.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <script type="text/javascript" src="../../_static/scrollfix.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
  
    <div class="container-fluid alert-danger devbar">
      <div class="row no-gutters">
        <div class="col-12 text-center">
          This is documentation for the <em>unstable development version</em> of MNE-Python. <a class="alert-link" href="https://mne.tools/stable">Click here</a> to switch to the stable version.
        </div>
      </div>
    </div>
  

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">
    <a class="navbar-brand" href="../../index.html">
        
        <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo" />
        
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-auto col-lg-9 collapse navbar-collapse">
        <ul id="navbar-main-elements" class="navbar-nav mr-auto">
            
            
            <li class="nav-item ">
                <a class="nav-link" href="../../install/index.html">Install</a>
            </li>
            
            <li class="nav-item active">
                <a class="nav-link" href="../../overview/index.html">Documentation</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="../../python_reference.html">API Reference</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="../../overview/get_help.html">Get help</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="../../overview/development.html">Development</a>
            </li>
            
            
        </ul>

        

        <ul class="navbar-nav">
            <!-- version dropdown -->
            <li class="mr-2 dropdown">
                <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
                    v0.23.dev0
                    <span class="caret"></span>
                </button>
                <ul class="dropdown-menu" aria-labelledby="dLabelMore">
                    <li><a href="https://mne-tools.github.io/dev/index.html">v0.23 (devel)</a></li>
                    <li><a href="https://mne-tools.github.io/stable/index.html">v0.22 (stable)</a></li>
                    <li><a href="https://mne-tools.github.io/0.21/index.html">v0.21</a></li>
                    <li><a href="https://mne-tools.github.io/0.20/index.html">v0.20</a></li>
                    <li><a href="https://mne-tools.github.io/0.19/index.html">v0.19</a></li>
                    <li><a href="https://mne-tools.github.io/0.18/index.html">v0.18</a></li>
                    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
                    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
                    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
                    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
                    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
                    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
                    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
                </ul>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="https://github.com/mne-tools/mne-python" target="_blank" rel="noopener">
                    <span><i class="fab fa-github-square"></i></span>
                </a>
            </li>
            
            
            <li class="nav-item">
                <a class="nav-link" href="https://twitter.com/mne_python" target="_blank" rel="noopener">
                    <span><i class="fab fa-twitter-square"></i></span>
                </a>
            </li>
            
            <!-- discourse forum link -->
            <li class="nav-item">
                <a class="nav-link" href="https://mne.discourse.group" target="_blank" rel="noopener">
                    <span><i class="fab fa-discourse"></i></span>
                </a>
            </li>
        </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
      <li class="toctree-l2 current active">
 <a class="reference internal" href="../index.html">
  Tutorials
 </a>
 <ul class="current">
  <li class="toctree-l3">
   <a class="reference internal" href="plot_10_overview.html">
    Overview of MEG/EEG analysis with MNE-Python
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="plot_20_events_from_raw.html">
    Parsing events from raw data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="plot_30_info.html">
    The Info data structure
   </a>
  </li>
  <li class="toctree-l3 current active">
   <a class="current reference internal" href="#">
    Working with sensor locations
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="plot_50_configure_mne.html">
    Configuring MNE-Python
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../io/plot_10_reading_meg_data.html">
    Importing data from MEG devices
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../io/plot_20_reading_eeg_data.html">
    Importing data from EEG devices
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../io/plot_30_reading_fnirs_data.html">
    Importing data from fNIRS devices
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../raw/plot_10_raw_overview.html">
    The Raw data structure: continuous data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../raw/plot_20_event_arrays.html">
    Working with events
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../raw/plot_30_annotate_raw.html">
    Annotating continuous data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../raw/plot_40_visualize_raw.html">
    Built-in plotting methods for Raw objects
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_10_preprocessing_overview.html">
    Overview of artifact detection
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_15_handling_bad_channels.html">
    Interpolating bad channels
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_20_rejecting_bad_data.html">
    Rejecting bad data spans
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_30_filtering_resampling.html">
    Filtering and resampling data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_35_artifact_correction_regression.html">
    Repairing artifacts with regression
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_40_artifact_correction_ica.html">
    Repairing artifacts with ICA
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_45_projectors_background.html">
    Background on projectors and projections
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_50_artifact_correction_ssp.html">
    Repairing artifacts with SSP
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_55_setting_eeg_reference.html">
    Setting the EEG reference
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_59_head_positions.html">
    Extracting and visualizing subject head movement
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_60_maxwell_filtering_sss.html">
    Signal-space separation (SSS) and Maxwell filtering
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../preprocessing/plot_70_fnirs_processing.html">
    Preprocessing functional near-infrared spectroscopy (fNIRS) data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../epochs/plot_10_epochs_overview.html">
    The Epochs data structure: discontinuous data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../epochs/plot_20_visualize_epochs.html">
    Visualizing epoched data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../epochs/plot_30_epochs_metadata.html">
    Working with Epoch metadata
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../epochs/plot_40_epochs_to_data_frame.html">
    Exporting Epochs to Pandas DataFrames
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../evoked/plot_10_evoked_overview.html">
    The Evoked data structure: evoked/averaged data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../evoked/plot_20_visualize_evoked.html">
    Visualizing Evoked data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../evoked/plot_eeg_erp.html">
    EEG processing and Event Related Potentials (ERPs)
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../evoked/plot_whitened.html">
    Plotting whitened data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../time-freq/plot_sensors_time_frequency.html">
    Frequency and time-frequency sensor analysis
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_background_freesurfer.html">
    FreeSurfer MRI reconstruction
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_background_freesurfer_mne.html">
    How MNE uses FreeSurfer’s outputs
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_beamformer_lcmv.html">
    Source reconstruction using an LCMV beamformer
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_compute_covariance.html">
    Computing a covariance matrix
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_dipole_fit.html">
    Source localization with equivalent current dipole (ECD) fit
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_dipole_orientations.html">
    The role of dipole orientations in distributed source localization
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_eeg_mri_coords.html">
    EEG source localization given electrode locations on an MRI
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_eeg_no_mri.html">
    EEG forward operator with a template MRI
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_fix_bem_in_blender.html">
    Editing BEM surfaces in Blender
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_forward.html">
    Head model and forward computation
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_mne_dspm_source_localization.html">
    Source localization with MNE/dSPM/sLORETA/eLORETA
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_mne_solutions.html">
    Computing various MNE solutions
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_object_source_estimate.html">
    The
    <code class="xref py py-class docutils literal notranslate">
     <span class="pre">
      SourceEstimate
     </span>
    </code>
    data structure
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_source_alignment.html">
    Source alignment and coordinate frames
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../source-modeling/plot_visualize_stc.html">
    Visualize source time courses (stcs)
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-sensor-space/plot_stats_cluster_1samp_test_time_frequency.html">
    Non-parametric 1 sample cluster statistic on single trial power
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-sensor-space/plot_stats_cluster_erp.html">
    Visualising statistical significance thresholds on EEG data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-sensor-space/plot_stats_cluster_time_frequency.html">
    Non-parametric between conditions cluster statistic on single trial power
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-sensor-space/plot_stats_spatio_temporal_cluster_sensors.html">
    Spatiotemporal permutation F-test on full sensor data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-source-space/plot_stats_cluster_spatio_temporal.html">
    Permutation t-test on source data with spatio-temporal clustering
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-source-space/plot_stats_cluster_spatio_temporal_2samp.html">
    2 samples permutation test on source data with spatio-temporal clustering
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-source-space/plot_stats_cluster_spatio_temporal_repeated_measures_anova.html">
    Repeated measures ANOVA on source data with spatio-temporal clustering
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../stats-source-space/plot_stats_cluster_time_frequency_repeated_measures_anova.html">
    Mass-univariate twoway repeated measures ANOVA on single trial power
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../machine-learning/plot_receptive_field.html">
    Spectro-temporal receptive field (STRF) estimation on continuous data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../machine-learning/plot_sensors_decoding.html">
    Decoding (MVPA)
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../simulation/plot_creating_data_structures.html">
    Creating MNE-Python data structures from scratch
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../simulation/plot_dics.html">
    DICS for power mapping
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../simulation/plot_point_spread.html">
    Corrupt known signal with point spread
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../sample-datasets/plot_brainstorm_auditory.html">
    Brainstorm auditory tutorial dataset
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../sample-datasets/plot_brainstorm_phantom_ctf.html">
    Brainstorm CTF phantom dataset tutorial
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../sample-datasets/plot_brainstorm_phantom_elekta.html">
    Brainstorm Elekta phantom dataset tutorial
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../sample-datasets/plot_phantom_4DBTi.html">
    4D Neuroimaging/BTi phantom dataset tutorial
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../sample-datasets/plot_sleep.html">
    Sleep stage classification from polysomnography (PSG) data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../discussions/plot_background_filtering.html">
    Background information on filtering
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../discussions/plot_background_ica.html">
    Background on Independent Component Analysis (ICA)
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../discussions/plot_background_statistics.html">
    Statistical inference
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../misc/plot_ecog.html">
    Working with ECoG data
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../misc/plot_modifying_data_inplace.html">
    Modifying data in-place
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../misc/plot_report.html">
    Getting started with
    <code class="docutils literal notranslate">
     <span class="pre">
      mne.Report
     </span>
    </code>
   </a>
  </li>
  <li class="toctree-l3">
   <a class="reference internal" href="../misc/plot_seeg.html">
    Working with sEEG data
   </a>
  </li>
 </ul>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../auto_examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../glossary.html">
  Glossary
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/implementation.html">
  Implementation details
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/design_philosophy.html">
  Design philosophy
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/datasets_index.html">
  Example datasets
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../generated/commands.html">
  Command-line tools
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/migrating.html">
  Migrating from other analysis software
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/cookbook.html">
  The typical M/EEG workflow
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../overview/cite.html">
  How to cite MNE-Python
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../../cited.html">
  Papers citing MNE-Python
 </a>
</li>

    </ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>



<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#about-montages-and-layouts">
   About montages and layouts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#working-with-built-in-montages">
   Working with built-in montages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#controlling-channel-projection-mne-vs-eeglab">
   Controlling channel projection (MNE vs EEGLAB)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reading-sensor-digitization-files">
   Reading sensor digitization files
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rendering-sensor-position-with-mayavi">
   Rendering sensor position with mayavi
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#working-with-layout-files">
   Working with layout files
  </a>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-intro-plot-40-sensor-locations-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="working-with-sensor-locations">
<span id="tut-sensor-locations"></span><span id="sphx-glr-auto-tutorials-intro-plot-40-sensor-locations-py"></span><h1>Working with sensor locations<a class="headerlink" href="#working-with-sensor-locations" title="Permalink to this headline">¶</a></h1>
<p>This tutorial describes how to read and plot sensor locations, and how
the physical location of sensors is handled in MNE-Python.</p>
<p>As usual we’ll start by importing the modules we need and loading some
<a class="reference internal" href="../../overview/datasets_index.html#sample-dataset"><span class="std std-ref">example data</span></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>  <span class="c1"># noqa</span>
<span class="kn">import</span> <span class="nn">mne</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a><span class="p">,</span> <span class="s1">&#39;MEG&#39;</span><span class="p">,</span> <span class="s1">&#39;sample&#39;</span><span class="p">,</span>
                                    <span class="s1">&#39;sample_audvis_raw.fif&#39;</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="about-montages-and-layouts">
<h2>About montages and layouts<a class="headerlink" href="#about-montages-and-layouts" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">Montages</span></code></a> contain sensor
positions in 3D (<code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z</span></code>, in meters), and can be used to set
the physical positions of sensors. By specifying the location of sensors
relative to the brain, <a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">Montages</span></code></a> play an
important role in computing the forward solution and computing inverse
estimates.</p>
<p>In contrast, <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layouts</span></code></a> are <em>idealized</em> 2-D
representations of sensor positions, and are primarily used for arranging
individual sensor subplots in a topoplot, or for showing the <em>approximate</em>
relative arrangement of sensors as seen from above.</p>
</div>
<div class="section" id="working-with-built-in-montages">
<h2>Working with built-in montages<a class="headerlink" href="#working-with-built-in-montages" title="Permalink to this headline">¶</a></h2>
<p>The 3D coordinates of MEG sensors are included in the raw recordings from MEG
systems, and are automatically stored in the <code class="docutils literal notranslate"><span class="pre">info</span></code> attribute of the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> file upon loading. EEG electrode locations are much more
variable because of differences in head shape. Idealized montages for many
EEG systems are included during MNE-Python installation; these files are
stored in your <code class="docutils literal notranslate"><span class="pre">mne-python</span></code> directory, in the
<code class="file docutils literal notranslate"><span class="pre">mne/channels/data/montages</span></code> folder:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><span class="n">mne</span><span class="o">.</span><span class="vm">__file__</span><span class="p">),</span>
                           <span class="s1">&#39;channels&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;montages&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">BUILT-IN MONTAGE FILES&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;======================&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><a href="https://docs.python.org/3/library/os.html#os.listdir" title="os.listdir" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">listdir</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage_dir</span></a><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>BUILT-IN MONTAGE FILES
======================
[&#39;EGI_256.csd&#39;, &#39;GSN-HydroCel-128.sfp&#39;, &#39;GSN-HydroCel-129.sfp&#39;, &#39;GSN-HydroCel-256.sfp&#39;, &#39;GSN-HydroCel-257.sfp&#39;, &#39;GSN-HydroCel-32.sfp&#39;, &#39;GSN-HydroCel-64_1.0.sfp&#39;, &#39;GSN-HydroCel-65_1.0.sfp&#39;, &#39;biosemi128.txt&#39;, &#39;biosemi16.txt&#39;, &#39;biosemi160.txt&#39;, &#39;biosemi256.txt&#39;, &#39;biosemi32.txt&#39;, &#39;biosemi64.txt&#39;, &#39;easycap-M1.txt&#39;, &#39;easycap-M10.txt&#39;, &#39;mgh60.elc&#39;, &#39;mgh70.elc&#39;, &#39;standard_1005.elc&#39;, &#39;standard_1020.elc&#39;, &#39;standard_alphabetic.elc&#39;, &#39;standard_postfixed.elc&#39;, &#39;standard_prefixed.elc&#39;, &#39;standard_primed.elc&#39;]
</pre></div>
</div>
<div class="sidebar">
<p class="sidebar-title">Computing sensor locations</p>
<p>If you are interested in how standard (“idealized”) EEG sensor positions
are computed on a spherical head model, the <a class="reference external" href="https://github.com/sappelhoff/eeg_positions">eeg_positions</a> repository
provides code and documentation to this end.</p>
</div>
<p>These built-in EEG montages can be loaded via
<a class="reference internal" href="../../generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.make_standard_montage()</span></code></a>. Note that when loading via
<a class="reference internal" href="../../generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_standard_montage()</span></code></a>, provide the filename <em>without</em>
its file extension:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ten_twenty_montage</span></a> <span class="o">=</span> <a href="../../generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">make_standard_montage</span></a><span class="p">(</span><span class="s1">&#39;standard_1020&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ten_twenty_montage</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;DigMontage | 0 extras (headshape), 0 HPIs, 3 fiducials, 94 channels&gt;
</pre></div>
</div>
<p>Once loaded, a montage can be applied to data via one of the instance methods
such as <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage"><code class="xref py py-meth docutils literal notranslate"><span class="pre">raw.set_montage</span></code></a>. It is also possible
to skip the loading step by passing the filename string directly to the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_montage()</span></code></a> method. This won’t work with our sample
data, because it’s channel names don’t match the channel names in the
standard 10-20 montage, so these commands are not run here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># these will be equivalent:</span>
<span class="c1"># raw_1020 = raw.copy().set_montage(ten_twenty_montage)</span>
<span class="c1"># raw_1020 = raw.copy().set_montage(&#39;standard_1020&#39;)</span>
</pre></div>
</div>
<p><a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">Montage</span></code></a> objects have a
<a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> method for visualization of the sensor
locations in 3D; 2D projections are also possible by passing
<code class="docutils literal notranslate"><span class="pre">kind='topomap'</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">ten_twenty_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">azim</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">elev</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">ten_twenty_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;topomap&#39;</span><span class="p">,</span> <span class="n">show_names</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="plot 40 sensor locations" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_40_sensor_locations_001.png" />
</li>
<li><img alt="plot 40 sensor locations" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_40_sensor_locations_002.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>4 duplicate electrode labels found:
T7/T3, T8/T4, P7/T5, P8/T6
Plotting 90 unique labels.
Creating RawArray with float64 data, n_channels=90, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
4 duplicate electrode labels found:
T7/T3, T8/T4, P7/T5, P8/T6
Plotting 90 unique labels.
Creating RawArray with float64 data, n_channels=90, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
</div>
<div class="section" id="controlling-channel-projection-mne-vs-eeglab">
<span id="control-chan-projection"></span><h2>Controlling channel projection (MNE vs EEGLAB)<a class="headerlink" href="#controlling-channel-projection-mne-vs-eeglab" title="Permalink to this headline">¶</a></h2>
<p>Channel positions in 2d space are obtained by projecting their actual 3d
positions using a sphere as a reference. Because <code class="docutils literal notranslate"><span class="pre">'standard_1020'</span></code> montage
contains realistic, not spherical, channel positions, we will use a different
montage to demonstrate controlling how channels are projected to 2d space.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">biosemi_montage</span></a> <span class="o">=</span> <a href="../../generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">make_standard_montage</span></a><span class="p">(</span><span class="s1">&#39;biosemi64&#39;</span><span class="p">)</span>
<a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">show_names</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_003.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=64, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
<p>By default a sphere  with an origin in <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">0)</span></code> x, y, z coordinates and
radius of <code class="docutils literal notranslate"><span class="pre">0.095</span></code> meters (9.5 cm) is used. You can use a different sphere
radius by passing a single value to <code class="docutils literal notranslate"><span class="pre">sphere</span></code> argument in any function that
plots channels in 2d (like <a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> that we use
here, but also for example <a class="reference internal" href="../../generated/mne.viz.plot_topomap.html#mne.viz.plot_topomap" title="mne.viz.plot_topomap"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_topomap()</span></code></a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">show_names</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sphere</span><span class="o">=</span><span class="mf">0.07</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=64, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
<p>To control not only radius, but also the sphere origin, pass a
<code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">z,</span> <span class="pre">radius)</span></code> tuple to <code class="docutils literal notranslate"><span class="pre">sphere</span></code> argument:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">show_names</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sphere</span><span class="o">=</span><span class="p">(</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.075</span><span class="p">))</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_005.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=64, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
<p>In mne-python the head center and therefore the sphere center are calculated
using <a class="reference internal" href="../../glossary.html#term-fiducial"><span class="xref std std-term">fiducial points</span></a>.
Because of this the head circle represents head
circumference at the nasion and ear level, and not where it is commonly
measured in 10-20 EEG system: above nasion at T4/T8, T3/T7, Oz, Fz level.
Notice below that by default T7 and Oz channels are placed within the head
circle, not on the head outline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_006.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=64, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
<p>If you have previous EEGLAB experience you may prefer its convention to
represent 10-20 head circumference with the head circle. To get EEGLAB-like
channel layout you would have to move the sphere origin a few centimeters
up on the z dimension:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_montage</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">sphere</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.035</span><span class="p">,</span> <span class="mf">0.094</span><span class="p">))</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_007.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=64, n_times=1
    Range : 0 ... 0 =      0.000 ...     0.000 secs
Ready.
</pre></div>
</div>
<p>Instead of approximating the EEGLAB-esque sphere location as above, you can
calculate the sphere origin from position of Oz, Fpz, T3/T7 or T4/T8
channels. This is easier once the montage has been applied to the data and
channel positions are in the head space - see
<a class="reference internal" href="../../auto_examples/visualization/plot_eeglab_head_sphere.html#ex-topomap-eeglab-style"><span class="std std-ref">this example</span></a>.</p>
</div>
<div class="section" id="reading-sensor-digitization-files">
<span id="reading-dig-montages"></span><h2>Reading sensor digitization files<a class="headerlink" href="#reading-sensor-digitization-files" title="Permalink to this headline">¶</a></h2>
<p>In the sample data, setting the digitized EEG montage was done prior to
saving the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> object to disk, so the sensor positions are
already incorporated into the <code class="docutils literal notranslate"><span class="pre">info</span></code> attribute of the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
object (see the documentation of the reading functions and
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_montage()</span></code></a> for details on how that works). Because of
that, we can plot sensor locations directly from the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
object using the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.plot_sensors" title="mne.io.Raw.plot_sensors"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_sensors()</span></code></a> method, which provides
similar functionality to
<a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">montage.plot()</span></code></a>.
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.plot_sensors" title="mne.io.Raw.plot_sensors"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_sensors()</span></code></a> also allows channel selection by type, can
color-code channels in various ways (by default, channels listed in
<code class="docutils literal notranslate"><span class="pre">raw.info['bads']</span></code> will be plotted in red), and allows drawing into an
existing matplotlib <code class="docutils literal notranslate"><span class="pre">axes</span></code> object (so the channel positions can easily be
made as a subplot in a multi-panel figure):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">()</span>
<span class="n">ax2d</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax3d</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.plot_sensors" title="mne.io.Raw.plot_sensors" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">plot_sensors</span></a><span class="p">(</span><span class="n">ch_type</span><span class="o">=</span><span class="s1">&#39;eeg&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax2d</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.plot_sensors" title="mne.io.Raw.plot_sensors" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">plot_sensors</span></a><span class="p">(</span><span class="n">ch_type</span><span class="o">=</span><span class="s1">&#39;eeg&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax3d</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">azim</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">elev</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_008.png" />
<p>It’s probably evident from the 2D topomap above that there is some
irregularity in the EEG sensor positions in the <a class="reference internal" href="../../overview/datasets_index.html#sample-dataset"><span class="std std-ref">sample dataset</span></a> — this is because the sensor positions in that dataset are
digitizations of the sensor positions on an actual subject’s head, rather
than idealized sensor positions based on a spherical head model. Depending on
what system was used to digitize the electrode positions (e.g., a Polhemus
Fastrak digitizer), you must use different montage reading functions (see
<a class="reference internal" href="../../overview/implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>). The resulting <a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">montage</span></code></a>
can then be added to <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects by passing it to the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_montage()</span></code></a> method (just as we did above with the name of
the idealized montage <code class="docutils literal notranslate"><span class="pre">'standard_1020'</span></code>). Once loaded, locations can be
plotted with <a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot" title="mne.channels.DigMontage.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> and saved with
<a class="reference internal" href="../../generated/mne.channels.DigMontage.html#mne.channels.DigMontage.save" title="mne.channels.DigMontage.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>, like when working with a standard
montage.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When setting a montage with <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_montage()</span></code></a>
the measurement info is updated in two places (the <code class="docutils literal notranslate"><span class="pre">chs</span></code>
and <code class="docutils literal notranslate"><span class="pre">dig</span></code> entries are updated). See <a class="reference internal" href="plot_30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a>.
<code class="docutils literal notranslate"><span class="pre">dig</span></code> may contain HPI, fiducial, or head shape points in
addition to electrode locations.</p>
</div>
</div>
<div class="section" id="rendering-sensor-position-with-mayavi">
<h2>Rendering sensor position with mayavi<a class="headerlink" href="#rendering-sensor-position-with-mayavi" title="Permalink to this headline">¶</a></h2>
<p>It is also possible to render an image of a MEG sensor helmet in 3D, using
mayavi instead of matplotlib, by calling <a class="reference internal" href="../../generated/mne.viz.plot_alignment.html#mne.viz.plot_alignment" title="mne.viz.plot_alignment"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_alignment()</span></code></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <a href="../../generated/mne.viz.plot_alignment.html#mne.viz.plot_alignment" title="mne.viz.plot_alignment" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_alignment</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dig</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eeg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">surfaces</span><span class="o">=</span><span class="p">[],</span> <span class="n">meg</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;helmet&#39;</span><span class="p">,</span> <span class="s1">&#39;sensors&#39;</span><span class="p">],</span>
                             <span class="n">coord_frame</span><span class="o">=</span><span class="s1">&#39;meg&#39;</span><span class="p">)</span>
<a href="../../generated/mne.viz.set_3d_view.html#mne.viz.set_3d_view" title="mne.viz.set_3d_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">set_3d_view</span></a><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">azimuth</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">elevation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_009.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Getting helmet for system 306m
</pre></div>
</div>
<p><a class="reference internal" href="../../generated/mne.viz.plot_alignment.html#mne.viz.plot_alignment" title="mne.viz.plot_alignment"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_alignment()</span></code></a> requires an <a class="reference internal" href="../../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-class docutils literal notranslate"><span class="pre">Info</span></code></a> object, and
can also render MRI surfaces of the scalp, skull, and brain (by passing
keywords like <code class="docutils literal notranslate"><span class="pre">'head'</span></code>, <code class="docutils literal notranslate"><span class="pre">'outer_skull'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'brain'</span></code> to the
<code class="docutils literal notranslate"><span class="pre">surfaces</span></code> parameter) making it useful for <a class="reference internal" href="../source-modeling/plot_source_alignment.html#plot-source-alignment"><span class="std std-ref">assessing coordinate frame
transformations</span></a>. For examples of various uses of
<a class="reference internal" href="../../generated/mne.viz.plot_alignment.html#mne.viz.plot_alignment" title="mne.viz.plot_alignment"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_alignment()</span></code></a>, see <a class="reference internal" href="../../auto_examples/visualization/montage.html#plot-montage"><span class="std std-ref">Plotting sensor layouts of EEG systems</span></a>,
<a class="reference internal" href="../../auto_examples/visualization/plot_eeg_on_scalp.html"><span class="doc">Plotting EEG sensors on the scalp</span></a>, and
<a class="reference internal" href="../../auto_examples/visualization/plot_meg_sensors.html"><span class="doc">Plotting sensor layouts of MEG systems</span></a>.</p>
</div>
<div class="section" id="working-with-layout-files">
<h2>Working with layout files<a class="headerlink" href="#working-with-layout-files" title="Permalink to this headline">¶</a></h2>
<p>As with montages, many layout files are included during MNE-Python
installation, and are stored in the <code class="file docutils literal notranslate"><span class="pre">mne/channels/data/layouts</span></code> folder:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">layout_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/os.path.html#os.path.dirname" title="os.path.dirname" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span></a><span class="p">(</span><span class="n">mne</span><span class="o">.</span><span class="vm">__file__</span><span class="p">),</span>
                          <span class="s1">&#39;channels&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;layouts&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">BUILT-IN LAYOUT FILES&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=====================&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><a href="https://docs.python.org/3/library/os.html#os.listdir" title="os.listdir" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">listdir</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">layout_dir</span></a><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>BUILT-IN LAYOUT FILES
=====================
[&#39;CTF-275.lout&#39;, &#39;CTF151.lay&#39;, &#39;CTF275.lay&#39;, &#39;EEG1005.lay&#39;, &#39;EGI256.lout&#39;, &#39;KIT-125.lout&#39;, &#39;KIT-157.lout&#39;, &#39;KIT-160.lay&#39;, &#39;KIT-AD.lout&#39;, &#39;KIT-AS-2008.lout&#39;, &#39;KIT-UMD-3.lout&#39;, &#39;Neuromag_122.lout&#39;, &#39;Vectorview-all.lout&#39;, &#39;Vectorview-grad.lout&#39;, &#39;Vectorview-grad_norm.lout&#39;, &#39;Vectorview-mag.lout&#39;, &#39;biosemi.lay&#39;, &#39;magnesWH3600.lout&#39;]
</pre></div>
</div>
<p>You may have noticed that the file formats and filename extensions of the
built-in layout and montage files vary considerably. This reflects different
manufacturers’ conventions; to make loading easier the montage and layout
loading functions in MNE-Python take the filename <em>without its extension</em> so
you don’t have to keep track of which file format is used by which
manufacturer.</p>
<p>To load a layout file, use the <a class="reference internal" href="../../generated/mne.channels.read_layout.html#mne.channels.read_layout" title="mne.channels.read_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.read_layout()</span></code></a> function, and
provide the filename <em>without</em> its file extension. You can then visualize the
layout using its <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> method, or (equivalently)
by passing it to <a class="reference internal" href="../../generated/mne.viz.plot_layout.html#mne.viz.plot_layout" title="mne.viz.plot_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_layout()</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">biosemi_layout</span></a> <span class="o">=</span> <a href="../../generated/mne.channels.read_layout.html#mne.channels.read_layout" title="mne.channels.read_layout" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">read_layout</span></a><span class="p">(</span><span class="s1">&#39;biosemi&#39;</span><span class="p">)</span>
<a href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_layout</span><span class="o">.</span><span class="n">plot</span></a><span class="p">()</span>  <span class="c1"># same result as: mne.viz.plot_layout(biosemi_layout)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_010.png" />
<p>Similar to the <code class="docutils literal notranslate"><span class="pre">picks</span></code> argument for selecting channels from
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects, the <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> method of
<a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> objects also has a <code class="docutils literal notranslate"><span class="pre">picks</span></code> argument. However,
because layouts only contain information about sensor name and location (not
sensor type), the <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot()</span></code></a> method only allows
picking channels by index (not by name or by type). Here we find the indices
we want using <a class="reference external" href="https://numpy.org/devdocs/reference/generated/numpy.where.html#numpy.where" title="(in NumPy v1.21.dev0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.where()</span></code></a>; selection by name or type is possible via
<a class="reference internal" href="../../generated/mne.pick_channels.html#mne.pick_channels" title="mne.pick_channels"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.pick_channels()</span></code></a> or <a class="reference internal" href="../../generated/mne.pick_types.html#mne.pick_types" title="mne.pick_types"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.pick_types()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">midline</span></a> <span class="o">=</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.where.html#numpy.where" title="numpy.where" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">([</span><span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">biosemi_layout</span><span class="o">.</span><span class="n">names</span></a><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<a href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">biosemi_layout</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">picks</span><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">midline</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_011.png" />
<p>If you’re working with a <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> object that already has sensor
positions incorporated, you can create a <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> object
with either the <a class="reference internal" href="../../generated/mne.channels.make_eeg_layout.html#mne.channels.make_eeg_layout" title="mne.channels.make_eeg_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.make_eeg_layout()</span></code></a> function or
(equivalently) the <a class="reference internal" href="../../generated/mne.channels.find_layout.html#mne.channels.find_layout" title="mne.channels.find_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.find_layout()</span></code></a> function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">layout_from_raw</span></a> <span class="o">=</span> <a href="../../generated/mne.channels.make_eeg_layout.html#mne.channels.make_eeg_layout" title="mne.channels.make_eeg_layout" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">make_eeg_layout</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">)</span>
<span class="c1"># same result as: mne.channels.find_layout(raw.info, ch_type=&#39;eeg&#39;)</span>
<a href="../../generated/mne.channels.Layout.html#mne.channels.Layout.plot" title="mne.channels.Layout.plot" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">layout_from_raw</span><span class="o">.</span><span class="n">plot</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="plot 40 sensor locations" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_40_sensor_locations_012.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is no corresponding <code class="docutils literal notranslate"><span class="pre">make_meg_layout</span></code> function because sensor
locations are fixed in a MEG system (unlike in EEG, where the sensor caps
deform to fit each subject’s head). Thus MEG layouts are consistent for a
given system and you can simply load them with
<a class="reference internal" href="../../generated/mne.channels.read_layout.html#mne.channels.read_layout" title="mne.channels.read_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.read_layout()</span></code></a>, or use <a class="reference internal" href="../../generated/mne.channels.find_layout.html#mne.channels.find_layout" title="mne.channels.find_layout"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.channels.find_layout()</span></code></a>
with the <code class="docutils literal notranslate"><span class="pre">ch_type</span></code> parameter, as shown above for EEG.</p>
</div>
<p>All <a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> objects have a
<a class="reference internal" href="../../generated/mne.channels.Layout.html#mne.channels.Layout.save" title="mne.channels.Layout.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a> method that allows writing layouts to disk,
in either <code class="file docutils literal notranslate"><span class="pre">.lout</span></code> or <code class="file docutils literal notranslate"><span class="pre">.lay</span></code> format (which format gets written is
inferred from the file extension you pass to the method’s <code class="docutils literal notranslate"><span class="pre">fname</span></code>
parameter). The choice between <code class="file docutils literal notranslate"><span class="pre">.lout</span></code> and <code class="file docutils literal notranslate"><span class="pre">.lay</span></code> format only
matters if you need to load the layout file in some other software
(MNE-Python can read either format equally well).</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  13.933 seconds)</p>
<p><strong>Estimated memory usage:</strong>  493 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-intro-plot-40-sensor-locations-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8ed64d7c92012e6fcb6501cd8cdb8d25/plot_40_sensor_locations.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_40_sensor_locations.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/59a29cf7eb53c7ab95857dfb2e3b31ba/plot_40_sensor_locations.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_40_sensor_locations.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="plot_30_info.html" title="previous page">The Info data structure</a>
    <a class='right-next' id="next-link" href="plot_50_configure_mne.html" title="next page">Configuring MNE-Python</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.014cad6f3a039303089e.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-37225609-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
<footer class="footer mt-5 mt-md-0">
  <div class="container institutions">
    <div class="d-flex flex-wrap flex-row justify-content-center">
      <div class="m-2">
          <a href="https://www.massgeneral.org/">
            <img class="institution" src="../../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://martinos.org/">
            <img class="institution" src="../../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://hms.harvard.edu/">
            <img class="institution" src="../../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://web.mit.edu/">
            <img class="institution" src="../../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.nyu.edu/">
            <img class="institution" src="../../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="http://www.cea.fr/">
            <img class="institution" src="../../_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://sci.aalto.fi/">
            <img class="institution" src="../../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.telecom-paris.fr/">
            <img class="institution" src="../../_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.washington.edu/">
            <img class="institution" src="../../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://icm-institute.org/">
            <img class="institution" src="../../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.bu.edu/">
            <img class="institution" src="../../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inserm.fr/">
            <img class="institution" src="../../_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.fz-juelich.de/">
            <img class="institution" src="../../_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.tu-ilmenau.de/">
            <img class="institution" src="../../_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://bids.berkeley.edu/">
            <img class="institution" src="../../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inria.fr/">
            <img class="institution" src="../../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.au.dk/">
            <img class="institution" src="../../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.uni-graz.at/">
            <img class="institution" src="../../_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/>
          </a>
        </div>
      
    </div>
  </div>
  <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-02-19T12:28:42.787072+00:00" class="localized">2021-02-19 12:28 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
</footer>
  <script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>