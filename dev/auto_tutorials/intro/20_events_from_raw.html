
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Parsing events from raw data &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="The Info data structure" href="30_info.html" />
    <link rel="prev" title="Modifying data in-place" href="15_inplace.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_time_generalization_conditions.html">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/decoding/ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_examples/datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-events-and-annotations-data-structures">
   The Events and Annotations data structures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-stim-channel">
   What is a STIM channel?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-a-stim-channel-signal-to-an-events-array">
   Converting a STIM channel signal to an Events array
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reading-embedded-events-as-annotations">
   Reading embedded events as Annotations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-between-events-arrays-and-annotations-objects">
   Converting between Events arrays and Annotations objects
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#making-multiple-events-per-annotation">
   Making multiple events per annotation
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-intro-20-events-from-raw-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="parsing-events-from-raw-data">
<span id="tut-events-vs-annotations"></span><span id="sphx-glr-auto-tutorials-intro-20-events-from-raw-py"></span><h1>Parsing events from raw data<a class="headerlink" href="#parsing-events-from-raw-data" title="Permalink to this headline">¶</a></h1>
<p>This tutorial describes how to read experimental events from raw recordings,
and how to convert between the two different representations of events within
MNE-Python (Events arrays and Annotations objects).</p>
<p>In the <a class="reference internal" href="10_overview.html#overview-tut-events-section"><span class="std std-ref">introductory tutorial</span></a> we saw an
example of reading experimental events from a <a class="reference internal" href="../../glossary.html#term-stim-channel"><span class="xref std std-term">“STIM” channel</span></a>; here we’ll discuss <a class="reference internal" href="../../glossary.html#term-events"><span class="xref std std-term">events</span></a> and <a class="reference internal" href="../../glossary.html#term-annotations"><span class="xref std std-term">annotations</span></a> more
broadly, give more detailed information about reading from STIM channels, and
give an example of reading events that are in a marker file or included in
the data file as an embedded array. The tutorials <a class="reference internal" href="../raw/20_event_arrays.html#tut-event-arrays"><span class="std std-ref">Working with events</span></a> and
<a class="reference internal" href="../raw/30_annotate_raw.html#tut-annotate-raw"><span class="std std-ref">Annotating continuous data</span></a> discuss how to plot, combine, load, save, and
export <a class="reference internal" href="../../glossary.html#term-events"><span class="xref std std-term">events</span></a> and <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> (respectively), and the
latter tutorial also covers interactive annotation of <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects.</p>
<p>We’ll begin by loading the Python modules we need, and loading the same
<a class="reference internal" href="../../overview/datasets_index.html#sample-dataset"><span class="std std-ref">example data</span></a> we used in the <a class="reference internal" href="10_overview.html#tut-overview"><span class="std std-ref">introductory tutorial</span></a>, but to save memory we’ll crop the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object
to just 60 seconds before loading it into RAM:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mne</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_folder</span></a><span class="p">,</span> <span class="s1">&#39;MEG&#39;</span><span class="p">,</span> <span class="s1">&#39;sample&#39;</span><span class="p">,</span>
                                    <span class="s1">&#39;sample_audvis_raw.fif&#39;</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_data_raw_file</span></a><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.crop" title="mne.io.Raw.crop" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">crop</span></a><span class="p">(</span><span class="n">tmax</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
    Read a total of 3 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
    Range : 25800 ... 192599 =     42.956 ...   320.670 secs
Ready.
Reading 0 ... 36037  =      0.000 ...    60.000 secs...
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">


<table class="table table-hover">
    <tr>
        <th>Measurement date</th>
        <td>December 03, 2002  19:01:10 GMT</td>

    </tr>
    <tr>
        <th>Experimenter</th>
        <td>MEG</td>

    </tr>
        <th>Participant</th>
<td>Unknown</td>
    </tr>
    <tr>
        <th>Digitized points</th>
        <td>146 points</td>
    </tr>
    <tr>
        <th>Good channels</th>
        <td>102 magnetometer, 203 gradiometer,
            59 EEG channels, and 0 fNIRS channels.</td>
    </tr>
    <tr>
        <th>Bad channels</th>
        <td>MEG 2443, EEG 053</td>

    </tr>
    <tr>
        <th>EOG channels</th>
        <td>EOG 061</td>
    </tr>
    <tr>
        <th>ECG channels</th>
        <td>Not available</td>
    <tr>
        <th>Sampling frequency</th>
        <td>600.61 Hz</td>
    </tr>
    <tr>
        <th>Highpass</th>
        <td>0.10 Hz</td>
    </tr>
    <tr>
        <th>Lowpass</th>
        <td>172.18 Hz</td>
    </tr>
        <tr>
            <th>Projections</th>
            <td>PCA-v1: off<br/>PCA-v2: off<br/>PCA-v3: off</td>
        </tr>

    <tr>
        <th>Filenames</th>
        <td>sample_audvis_raw.fif</td>
    </tr>
    <tr>
        <th>Duration</th>
        <td>00:01:00 (HH:MM:SS)</td>
    </tr>
</table>

</div>
<br />
<br /><div class="section" id="the-events-and-annotations-data-structures">
<h2>The Events and Annotations data structures<a class="headerlink" href="#the-events-and-annotations-data-structures" title="Permalink to this headline">¶</a></h2>
<p>Generally speaking, both the Events and <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> data
structures serve the same purpose: they provide a mapping between times
during an EEG/MEG recording and a description of what happened at those
times. In other words, they associate a <em>when</em> with a <em>what</em>. The main
differences are:</p>
<ol class="arabic simple">
<li><p><strong>Units</strong>: the Events data structure represents the <em>when</em> in terms of
samples, whereas the <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> data structure represents
the <em>when</em> in seconds.</p></li>
<li><p><strong>Limits on the description</strong>: the Events data structure represents the
<em>what</em> as an integer “Event ID” code, whereas the <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> data
structure represents the <em>what</em> as a string.</p></li>
<li><p><strong>How duration is encoded</strong>: Events in an Event array do not have a
duration (though it is possible to represent duration with pairs of
onset/offset events within an Events array), whereas each element of an
<a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object necessarily includes a duration (though
the duration can be zero if an instantaneous event is desired).</p></li>
<li><p><strong>Internal representation</strong>: Events are stored as an ordinary
<a class="reference external" href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NumPy</span> <span class="pre">array</span></code></a>, whereas <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> is
a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>-like class defined in MNE-Python.</p></li>
</ol>
</div>
<div class="section" id="what-is-a-stim-channel">
<span id="stim-channel-defined"></span><h2>What is a STIM channel?<a class="headerlink" href="#what-is-a-stim-channel" title="Permalink to this headline">¶</a></h2>
<p>A <a class="reference internal" href="../../glossary.html#term-stim-channel"><span class="xref std std-term">stim channel</span></a> (short for “stimulus channel”) is a channel that does
not receive signals from an EEG, MEG, or other sensor. Instead, STIM channels
record voltages (usually short, rectangular DC pulses of fixed magnitudes
sent from the experiment-controlling computer) that are time-locked to
experimental events, such as the onset of a stimulus or a button-press
response by the subject (those pulses are sometimes called <a class="reference external" href="https://en.wikipedia.org/wiki/Transistor%E2%80%93transistor_logic">TTL</a> pulses,
event pulses, trigger signals, or just “triggers”). In other cases, these
pulses may not be strictly time-locked to an experimental event, but instead
may occur in between trials to indicate the type of stimulus (or experimental
condition) that is about to occur on the upcoming trial.</p>
<p>The DC pulses may be all on one STIM channel (in which case different
experimental events or trial types are encoded as different voltage
magnitudes), or they may be spread across several channels, in which case the
channel(s) on which the pulse(s) occur can be used to encode different events
or conditions. Even on systems with multiple STIM channels, there is often
one channel that records a weighted sum of the other STIM channels, in such a
way that voltage levels on that channel can be unambiguously decoded as
particular event types. On older Neuromag systems (such as that used to
record the sample data) this “summation channel” was typically <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code>;
on newer systems it is more commonly <code class="docutils literal notranslate"><span class="pre">STI101</span></code>. You can see the STIM
channels in the raw data file here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.io.Raw.html#mne.io.Raw.copy" title="mne.io.Raw.copy" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">copy</span></a><span class="p">()</span><span class="o">.</span><span class="n">pick_types</span><span class="p">(</span><span class="n">meg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">stim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_20_events_from_raw_001.png" srcset="../../_images/sphx_glr_20_events_from_raw_001.png" alt="20 events from raw" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Removing projector &lt;Projection | PCA-v1, active : False, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v2, active : False, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v3, active : False, n_channels : 102&gt;
</pre></div>
</div>
<p>You can see that <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code> (the summation channel) contains pulses of
different magnitudes whereas pulses on other channels have consistent
magnitudes. You can also see that every time there is a pulse on one of the
other STIM channels, there is a corresponding pulse on <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code>.</p>
</div>
<div class="section" id="converting-a-stim-channel-signal-to-an-events-array">
<h2>Converting a STIM channel signal to an Events array<a class="headerlink" href="#converting-a-stim-channel-signal-to-an-events-array" title="Permalink to this headline">¶</a></h2>
<p>If your data has events recorded on a STIM channel, you can convert them into
an events array using <a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a>. The sample number of the onset
(or offset) of each pulse is recorded as the event time, the pulse magnitudes
are converted into integers, and these pairs of sample numbers plus integer
codes are stored in <a class="reference external" href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NumPy</span> <span class="pre">arrays</span></code></a> (usually called
“the events array” or just “the events”). In its simplest form, the function
requires only the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object, and the name of the channel(s)
from which to read events:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">,</span> <span class="n">stim_channel</span><span class="o">=</span><span class="s1">&#39;STI 014&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>  <span class="c1"># show the first 5</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>86 events found
Event IDs: [ 1  2  3  4  5 32]
[[27977     0     2]
 [28345     0     3]
 [28771     0     1]
 [29219     0     4]
 [29652     0     2]]
</pre></div>
</div>
<div class="sidebar">
<p class="sidebar-title">The middle column of the Events array</p>
<p>MNE-Python events are actually <em>three</em> values: in between the sample
number and the integer event code is a value indicating what the event
code was on the immediately preceding sample. In practice, that value is
almost always <code class="docutils literal notranslate"><span class="pre">0</span></code>, but it can be used to detect the <em>endpoint</em> of an
event whose duration is longer than one sample. See the documentation of
<a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a> for more details.</p>
</div>
<p>If you don’t provide the name of a STIM channel, <a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a>
will first look for MNE-Python <a class="reference internal" href="50_configure_mne.html#tut-configure-mne"><span class="std std-ref">config variables</span></a>
for variables <code class="docutils literal notranslate"><span class="pre">MNE_STIM_CHANNEL</span></code>, <code class="docutils literal notranslate"><span class="pre">MNE_STIM_CHANNEL_1</span></code>, etc. If those are
not found, channels <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code> and <code class="docutils literal notranslate"><span class="pre">STI101</span></code> are tried, followed by the
first channel with type “STIM” present in <code class="docutils literal notranslate"><span class="pre">raw.ch_names</span></code>. If you regularly
work with data from several different MEG systems with different STIM channel
names, setting the <code class="docutils literal notranslate"><span class="pre">MNE_STIM_CHANNEL</span></code> config variable may not be very
useful, but for researchers whose data is all from a single system it can be
a time-saver to configure that variable once and then forget about it.</p>
<p><a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a> has several options, including options for aligning
events to the onset or offset of the STIM channel pulses, setting the minimum
pulse duration, and handling of consecutive pulses (with no return to zero
between them). For example, you can effectively encode event duration by
passing <code class="docutils literal notranslate"><span class="pre">output='step'</span></code> to <a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a>; see the documentation
of <a class="reference internal" href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_events</span></code></a> for details. More information on working with
events arrays (including how to plot, combine, load, and save event arrays)
can be found in the tutorial <a class="reference internal" href="../raw/20_event_arrays.html#tut-event-arrays"><span class="std std-ref">Working with events</span></a>.</p>
</div>
<div class="section" id="reading-embedded-events-as-annotations">
<h2>Reading embedded events as Annotations<a class="headerlink" href="#reading-embedded-events-as-annotations" title="Permalink to this headline">¶</a></h2>
<p>Some EEG/MEG systems generate files where events are stored in a separate
data array rather than as pulses on one or more STIM channels. For example,
the EEGLAB format stores events as a collection of arrays in the <code class="file docutils literal notranslate"><span class="pre">.set</span></code>
file. When reading those files, MNE-Python will automatically convert the
stored events into an <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object and store it as the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.annotations" title="mne.io.Raw.annotations"><code class="xref py py-attr docutils literal notranslate"><span class="pre">annotations</span></code></a> attribute of the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">testing_data_folder</span></a> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">data_path</span><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eeglab_raw_file</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/os.path.html#os.path.join" title="os.path.join" class="sphx-glr-backref-module-os-path sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">testing_data_folder</span></a><span class="p">,</span> <span class="s1">&#39;EEGLAB&#39;</span><span class="p">,</span> <span class="s1">&#39;test_raw.set&#39;</span><span class="p">)</span>
<span class="n">eeglab_raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_eeglab.html#mne.io.read_raw_eeglab" title="mne.io.read_raw_eeglab" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_eeglab</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eeglab_raw_file</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../generated/mne.io.BaseRaw.html#mne.io.BaseRaw.annotations" title="mne.io.BaseRaw.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">eeglab_raw</span><span class="o">.</span><span class="n">annotations</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading /home/circleci/mne_data/MNE-testing-data/EEGLAB/test_raw.fdt
&lt;Annotations | 154 segments: rt (74), square (80)&gt;
</pre></div>
</div>
<p>The core data within an <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is accessible
through three of its attributes: <code class="docutils literal notranslate"><span class="pre">onset</span></code>, <code class="docutils literal notranslate"><span class="pre">duration</span></code>, and
<code class="docutils literal notranslate"><span class="pre">description</span></code>. Here we can see that there were 154 events stored in the
EEGLAB file, they all had a duration of zero seconds, there were two
different types of events, and the first event occurred about 1 second after
the recording began:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><a href="../../generated/mne.io.BaseRaw.html#mne.io.BaseRaw.annotations" title="mne.io.BaseRaw.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">eeglab_raw</span><span class="o">.</span><span class="n">annotations</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><a href="../../generated/mne.io.BaseRaw.html#mne.io.BaseRaw.annotations" title="mne.io.BaseRaw.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">eeglab_raw</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">duration</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><a href="../../generated/mne.io.BaseRaw.html#mne.io.BaseRaw.annotations" title="mne.io.BaseRaw.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">eeglab_raw</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">description</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a href="../../generated/mne.io.BaseRaw.html#mne.io.BaseRaw.annotations" title="mne.io.BaseRaw.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">eeglab_raw</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">onset</span></a><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>154
{0.0}
{&#39;square&#39;, &#39;rt&#39;}
1.000068
</pre></div>
</div>
<p>More information on working with <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> objects, including
how to add annotations to <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects interactively, and how
to plot, concatenate, load, save, and export <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a>
objects can be found in the tutorial <a class="reference internal" href="../raw/30_annotate_raw.html#tut-annotate-raw"><span class="std std-ref">Annotating continuous data</span></a>.</p>
</div>
<div class="section" id="converting-between-events-arrays-and-annotations-objects">
<h2>Converting between Events arrays and Annotations objects<a class="headerlink" href="#converting-between-events-arrays-and-annotations-objects" title="Permalink to this headline">¶</a></h2>
<p>Once your experimental events are read into MNE-Python (as either an Events
array or an <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object), you can easily convert between
the two formats as needed. You might do this because, e.g., an Events array
is needed for epoching continuous data, or because you want to take advantage
of the “annotation-aware” capability of some functions, which automatically
omit spans of data if they overlap with certain annotations.</p>
<p>To convert an <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object to an Events array, use the
function <a class="reference internal" href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.events_from_annotations</span></code></a> on the <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> file
containing the annotations. This function will assign an integer Event ID to
each unique element of <code class="docutils literal notranslate"><span class="pre">raw.annotations.description</span></code>, and will return the
mapping of descriptions to integer Event IDs along with the derived Event
array. By default, one event will be created at the onset of each annotation;
this can be modified via the <code class="docutils literal notranslate"><span class="pre">chunk_duration</span></code> parameter of
<a class="reference internal" href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events_from_annotations</span></code></a> to create equally spaced events within
each annotation span (see <a class="reference internal" href="#chunk-duration"><span class="std std-ref">Making multiple events per annotation</span></a>, below, or see
<a class="reference internal" href="../raw/20_event_arrays.html#fixed-length-events"><span class="std std-ref">Making equally-spaced Events arrays</span></a> for direct creation of an Events array of
equally-spaced events).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_from_annot</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a> <span class="o">=</span> <a href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">events_from_annotations</span></a><span class="p">(</span><span class="n">eeglab_raw</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_from_annot</span></a><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Used Annotations descriptions: [&#39;rt&#39;, &#39;square&#39;]
{&#39;rt&#39;: 1, &#39;square&#39;: 2}
[[128   0   2]
 [217   0   2]
 [267   0   1]
 [602   0   2]
 [659   0   1]]
</pre></div>
</div>
<p>If you want to control which integers are mapped to each unique description
value, you can pass a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a> specifying the mapping as the
<code class="docutils literal notranslate"><span class="pre">event_id</span></code> parameter of <a class="reference internal" href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events_from_annotations</span></code></a>; this
<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a> will be returned unmodified as the <code class="docutils literal notranslate"><span class="pre">event_dict</span></code>.</p>
<p>Note that this <code class="docutils literal notranslate"><span class="pre">event_dict</span></code> can be used when creating <a class="reference internal" href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Epochs</span></code></a> from
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects, as demonstrated in the tutorial
<a class="reference internal" href="../epochs/10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">custom_mapping</span></a> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rt&#39;</span><span class="p">:</span> <span class="mi">77</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">:</span> <span class="mi">42</span><span class="p">}</span>
<span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_from_annot</span></a><span class="p">,</span>
 <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a><span class="p">)</span> <span class="o">=</span> <a href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">events_from_annotations</span></a><span class="p">(</span><span class="n">eeglab_raw</span><span class="p">,</span> <span class="n">event_id</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">custom_mapping</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_dict</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_from_annot</span></a><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Used Annotations descriptions: [&#39;rt&#39;, &#39;square&#39;]
{&#39;rt&#39;: 77, &#39;square&#39;: 42}
[[128   0  42]
 [217   0  42]
 [267   0  77]
 [602   0  42]
 [659   0  77]]
</pre></div>
</div>
<p>To make the opposite conversion (from an Events array to an
<a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object), you can create a mapping from integer
Event ID to string descriptions, use <a class="reference internal" href="../../generated/mne.annotations_from_events.html#mne.annotations_from_events" title="mne.annotations_from_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">annotations_from_events</span></code></a>
to construct the <a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object, and call the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw.set_annotations" title="mne.io.Raw.set_annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_annotations</span></code></a> method to add the annotations to the
<a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object.</p>
<p>Because the <a class="reference internal" href="../../overview/datasets_index.html#sample-dataset"><span class="std std-ref">sample data</span></a> was recorded on a Neuromag
system (where sample numbering starts when the acquisition system is
initiated, not when the <em>recording</em> is initiated), we also need to pass in
the <code class="docutils literal notranslate"><span class="pre">orig_time</span></code> parameter so that the onsets are properly aligned relative
to the start of recording:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mapping</span></a> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;auditory/left&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;auditory/right&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;visual/left&#39;</span><span class="p">,</span>
           <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;visual/right&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s1">&#39;smiley&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">:</span> <span class="s1">&#39;buttonpress&#39;</span><span class="p">}</span>
<a href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">annot_from_events</span></a> <span class="o">=</span> <a href="../../generated/mne.annotations_from_events.html#mne.annotations_from_events" title="mne.annotations_from_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">annotations_from_events</span></a><span class="p">(</span>
    <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <span class="n">event_desc</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mapping</span></a><span class="p">,</span> <span class="n">sfreq</span><span class="o">=</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">[</span><span class="s1">&#39;sfreq&#39;</span><span class="p">],</span>
    <span class="n">orig_time</span><span class="o">=</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">[</span><span class="s1">&#39;meas_date&#39;</span><span class="p">])</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.set_annotations" title="mne.io.Raw.set_annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">set_annotations</span></a><span class="p">(</span><a href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">annot_from_events</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">


<table class="table table-hover">
    <tr>
        <th>Measurement date</th>
        <td>December 03, 2002  19:01:10 GMT</td>

    </tr>
    <tr>
        <th>Experimenter</th>
        <td>MEG</td>

    </tr>
        <th>Participant</th>
<td>Unknown</td>
    </tr>
    <tr>
        <th>Digitized points</th>
        <td>146 points</td>
    </tr>
    <tr>
        <th>Good channels</th>
        <td>102 magnetometer, 203 gradiometer,
            59 EEG channels, and 0 fNIRS channels.</td>
    </tr>
    <tr>
        <th>Bad channels</th>
        <td>MEG 2443, EEG 053</td>

    </tr>
    <tr>
        <th>EOG channels</th>
        <td>EOG 061</td>
    </tr>
    <tr>
        <th>ECG channels</th>
        <td>Not available</td>
    <tr>
        <th>Sampling frequency</th>
        <td>600.61 Hz</td>
    </tr>
    <tr>
        <th>Highpass</th>
        <td>0.10 Hz</td>
    </tr>
    <tr>
        <th>Lowpass</th>
        <td>172.18 Hz</td>
    </tr>
        <tr>
            <th>Projections</th>
            <td>PCA-v1: off<br/>PCA-v2: off<br/>PCA-v3: off</td>
        </tr>

    <tr>
        <th>Filenames</th>
        <td>sample_audvis_raw.fif</td>
    </tr>
    <tr>
        <th>Duration</th>
        <td>00:01:00 (HH:MM:SS)</td>
    </tr>
</table>

</div>
<br />
<br /><p>Now, the annotations will appear automatically when plotting the raw data,
and will be color-coded by their label value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.io.Raw.html#mne.io.Raw.plot" title="mne.io.Raw.plot" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_20_events_from_raw_002.png" srcset="../../_images/sphx_glr_20_events_from_raw_002.png" alt="20 events from raw" class = "sphx-glr-single-img"/></div>
<div class="section" id="making-multiple-events-per-annotation">
<span id="chunk-duration"></span><h2>Making multiple events per annotation<a class="headerlink" href="#making-multiple-events-per-annotation" title="Permalink to this headline">¶</a></h2>
<p>As mentioned above, you can generate equally-spaced events from an
<a class="reference internal" href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Annotations</span></code></a> object using the <code class="docutils literal notranslate"><span class="pre">chunk_duration</span></code> parameter of
<a class="reference internal" href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events_from_annotations</span></code></a>. For example, suppose we have an
annotation in our <a class="reference internal" href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> object indicating when the subject was
in REM sleep, and we want to perform a resting-state analysis on those spans
of data. We can create an Events array with a series of equally-spaced events
within each “REM” span, and then use those events to generate (potentially
overlapping) epochs that we can analyze further.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the REM annotations</span>
<a href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rem_annot</span></a> <span class="o">=</span> <a href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Annotations</span></a><span class="p">(</span><span class="n">onset</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">41</span><span class="p">],</span>
                            <span class="n">duration</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
                            <span class="n">description</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;REM&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.set_annotations" title="mne.io.Raw.set_annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">set_annotations</span></a><span class="p">(</span><a href="../../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rem_annot</span></a><span class="p">)</span>
<span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rem_events</span></a><span class="p">,</span>
 <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rem_event_dict</span></a><span class="p">)</span> <span class="o">=</span> <a href="../../generated/mne.events_from_annotations.html#mne.events_from_annotations" title="mne.events_from_annotations" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">events_from_annotations</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">,</span> <span class="n">chunk_duration</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Used Annotations descriptions: [&#39;REM&#39;]
</pre></div>
</div>
<p>Now we can check that our events indeed fall in the ranges 5-21 seconds and
41-52 seconds, and are ~1.5 seconds apart (modulo some jitter due to the
sampling frequency). Here are the event times rounded to the nearest
millisecond:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">((</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rem_events</span></a><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <a href="../../generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">raw</span><span class="o">.</span><span class="n">first_samp</span></a><span class="p">)</span> <span class="o">/</span> <a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">[</span><span class="s1">&#39;sfreq&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[ 5.     6.5    8.     9.5   11.    12.501 14.001 15.501 16.999 18.499
 41.    42.5   44.    45.5   47.    48.5   50.   ]
</pre></div>
</div>
<p>Other examples of resting-state analysis can be found in the online
documentation for <a class="reference internal" href="../../generated/mne.make_fixed_length_events.html#mne.make_fixed_length_events" title="mne.make_fixed_length_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_fixed_length_events</span></code></a>, such as
<a class="reference internal" href="../../auto_examples/connectivity/mne_inverse_envelope_correlation.html#ex-envelope-correlation"><span class="std std-ref">Compute envelope correlations in source space</span></a>.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  6.472 seconds)</p>
<p><strong>Estimated memory usage:</strong>  112 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-intro-20-events-from-raw-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/1d9c09726662ccb62d60b1a9bfb40280/20_events_from_raw.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">20_events_from_raw.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f61f2c2f6132bd3b1076dab7ac194713/20_events_from_raw.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">20_events_from_raw.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="15_inplace.html" title="previous page">Modifying data in-place</a>
    <a class='right-next' id="next-link" href="30_info.html" title="next page">The Info data structure</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-06-15T12:45:13.416880+00:00" class="localized">2021-06-15 12:45 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>