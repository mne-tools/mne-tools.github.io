
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="auto">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Tutorials &#8212; MNE 1.9.0.dev144+g14938b965 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "auto";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=1395d0ad" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=c0bb9bb1"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-5TBCPCRB6X"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_tutorials/index';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://mne.tools/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.9';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introductory tutorials" href="intro/index.html" />
    <link rel="prev" title="Documentation overview" href="../documentation/index.html" />
    <link rel="canonical" href="https://mne.tools/stable/auto_tutorials/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.9" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="auto">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/mne_logo_small.svg" class="logo__image only-light" alt="MNE 1.9.0.dev144+g14938b965 documentation - Home"/>
    <img src="../_static/mne_logo_small.svg" class="logo__image only-dark pst-js-only" alt="MNE 1.9.0.dev144+g14938b965 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help/index.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help/index.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="intro/index.html">Introductory tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="intro/10_overview.html">Overview of MEG/EEG analysis with MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/15_inplace.html">Modifying data in-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/20_events_from_raw.html">Parsing events from raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/30_info.html">The Info data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/40_sensor_locations.html">Working with sensor locations</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/50_configure_mne.html">Configuring MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="intro/70_report.html">Getting started with mne.Report</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="io/index.html">Reading data for different recording systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="io/10_reading_meg_data.html">Importing data from MEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/20_reading_eeg_data.html">Importing data from EEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/30_reading_fnirs_data.html">Importing data from fNIRS devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/60_ctf_bst_auditory.html">Working with CTF data: the Brainstorm auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/70_reading_eyetracking_data.html">Importing Data from Eyetracking devices</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="raw/index.html">Working with continuous data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="raw/10_raw_overview.html">The Raw data structure: continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="raw/20_event_arrays.html">Working with events</a></li>
<li class="toctree-l3"><a class="reference internal" href="raw/30_annotate_raw.html">Annotating continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="raw/40_visualize_raw.html">Built-in plotting methods for Raw objects</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/10_preprocessing_overview.html">Overview of artifact detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/15_handling_bad_channels.html">Handling bad channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/20_rejecting_bad_data.html">Rejecting bad data spans and breaks</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/25_background_filtering.html">Background information on filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/30_filtering_resampling.html">Filtering and resampling data</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/35_artifact_correction_regression.html">Repairing artifacts with regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/40_artifact_correction_ica.html">Repairing artifacts with ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/45_projectors_background.html">Background on projectors and projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/50_artifact_correction_ssp.html">Repairing artifacts with SSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/55_setting_eeg_reference.html">Setting the EEG reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/59_head_positions.html">Extracting and visualizing subject head movement</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/60_maxwell_filtering_sss.html">Signal-space separation (SSS) and Maxwell filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/70_fnirs_processing.html">Preprocessing functional near-infrared spectroscopy (fNIRS) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/80_opm_processing.html">Preprocessing optically pumped magnetometer (OPM) MEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/90_eyetracking_data.html">Working with eye tracker data in MNE-Python</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="epochs/index.html">Segmenting continuous data into epochs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="epochs/10_epochs_overview.html">The Epochs data structure: discontinuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/15_baseline_regression.html">Regression-based baseline correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/20_visualize_epochs.html">Visualizing epoched data</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/30_epochs_metadata.html">Working with Epoch metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/40_autogenerate_metadata.html">Auto-generating Epochs metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/50_epochs_to_data_frame.html">Exporting Epochs to Pandas DataFrames</a></li>
<li class="toctree-l3"><a class="reference internal" href="epochs/60_make_fixed_length_epochs.html">Divide continuous data into equally-spaced epochs</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="evoked/index.html">Estimating evoked responses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="evoked/10_evoked_overview.html">The Evoked data structure: evoked/averaged data</a></li>
<li class="toctree-l3"><a class="reference internal" href="evoked/20_visualize_evoked.html">Visualizing Evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="evoked/30_eeg_erp.html">EEG analysis - Event-Related Potentials (ERPs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="evoked/40_whitened.html">Plotting whitened data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="time-freq/index.html">Time-frequency analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="time-freq/10_spectrum_class.html">The Spectrum and EpochsSpectrum classes: frequency-domain data</a></li>
<li class="toctree-l3"><a class="reference internal" href="time-freq/20_sensors_time_frequency.html">Frequency and time-frequency sensor analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="time-freq/50_ssvep.html">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="forward/index.html">Forward models and source spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="forward/10_background_freesurfer.html">FreeSurfer MRI reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/20_source_alignment.html">Source alignment and coordinate frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/25_automated_coreg.html">Using an automated approach to coregistration</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/30_forward.html">Head model and forward computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/35_eeg_no_mri.html">EEG forward operator with a template MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/50_background_freesurfer_mne.html">How MNE uses FreeSurfer’s outputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/80_fix_bem_in_blender.html">Fixing BEM and head surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/90_compute_covariance.html">Computing a covariance matrix</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="inverse/index.html">Source localization and inverses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="inverse/10_stc_class.html">The SourceEstimate data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/20_dipole_fit.html">Source localization with equivalent current dipole (ECD) fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/30_mne_dspm_loreta.html">Source localization with MNE, dSPM, sLORETA, and eLORETA</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/35_dipole_orientations.html">The role of dipole orientations in distributed source localization</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/40_mne_fixed_free.html">Computing various MNE solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/50_beamformer_lcmv.html">Source reconstruction using an LCMV beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/60_visualize_stc.html">Visualize source time courses (stcs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/70_eeg_mri_coords.html">EEG source localization given electrode locations on an MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/80_brainstorm_phantom_elekta.html">Brainstorm Elekta phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/85_brainstorm_phantom_ctf.html">Brainstorm CTF phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/90_phantom_4DBTi.html">4D Neuroimaging/BTi phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/95_phantom_KIT.html">KIT phantom dataset tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="stats-sensor-space/index.html">Statistical analysis of sensor data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/10_background_stats.html">Statistical inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/20_erp_stats.html">Visualising statistical significance thresholds on EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/40_cluster_1samp_time_freq.html">Non-parametric 1 sample cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/50_cluster_between_time_freq.html">Non-parametric between conditions cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/70_cluster_rmANOVA_time_freq.html">Mass-univariate twoway repeated measures ANOVA on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-sensor-space/75_cluster_ftest_spatiotemporal.html">Spatiotemporal permutation F-test on full sensor data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="stats-source-space/index.html">Statistical analysis of source estimates</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="stats-source-space/20_cluster_1samp_spatiotemporal.html">Permutation t-test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-source-space/30_cluster_ftest_spatiotemporal.html">2 samples permutation test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">Repeated measures ANOVA on source data with spatio-temporal clustering</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="machine-learning/index.html">Machine learning models of neural activity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="machine-learning/30_strf.html">Spectro-temporal receptive field (STRF) estimation on continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="machine-learning/50_decoding.html">Decoding (MVPA)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="clinical/index.html">Clinical applications</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="clinical/20_seeg.html">Working with sEEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="clinical/30_ecog.html">Working with ECoG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="clinical/60_sleep.html">Sleep stage classification from polysomnography (PSG) data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="simulation/index.html">Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="simulation/10_array_objs.html">Creating MNE-Python data structures from scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/70_point_spread.html">Corrupt known signal with point spread</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/80_dics.html">DICS for power mapping</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="visualization/index.html">Visualization tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="visualization/10_publication_figure.html">Make figures more publication ready</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/20_ui_events.html">Using the event system to link figures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/io/index.html">Input/Output</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/elekta_epochs.html">Getting averaging info from .fif files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_impedances.html">Getting impedances from raw files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_neo_format.html">How to use data in neural ensemble (NEO) format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_noise_covariance_matrix.html">Reading/Writing a noise covariance matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_xdf.html">Reading XDF EEG data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/simulation/index.html">Data Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/plot_stc_metrics.html">Compare simulated and estimated source activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulate_evoked_data.html">Generate simulated evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulate_raw_data.html">Generate simulated raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">Simulate raw data using subject anatomy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/source_simulator.html">Generate simulated source data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/contralateral_referencing.html">Using contralateral referencing for EEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/css.html">Cortical Signal Suppression (CSS) for removal of cortical signals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/define_target_events.html">Define target events based on time lag, plot evoked response</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eeg_bridging.html">Identify EEG Electrodes Bridged by too much Gel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eeg_csd.html">Transform EEG data using current source density (CSD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eog_artifact_histogram.html">Show EOG artifact timing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eog_regression.html">Reduce EOG artifacts through regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/epochs_metadata.html">Automated epochs metadata generation with variable time windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/find_ref_artifacts.html">Find MEG reference channel artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/fnirs_artifact_removal.html">Visualise NIRS artifact correction methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/ica_comparison.html">Compare the different ICA algorithms in MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/interpolate_bad_channels.html">Interpolate bad channels for MEG/EEG channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/movement_compensation.html">Maxwell filter data with movement compensation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/movement_detection.html">Annotate movement artifacts and reestimate dev_head_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/muscle_detection.html">Annotate muscle artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/muscle_ica.html">Removing muscle ICA components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/otp.html">Plot sensor denoising using oversampled temporal projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/shift_evoked.html">Shifting time-scale in evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/virtual_evoked.html">Remap MEG channel types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/xdawn_denoising.html">XDAWN Denoising</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/visualization/index.html">Visualization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/3d_to_2d.html">How to convert 3D electrode positions to a 2D image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/brain.html">Plotting with <code class="docutils literal notranslate"><span class="pre">mne.viz.Brain</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/channel_epochs_image.html">Visualize channel over epochs as an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/eeg_on_scalp.html">Plotting EEG sensors on the scalp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_arrowmap.html">Plotting topographic arrowmaps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_topomap.html">Plotting topographic maps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_whitening.html">Whitening evoked data with a noise covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/eyetracking_plot_heatmap.html">Plotting eye-tracking heatmaps in MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/meg_sensors.html">Plotting sensor layouts of MEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/mne_helmet.html">Plot the MNE brain and helmet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/montage_sgskip.html">Plotting sensor layouts of EEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/parcellation.html">Plot a cortical parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/roi_erpimage_by_rt.html">Plot single trial activity, grouped by ROI and sorted by RT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/ssp_projs_sensitivity_map.html">Sensitivity map of SSP projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/topo_compare_conditions.html">Compare evoked responses for different conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/topo_customized.html">Plot custom topographies for MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/xhemi.html">Cross-hemisphere comparison</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/time_frequency/index.html">Time-Frequency Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/compute_csd.html">Compute a cross-spectral density (CSD) matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/compute_source_psd_epochs.html">Compute Power Spectral Density of inverse solution from single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_label_time_frequency.html">Compute power and phase lock in label of the source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_power_spectrum.html">Compute source power spectral density (PSD) in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_power_spectrum_opm.html">Compute source power spectral density (PSD) of VectorView and OPM data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_space_time_frequency.html">Compute induced power in the source space with dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/temporal_whitening.html">Temporal whitening with AR model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_erds.html">Compute and visualize ERDS maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_global_field_power.html">Explore event-related dynamics for specific frequency bands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_simulated.html">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/stats/index.html">Statistics Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/cluster_stats_evoked.html">Permutation F-test on sensor data with 1D cluster level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/fdr_stats_evoked.html">FDR correction on T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/linear_regression_raw.html">Regression on continuous data (rER[P/F])</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/sensor_permutation_test.html">Permutation T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/sensor_regression.html">Analysing continuous features with binning and regression in sensor space</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/decoding/index.html">Machine Learning (Decoding, Encoding, and MVPA)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_csp_eeg.html">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_csp_timefreq.html">Decoding in time-frequency space using Common Spatial Patterns (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_rsa_sgskip.html">Representational Similarity Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_spatio_temporal_source.html">Decoding source space data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_spoc_CMC.html">Continuous Target Decoding with SPoC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_time_generalization_conditions.html">Decoding sensor space data with generalization across time and conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">Analysis of evoked response using ICA and PCA reduction techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_xdawn_eeg.html">XDAWN Decoding From EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/ems_filtering.html">Compute effect-matched-spatial filtering (EMS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/linear_model_patterns.html">Linear classifier on sensor data with plot patterns and filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/receptive_field_mtrf.html">Receptive Field Estimation and Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/ssd_spatial_filters.html">Compute spatial filters with Spatio-Spectral Decomposition (SSD)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/connectivity/index.html">Connectivity Analysis Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/forward/index.html">Forward modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/forward_sensitivity_maps.html">Display sensitivity maps for EEG and MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/left_cerebellum_volume_source.html">Generate a left cerebellum volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/source_space_morphing.html">Use source space morphing</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/inverse/index.html">Inverse problem and source analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">Compute MNE-dSPM inverse solution on single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">Compute sLORETA inverse solution on raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_volume.html">Compute MNE-dSPM inverse solution on evoked data in volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/custom_inverse_solver.html">Source localization with a custom inverse solver</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/dics_epochs.html">Compute source level time-frequency timecourses using a DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/dics_source_power.html">Compute source power using DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/evoked_ers_source_power.html">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/gamma_map_inverse.html">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_activation_from_stc.html">Extracting time course from source_estimate object</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_from_stc.html">Generate a functional label from source estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_source_activations.html">Extracting the time series of activations in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mixed_norm_inverse.html">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mixed_source_space_inverse.html">Compute MNE inverse solution on evoked data with a mixed source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mne_cov_power.html">Compute source power estimate by projecting the covariance with MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/morph_surface_stc.html">Morph surface source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/morph_volume_stc.html">Morph volumetric source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/multi_dipole_model.html">Computing source timecourses with an XFit-like multi-dipole model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/multidict_reweighted_tfmxne.html">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_label_leakage.html">Visualize source leakage among labels using a circular graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_vertices.html">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_vertices_lcmv.html">Compute cross-talk functions for LCMV beamformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_volume.html">Plot point-spread functions (PSFs) for a volume</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/rap_music.html">Compute Rap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/read_inverse.html">Reading an inverse operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/read_stc.html">Reading an STC file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/resolution_metrics.html">Compute spatial resolution metrics in source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/resolution_metrics_eegmeg.html">Compute spatial resolution metrics to compare MEG with EEG+MEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/snr_estimate.html">Estimate data SNR using an inverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/source_space_snr.html">Computing source space SNR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">Compute MxNE with time-frequency sparse prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/trap_music.html">Compute Trap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/vector_mne_solution.html">Plotting the full vector-valued MNE solution</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/datasets/index.html">Examples on open datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/brainstorm_data.html">Brainstorm raw (median nerve) dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/hf_sef_data.html">HF-SEF dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/kernel_phantom.html">Kernel OPM phantom data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/limo_data.html">Single trial linear regression analysis with the LIMO dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/opm_data.html">Optically pumped magnetometer (OPM) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/spm_faces_dataset.html">From raw data to dSPM on SPM Faces dataset</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/implementation.html">Implementation details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/design_philosophy.html">Design philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/datasets.html">Example datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/commands.html">Command-line tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help/migrating.html">Migrating from other analysis software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cookbook.html">The typical M/EEG workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cite.html">How to cite MNE-Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cited.html">Papers citing MNE-Python</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
<div>
  
  <section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Link to this heading">#</a></h1>
<p>These tutorials provide narrative explanations, sample code, and expected
output for the most common MNE-Python analysis tasks. The emphasis here is on
thorough explanations that get you up to speed quickly, at the expense of
covering only a limited number of topics. The sections and tutorials are
arranged in a fixed order, so in theory a new user should be able to progress
through in order without encountering any cases where background
knowledge is assumed and unexplained. More experienced users (i.e., those with
significant experience analyzing EEG/MEG signals with different software) can
probably skip around to just the topics they need without too much trouble.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If tutorial-scripts contain plots and are run locally, using the
interactive flag with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-i</span> <span class="pre">tutorial_script.py</span></code>
keeps them open.</p>
</div>
<div class="sphx-glr-thumbnails"></div><section id="introductory-tutorials">
<h2>Introductory tutorials<a class="headerlink" href="#introductory-tutorials" title="Link to this heading">#</a></h2>
<p>These tutorials cover the basic EEG/MEG pipeline for event-related analysis,
introduce the <a class="reference internal" href="../generated/mne.Info.html#mne.Info" title="mne.Info"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Info</span></code></a>, <a class="reference internal" href="../documentation/glossary.html#term-events"><span class="xref std std-term">events</span></a>, and <a class="reference internal" href="../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Annotations</span></code></a>
data structures, discuss how sensor locations are handled, and introduce some
of the configuration options available.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basic EEG/MEG pipeline for event-related analysis: loading data, epoching, averaging, plotting, and estimating cortical activity from sensor data. It introduces the core MNE-Python data structures Raw, Epochs, Evoked, and SourceEstimate, and covers a lot of ground fairly quickly (at the expense of depth). Subsequent tutorials address each of these topics in greater detail."><img alt="" src="../_images/sphx_glr_10_overview_thumb.png" />
<p><a class="reference internal" href="intro/10_overview.html#sphx-glr-auto-tutorials-intro-10-overview-py"><span class="std std-ref">Overview of MEG/EEG analysis with MNE-Python</span></a></p>
  <div class="sphx-glr-thumbnail-title">Overview of MEG/EEG analysis with MNE-Python</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Many of MNE-Python&#x27;s data objects (`~mne.io.Raw`, Epochs, Evoked, etc) have methods that modify the data in-place (either optionally or obligatorily). This can be advantageous when working with large datasets because it reduces the amount of computer memory needed to perform the computations. However, it can lead to unexpected results if you&#x27;re not aware that it&#x27;s happening. This tutorial provides a few examples of in-place processing, and how and when to avoid it."><img alt="" src="../_images/sphx_glr_15_inplace_thumb.png" />
<p><a class="reference internal" href="intro/15_inplace.html#sphx-glr-auto-tutorials-intro-15-inplace-py"><span class="std std-ref">Modifying data in-place</span></a></p>
  <div class="sphx-glr-thumbnail-title">Modifying data in-place</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes how to read experimental events from raw recordings, and how to convert between the two different representations of events within MNE-Python (Events arrays and Annotations objects)."><img alt="" src="../_images/sphx_glr_20_events_from_raw_thumb.png" />
<p><a class="reference internal" href="intro/20_events_from_raw.html#sphx-glr-auto-tutorials-intro-20-events-from-raw-py"><span class="std std-ref">Parsing events from raw data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Parsing events from raw data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes the mne.Info data structure, which keeps track of various recording details, and is attached to Raw, Epochs, and Evoked objects."><img alt="" src="../_images/sphx_glr_30_info_thumb.png" />
<p><a class="reference internal" href="intro/30_info.html#sphx-glr-auto-tutorials-intro-30-info-py"><span class="std std-ref">The Info data structure</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Info data structure</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes how to read and plot sensor locations, and how MNE-Python handles physical locations of sensors. As usual we&#x27;ll start by importing the modules we need:"><img alt="" src="../_images/sphx_glr_40_sensor_locations_thumb.png" />
<p><a class="reference internal" href="intro/40_sensor_locations.html#sphx-glr-auto-tutorials-intro-40-sensor-locations-py"><span class="std std-ref">Working with sensor locations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with sensor locations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers how to configure MNE-Python to suit your local system and your analysis preferences."><img alt="" src="../_images/sphx_glr_50_configure_mne_thumb.png" />
<p><a class="reference internal" href="intro/50_configure_mne.html#sphx-glr-auto-tutorials-intro-50-configure-mne-py"><span class="std std-ref">Configuring MNE-Python</span></a></p>
  <div class="sphx-glr-thumbnail-title">Configuring MNE-Python</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="mne.Report is a way to create interactive HTML summaries of your data. These reports can show many different visualizations for one or multiple participants. A common use case is creating diagnostic summaries to check data quality at different stages in the processing pipeline. The report can show things like plots of data before and after each preprocessing step, epoch rejection statistics, MRI slices with overlaid BEM shells, all the way up to plots of estimated cortical activity."><img alt="" src="../_images/sphx_glr_70_report_thumb.svg" />
<p><a class="reference internal" href="intro/70_report.html#sphx-glr-auto-tutorials-intro-70-report-py"><span class="std std-ref">Getting started with mne.Report</span></a></p>
  <div class="sphx-glr-thumbnail-title">Getting started with mne.Report</div>
</div></div></section>
<section id="reading-data-for-different-recording-systems">
<h2>Reading data for different recording systems<a class="headerlink" href="#reading-data-for-different-recording-systems" title="Link to this heading">#</a></h2>
<p>These tutorials cover the basics of loading EEG/MEG data into MNE-Python
for various recording devices.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This section describes how to read data for various MEG manufacturers."><img alt="" src="../_images/sphx_glr_10_reading_meg_data_thumb.png" />
<p><a class="reference internal" href="io/10_reading_meg_data.html#sphx-glr-auto-tutorials-io-10-reading-meg-data-py"><span class="std std-ref">Importing data from MEG devices</span></a></p>
  <div class="sphx-glr-thumbnail-title">Importing data from MEG devices</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="MNE includes various functions and utilities for reading EEG data and electrode locations."><img alt="" src="../_images/sphx_glr_20_reading_eeg_data_thumb.png" />
<p><a class="reference internal" href="io/20_reading_eeg_data.html#sphx-glr-auto-tutorials-io-20-reading-eeg-data-py"><span class="std std-ref">Importing data from EEG devices</span></a></p>
  <div class="sphx-glr-thumbnail-title">Importing data from EEG devices</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="fNIRS devices consist of two kinds of optodes: light sources (AKA &quot;emitters&quot; or &quot;transmitters&quot;) and light detectors (AKA &quot;receivers&quot;). Channels are defined as source-detector pairs, and channel locations are defined as the midpoint between source and detector."><img alt="" src="../_images/sphx_glr_30_reading_fnirs_data_thumb.png" />
<p><a class="reference internal" href="io/30_reading_fnirs_data.html#sphx-glr-auto-tutorials-io-30-reading-fnirs-data-py"><span class="std std-ref">Importing data from fNIRS devices</span></a></p>
  <div class="sphx-glr-thumbnail-title">Importing data from fNIRS devices</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compute the evoked from raw for the auditory Brainstorm tutorial dataset. For comparison, see TadelEtAl2011 and the associated brainstorm site."><img alt="" src="../_images/sphx_glr_60_ctf_bst_auditory_thumb.png" />
<p><a class="reference internal" href="io/60_ctf_bst_auditory.html#sphx-glr-auto-tutorials-io-60-ctf-bst-auditory-py"><span class="std std-ref">Working with CTF data: the Brainstorm auditory dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with CTF data: the Brainstorm auditory dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Eyetracking devices record a persons point of gaze, usually in relation to a screen. Typically, gaze position (also referred to as eye or pupil position) and pupil size are recorded as separate channels. This section describes how to read data from supported eyetracking manufacturers."><img alt="" src="../_images/sphx_glr_70_reading_eyetracking_data_thumb.png" />
<p><a class="reference internal" href="io/70_reading_eyetracking_data.html#sphx-glr-auto-tutorials-io-70-reading-eyetracking-data-py"><span class="std std-ref">Importing Data from Eyetracking devices</span></a></p>
  <div class="sphx-glr-thumbnail-title">Importing Data from Eyetracking devices</div>
</div></div></section>
<section id="working-with-continuous-data">
<h2>Working with continuous data<a class="headerlink" href="#working-with-continuous-data" title="Link to this heading">#</a></h2>
<p>These tutorials cover the basics of loading EEG/MEG data into MNE-Python, and
how to query, manipulate, annotate, plot, and export continuous data in the
<a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> format.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of working with raw EEG/MEG data in Python. It introduces the Raw data structure in detail, including how to load, query, subselect, export, and plot data from a Raw object. For more info on visualization of Raw objects, see tut-visualize-raw. For info on creating a Raw object from simulated data in a NumPy array &lt;numpy.ndarray&gt;, see tut-creating-data-structures."><img alt="" src="../_images/sphx_glr_10_raw_overview_thumb.png" />
<p><a class="reference internal" href="raw/10_raw_overview.html#sphx-glr-auto-tutorials-raw-10-raw-overview-py"><span class="std std-ref">The Raw data structure: continuous data</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Raw data structure: continuous data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes event representation and how event arrays are used to subselect data."><img alt="" src="../_images/sphx_glr_20_event_arrays_thumb.png" />
<p><a class="reference internal" href="raw/20_event_arrays.html#sphx-glr-auto-tutorials-raw-20-event-arrays-py"><span class="std std-ref">Working with events</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with events</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes adding annotations to a Raw object, and how annotations are used in later stages of data processing."><img alt="" src="../_images/sphx_glr_30_annotate_raw_thumb.png" />
<p><a class="reference internal" href="raw/30_annotate_raw.html#sphx-glr-auto-tutorials-raw-30-annotate-raw-py"><span class="std std-ref">Annotating continuous data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Annotating continuous data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to plot continuous data as a time series, how to plot the spectral density of continuous data, and how to plot the sensor locations and projectors stored in Raw objects."><img alt="" src="../_images/sphx_glr_40_visualize_raw_thumb.png" />
<p><a class="reference internal" href="raw/40_visualize_raw.html#sphx-glr-auto-tutorials-raw-40-visualize-raw-py"><span class="std std-ref">Built-in plotting methods for Raw objects</span></a></p>
  <div class="sphx-glr-thumbnail-title">Built-in plotting methods for Raw objects</div>
</div></div></section>
<section id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Link to this heading">#</a></h2>
<p>These tutorials cover various preprocessing techniques for continuous
data, as well as some diagnostic plotting methods.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of artifact detection, and introduces the artifact detection tools available in MNE-Python."><img alt="" src="../_images/sphx_glr_10_preprocessing_overview_thumb.png" />
<p><a class="reference internal" href="preprocessing/10_preprocessing_overview.html#sphx-glr-auto-tutorials-preprocessing-10-preprocessing-overview-py"><span class="std std-ref">Overview of artifact detection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Overview of artifact detection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers manual marking of bad channels and reconstructing bad channels based on good signals at other sensors."><img alt="" src="../_images/sphx_glr_15_handling_bad_channels_thumb.png" />
<p><a class="reference internal" href="preprocessing/15_handling_bad_channels.html#sphx-glr-auto-tutorials-preprocessing-15-handling-bad-channels-py"><span class="std std-ref">Handling bad channels</span></a></p>
  <div class="sphx-glr-thumbnail-title">Handling bad channels</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers:"><img alt="" src="../_images/sphx_glr_20_rejecting_bad_data_thumb.png" />
<p><a class="reference internal" href="preprocessing/20_rejecting_bad_data.html#sphx-glr-auto-tutorials-preprocessing-20-rejecting-bad-data-py"><span class="std std-ref">Rejecting bad data spans and breaks</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rejecting bad data spans and breaks</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we give some background information on filtering in general, and how it is done in MNE-Python in particular. Recommended reading for practical applications of digital filter design can be found in Parks &amp; Burrus (1987) ParksBurrus1987 and Ifeachor &amp; Jervis (2002) IfeachorJervis2002, and for filtering in an M/EEG context we recommend reading Widmann et al. (2015) WidmannEtAl2015."><img alt="" src="../_images/sphx_glr_25_background_filtering_thumb.png" />
<p><a class="reference internal" href="preprocessing/25_background_filtering.html#sphx-glr-auto-tutorials-preprocessing-25-background-filtering-py"><span class="std std-ref">Background information on filtering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Background information on filtering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers filtering and resampling, and gives examples of how filtering can be used for artifact repair."><img alt="" src="../_images/sphx_glr_30_filtering_resampling_thumb.png" />
<p><a class="reference internal" href="preprocessing/30_filtering_resampling.html#sphx-glr-auto-tutorials-preprocessing-30-filtering-resampling-py"><span class="std std-ref">Filtering and resampling data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Filtering and resampling data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers removal of artifacts using regression as in Gratton et al. (1983) GrattonEtAl1983 and Croft &amp; Barry (2000) CroftBarry2000."><img alt="" src="../_images/sphx_glr_35_artifact_correction_regression_thumb.png" />
<p><a class="reference internal" href="preprocessing/35_artifact_correction_regression.html#sphx-glr-auto-tutorials-preprocessing-35-artifact-correction-regression-py"><span class="std std-ref">Repairing artifacts with regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Repairing artifacts with regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of independent components analysis (ICA) and shows how ICA can be used for artifact repair; an extended example illustrates repair of ocular and heartbeat artifacts. For conceptual background on ICA, see this scikit-learn tutorial &lt;sphx_glr_auto_examples_decomposition_plot_ica_blind_source_separation.py&gt;."><img alt="" src="../_images/sphx_glr_40_artifact_correction_ica_thumb.png" />
<p><a class="reference internal" href="preprocessing/40_artifact_correction_ica.html#sphx-glr-auto-tutorials-preprocessing-40-artifact-correction-ica-py"><span class="std std-ref">Repairing artifacts with ICA</span></a></p>
  <div class="sphx-glr-thumbnail-title">Repairing artifacts with ICA</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial provides background information on projectors and Signal Space Projection (SSP), and covers loading and saving projectors, adding and removing projectors from Raw objects, the difference between &quot;applied&quot; and &quot;unapplied&quot; projectors, and at what stages MNE-Python applies projectors automatically."><img alt="" src="../_images/sphx_glr_45_projectors_background_thumb.png" />
<p><a class="reference internal" href="preprocessing/45_projectors_background.html#sphx-glr-auto-tutorials-preprocessing-45-projectors-background-py"><span class="std std-ref">Background on projectors and projections</span></a></p>
  <div class="sphx-glr-thumbnail-title">Background on projectors and projections</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of signal-space projection (SSP) and shows how SSP can be used for artifact repair; extended examples illustrate use of SSP for environmental noise reduction, and for repair of ocular and heartbeat artifacts."><img alt="" src="../_images/sphx_glr_50_artifact_correction_ssp_thumb.png" />
<p><a class="reference internal" href="preprocessing/50_artifact_correction_ssp.html#sphx-glr-auto-tutorials-preprocessing-50-artifact-correction-ssp-py"><span class="std std-ref">Repairing artifacts with SSP</span></a></p>
  <div class="sphx-glr-thumbnail-title">Repairing artifacts with SSP</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial describes how to set or change the EEG reference in MNE-Python."><img alt="" src="../_images/sphx_glr_55_setting_eeg_reference_thumb.png" />
<p><a class="reference internal" href="preprocessing/55_setting_eeg_reference.html#sphx-glr-auto-tutorials-preprocessing-55-setting-eeg-reference-py"><span class="std std-ref">Setting the EEG reference</span></a></p>
  <div class="sphx-glr-thumbnail-title">Setting the EEG reference</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Continuous head movement can be encoded during MEG recordings by use of HPI coils that continuously emit sinusoidal signals. These signals can then be extracted from the recording and used to estimate head position as a function of time. Here we show an example of how to do this, and how to visualize the result."><img alt="" src="../_images/sphx_glr_59_head_positions_thumb.png" />
<p><a class="reference internal" href="preprocessing/59_head_positions.html#sphx-glr-auto-tutorials-preprocessing-59-head-positions-py"><span class="std std-ref">Extracting and visualizing subject head movement</span></a></p>
  <div class="sphx-glr-thumbnail-title">Extracting and visualizing subject head movement</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers reducing environmental noise and compensating for head movement with SSS and Maxwell filtering."><img alt="" src="../_images/sphx_glr_60_maxwell_filtering_sss_thumb.png" />
<p><a class="reference internal" href="preprocessing/60_maxwell_filtering_sss.html#sphx-glr-auto-tutorials-preprocessing-60-maxwell-filtering-sss-py"><span class="std std-ref">Signal-space separation (SSS) and Maxwell filtering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Signal-space separation (SSS) and Maxwell filtering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers how to convert functional near-infrared spectroscopy (fNIRS) data from raw measurements to relative oxyhaemoglobin (HbO) and deoxyhaemoglobin (HbR) concentration, view the average waveform, and topographic representation of the response."><img alt="" src="../_images/sphx_glr_70_fnirs_processing_thumb.png" />
<p><a class="reference internal" href="preprocessing/70_fnirs_processing.html#sphx-glr-auto-tutorials-preprocessing-70-fnirs-processing-py"><span class="std std-ref">Preprocessing functional near-infrared spectroscopy (fNIRS) data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Preprocessing functional near-infrared spectroscopy (fNIRS) data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers preprocessing steps that are specific to OPM MEG data. OPMs use a different sensing technology than traditional SQUID MEG systems, which leads to several important differences for analysis:"><img alt="" src="../_images/sphx_glr_80_opm_processing_thumb.png" />
<p><a class="reference internal" href="preprocessing/80_opm_processing.html#sphx-glr-auto-tutorials-preprocessing-80-opm-processing-py"><span class="std std-ref">Preprocessing optically pumped magnetometer (OPM) MEG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Preprocessing optically pumped magnetometer (OPM) MEG data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial we will explore simultaneously recorded eye-tracking and EEG data from a pupillary light reflex task. We will combine the eye-tracking and EEG data, and plot the ERP and pupil response to the light flashes (i.e. the pupillary light reflex)."><img alt="" src="../_images/sphx_glr_90_eyetracking_data_thumb.png" />
<p><a class="reference internal" href="preprocessing/90_eyetracking_data.html#sphx-glr-auto-tutorials-preprocessing-90-eyetracking-data-py"><span class="std std-ref">Working with eye tracker data in MNE-Python</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with eye tracker data in MNE-Python</div>
</div></div></section>
<section id="segmenting-continuous-data-into-epochs">
<h2>Segmenting continuous data into epochs<a class="headerlink" href="#segmenting-continuous-data-into-epochs" title="Link to this heading">#</a></h2>
<p>These tutorials cover epoched data, and how it differs from working with
continuous data.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of creating and working with epochs data. It introduces the Epochs data structure in detail, including how to load, query, subselect, export, and plot data from an Epochs object. For more information about visualizing Epochs objects, see tut-visualize-epochs. For info on creating an Epochs object from (possibly simulated) data in a NumPy array &lt;numpy.ndarray&gt;, see tut-creating-data-structures."><img alt="" src="../_images/sphx_glr_10_epochs_overview_thumb.png" />
<p><a class="reference internal" href="epochs/10_epochs_overview.html#sphx-glr-auto-tutorials-epochs-10-epochs-overview-py"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Epochs data structure: discontinuous data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial compares traditional baseline correction (adding or subtracting a scalar amount from every timepoint in an epoch) to a regression-based approach to baseline correction (which allows the effect of the baseline period to vary by timepoint). Specifically, this tutorial follows the method introduced by :footciteAlday2019."><img alt="" src="../_images/sphx_glr_15_baseline_regression_thumb.png" />
<p><a class="reference internal" href="epochs/15_baseline_regression.html#sphx-glr-auto-tutorials-epochs-15-baseline-regression-py"><span class="std std-ref">Regression-based baseline correction</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regression-based baseline correction</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to plot epoched data as time series, how to plot the spectral density of epoched data, how to plot epochs as an imagemap, and how to plot the sensor locations and projectors stored in Epochs objects."><img alt="" src="../_images/sphx_glr_20_visualize_epochs_thumb.png" />
<p><a class="reference internal" href="epochs/20_visualize_epochs.html#sphx-glr-auto-tutorials-epochs-20-visualize-epochs-py"><span class="std std-ref">Visualizing epoched data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualizing epoched data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to add metadata to Epochs objects, and how to use Pandas query strings &lt;pandas:indexing.query&gt; to select and plot epochs based on metadata properties."><img alt="" src="../_images/sphx_glr_30_epochs_metadata_thumb.png" />
<p><a class="reference internal" href="epochs/30_epochs_metadata.html#sphx-glr-auto-tutorials-epochs-30-epochs-metadata-py"><span class="std std-ref">Working with Epoch metadata</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with Epoch metadata</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to auto-generate metadata for Epochs, based on events via mne.epochs.make_metadata."><img alt="" src="../_images/sphx_glr_40_autogenerate_metadata_thumb.png" />
<p><a class="reference internal" href="epochs/40_autogenerate_metadata.html#sphx-glr-auto-tutorials-epochs-40-autogenerate-metadata-py"><span class="std std-ref">Auto-generating Epochs metadata</span></a></p>
  <div class="sphx-glr-thumbnail-title">Auto-generating Epochs metadata</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to export the data in Epochs objects to a Pandas DataFrame &lt;pandas.DataFrame&gt;, and applies a typical Pandas pandas:user_guide/groupby workflow to examine the latencies of the response maxima across epochs and conditions."><img alt="" src="../_images/sphx_glr_50_epochs_to_data_frame_thumb.png" />
<p><a class="reference internal" href="epochs/50_epochs_to_data_frame.html#sphx-glr-auto-tutorials-epochs-50-epochs-to-data-frame-py"><span class="std std-ref">Exporting Epochs to Pandas DataFrames</span></a></p>
  <div class="sphx-glr-thumbnail-title">Exporting Epochs to Pandas DataFrames</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to segment continuous data into a set of epochs spaced equidistantly in time. The epochs will not be created based on experimental events; instead, the continuous data will be &quot;chunked&quot; into consecutive epochs (which may be temporally overlapping, adjacent, or separated). We will also briefly demonstrate how to use these epochs in connectivity analysis."><img alt="" src="../_images/sphx_glr_60_make_fixed_length_epochs_thumb.png" />
<p><a class="reference internal" href="epochs/60_make_fixed_length_epochs.html#sphx-glr-auto-tutorials-epochs-60-make-fixed-length-epochs-py"><span class="std std-ref">Divide continuous data into equally-spaced epochs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Divide continuous data into equally-spaced epochs</div>
</div></div></section>
<section id="estimating-evoked-responses">
<h2>Estimating evoked responses<a class="headerlink" href="#estimating-evoked-responses" title="Link to this heading">#</a></h2>
<p>These tutorials cover estimates of evoked responses (i.e., averages across
several repetitions of an experimental condition).</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers the basics of creating and working with evoked data. It introduces the Evoked data structure in detail, including how to load, query, subset, export, and plot data from an Evoked object. For details on creating an Evoked object from (possibly simulated) data in a NumPy array &lt;numpy.ndarray&gt;, see tut-creating-data-structures."><img alt="" src="../_images/sphx_glr_10_evoked_overview_thumb.png" />
<p><a class="reference internal" href="evoked/10_evoked_overview.html#sphx-glr-auto-tutorials-evoked-10-evoked-overview-py"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Evoked data structure: evoked/averaged data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows the different visualization methods for Evoked objects."><img alt="" src="../_images/sphx_glr_20_visualize_evoked_thumb.png" />
<p><a class="reference internal" href="evoked/20_visualize_evoked.html#sphx-glr-auto-tutorials-evoked-20-visualize-evoked-py"><span class="std std-ref">Visualizing Evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualizing Evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to perform standard ERP analyses in MNE-Python. Most of the material here is covered in other tutorials too, but for convenience the functions and methods most useful for ERP analyses are collected here, with links to other tutorials where more detailed information is given."><img alt="" src="../_images/sphx_glr_30_eeg_erp_thumb.png" />
<p><a class="reference internal" href="evoked/30_eeg_erp.html#sphx-glr-auto-tutorials-evoked-30-eeg-erp-py"><span class="std std-ref">EEG analysis - Event-Related Potentials (ERPs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">EEG analysis - Event-Related Potentials (ERPs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial demonstrates how to plot whitening evoked data."><img alt="" src="../_images/sphx_glr_40_whitened_thumb.png" />
<p><a class="reference internal" href="evoked/40_whitened.html#sphx-glr-auto-tutorials-evoked-40-whitened-py"><span class="std std-ref">Plotting whitened data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting whitened data</div>
</div></div></section>
<section id="time-frequency-analysis">
<h2>Time-frequency analysis<a class="headerlink" href="#time-frequency-analysis" title="Link to this heading">#</a></h2>
<p>These tutorials cover frequency and time-frequency analysis of neural
signals.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to create and visualize frequency-domain representations of your data, starting from continuous Raw, discontinuous Epochs, or averaged Evoked data."><img alt="" src="../_images/sphx_glr_10_spectrum_class_thumb.png" />
<p><a class="reference internal" href="time-freq/10_spectrum_class.html#sphx-glr-auto-tutorials-time-freq-10-spectrum-class-py"><span class="std std-ref">The Spectrum and EpochsSpectrum classes: frequency-domain data</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Spectrum and EpochsSpectrum classes: frequency-domain data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The objective is to show you how to explore the spectral content of your data (frequency and time-frequency). Here we&#x27;ll work on Epochs."><img alt="" src="../_images/sphx_glr_20_sensors_time_frequency_thumb.png" />
<p><a class="reference internal" href="time-freq/20_sensors_time_frequency.html#sphx-glr-auto-tutorials-time-freq-20-sensors-time-frequency-py"><span class="std std-ref">Frequency and time-frequency sensor analysis</span></a></p>
  <div class="sphx-glr-thumbnail-title">Frequency and time-frequency sensor analysis</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial we compute the frequency spectrum and quantify signal-to-noise ratio (SNR) at a target frequency in EEG data recorded during fast periodic visual stimulation (FPVS) at 12 Hz and 15 Hz in different trials. Extracting SNR at stimulation frequency is a simple way to quantify frequency tagged responses in MEEG (a.k.a. steady state visually evoked potentials, SSVEP, or visual steady-state responses, vSSR in the visual domain, or auditory steady-state responses, ASSR in the auditory domain)."><img alt="" src="../_images/sphx_glr_50_ssvep_thumb.png" />
<p><a class="reference internal" href="time-freq/50_ssvep.html#sphx-glr-auto-tutorials-time-freq-50-ssvep-py"><span class="std std-ref">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</div>
</div></div></section>
<section id="forward-models-and-source-spaces">
<h2>Forward models and source spaces<a class="headerlink" href="#forward-models-and-source-spaces" title="Link to this heading">#</a></h2>
<p>These tutorials cover how the cortical source locations (source spaces) and
forward models (AKA leadfield matrices) are defined.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers how to use FreeSurfer alongside MNE-Python, to handle the structural MRI data that we use to build subject-specific anatomical models of the scalp, inner/outer skull, and cortical surface."><img alt="" src="../_images/sphx_glr_10_background_freesurfer_thumb.png" />
<p><a class="reference internal" href="forward/10_background_freesurfer.html#sphx-glr-auto-tutorials-forward-10-background-freesurfer-py"><span class="std std-ref">FreeSurfer MRI reconstruction</span></a></p>
  <div class="sphx-glr-thumbnail-title">FreeSurfer MRI reconstruction</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to visually assess the spatial alignment of MEG sensor locations, digitized scalp landmark and sensor locations, and MRI volumes. This alignment process is crucial for computing the forward solution, as is understanding the different coordinate frames involved in this process."><img alt="" src="../_images/sphx_glr_20_source_alignment_thumb.png" />
<p><a class="reference internal" href="forward/20_source_alignment.html#sphx-glr-auto-tutorials-forward-20-source-alignment-py"><span class="std std-ref">Source alignment and coordinate frames</span></a></p>
  <div class="sphx-glr-thumbnail-title">Source alignment and coordinate frames</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the coregistration functions to perform an automated MEG-MRI coregistration via scripting. Generally the results of this approach are consistent with those obtained from manual coregistration HouckClaus2020."><img alt="" src="../_images/sphx_glr_25_automated_coreg_thumb.png" />
<p><a class="reference internal" href="forward/25_automated_coreg.html#sphx-glr-auto-tutorials-forward-25-automated-coreg-py"><span class="std std-ref">Using an automated approach to coregistration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using an automated approach to coregistration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The aim of this tutorial is to be a getting started for forward computation."><img alt="" src="../_images/sphx_glr_30_forward_thumb.png" />
<p><a class="reference internal" href="forward/30_forward.html#sphx-glr-auto-tutorials-forward-30-forward-py"><span class="std std-ref">Head model and forward computation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Head model and forward computation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial explains how to compute the forward operator from EEG data using the standard template MRI subject fsaverage."><img alt="" src="../_images/sphx_glr_35_eeg_no_mri_thumb.png" />
<p><a class="reference internal" href="forward/35_eeg_no_mri.html#sphx-glr-auto-tutorials-forward-35-eeg-no-mri-py"><span class="std std-ref">EEG forward operator with a template MRI</span></a></p>
  <div class="sphx-glr-thumbnail-title">EEG forward operator with a template MRI</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial explains how MRI coordinate frames are handled in MNE-Python, and how MNE-Python integrates with FreeSurfer for handling MRI data and source space data in general."><img alt="" src="../_images/sphx_glr_50_background_freesurfer_mne_thumb.png" />
<p><a class="reference internal" href="forward/50_background_freesurfer_mne.html#sphx-glr-auto-tutorials-forward-50-background-freesurfer-mne-py"><span class="std std-ref">How MNE uses FreeSurfer’s outputs</span></a></p>
  <div class="sphx-glr-thumbnail-title">How MNE uses FreeSurfer's outputs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Sometimes when creating a BEM model the surfaces need manual correction because of a series of problems that can arise (e.g. intersection between surfaces). Here, we will see how this can be achieved by exporting the surfaces to the 3D modeling program Blender, editing them, and re-importing them. We will also give a simple example of how to use tut-fix-meshes-pymeshfix to fix topological problems."><img alt="" src="../_images/sphx_glr_80_fix_bem_in_blender_thumb.jpg" />
<p><a class="reference internal" href="forward/80_fix_bem_in_blender.html#sphx-glr-auto-tutorials-forward-80-fix-bem-in-blender-py"><span class="std std-ref">Fixing BEM and head surfaces</span></a></p>
  <div class="sphx-glr-thumbnail-title">Fixing BEM and head surfaces</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Many methods in MNE, including source estimation and some classification algorithms, require covariance estimations from the recordings. In this tutorial we cover the basics of sensor covariance computations and construct a noise covariance matrix that can be used when computing the minimum-norm inverse solution. For more information, see minimum_norm_estimates."><img alt="" src="../_images/sphx_glr_90_compute_covariance_thumb.png" />
<p><a class="reference internal" href="forward/90_compute_covariance.html#sphx-glr-auto-tutorials-forward-90-compute-covariance-py"><span class="std std-ref">Computing a covariance matrix</span></a></p>
  <div class="sphx-glr-thumbnail-title">Computing a covariance matrix</div>
</div></div></section>
<section id="source-localization-and-inverses">
<h2>Source localization and inverses<a class="headerlink" href="#source-localization-and-inverses" title="Link to this heading">#</a></h2>
<p>These tutorials cover estimation of cortical activity from sensor recordings.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Source estimates, commonly referred to as STC (Source Time Courses) &lt;stc&gt;, are obtained from source localization methods. Source localization method solve the so-called &#x27;inverse problem&#x27;. MNE provides different methods for solving it: dSPM, sLORETA, LCMV, MxNE etc."><img alt="" src="../_images/sphx_glr_10_stc_class_thumb.png" />
<p><a class="reference internal" href="inverse/10_stc_class.html#sphx-glr-auto-tutorials-inverse-10-stc-class-py"><span class="std std-ref">The SourceEstimate data structure</span></a></p>
  <div class="sphx-glr-thumbnail-title">The SourceEstimate data structure</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This shows how to fit a dipole Sarvas1987 using MNE-Python."><img alt="" src="../_images/sphx_glr_20_dipole_fit_thumb.png" />
<p><a class="reference internal" href="inverse/20_dipole_fit.html#sphx-glr-auto-tutorials-inverse-20-dipole-fit-py"><span class="std std-ref">Source localization with equivalent current dipole (ECD) fit</span></a></p>
  <div class="sphx-glr-thumbnail-title">Source localization with equivalent current dipole (ECD) fit</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The aim of this tutorial is to teach you how to compute and apply a linear minimum-norm inverse method on evoked/raw/epochs data."><img alt="" src="../_images/sphx_glr_30_mne_dspm_loreta_thumb.gif" />
<p><a class="reference internal" href="inverse/30_mne_dspm_loreta.html#sphx-glr-auto-tutorials-inverse-30-mne-dspm-loreta-py"><span class="std std-ref">Source localization with MNE, dSPM, sLORETA, and eLORETA</span></a></p>
  <div class="sphx-glr-thumbnail-title">Source localization with MNE, dSPM, sLORETA, and eLORETA</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When performing source localization in a distributed manner (i.e., using MNE/dSPM/sLORETA/eLORETA), the source space is defined as a grid of dipoles that spans a large portion of the cortex. These dipoles have both a position and an orientation. In this tutorial, we will look at the various options available to restrict the orientation of the dipoles and the impact on the resulting source estimate."><img alt="" src="../_images/sphx_glr_35_dipole_orientations_thumb.png" />
<p><a class="reference internal" href="inverse/35_dipole_orientations.html#sphx-glr-auto-tutorials-inverse-35-dipole-orientations-py"><span class="std std-ref">The role of dipole orientations in distributed source localization</span></a></p>
  <div class="sphx-glr-thumbnail-title">The role of dipole orientations in distributed source localization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows example fixed- and free-orientation source localizations produced by the minimum-norm variants implemented in MNE-Python: MNE, dSPM, sLORETA, and eLORETA."><img alt="" src="../_images/sphx_glr_40_mne_fixed_free_thumb.png" />
<p><a class="reference internal" href="inverse/40_mne_fixed_free.html#sphx-glr-auto-tutorials-inverse-40-mne-fixed-free-py"><span class="std std-ref">Computing various MNE solutions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Computing various MNE solutions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial gives an overview of the beamformer method and shows how to reconstruct source activity using an LCMV beamformer."><img alt="" src="../_images/sphx_glr_50_beamformer_lcmv_thumb.png" />
<p><a class="reference internal" href="inverse/50_beamformer_lcmv.html#sphx-glr-auto-tutorials-inverse-50-beamformer-lcmv-py"><span class="std std-ref">Source reconstruction using an LCMV beamformer</span></a></p>
  <div class="sphx-glr-thumbnail-title">Source reconstruction using an LCMV beamformer</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial focuses on visualization of source estimates &lt;STC&gt;."><img alt="" src="../_images/sphx_glr_60_visualize_stc_thumb.gif" />
<p><a class="reference internal" href="inverse/60_visualize_stc.html#sphx-glr-auto-tutorials-inverse-60-visualize-stc-py"><span class="std std-ref">Visualize source time courses (stcs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualize source time courses (stcs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial explains how to compute the forward operator from EEG data when the electrodes are in MRI voxel coordinates."><img alt="" src="../_images/sphx_glr_70_eeg_mri_coords_thumb.png" />
<p><a class="reference internal" href="inverse/70_eeg_mri_coords.html#sphx-glr-auto-tutorials-inverse-70-eeg-mri-coords-py"><span class="std std-ref">EEG source localization given electrode locations on an MRI</span></a></p>
  <div class="sphx-glr-thumbnail-title">EEG source localization given electrode locations on an MRI</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compute the evoked from raw for the Brainstorm Elekta phantom tutorial dataset. For comparison, see TadelEtAl2011 and the original Brainstorm tutorial."><img alt="" src="../_images/sphx_glr_80_brainstorm_phantom_elekta_thumb.png" />
<p><a class="reference internal" href="inverse/80_brainstorm_phantom_elekta.html#sphx-glr-auto-tutorials-inverse-80-brainstorm-phantom-elekta-py"><span class="std std-ref">Brainstorm Elekta phantom dataset tutorial</span></a></p>
  <div class="sphx-glr-thumbnail-title">Brainstorm Elekta phantom dataset tutorial</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compute the evoked from raw for the Brainstorm CTF phantom tutorial dataset. For comparison, see TadelEtAl2011 and:"><img alt="" src="../_images/sphx_glr_85_brainstorm_phantom_ctf_thumb.png" />
<p><a class="reference internal" href="inverse/85_brainstorm_phantom_ctf.html#sphx-glr-auto-tutorials-inverse-85-brainstorm-phantom-ctf-py"><span class="std std-ref">Brainstorm CTF phantom dataset tutorial</span></a></p>
  <div class="sphx-glr-thumbnail-title">Brainstorm CTF phantom dataset tutorial</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we read 4DBTi epochs data obtained with a spherical phantom using four different dipole locations. For each condition we compute evoked data and compute dipole fits."><img alt="" src="../_images/sphx_glr_90_phantom_4DBTi_thumb.png" />
<p><a class="reference internal" href="inverse/90_phantom_4DBTi.html#sphx-glr-auto-tutorials-inverse-90-phantom-4dbti-py"><span class="std std-ref">4D Neuroimaging/BTi phantom dataset tutorial</span></a></p>
  <div class="sphx-glr-thumbnail-title">4D Neuroimaging/BTi phantom dataset tutorial</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we read KIT data obtained from a phantom with 49 dipoles sequentially activated with 2-cycle 11 Hz sinusoidal bursts to verify source localization accuracy."><img alt="" src="../_images/sphx_glr_95_phantom_KIT_thumb.png" />
<p><a class="reference internal" href="inverse/95_phantom_KIT.html#sphx-glr-auto-tutorials-inverse-95-phantom-kit-py"><span class="std std-ref">KIT phantom dataset tutorial</span></a></p>
  <div class="sphx-glr-thumbnail-title">KIT phantom dataset tutorial</div>
</div></div></section>
<section id="statistical-analysis-of-sensor-data">
<h2>Statistical analysis of sensor data<a class="headerlink" href="#statistical-analysis-of-sensor-data" title="Link to this heading">#</a></h2>
<p>These tutorials describe some approaches to statistical analysis of
sensor-level data.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Here we will briefly cover multiple concepts of inferential statistics in an introductory manner, and demonstrate how to use some MNE statistical functions."><img alt="" src="../_images/sphx_glr_10_background_stats_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/10_background_stats.html#sphx-glr-auto-tutorials-stats-sensor-space-10-background-stats-py"><span class="std std-ref">Statistical inference</span></a></p>
  <div class="sphx-glr-thumbnail-title">Statistical inference</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="MNE-Python provides a range of tools for statistical hypothesis testing and the visualisation of the results. Here, we show a few options for exploratory and confirmatory tests - e.g., targeted t-tests, cluster-based permutation approaches (here with Threshold-Free Cluster Enhancement); and how to visualise the results."><img alt="" src="../_images/sphx_glr_20_erp_stats_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/20_erp_stats.html#sphx-glr-auto-tutorials-stats-sensor-space-20-erp-stats-py"><span class="std std-ref">Visualising statistical significance thresholds on EEG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualising statistical significance thresholds on EEG data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows how to estimate significant clusters in time-frequency power estimates. It uses a non-parametric statistical procedure based on permutations and cluster level statistics."><img alt="" src="../_images/sphx_glr_40_cluster_1samp_time_freq_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/40_cluster_1samp_time_freq.html#sphx-glr-auto-tutorials-stats-sensor-space-40-cluster-1samp-time-freq-py"><span class="std std-ref">Non-parametric 1 sample cluster statistic on single trial power</span></a></p>
  <div class="sphx-glr-thumbnail-title">Non-parametric 1 sample cluster statistic on single trial power</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows how to compare clusters in time-frequency power estimates between conditions. It uses a non-parametric statistical procedure based on permutations and cluster level statistics."><img alt="" src="../_images/sphx_glr_50_cluster_between_time_freq_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/50_cluster_between_time_freq.html#sphx-glr-auto-tutorials-stats-sensor-space-50-cluster-between-time-freq-py"><span class="std std-ref">Non-parametric between conditions cluster statistic on single trial power</span></a></p>
  <div class="sphx-glr-thumbnail-title">Non-parametric between conditions cluster statistic on single trial power</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows how to conduct a mass-univariate repeated measures ANOVA. As the model to be fitted assumes two fully crossed factors, we will study the interplay between perceptual modality (auditory VS visual) and the location of stimulus presentation (left VS right). Here we use single trials as replications (subjects) while iterating over time slices plus frequency bands for to fit our mass-univariate model. For the sake of simplicity we will confine this analysis to one single channel of which we know that it exposes a strong induced response. We will then visualize each effect by creating a corresponding mass-univariate effect image. We conclude with accounting for multiple comparisons by performing a permutation clustering test using the ANOVA as clustering function. The results final will be compared to multiple comparisons using False Discovery Rate correction."><img alt="" src="../_images/sphx_glr_70_cluster_rmANOVA_time_freq_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/70_cluster_rmANOVA_time_freq.html#sphx-glr-auto-tutorials-stats-sensor-space-70-cluster-rmanova-time-freq-py"><span class="std std-ref">Mass-univariate twoway repeated measures ANOVA on single trial power</span></a></p>
  <div class="sphx-glr-thumbnail-title">Mass-univariate twoway repeated measures ANOVA on single trial power</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Tests for differential evoked responses in at least one condition using a permutation clustering test. The FieldTrip neighbor templates will be used to determine the adjacency between sensors. This serves as a spatial prior to the clustering. Spatiotemporal clusters will then be visualized using custom matplotlib code."><img alt="" src="../_images/sphx_glr_75_cluster_ftest_spatiotemporal_thumb.png" />
<p><a class="reference internal" href="stats-sensor-space/75_cluster_ftest_spatiotemporal.html#sphx-glr-auto-tutorials-stats-sensor-space-75-cluster-ftest-spatiotemporal-py"><span class="std std-ref">Spatiotemporal permutation F-test on full sensor data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Spatiotemporal permutation F-test on full sensor data</div>
</div></div></section>
<section id="statistical-analysis-of-source-estimates">
<h2>Statistical analysis of source estimates<a class="headerlink" href="#statistical-analysis-of-source-estimates" title="Link to this heading">#</a></h2>
<p>These tutorials cover within-subject statistical analysis of source
estimates.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example tests if the evoked response is significantly different between two conditions across subjects. Here just for demonstration purposes we simulate data from multiple subjects using one subject&#x27;s data. The multiple comparisons problem is addressed with a cluster-level permutation test across space and time."><img alt="" src="../_images/sphx_glr_20_cluster_1samp_spatiotemporal_thumb.png" />
<p><a class="reference internal" href="stats-source-space/20_cluster_1samp_spatiotemporal.html#sphx-glr-auto-tutorials-stats-source-space-20-cluster-1samp-spatiotemporal-py"><span class="std std-ref">Permutation t-test on source data with spatio-temporal clustering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Permutation t-test on source data with spatio-temporal clustering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Tests if the source space data are significantly different between 2 groups of subjects (simulated here using one subject&#x27;s data). The multiple comparisons problem is addressed with a cluster-level permutation test across space and time."><img alt="" src="../_images/sphx_glr_30_cluster_ftest_spatiotemporal_thumb.png" />
<p><a class="reference internal" href="stats-source-space/30_cluster_ftest_spatiotemporal.html#sphx-glr-auto-tutorials-stats-source-space-30-cluster-ftest-spatiotemporal-py"><span class="std std-ref">2 samples permutation test on source data with spatio-temporal clustering</span></a></p>
  <div class="sphx-glr-thumbnail-title">2 samples permutation test on source data with spatio-temporal clustering</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to make use of the clustering functions for arbitrary, self-defined contrasts beyond standard t-tests. In this case we will tests if the differences in evoked responses between stimulation modality (visual VS auditory) depend on the stimulus location (left vs right) for a group of subjects (simulated here using one subject&#x27;s data). For this purpose we will compute an interaction effect using a repeated measures ANOVA. The multiple comparisons problem is addressed with a cluster-level permutation test across space and time."><img alt="" src="../_images/sphx_glr_60_cluster_rmANOVA_spatiotemporal_thumb.png" />
<p><a class="reference internal" href="stats-source-space/60_cluster_rmANOVA_spatiotemporal.html#sphx-glr-auto-tutorials-stats-source-space-60-cluster-rmanova-spatiotemporal-py"><span class="std std-ref">Repeated measures ANOVA on source data with spatio-temporal clustering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Repeated measures ANOVA on source data with spatio-temporal clustering</div>
</div></div></section>
<section id="machine-learning-models-of-neural-activity">
<h2>Machine learning models of neural activity<a class="headerlink" href="#machine-learning-models-of-neural-activity" title="Link to this heading">#</a></h2>
<p>These tutorials cover some of the machine learning methods available in
MNE-Python.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This demonstrates how an encoding model can be fit with multiple continuous inputs. In this case, we simulate the model behind a spectro-temporal receptive field (or STRF). First, we create a linear filter that maps patterns in spectro-temporal space onto an output, representing neural activity. We fit a receptive field model that attempts to recover the original linear filter that was used to create this data."><img alt="" src="../_images/sphx_glr_30_strf_thumb.png" />
<p><a class="reference internal" href="machine-learning/30_strf.html#sphx-glr-auto-tutorials-machine-learning-30-strf-py"><span class="std std-ref">Spectro-temporal receptive field (STRF) estimation on continuous data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Spectro-temporal receptive field (STRF) estimation on continuous data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Design philosophy ================= Decoding (a.k.a. MVPA) in MNE largely follows the machine learning API of the scikit-learn package. Each estimator implements fit, transform, fit_transform, and (optionally) inverse_transform methods. For more details on this design, visit scikit-learn_. For additional theoretical insights into the decoding framework in MNE KingEtAl2018."><img alt="" src="../_images/sphx_glr_50_decoding_thumb.png" />
<p><a class="reference internal" href="machine-learning/50_decoding.html#sphx-glr-auto-tutorials-machine-learning-50-decoding-py"><span class="std std-ref">Decoding (MVPA)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding (MVPA)</div>
</div></div></section>
<section id="clinical-applications">
<h2>Clinical applications<a class="headerlink" href="#clinical-applications" title="Link to this heading">#</a></h2>
<p>These tutorials illustrate some clinical use cases.</p>
<section id="mne-gui-addons-examples">
<h3>MNE-GUI-addons examples<a class="headerlink" href="#mne-gui-addons-examples" title="Link to this heading">#</a></h3>
<p>The <a class="reference external" href="https://mne.tools/mne-gui-addons/api.html#module-mne_gui_addons" title="(in MNE-GUI-Addons v0.2)"><code class="docutils literal notranslate"><span class="pre">mne_gui_addons</span></code></a> package supports some clinical use cases:</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="MNE supports working with more than just MEG and EEG data. Here we show some of the functions t..."><img alt="" src="https://mne.tools/mne-gui-addons/_images/sphx_glr_ieeg_locate_005.png" />
<p><a class="reference external" href="https://mne.tools/mne-gui-addons/auto_examples/ieeg_locate.html#tut-ieeg-localize" title="(in MNE-GUI-Addons v0.2)"><span>Locating intracranial electrode contacts</span></a></p>
  <div class="sphx-glr-thumbnail-title">Locating intracranial electrode contacts</div>
</div></div></section>
<section id="mne-python-examples">
<h3>MNE-Python examples<a class="headerlink" href="#mne-python-examples" title="Link to this heading">#</a></h3>
<p>MNE-Python also supports some clinical use cases directly:</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="MNE-Python supports working with more than just MEG and EEG data. Here we show some of the functions that can be used to facilitate working with stereoelectroencephalography (sEEG) data."><img alt="" src="../_images/sphx_glr_20_seeg_thumb.png" />
<p><a class="reference internal" href="clinical/20_seeg.html#sphx-glr-auto-tutorials-clinical-20-seeg-py"><span class="std std-ref">Working with sEEG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with sEEG data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="MNE supports working with more than just MEG and EEG data. Here we show some of the functions that can be used to facilitate working with electrocorticography (ECoG) data."><img alt="" src="../_images/sphx_glr_30_ecog_thumb.png" />
<p><a class="reference internal" href="clinical/30_ecog.html#sphx-glr-auto-tutorials-clinical-30-ecog-py"><span class="std std-ref">Working with ECoG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Working with ECoG data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial explains how to perform a toy polysomnography analysis that answers the following question:"><img alt="" src="../_images/sphx_glr_60_sleep_thumb.png" />
<p><a class="reference internal" href="clinical/60_sleep.html#sphx-glr-auto-tutorials-clinical-60-sleep-py"><span class="std std-ref">Sleep stage classification from polysomnography (PSG) data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Sleep stage classification from polysomnography (PSG) data</div>
</div></div></section>
</section>
<section id="simulation">
<h2>Simulation<a class="headerlink" href="#simulation" title="Link to this heading">#</a></h2>
<p>These tutorials describe how to populate MNE-Python data structures with
arbitrary data, using the array-based constructors and the simulation
submodule.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to create MNE-Python&#x27;s core data structures using an existing NumPy array &lt;numpy.ndarray&gt; of (real or synthetic) data."><img alt="" src="../_images/sphx_glr_10_array_objs_thumb.png" />
<p><a class="reference internal" href="simulation/10_array_objs.html#sphx-glr-auto-tutorials-simulation-10-array-objs-py"><span class="std std-ref">Creating MNE-Python data structures from scratch</span></a></p>
  <div class="sphx-glr-thumbnail-title">Creating MNE-Python data structures from scratch</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The aim of this tutorial is to demonstrate how to put a known signal at a desired location(s) in a mne.SourceEstimate and then corrupt the signal with point-spread by applying a forward and inverse solution."><img alt="" src="../_images/sphx_glr_70_point_spread_thumb.png" />
<p><a class="reference internal" href="simulation/70_point_spread.html#sphx-glr-auto-tutorials-simulation-70-point-spread-py"><span class="std std-ref">Corrupt known signal with point spread</span></a></p>
  <div class="sphx-glr-thumbnail-title">Corrupt known signal with point spread</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we&#x27;ll simulate two signals originating from two locations on the cortex. These signals will be sinusoids, so we&#x27;ll be looking at oscillatory activity (as opposed to evoked activity)."><img alt="" src="../_images/sphx_glr_80_dics_thumb.png" />
<p><a class="reference internal" href="simulation/80_dics.html#sphx-glr-auto-tutorials-simulation-80-dics-py"><span class="std std-ref">DICS for power mapping</span></a></p>
  <div class="sphx-glr-thumbnail-title">DICS for power mapping</div>
</div></div></section>
<section id="visualization-tutorials">
<h2>Visualization tutorials<a class="headerlink" href="#visualization-tutorials" title="Link to this heading">#</a></h2>
<p>These tutorials cover the more advanced visualization options provided by
MNE-Python, such as how to produce publication-quality figures or how to make
plots more interactive.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show several use cases to take MNE plots and customize them for a more publication-ready look."><img alt="" src="../_images/sphx_glr_10_publication_figure_thumb.png" />
<p><a class="reference internal" href="visualization/10_publication_figure.html#sphx-glr-auto-tutorials-visualization-10-publication-figure-py"><span class="std std-ref">Make figures more publication ready</span></a></p>
  <div class="sphx-glr-thumbnail-title">Make figures more publication ready</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Many of MNE-Python&#x27;s figures are interactive. For example, you can select channels or scroll through time. The event system allows you to link figures together so that interacting with one figure will simultaneously update another figure."><img alt="" src="../_images/sphx_glr_20_ui_events_thumb.png" />
<p><a class="reference internal" href="visualization/20_ui_events.html#sphx-glr-auto-tutorials-visualization-20-ui-events-py"><span class="std std-ref">Using the event system to link figures</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using the event system to link figures</div>
</div></div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-footer sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/cab7a090c4183ca69dc0cd84d3b04413/auto_tutorials_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">auto_tutorials_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/97a1de59bce682890841bb846e3dd09c/auto_tutorials_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">auto_tutorials_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../documentation/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Documentation overview</p>
      </div>
    </a>
    <a class="right-next"
       href="intro/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introductory tutorials</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introductory-tutorials">Introductory tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reading-data-for-different-recording-systems">Reading data for different recording systems</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-continuous-data">Working with continuous data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#segmenting-continuous-data-into-epochs">Segmenting continuous data into epochs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-evoked-responses">Estimating evoked responses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-frequency-analysis">Time-frequency analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-models-and-source-spaces">Forward models and source spaces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#source-localization-and-inverses">Source localization and inverses</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-analysis-of-sensor-data">Statistical analysis of sensor data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-analysis-of-source-estimates">Statistical analysis of source estimates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-models-of-neural-activity">Machine learning models of neural activity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clinical-applications">Clinical applications</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mne-gui-addons-examples">MNE-GUI-addons examples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mne-python-examples">MNE-Python examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation">Simulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-tutorials">Visualization tutorials</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://mne.tools/versionwarning.js"></script>
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center small">&copy; Copyright 2012–2024, MNE Developers. Last updated <time datetime="2024-12-18T19:57:53.219820+00:00" class="localized">2024-12-18 19:57 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>