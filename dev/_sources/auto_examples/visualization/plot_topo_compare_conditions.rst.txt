

.. _sphx_glr_auto_examples_visualization_plot_topo_compare_conditions.py:


=================================================
Compare evoked responses for different conditions
=================================================

In this example, an Epochs object for visual and
auditory responses is created. Both conditions
are then accessed by their respective names to
create a sensor layout plot of the related
evoked responses.




.. code-block:: python


    # Authors: Denis Engemann <denis.engemann@gmail.com>
    #          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>

    # License: BSD (3-clause)


    import matplotlib.pyplot as plt
    import mne

    from mne.viz import plot_evoked_topo
    from mne.datasets import sample

    print(__doc__)

    data_path = sample.data_path()







Set parameters



.. code-block:: python

    raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'
    event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'
    event_id = 1
    tmin = -0.2
    tmax = 0.5

    #   Setup for reading the raw data
    raw = mne.io.read_raw_fif(raw_fname)
    events = mne.read_events(event_fname)

    #   Set up pick list: MEG + STI 014 - bad channels (modify to your needs)
    include = []  # or stim channels ['STI 014']
    # bad channels in raw.info['bads'] will be automatically excluded

    #   Set up amplitude-peak rejection values for MEG channels
    reject = dict(grad=4000e-13, mag=4e-12)

    # pick MEG channels
    picks = mne.pick_types(raw.info, meg=True, eeg=False, stim=False, eog=True,
                           include=include, exclude='bads')

    # Create epochs including different events
    event_id = {'audio/left': 1, 'audio/right': 2,
                'visual/left': 3, 'visual/right': 4}
    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,
                        picks=picks, baseline=(None, 0), reject=reject)

    # Generate list of evoked objects from conditions names
    evokeds = [epochs[name].average() for name in ('left', 'right')]





.. rst-class:: sphx-glr-script-out

 Out::

    Opening raw data file /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
            Average EEG reference (1 x 60)  idle
        Range : 6450 ... 48149 =     42.956 ...   320.665 secs
    Ready.
    Current compensation grade : 0
    288 matching events found
    Created an SSP operator (subspace dimension = 3)
    4 projection items activated
        Rejecting  epoch based on MAG : [u'MEG 1711']
        Rejecting  epoch based on MAG : [u'MEG 1711']


Show topography for two different conditions



.. code-block:: python


    colors = 'blue', 'red'
    title = 'MNE sample data\nleft vs right (A/V combined)'

    plot_evoked_topo(evokeds, color=colors, title=title, background_color='w')

    plt.show()



.. image:: /auto_examples/visualization/images/sphx_glr_plot_topo_compare_conditions_001.png
    :align: center




**Total running time of the script:** ( 0 minutes  3.948 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_topo_compare_conditions.py <plot_topo_compare_conditions.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_topo_compare_conditions.ipynb <plot_topo_compare_conditions.ipynb>`

.. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
