.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_inverse_plot_lcmv_beamformer_volume.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_inverse_plot_lcmv_beamformer_volume.py:


===================================================================
Compute LCMV inverse solution on evoked data in volume source space
===================================================================

Compute LCMV inverse solution on an auditory evoked dataset in a volume source
space.


.. code-block:: python

    # Author: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>
    #
    # License: BSD (3-clause)

    # sphinx_gallery_thumbnail_number = 3

    import mne
    from mne.datasets import sample
    from mne.beamformer import make_lcmv, apply_lcmv

    print(__doc__)







Data preprocessing:


.. code-block:: python


    data_path = sample.data_path()
    subjects_dir = data_path + '/subjects'
    raw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'
    event_fname = data_path + '/MEG/sample/sample_audvis_raw-eve.fif'
    fname_fwd = data_path + '/MEG/sample/sample_audvis-meg-vol-7-fwd.fif'

    # Get epochs
    event_id, tmin, tmax = [1, 2], -0.2, 0.5

    # Read forward model
    forward = mne.read_forward_solution(fname_fwd)

    # Setup for reading the raw data
    raw = mne.io.read_raw_fif(raw_fname, preload=True)
    raw.info['bads'] = ['MEG 2443', 'EEG 053']  # 2 bads channels
    events = mne.read_events(event_fname)

    # Set up pick list: gradiometers and magnetometers, excluding bad channels
    picks = mne.pick_types(raw.info, meg=True, eeg=False, stim=True, eog=True,
                           exclude='bads')

    # Pick the channels of interest
    raw.pick_channels([raw.ch_names[pick] for pick in picks])

    # Re-normalize our empty-room projectors, so they are fine after subselection
    raw.info.normalize_proj()

    # Read epochs
    proj = False  # already applied
    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,
                        baseline=(None, 0), preload=True, proj=proj,
                        reject=dict(grad=4000e-13, mag=4e-12, eog=150e-6))
    evoked = epochs.average()

    # Visualize sensor space data
    evoked.plot_joint(ts_args=dict(time_unit='s'),
                      topomap_args=dict(time_unit='s'))




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_lcmv_beamformer_volume_001.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_lcmv_beamformer_volume_002.png
            :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Reading forward solution from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-vol-7-fwd.fif...
        Reading a source space...
        [done]
        1 source spaces read
        Desired named matrix (kind = 3523) not available
        Read MEG forward solution (3757 sources, 306 channels, free orientations)
        Source spaces transformed to the forward solution coordinate frame
    Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
        Read a total of 3 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
        Range : 25800 ... 192599 =     42.956 ...   320.670 secs
    Ready.
    Current compensation grade : 0
    Reading 0 ... 166799  =      0.000 ...   277.714 secs...
    145 matching events found
    Applying baseline correction (mode: mean)
    Not setting metadata
    Created an SSP operator (subspace dimension = 3)
    Loading data for 145 events and 421 original time points ...
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 0111', 'MEG 1411', 'MEG 1421']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 1131', 'MEG 1411', 'MEG 1421']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 1711']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 1711']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 1421']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
    31 bad epochs dropped


Compute covariance matrices, fit and apply  spatial filter.


.. code-block:: python


    # Read regularized noise covariance and compute regularized data covariance
    noise_cov = mne.compute_covariance(epochs, tmin=tmin, tmax=0, method='shrunk')
    data_cov = mne.compute_covariance(epochs, tmin=0.04, tmax=0.15,
                                      method='shrunk')

    # Compute weights of free orientation (vector) beamformer with weight
    # normalization (neural activity index, NAI). Providing a noise covariance
    # matrix enables whitening of the data and forward solution. Source orientation
    # is optimized by setting pick_ori to 'max-power'.
    # weight_norm can also be set to 'unit-noise-gain'. Source orientation can also
    # be 'normal' (but only when using a surface-based source space) or None,
    # which computes a vector beamfomer. Note, however, that not all combinations
    # of orientation selection and weight normalization are implemented yet.
    filters = make_lcmv(evoked.info, forward, data_cov, reg=0.05,
                        noise_cov=noise_cov, pick_ori='max-power',
                        weight_norm='nai')
    print(filters)

    # You can save these with:
    # filters.save('filters-lcmv.h5')

    # Apply this spatial filter to the evoked data.
    stc = apply_lcmv(evoked, filters, max_ori_out='signed')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Estimating covariance using SHRUNK
    Done.
    Number of samples used : 13794
    [done]
    Estimating covariance using SHRUNK
    Done.
    Number of samples used : 7638
    [done]
        305 out of 306 channels remain after picking
        Created an SSP operator (subspace dimension = 3)
    estimated rank (mag + grad): 302
    Setting small MEG eigenvalues to zero.
    Not doing PCA for MEG.
        Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)
    <Beamformer  |  LCMV, subject unknown, 3757 vert, 305 ch, max-power ori, nai norm, rank 302>


Plot source space activity:


.. code-block:: python


    # You can save result in stc files with:
    # stc.save('lcmv-vol')

    clim = dict(kind='value', pos_lims=[0.3, 0.6, 0.9])
    stc.plot(src=forward['src'], subject='sample', subjects_dir=subjects_dir,
             clim=clim)




.. image:: /auto_examples/inverse/images/sphx_glr_plot_lcmv_beamformer_volume_003.png
    :class: sphx-glr-single-img




We can also visualize the activity on a "glass brain" (shown here with
absolute values):


.. code-block:: python


    clim = dict(kind='value', lims=[0.3, 0.6, 0.9])
    abs(stc).plot(src=forward['src'], subject='sample', subjects_dir=subjects_dir,
                  mode='glass_brain', clim=clim)



.. image:: /auto_examples/inverse/images/sphx_glr_plot_lcmv_beamformer_volume_004.png
    :class: sphx-glr-single-img




**Total running time of the script:** ( 0 minutes  39.310 seconds)


.. _sphx_glr_download_auto_examples_inverse_plot_lcmv_beamformer_volume.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_lcmv_beamformer_volume.py <plot_lcmv_beamformer_volume.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_lcmv_beamformer_volume.ipynb <plot_lcmv_beamformer_volume.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
