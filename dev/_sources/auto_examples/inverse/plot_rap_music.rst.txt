

.. _sphx_glr_auto_examples_inverse_plot_rap_music.py:


================================
Compute Rap-Music on evoked data
================================

Compute a Recursively Applied and Projected MUltiple Signal Classification
(RAP-MUSIC) on evoked dataset.

The reference for Rap-Music is:
J.C. Mosher and R.M. Leahy. 1999. Source localization using recursively
applied and projected (RAP) MUSIC. Trans. Sig. Proc. 47, 2
(February 1999), 332-340.
DOI=10.1109/78.740118 http://dx.doi.org/10.1109/78.740118




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_001.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_002.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_003.png
            :scale: 47

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_004.png
            :scale: 47


.. rst-class:: sphx-glr-script-out

 Out::

    Reading /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Right Auditory)
            0 CTF compensation matrices available
            nave = 61 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    Applying baseline correction (mode: mean)
    Reading forward solution from /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif...
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        2 source spaces read
        Desired named matrix (kind = 3523) not available
        Read MEG forward solution (7498 sources, 306 channels, free orientations)
        Desired named matrix (kind = 3523) not available
        Read EEG forward solution (7498 sources, 60 channels, free orientations)
        MEG and EEG forward solutions combined
        Source spaces transformed to the forward solution coordinate frame
        Converting to surface-based source orientations...
        Average patch normals will be employed in the rotation to the local surface coordinates....
    [done]
        366 x 366 full covariance (kind = 1) found.
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
    info["bads"] and noise_cov["bads"] do not match, excluding bad channels from both
        305 out of 366 channels remain after picking
        Created an SSP operator (subspace dimension = 3)
    estimated rank (mag + grad): 302
    Setting small MEG eigenvalues to zero.
    Not doing PCA for MEG.
    source 1 found: p = 1834
    ori = -0.247032414225 0.776432601473 0.579764953832
    source 2 found: p = 5304
    ori = -0.515459181388 0.53451168955 0.66977539971
    4 projection items deactivated
    Created an SSP operator (subspace dimension = 3)
    4 projection items activated
    SSP projectors applied...




|


.. code-block:: python


    # Author: Yousra Bekhti <yousra.bekhti@gmail.com>
    #
    # License: BSD (3-clause)

    import mne

    from mne.datasets import sample
    from mne.beamformer import rap_music
    from mne.viz import plot_dipole_locations, plot_dipole_amplitudes

    print(__doc__)

    data_path = sample.data_path()
    subjects_dir = data_path + '/subjects'
    fwd_fname = data_path + '/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif'
    evoked_fname = data_path + '/MEG/sample/sample_audvis-ave.fif'
    cov_fname = data_path + '/MEG/sample/sample_audvis-cov.fif'

    # Read the evoked response and crop it
    condition = 'Right Auditory'
    evoked = mne.read_evokeds(evoked_fname, condition=condition,
                              baseline=(None, 0))
    evoked.crop(tmin=0.05, tmax=0.15)  # select N100

    evoked.pick_types(meg=True, eeg=False)

    # Read the forward solution
    forward = mne.read_forward_solution(fwd_fname, surf_ori=True,
                                        force_fixed=False)

    # Read noise covariance matrix
    noise_cov = mne.read_cov(cov_fname)

    dipoles, residual = rap_music(evoked, forward, noise_cov, n_dipoles=2,
                                  return_residual=True, verbose=True)
    trans = forward['mri_head_t']
    plot_dipole_locations(dipoles, trans, 'sample', subjects_dir=subjects_dir)
    plot_dipole_amplitudes(dipoles)

    # Plot the evoked data and the residual.
    evoked.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]))
    residual.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]))

**Total running time of the script:** ( 0 minutes  16.459 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_rap_music.py <plot_rap_music.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_rap_music.ipynb <plot_rap_music.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
