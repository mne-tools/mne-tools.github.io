

.. _sphx_glr_auto_tutorials_plot_visualize_evoked.py:


.. _tut_viz_evoked:

=====================
Visualize Evoked data
=====================



.. code-block:: python

    import os.path as op
    import numpy as np
    import matplotlib.pyplot as plt

    import mne







In this tutorial we focus on plotting functions of :class:`mne.Evoked`.
Here we read the evoked object from a file. Check out
:ref:`tut_epoching_and_averaging` to get to this stage from raw data.



.. code-block:: python

    data_path = mne.datasets.sample.data_path()
    fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis-ave.fif')
    evoked = mne.read_evokeds(fname, baseline=(None, 0), proj=True)
    print(evoked)





.. rst-class:: sphx-glr-script-out

 Out::

    Reading /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Left Auditory)
            0 CTF compensation matrices available
            nave = 55 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    No baseline correction applied
    Applying baseline correction (mode: mean)
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Right Auditory)
            0 CTF compensation matrices available
            nave = 61 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    No baseline correction applied
    Applying baseline correction (mode: mean)
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Left visual)
            0 CTF compensation matrices available
            nave = 67 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    No baseline correction applied
    Applying baseline correction (mode: mean)
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Right visual)
            0 CTF compensation matrices available
            nave = 58 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    No baseline correction applied
    Applying baseline correction (mode: mean)
    [<Evoked  |  comment : 'Left Auditory', kind : average, time : [-0.199795, 0.499488], n_epochs : 55, n_channels x n_times : 376 x 421>, <Evoked  |  comment : 'Right Auditory', kind : average, time : [-0.199795, 0.499488], n_epochs : 61, n_channels x n_times : 376 x 421>, <Evoked  |  comment : 'Left visual', kind : average, time : [-0.199795, 0.499488], n_epochs : 67, n_channels x n_times : 376 x 421>, <Evoked  |  comment : 'Right visual', kind : average, time : [-0.199795, 0.499488], n_epochs : 58, n_channels x n_times : 376 x 421>]


Notice that ``evoked`` is a list of evoked instances. You can read only one
of the categories by passing the argument ``condition`` to
:func:`mne.read_evokeds`. To make things more simple for this tutorial, we
read each instance to a variable.



.. code-block:: python

    evoked_l_aud = evoked[0]
    evoked_r_aud = evoked[1]
    evoked_l_vis = evoked[2]
    evoked_r_vis = evoked[3]







Let's start with a simple one. We plot event related potentials / fields
(ERP/ERF). The bad channels are not plotted by default. Here we explicitly
set the exclude parameter to show the bad channels in red. All plotting
functions of MNE-python return a handle to the figure instance. When we have
the handle, we can customise the plots to our liking.



.. code-block:: python

    fig = evoked_l_aud.plot(exclude=())




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_001.png
    :align: center




All plotting functions of MNE-python returns a handle to the figure instance.
When we have the handle, we can customise the plots to our liking. We can get
rid of the empty space with a simple function call.



.. code-block:: python

    fig.tight_layout()







Now let's make it a bit fancier and only use MEG channels. Many of the
MNE-functions include a ``picks`` parameter to include a selection of
channels. ``picks`` is simply a list of channel indices that you can easily
construct with :func:`mne.pick_types`. See also :func:`mne.pick_channels` and
:func:`mne.pick_channels_regexp`.
Using ``spatial_colors=True``, the individual channel lines are color coded
to show the sensor positions - specifically, the x, y, and z locations of
the sensors are transformed into R, G and B values.



.. code-block:: python

    picks = mne.pick_types(evoked_l_aud.info, meg=True, eeg=False, eog=False)
    evoked_l_aud.plot(spatial_colors=True, gfp=True, picks=picks)




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_002.png
    :align: center




Notice the legend on the left. The colors would suggest that there may be two
separate sources for the signals. This wasn't obvious from the first figure.
Try painting the slopes with left mouse button. It should open a new window
with topomaps (scalp plots) of the average over the painted area. There is
also a function for drawing topomaps separately.



.. code-block:: python

    evoked_l_aud.plot_topomap()




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_003.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Disabling interactive colorbar for multiple axes. Turn interactivity on explicitly by passing cmap as a tuple.


By default the topomaps are drawn from evenly spread out points of time over
the evoked data. We can also define the times ourselves.



.. code-block:: python

    times = np.arange(0.05, 0.151, 0.05)
    evoked_r_aud.plot_topomap(times=times, ch_type='mag')




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_004.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Disabling interactive colorbar for multiple axes. Turn interactivity on explicitly by passing cmap as a tuple.


Or we can automatically select the peaks.



.. code-block:: python

    evoked_r_aud.plot_topomap(times='peaks', ch_type='mag')




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_005.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Disabling interactive colorbar for multiple axes. Turn interactivity on explicitly by passing cmap as a tuple.


You can take a look at the documentation of :func:`mne.Evoked.plot_topomap`
or simply write ``evoked_r_aud.plot_topomap?`` in your python console to
see the different parameters you can pass to this function. Most of the
plotting functions also accept ``axes`` parameter. With that, you can
customise your plots even further. First we shall create a set of matplotlib
axes in a single figure and plot all of our evoked categories next to each
other.



.. code-block:: python

    fig, ax = plt.subplots(1, 5)
    evoked_l_aud.plot_topomap(times=0.1, axes=ax[0], show=False)
    evoked_r_aud.plot_topomap(times=0.1, axes=ax[1], show=False)
    evoked_l_vis.plot_topomap(times=0.1, axes=ax[2], show=False)
    evoked_r_vis.plot_topomap(times=0.1, axes=ax[3], show=True)




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_006.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Colorbar is drawn to the rightmost column of the figure. Be sure to provide enough space for it or turn it off with colorbar=False.
    Colorbar is drawn to the rightmost column of the figure. Be sure to provide enough space for it or turn it off with colorbar=False.
    Colorbar is drawn to the rightmost column of the figure. Be sure to provide enough space for it or turn it off with colorbar=False.
    Colorbar is drawn to the rightmost column of the figure. Be sure to provide enough space for it or turn it off with colorbar=False.


Notice that we created five axes, but had only four categories. The fifth
axes was used for drawing the colorbar. You must provide room for it when you
create this kind of custom plots or turn the colorbar off with
``colorbar=False``. That's what the warnings are trying to tell you. Also, we
used ``show=False`` for the three first function calls. This prevents the
showing of the figure prematurely. The behavior depends on the mode you are
using for your python session. See http://matplotlib.org/users/shell.html for
more information.

We can combine the two kinds of plots in one figure using the ``plot_joint``
method of Evoked objects. Called as-is (``evoked.plot_joint()``), this
function should give a stylish and informative display of spatio-temporal
dynamics. Also note the ``topomap_args`` and ``ts_args`` parameters of
:func:`mne.Evoked.plot_joint`. You can pass key-value pairs as a python
dictionary that gets passed as parameters to the topomaps
(:func:`mne.Evoked.plot_topomap`) and time series (:func:`mne.Evoked.plot`)
of the joint plot.
For specific styling, use these ``topomap_args`` and ``ts_args``
arguments. Here, topomaps at specific time points (70 and 105 msec) are
shown, sensors are not plotted, and the Global Field Power is shown:



.. code-block:: python

    ts_args = dict(gfp=True)
    topomap_args = dict(sensors=False)
    evoked_r_aud.plot_joint(title='right auditory', times=[.07, .105],
                            ts_args=ts_args, topomap_args=topomap_args)




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_007.png
            :scale: 47

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_008.png
            :scale: 47

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_009.png
            :scale: 47




We can also plot the activations as images. The time runs along the x-axis
and the channels along the y-axis. The amplitudes are color coded so that
the amplitudes from negative to positive translates to shift from blue to
red. White means zero amplitude. You can use the ``cmap`` parameter to define
the color map yourself. The accepted values include all matplotlib colormaps.



.. code-block:: python

    evoked_r_aud.plot_image(picks=picks)




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_010.png
    :align: center




Finally we plot the sensor data as a topographical view. In the simple case
we plot only left auditory responses, and then we plot them all in the same
figure for comparison. Click on the individual plots to open them bigger.



.. code-block:: python

    title = 'MNE sample data (condition : %s)'
    evoked_l_aud.plot_topo(title=title % evoked_l_aud.comment)
    colors = 'yellow', 'green', 'red', 'blue'
    mne.viz.plot_evoked_topo(evoked, color=colors,
                             title=title % 'Left/Right Auditory/Visual')




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_011.png
            :scale: 47

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_012.png
            :scale: 47




Visualizing field lines in 3D
-----------------------------

We now compute the field maps to project MEG and EEG data to MEG helmet
and scalp surface.

To do this we'll need coregistration information. See
:ref:`tut_forward` for more details.

Here we just illustrate usage.



.. code-block:: python


    subjects_dir = data_path + '/subjects'
    trans_fname = data_path + '/MEG/sample/sample_audvis_raw-trans.fif'

    maps = mne.make_field_map(evoked_l_aud, trans=trans_fname, subject='sample',
                              subjects_dir=subjects_dir, n_jobs=1)

    # explore several points in time
    field_map = evoked_l_aud.plot_field(maps, time=.1)




.. image:: /auto_tutorials/images/sphx_glr_plot_visualize_evoked_013.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Using surface from /home/ubuntu/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem.fif
    Getting helmet for system 306m
    Prepare EEG mapping...
    Computing dot products for 59 electrodes...
    Computing dot products for 2562 surface locations...
    Field mapping data ready
        Preparing the mapping matrix...
        [Truncate at 20 missing 0.001]
        The map will have average electrode reference
    Prepare MEG mapping...
    Computing dot products for 305 coils...
    Computing dot products for 304 surface locations...
    Field mapping data ready
        Preparing the mapping matrix...
        [Truncate at 209 missing 0.0001]


.. note::
    If trans_fname is set to None then only MEG estimates can be visualized.


**Total running time of the script:**
(0 minutes 27.832 seconds)



.. container:: sphx-glr-download

    **Download Python source code:** :download:`plot_visualize_evoked.py <plot_visualize_evoked.py>`


.. container:: sphx-glr-download

    **Download IPython notebook:** :download:`plot_visualize_evoked.ipynb <plot_visualize_evoked.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
