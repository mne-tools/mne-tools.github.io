

.. _sphx_glr_auto_tutorials_plot_stats_cluster_spatio_temporal_repeated_measures_anova.py:


.. _tut_stats_cluster_source_rANOVA:

======================================================================
Repeated measures ANOVA on source data with spatio-temporal clustering
======================================================================

This example illustrates how to make use of the clustering functions
for arbitrary, self-defined contrasts beyond standard t-tests. In this
case we will tests if the differences in evoked responses between
stimulation modality (visual VS auditory) depend on the stimulus
location (left vs right) for a group of subjects (simulated here
using one subject's data). For this purpose we will compute an
interaction effect using a repeated measures ANOVA. The multiple
comparisons problem is addressed with a cluster-level permutation test
across space and time.



.. code-block:: python

    # Authors: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>
    #          Eric Larson <larson.eric.d@gmail.com>
    #          Denis Engemannn <denis.engemann@gmail.com>
    #
    # License: BSD (3-clause)

    import os.path as op
    import numpy as np
    from numpy.random import randn
    import matplotlib.pyplot as plt

    import mne
    from mne import (io, spatial_tris_connectivity, compute_morph_matrix,
                     grade_to_tris)
    from mne.stats import (spatio_temporal_cluster_test, f_threshold_mway_rm,
                           f_mway_rm, summarize_clusters_stc)

    from mne.minimum_norm import apply_inverse, read_inverse_operator
    from mne.datasets import sample

    print(__doc__)







Set parameters
--------------



.. code-block:: python

    data_path = sample.data_path()
    raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'
    event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'
    subjects_dir = data_path + '/subjects'

    tmin = -0.2
    tmax = 0.3  # Use a lower tmax to reduce multiple comparisons

    #   Setup for reading the raw data
    raw = io.read_raw_fif(raw_fname)
    events = mne.read_events(event_fname)





.. rst-class:: sphx-glr-script-out

 Out::

    Opening raw data file /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
            Average EEG reference (1 x 60)  idle
        Range : 6450 ... 48149 =     42.956 ...   320.665 secs
    Ready.
    Current compensation grade : 0


Read epochs for all channels, removing a bad one
------------------------------------------------



.. code-block:: python

    raw.info['bads'] += ['MEG 2443']
    picks = mne.pick_types(raw.info, meg=True, eog=True, exclude='bads')
    # we'll load all four conditions that make up the 'two ways' of our ANOVA

    event_id = dict(l_aud=1, r_aud=2, l_vis=3, r_vis=4)
    reject = dict(grad=1000e-13, mag=4000e-15, eog=150e-6)
    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,
                        baseline=(None, 0), reject=reject, preload=True)

    #    Equalize trial counts to eliminate bias (which would otherwise be
    #    introduced by the abs() performed below)
    epochs.equalize_event_counts(event_id)





.. rst-class:: sphx-glr-script-out

 Out::

    288 matching events found
    Created an SSP operator (subspace dimension = 3)
    4 projection items activated
    Loading data for 288 events and 76 original time points ...
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on MAG : [u'MEG 1711']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on GRAD : [u'MEG 1333', u'MEG 1342']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
        Rejecting  epoch based on EOG : [u'EOG 061']
    33 bad epochs dropped
    Dropped 15 epochs


Transform to source space
-------------------------



.. code-block:: python

    fname_inv = data_path + '/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif'
    snr = 3.0
    lambda2 = 1.0 / snr ** 2
    method = "dSPM"  # use dSPM method (could also be MNE or sLORETA)
    inverse_operator = read_inverse_operator(fname_inv)

    # we'll only use one hemisphere to speed up this example
    # instead of a second vertex array we'll pass an empty array
    sample_vertices = [inverse_operator['src'][0]['vertno'], np.array([], int)]

    #    Let's average and compute inverse, then resample to speed things up
    conditions = []
    for cond in ['l_aud', 'r_aud', 'l_vis', 'r_vis']:  # order is important
        evoked = epochs[cond].average()
        evoked.resample(50, npad='auto')
        condition = apply_inverse(evoked, inverse_operator, lambda2, method)
        #    Let's only deal with t > 0, cropping to reduce multiple comparisons
        condition.crop(0, None)
        conditions.append(condition)

    tmin = conditions[0].tmin
    tstep = conditions[0].tstep





.. rst-class:: sphx-glr-script-out

 Out::

    Reading inverse operator decomposition from /home/ubuntu/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif...
        Reading inverse operator info...
        [done]
        Reading inverse operator decomposition...
        [done]
        305 x 305 full covariance (kind = 1) found.
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Noise covariance matrix read.
        22494 x 22494 diagonal covariance (kind = 2) found.
        Source covariance matrix read.
        22494 x 22494 diagonal covariance (kind = 6) found.
        Orientation priors read.
        22494 x 22494 diagonal covariance (kind = 5) found.
        Depth priors read.
        Did not find the desired covariance matrix (kind = 3)
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        2 source spaces read
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Source spaces transformed to the inverse solution coordinate frame
    Preparing the inverse operator for use...
        Scaled noise and source covariance from nave = 1 to nave = 60
        Created the regularized inverter
        Created an SSP operator (subspace dimension = 3)
        Created the whitener using a full noise covariance matrix (3 small eigenvalues omitted)
        Computing noise-normalization factors (dSPM)...
    [done]
    Picked 305 channels from the data
    Computing inverse...
    (eigenleads need to be weighted)...
    combining the current components...
    (dSPM)...
    [done]
    Preparing the inverse operator for use...
        Scaled noise and source covariance from nave = 1 to nave = 60
        Created the regularized inverter
        Created an SSP operator (subspace dimension = 3)
        Created the whitener using a full noise covariance matrix (3 small eigenvalues omitted)
        Computing noise-normalization factors (dSPM)...
    [done]
    Picked 305 channels from the data
    Computing inverse...
    (eigenleads need to be weighted)...
    combining the current components...
    (dSPM)...
    [done]
    Preparing the inverse operator for use...
        Scaled noise and source covariance from nave = 1 to nave = 60
        Created the regularized inverter
        Created an SSP operator (subspace dimension = 3)
        Created the whitener using a full noise covariance matrix (3 small eigenvalues omitted)
        Computing noise-normalization factors (dSPM)...
    [done]
    Picked 305 channels from the data
    Computing inverse...
    (eigenleads need to be weighted)...
    combining the current components...
    (dSPM)...
    [done]
    Preparing the inverse operator for use...
        Scaled noise and source covariance from nave = 1 to nave = 60
        Created the regularized inverter
        Created an SSP operator (subspace dimension = 3)
        Created the whitener using a full noise covariance matrix (3 small eigenvalues omitted)
        Computing noise-normalization factors (dSPM)...
    [done]
    Picked 305 channels from the data
    Computing inverse...
    (eigenleads need to be weighted)...
    combining the current components...
    (dSPM)...
    [done]


Transform to common cortical space
----------------------------------

Normally you would read in estimates across several subjects and morph them
to the same cortical space (e.g. fsaverage). For example purposes, we will
simulate this by just having each "subject" have the same response (just
noisy in source space) here.

We'll only consider the left hemisphere in this tutorial.



.. code-block:: python

    n_vertices_sample, n_times = conditions[0].lh_data.shape
    n_subjects = 7
    print('Simulating data for %d subjects.' % n_subjects)

    #    Let's make sure our results replicate, so set the seed.
    np.random.seed(0)
    X = randn(n_vertices_sample, n_times, n_subjects, 4) * 10
    for ii, condition in enumerate(conditions):
        X[:, :, :, ii] += condition.lh_data[:, :, np.newaxis]





.. rst-class:: sphx-glr-script-out

 Out::

    Simulating data for 7 subjects.


It's a good idea to spatially smooth the data, and for visualization
purposes, let's morph these to fsaverage, which is a grade 5 source space
with vertices 0:10242 for each hemisphere. Usually you'd have to morph
each subject's data separately (and you might want to use morph_data
instead), but here since all estimates are on 'sample' we can use one
morph matrix for all the heavy lifting.



.. code-block:: python

    fsave_vertices = [np.arange(10242), np.array([], int)]  # right hemi is empty
    morph_mat = compute_morph_matrix('sample', 'fsaverage', sample_vertices,
                                     fsave_vertices, 20, subjects_dir)
    n_vertices_fsave = morph_mat.shape[0]

    #    We have to change the shape for the dot() to work properly
    X = X.reshape(n_vertices_sample, n_times * n_subjects * 4)
    print('Morphing data.')
    X = morph_mat.dot(X)  # morph_mat is a sparse matrix
    X = X.reshape(n_vertices_fsave, n_times, n_subjects, 4)





.. rst-class:: sphx-glr-script-out

 Out::

    Computing morph matrix...
        Left-hemisphere map read.
        Right-hemisphere map read.
        20 smooth iterations done.
    [done]
    Morphing data.


Now we need to prepare the group matrix for the ANOVA statistic. To make the
clustering function work correctly with the ANOVA function X needs to be a
list of multi-dimensional arrays (one per condition) of shape: samples
(subjects) x time x space.

First we permute dimensions, then split the array into a list of conditions
and discard the empty dimension resulting from the split using numpy squeeze.



.. code-block:: python

    X = np.transpose(X, [2, 1, 0, 3])  #
    X = [np.squeeze(x) for x in np.split(X, 4, axis=-1)]







Prepare function for arbitrary contrast
---------------------------------------
As our ANOVA function is a multi-purpose tool we need to apply a few
modifications to integrate it with the clustering function. This
includes reshaping data, setting default arguments and processing
the return values. For this reason we'll write a tiny dummy function.

We will tell the ANOVA how to interpret the data matrix in terms of
factors. This is done via the factor levels argument which is a list
of the number factor levels for each factor.



.. code-block:: python

    factor_levels = [2, 2]







Finally we will pick the interaction effect by passing 'A:B'.
(this notation is borrowed from the R formula language). Without this also
the main effects will be returned.



.. code-block:: python

    effects = 'A:B'
    # Tell the ANOVA not to compute p-values which we don't need for clustering
    return_pvals = False

    # a few more convenient bindings
    n_times = X[0].shape[1]
    n_conditions = 4







A stat_fun must deal with a variable number of input arguments.

Inside the clustering function each condition will be passed as flattened
array, necessitated by the clustering procedure. The ANOVA however expects an
input array of dimensions: subjects X conditions X observations (optional).

The following function catches the list input and swaps the first and the
second dimension, and finally calls ANOVA.

Note. for further details on this ANOVA function consider the
corresponding
:ref:`time-frequency tutorial <tut_stats_cluster_sensor_rANOVA_tfr>`.



.. code-block:: python



    def stat_fun(*args):
        return f_mway_rm(np.swapaxes(args, 1, 0), factor_levels=factor_levels,
                         effects=effects, return_pvals=return_pvals)[0]
        # get f-values only.







Compute clustering statistic
----------------------------

To use an algorithm optimized for spatio-temporal clustering, we
just pass the spatial connectivity matrix (instead of spatio-temporal).



.. code-block:: python


    source_space = grade_to_tris(5)
    # as we only have one hemisphere we need only need half the connectivity
    lh_source_space = source_space[source_space[:, 0] < 10242]
    print('Computing connectivity.')
    connectivity = spatial_tris_connectivity(lh_source_space)

    #    Now let's actually do the clustering. Please relax, on a small
    #    notebook and one single thread only this will take a couple of minutes ...
    pthresh = 0.0005
    f_thresh = f_threshold_mway_rm(n_subjects, factor_levels, effects, pthresh)

    #    To speed things up a bit we will ...
    n_permutations = 128  # ... run fewer permutations (reduces sensitivity)

    print('Clustering.')
    T_obs, clusters, cluster_p_values, H0 = clu = \
        spatio_temporal_cluster_test(X, connectivity=connectivity, n_jobs=1,
                                     threshold=f_thresh, stat_fun=stat_fun,
                                     n_permutations=n_permutations,
                                     buffer_size=None)
    #    Now select the clusters that are sig. at p < 0.05 (note that this value
    #    is multiple-comparisons corrected).
    good_cluster_inds = np.where(cluster_p_values < 0.05)[0]





.. rst-class:: sphx-glr-script-out

 Out::

    Computing connectivity.
    -- number of connected vertices : 10242
    Clustering.
    stat_fun(H1): min=0.000000 max=500.726492
    Running initial clustering
    Found 146 clusters
    Permuting ...
    [                                        ] 0.78125 |        [..........                              ] 25.00000 /        [....................                    ] 50.00000 -        [..............................          ] 75.00000 \        [........................................] 100.00000 |    Computing cluster p-values
    Done.


Visualize the clusters
----------------------



.. code-block:: python


    print('Visualizing clusters.')

    #    Now let's build a convenient representation of each cluster, where each
    #    cluster becomes a "time point" in the SourceEstimate
    stc_all_cluster_vis = summarize_clusters_stc(clu, tstep=tstep,
                                                 vertices=fsave_vertices,
                                                 subject='fsaverage')

    #    Let's actually plot the first "time point" in the SourceEstimate, which
    #    shows all the clusters, weighted by duration

    subjects_dir = op.join(data_path, 'subjects')
    # The brighter the color, the stronger the interaction between
    # stimulus modality and stimulus location

    brain = stc_all_cluster_vis.plot(subjects_dir=subjects_dir, colormap='mne',
                                     views='lateral',
                                     time_label='Duration significant (ms)')
    brain.save_image('cluster-lh.png')
    brain.show_view('medial')




.. image:: /auto_tutorials/images/sphx_glr_plot_stats_cluster_spatio_temporal_repeated_measures_anova_001.png
    :align: center


.. rst-class:: sphx-glr-script-out

 Out::

    Visualizing clusters.
    Updating smoothing matrix, be patient..
    Smoothing matrix creation, step 1
    Smoothing matrix creation, step 2
    Smoothing matrix creation, step 3
    Smoothing matrix creation, step 4
    Smoothing matrix creation, step 5
    Smoothing matrix creation, step 6
    Smoothing matrix creation, step 7
    Smoothing matrix creation, step 8
    Smoothing matrix creation, step 9
    Smoothing matrix creation, step 10
    colormap: fmin=-4.00e+01 fmid=0.00e+00 fmax=4.00e+01 transparent=0


Finally, let's investigate interaction effect by reconstructing the time
courses



.. code-block:: python


    inds_t, inds_v = [(clusters[cluster_ind]) for ii, cluster_ind in
                      enumerate(good_cluster_inds)][0]  # first cluster

    times = np.arange(X[0].shape[1]) * tstep * 1e3

    plt.figure()
    colors = ['y', 'b', 'g', 'purple']
    event_ids = ['l_aud', 'r_aud', 'l_vis', 'r_vis']

    for ii, (condition, color, eve_id) in enumerate(zip(X, colors, event_ids)):
        # extract time course at cluster vertices
        condition = condition[:, :, inds_v]
        # normally we would normalize values across subjects but
        # here we use data from the same subject so we're good to just
        # create average time series across subjects and vertices.
        mean_tc = condition.mean(axis=2).mean(axis=0)
        std_tc = condition.std(axis=2).std(axis=0)
        plt.plot(times, mean_tc.T, color=color, label=eve_id)
        plt.fill_between(times, mean_tc + std_tc, mean_tc - std_tc, color='gray',
                         alpha=0.5, label='')

    ymin, ymax = mean_tc.min() - 5, mean_tc.max() + 5
    plt.xlabel('Time (ms)')
    plt.ylabel('Activation (F-values)')
    plt.xlim(times[[0, -1]])
    plt.ylim(ymin, ymax)
    plt.fill_betweenx((ymin, ymax), times[inds_t[0]],
                      times[inds_t[-1]], color='orange', alpha=0.3)
    plt.legend()
    plt.title('Interaction between stimulus-modality and location.')
    plt.show()



.. image:: /auto_tutorials/images/sphx_glr_plot_stats_cluster_spatio_temporal_repeated_measures_anova_002.png
    :align: center




**Total running time of the script:** ( 0 minutes  56.256 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_stats_cluster_spatio_temporal_repeated_measures_anova.py <plot_stats_cluster_spatio_temporal_repeated_measures_anova.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_stats_cluster_spatio_temporal_repeated_measures_anova.ipynb <plot_stats_cluster_spatio_temporal_repeated_measures_anova.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
