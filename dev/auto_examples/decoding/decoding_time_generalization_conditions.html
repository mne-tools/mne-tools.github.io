
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Decoding sensor space data with generalization across time and conditions &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Analysis of evoked response using ICA and PCA reduction techniques" href="decoding_unsupervised_spatial_filter.html" />
    <link rel="prev" title="Continuous Target Decoding with SPoC" href="decoding_spoc_CMC.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/10_ieeg_localize.html">
     Locating Intracranial Electrode Contacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="decoding-sensor-space-data-with-generalization-across-time-and-conditions">
<span id="sphx-glr-auto-examples-decoding-decoding-time-generalization-conditions-py"></span><h1>Decoding sensor space data with generalization across time and conditions<a class="headerlink" href="#decoding-sensor-space-data-with-generalization-across-time-and-conditions" title="Permalink to this headline">¶</a></h1>
<p>This example runs the analysis described in <a class="footnote-reference brackets" href="#kingdehaene2014" id="id1">1</a>. It
illustrates how one can
fit a linear classifier to identify a discriminatory topography at a given time
instant and subsequently assess whether this linear model can accurately
predict all of the time samples of a second set of conditions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Jean-Remi King &lt;jeanremi.king@gmail.com&gt;</span>
<span class="c1">#          Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Denis Engemann &lt;denis.engemann@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="kn">import</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a>

<span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># Preprocess data</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<span class="c1"># Load and filter data, set up epochs</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw.fif&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif&#39;</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a> <span class="o">=</span> <a href="../../generated/mne.pick_types.html#mne.pick_types" title="mne.pick_types" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">pick_types</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">meg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;bads&#39;</span><span class="p">)</span>  <span class="c1"># Pick MEG channels</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.filter" title="mne.io.Raw.filter" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">filter</span></a><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">30.</span><span class="p">,</span> <span class="n">fir_design</span><span class="o">=</span><span class="s1">&#39;firwin&#39;</span><span class="p">)</span>  <span class="c1"># Band pass filtering signals</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.read_events.html#mne.read_events" title="mne.read_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_events</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Auditory/Left&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Auditory/Right&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;Visual/Left&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;Visual/Right&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.050</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="mf">0.400</span>
<span class="c1"># decimate to make the example faster to run, but then use verbose=&#39;error&#39; in</span>
<span class="c1"># the Epochs constructor to suppress warning about decimation causing aliasing</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a> <span class="o">=</span> <span class="mi">2</span>
<a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span>
                    <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">mag</span><span class="o">=</span><span class="mf">5e-12</span><span class="p">),</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
Reading 0 ... 41699  =      0.000 ...   277.709 secs...
Filtering raw data in 1 contiguous segment
Setting up band-pass filter from 1 - 30 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 1.00
- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)
- Upper passband edge: 30.00 Hz
- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)
- Filter length: 497 samples (3.310 sec)
</pre></div>
</div>
<p>We will train the classifier on all left visual vs auditory trials
and test on all right visual vs auditory trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a><span class="p">(),</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_gen</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Fit classifiers on the epochs where the stimulus was presented to the left.</span>
<span class="c1"># Note that the experimental condition y indicates auditory or visual</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.fit" title="mne.decoding.GeneralizingEstimator.fit" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
             <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting GeneralizingEstimator : 0/35 [00:00&lt;?,       ?it/s]
  3%|2         | Fitting GeneralizingEstimator : 1/35 [00:00&lt;00:05,    6.47it/s]
  6%|5         | Fitting GeneralizingEstimator : 2/35 [00:00&lt;00:04,    6.68it/s]
  9%|8         | Fitting GeneralizingEstimator : 3/35 [00:00&lt;00:05,    6.23it/s]
 11%|#1        | Fitting GeneralizingEstimator : 4/35 [00:00&lt;00:04,    6.48it/s]
 14%|#4        | Fitting GeneralizingEstimator : 5/35 [00:00&lt;00:05,    5.36it/s]
 17%|#7        | Fitting GeneralizingEstimator : 6/35 [00:01&lt;00:05,    5.28it/s]
 20%|##        | Fitting GeneralizingEstimator : 7/35 [00:01&lt;00:05,    4.97it/s]
 23%|##2       | Fitting GeneralizingEstimator : 8/35 [00:01&lt;00:05,    5.13it/s]
 26%|##5       | Fitting GeneralizingEstimator : 9/35 [00:01&lt;00:05,    5.14it/s]
 29%|##8       | Fitting GeneralizingEstimator : 10/35 [00:01&lt;00:04,    5.16it/s]
 31%|###1      | Fitting GeneralizingEstimator : 11/35 [00:02&lt;00:04,    5.36it/s]
 34%|###4      | Fitting GeneralizingEstimator : 12/35 [00:02&lt;00:03,    5.88it/s]
 37%|###7      | Fitting GeneralizingEstimator : 13/35 [00:02&lt;00:03,    6.05it/s]
 40%|####      | Fitting GeneralizingEstimator : 14/35 [00:02&lt;00:03,    6.02it/s]
 43%|####2     | Fitting GeneralizingEstimator : 15/35 [00:02&lt;00:03,    6.25it/s]
 46%|####5     | Fitting GeneralizingEstimator : 16/35 [00:02&lt;00:02,    6.52it/s]
 49%|####8     | Fitting GeneralizingEstimator : 17/35 [00:02&lt;00:02,    6.40it/s]
 51%|#####1    | Fitting GeneralizingEstimator : 18/35 [00:02&lt;00:02,    6.84it/s]
 54%|#####4    | Fitting GeneralizingEstimator : 19/35 [00:02&lt;00:02,    6.77it/s]
 57%|#####7    | Fitting GeneralizingEstimator : 20/35 [00:03&lt;00:02,    7.09it/s]
 60%|######    | Fitting GeneralizingEstimator : 21/35 [00:03&lt;00:01,    7.01it/s]
 63%|######2   | Fitting GeneralizingEstimator : 22/35 [00:03&lt;00:01,    6.94it/s]
 66%|######5   | Fitting GeneralizingEstimator : 23/35 [00:03&lt;00:01,    7.18it/s]
 69%|######8   | Fitting GeneralizingEstimator : 24/35 [00:03&lt;00:01,    7.08it/s]
 71%|#######1  | Fitting GeneralizingEstimator : 25/35 [00:03&lt;00:01,    7.12it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 26/35 [00:03&lt;00:01,    6.92it/s]
 77%|#######7  | Fitting GeneralizingEstimator : 27/35 [00:04&lt;00:01,    6.89it/s]
 80%|########  | Fitting GeneralizingEstimator : 28/35 [00:04&lt;00:01,    6.83it/s]
 83%|########2 | Fitting GeneralizingEstimator : 29/35 [00:04&lt;00:00,    6.86it/s]
 86%|########5 | Fitting GeneralizingEstimator : 30/35 [00:04&lt;00:00,    6.76it/s]
 89%|########8 | Fitting GeneralizingEstimator : 31/35 [00:04&lt;00:00,    6.70it/s]
 91%|#########1| Fitting GeneralizingEstimator : 32/35 [00:04&lt;00:00,    6.93it/s]
 94%|#########4| Fitting GeneralizingEstimator : 33/35 [00:05&lt;00:00,    6.69it/s]
 97%|#########7| Fitting GeneralizingEstimator : 34/35 [00:05&lt;00:00,    6.81it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:05&lt;00:00,    7.03it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:05&lt;00:00,    6.74it/s]
</pre></div>
</div>
<p>Score on the epochs where the stimulus was presented to the right.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.score" title="mne.decoding.GeneralizingEstimator.score" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">score</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
                        <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Scoring GeneralizingEstimator : 0/1225 [00:00&lt;?,       ?it/s]
  0%|          | Scoring GeneralizingEstimator : 1/1225 [00:00&lt;01:04,   18.95it/s]
  1%|          | Scoring GeneralizingEstimator : 8/1225 [00:00&lt;00:12,   94.09it/s]
  1%|          | Scoring GeneralizingEstimator : 11/1225 [00:00&lt;00:13,   92.45it/s]
  1%|1         | Scoring GeneralizingEstimator : 13/1225 [00:00&lt;00:14,   83.39it/s]
  1%|1         | Scoring GeneralizingEstimator : 17/1225 [00:00&lt;00:15,   80.05it/s]
  2%|1         | Scoring GeneralizingEstimator : 21/1225 [00:00&lt;00:14,   83.65it/s]
  2%|1         | Scoring GeneralizingEstimator : 24/1225 [00:00&lt;00:15,   75.08it/s]
  2%|2         | Scoring GeneralizingEstimator : 29/1225 [00:00&lt;00:14,   82.84it/s]
  3%|2         | Scoring GeneralizingEstimator : 32/1225 [00:00&lt;00:14,   83.33it/s]
  3%|2         | Scoring GeneralizingEstimator : 33/1225 [00:00&lt;00:15,   77.83it/s]
  3%|3         | Scoring GeneralizingEstimator : 37/1225 [00:00&lt;00:14,   81.25it/s]
  3%|3         | Scoring GeneralizingEstimator : 40/1225 [00:00&lt;00:15,   78.14it/s]
  4%|3         | Scoring GeneralizingEstimator : 43/1225 [00:00&lt;00:14,   78.89it/s]
  4%|3         | Scoring GeneralizingEstimator : 48/1225 [00:00&lt;00:15,   75.07it/s]
  4%|4         | Scoring GeneralizingEstimator : 54/1225 [00:00&lt;00:14,   82.19it/s]
  5%|4         | Scoring GeneralizingEstimator : 56/1225 [00:00&lt;00:15,   75.78it/s]
  5%|4         | Scoring GeneralizingEstimator : 61/1225 [00:00&lt;00:14,   80.20it/s]
  5%|5         | Scoring GeneralizingEstimator : 63/1225 [00:00&lt;00:15,   73.53it/s]
  6%|5         | Scoring GeneralizingEstimator : 69/1225 [00:00&lt;00:14,   79.38it/s]
  6%|5         | Scoring GeneralizingEstimator : 71/1225 [00:00&lt;00:15,   73.64it/s]
  6%|6         | Scoring GeneralizingEstimator : 75/1225 [00:01&lt;00:15,   72.69it/s]
  6%|6         | Scoring GeneralizingEstimator : 76/1225 [00:01&lt;00:16,   70.38it/s]
  7%|6         | Scoring GeneralizingEstimator : 81/1225 [00:01&lt;00:16,   70.78it/s]
  7%|7         | Scoring GeneralizingEstimator : 87/1225 [00:01&lt;00:14,   75.91it/s]
  7%|7         | Scoring GeneralizingEstimator : 90/1225 [00:01&lt;00:15,   72.99it/s]
  8%|7         | Scoring GeneralizingEstimator : 95/1225 [00:01&lt;00:14,   76.44it/s]
  8%|8         | Scoring GeneralizingEstimator : 98/1225 [00:01&lt;00:15,   73.79it/s]
  8%|8         | Scoring GeneralizingEstimator : 102/1225 [00:01&lt;00:14,   75.71it/s]
  9%|8         | Scoring GeneralizingEstimator : 106/1225 [00:01&lt;00:14,   74.86it/s]
  9%|9         | Scoring GeneralizingEstimator : 111/1225 [00:01&lt;00:14,   77.99it/s]
  9%|9         | Scoring GeneralizingEstimator : 115/1225 [00:01&lt;00:14,   75.71it/s]
 10%|9         | Scoring GeneralizingEstimator : 118/1225 [00:01&lt;00:14,   76.13it/s]
 10%|9         | Scoring GeneralizingEstimator : 122/1225 [00:01&lt;00:14,   75.50it/s]
 10%|#         | Scoring GeneralizingEstimator : 125/1225 [00:01&lt;00:14,   75.74it/s]
 11%|#         | Scoring GeneralizingEstimator : 130/1225 [00:01&lt;00:14,   73.71it/s]
 11%|#         | Scoring GeneralizingEstimator : 134/1225 [00:01&lt;00:14,   75.41it/s]
 11%|#1        | Scoring GeneralizingEstimator : 138/1225 [00:01&lt;00:14,   74.62it/s]
 12%|#1        | Scoring GeneralizingEstimator : 141/1225 [00:01&lt;00:14,   75.09it/s]
 12%|#1        | Scoring GeneralizingEstimator : 143/1225 [00:01&lt;00:15,   70.50it/s]
 12%|#2        | Scoring GeneralizingEstimator : 147/1225 [00:02&lt;00:15,   68.46it/s]
 12%|#2        | Scoring GeneralizingEstimator : 151/1225 [00:02&lt;00:15,   70.20it/s]
 12%|#2        | Scoring GeneralizingEstimator : 152/1225 [00:02&lt;00:16,   65.61it/s]
 13%|#2        | Scoring GeneralizingEstimator : 155/1225 [00:02&lt;00:16,   66.41it/s]
 13%|#2        | Scoring GeneralizingEstimator : 156/1225 [00:02&lt;00:17,   62.39it/s]
 13%|#2        | Scoring GeneralizingEstimator : 158/1225 [00:02&lt;00:17,   62.24it/s]
 13%|#3        | Scoring GeneralizingEstimator : 160/1225 [00:02&lt;00:17,   59.63it/s]
 13%|#3        | Scoring GeneralizingEstimator : 162/1225 [00:02&lt;00:18,   57.13it/s]
 14%|#3        | Scoring GeneralizingEstimator : 167/1225 [00:02&lt;00:17,   59.84it/s]
 14%|#3        | Scoring GeneralizingEstimator : 168/1225 [00:02&lt;00:18,   57.61it/s]
 14%|#4        | Scoring GeneralizingEstimator : 175/1225 [00:02&lt;00:17,   59.13it/s]
 15%|#4        | Scoring GeneralizingEstimator : 180/1225 [00:02&lt;00:16,   62.01it/s]
 15%|#4        | Scoring GeneralizingEstimator : 181/1225 [00:02&lt;00:17,   58.83it/s]
 15%|#5        | Scoring GeneralizingEstimator : 185/1225 [00:02&lt;00:17,   60.75it/s]
 15%|#5        | Scoring GeneralizingEstimator : 187/1225 [00:02&lt;00:17,   58.64it/s]
 16%|#5        | Scoring GeneralizingEstimator : 192/1225 [00:02&lt;00:16,   61.51it/s]
 16%|#5        | Scoring GeneralizingEstimator : 193/1225 [00:02&lt;00:17,   57.95it/s]
 16%|#6        | Scoring GeneralizingEstimator : 200/1225 [00:02&lt;00:16,   62.78it/s]
 17%|#6        | Scoring GeneralizingEstimator : 206/1225 [00:03&lt;00:16,   63.15it/s]
 17%|#6        | Scoring GeneralizingEstimator : 207/1225 [00:03&lt;00:16,   61.70it/s]
 17%|#7        | Scoring GeneralizingEstimator : 210/1225 [00:03&lt;00:16,   62.50it/s]
 18%|#7        | Scoring GeneralizingEstimator : 215/1225 [00:03&lt;00:16,   62.68it/s]
 18%|#7        | Scoring GeneralizingEstimator : 219/1225 [00:03&lt;00:15,   64.43it/s]
 18%|#8        | Scoring GeneralizingEstimator : 223/1225 [00:03&lt;00:15,   66.17it/s]
 19%|#8        | Scoring GeneralizingEstimator : 230/1225 [00:03&lt;00:14,   68.44it/s]
 19%|#8        | Scoring GeneralizingEstimator : 231/1225 [00:03&lt;00:15,   65.30it/s]
 19%|#9        | Scoring GeneralizingEstimator : 235/1225 [00:03&lt;00:14,   66.48it/s]
 19%|#9        | Scoring GeneralizingEstimator : 238/1225 [00:03&lt;00:14,   66.59it/s]
 20%|#9        | Scoring GeneralizingEstimator : 241/1225 [00:03&lt;00:14,   67.25it/s]
 20%|##        | Scoring GeneralizingEstimator : 246/1225 [00:03&lt;00:14,   68.06it/s]
 20%|##        | Scoring GeneralizingEstimator : 250/1225 [00:03&lt;00:13,   69.69it/s]
 21%|##        | Scoring GeneralizingEstimator : 254/1225 [00:03&lt;00:14,   69.15it/s]
 21%|##        | Scoring GeneralizingEstimator : 256/1225 [00:03&lt;00:14,   68.78it/s]
 21%|##1       | Scoring GeneralizingEstimator : 262/1225 [00:03&lt;00:13,   70.00it/s]
 22%|##1       | Scoring GeneralizingEstimator : 266/1225 [00:03&lt;00:13,   71.57it/s]
 22%|##2       | Scoring GeneralizingEstimator : 271/1225 [00:03&lt;00:13,   71.27it/s]
 23%|##2       | Scoring GeneralizingEstimator : 277/1225 [00:03&lt;00:12,   74.70it/s]
 23%|##2       | Scoring GeneralizingEstimator : 278/1225 [00:04&lt;00:13,   71.79it/s]
 23%|##2       | Scoring GeneralizingEstimator : 279/1225 [00:04&lt;00:13,   69.95it/s]
 23%|##3       | Scoring GeneralizingEstimator : 284/1225 [00:04&lt;00:13,   68.86it/s]
 24%|##3       | Scoring GeneralizingEstimator : 289/1225 [00:04&lt;00:13,   71.40it/s]
 24%|##3       | Scoring GeneralizingEstimator : 291/1225 [00:04&lt;00:13,   67.80it/s]
 24%|##4       | Scoring GeneralizingEstimator : 297/1225 [00:04&lt;00:13,   69.35it/s]
 24%|##4       | Scoring GeneralizingEstimator : 299/1225 [00:04&lt;00:13,   68.96it/s]
 25%|##4       | Scoring GeneralizingEstimator : 303/1225 [00:04&lt;00:13,   69.02it/s]
 25%|##4       | Scoring GeneralizingEstimator : 305/1225 [00:04&lt;00:13,   68.65it/s]
 25%|##5       | Scoring GeneralizingEstimator : 310/1225 [00:04&lt;00:13,   68.85it/s]
 26%|##5       | Scoring GeneralizingEstimator : 314/1225 [00:04&lt;00:12,   70.40it/s]
 26%|##5       | Scoring GeneralizingEstimator : 318/1225 [00:04&lt;00:12,   70.13it/s]
 26%|##6       | Scoring GeneralizingEstimator : 321/1225 [00:04&lt;00:12,   70.70it/s]
 27%|##6       | Scoring GeneralizingEstimator : 325/1225 [00:04&lt;00:12,   70.06it/s]
 27%|##7       | Scoring GeneralizingEstimator : 331/1225 [00:04&lt;00:12,   73.56it/s]
 27%|##7       | Scoring GeneralizingEstimator : 334/1225 [00:04&lt;00:12,   71.53it/s]
 28%|##7       | Scoring GeneralizingEstimator : 338/1225 [00:04&lt;00:12,   72.94it/s]
 28%|##7       | Scoring GeneralizingEstimator : 342/1225 [00:04&lt;00:12,   72.51it/s]
 28%|##8       | Scoring GeneralizingEstimator : 345/1225 [00:04&lt;00:12,   73.01it/s]
 29%|##8       | Scoring GeneralizingEstimator : 350/1225 [00:05&lt;00:11,   73.00it/s]
 29%|##8       | Scoring GeneralizingEstimator : 353/1225 [00:05&lt;00:11,   73.06it/s]
 29%|##9       | Scoring GeneralizingEstimator : 356/1225 [00:05&lt;00:12,   71.99it/s]
 29%|##9       | Scoring GeneralizingEstimator : 359/1225 [00:05&lt;00:11,   72.37it/s]
 30%|##9       | Scoring GeneralizingEstimator : 362/1225 [00:05&lt;00:12,   70.55it/s]
 30%|##9       | Scoring GeneralizingEstimator : 364/1225 [00:05&lt;00:12,   70.09it/s]
 30%|##9       | Scoring GeneralizingEstimator : 366/1225 [00:05&lt;00:12,   67.88it/s]
 30%|##9       | Scoring GeneralizingEstimator : 367/1225 [00:05&lt;00:12,   66.52it/s]
 30%|###       | Scoring GeneralizingEstimator : 371/1225 [00:05&lt;00:13,   64.68it/s]
 31%|###       | Scoring GeneralizingEstimator : 375/1225 [00:05&lt;00:12,   66.40it/s]
 31%|###       | Scoring GeneralizingEstimator : 376/1225 [00:05&lt;00:13,   64.67it/s]
 31%|###       | Scoring GeneralizingEstimator : 377/1225 [00:05&lt;00:13,   63.45it/s]
 31%|###1      | Scoring GeneralizingEstimator : 382/1225 [00:05&lt;00:13,   64.26it/s]
 31%|###1      | Scoring GeneralizingEstimator : 384/1225 [00:05&lt;00:13,   63.96it/s]
 32%|###1      | Scoring GeneralizingEstimator : 388/1225 [00:05&lt;00:13,   63.88it/s]
 32%|###1      | Scoring GeneralizingEstimator : 389/1225 [00:05&lt;00:13,   62.57it/s]
 32%|###2      | Scoring GeneralizingEstimator : 394/1225 [00:05&lt;00:13,   63.57it/s]
 32%|###2      | Scoring GeneralizingEstimator : 395/1225 [00:05&lt;00:13,   62.39it/s]
 33%|###2      | Scoring GeneralizingEstimator : 401/1225 [00:05&lt;00:12,   64.26it/s]
 33%|###3      | Scoring GeneralizingEstimator : 405/1225 [00:06&lt;00:13,   61.05it/s]
 33%|###3      | Scoring GeneralizingEstimator : 407/1225 [00:06&lt;00:13,   60.86it/s]
 33%|###3      | Scoring GeneralizingEstimator : 410/1225 [00:06&lt;00:13,   59.07it/s]
 34%|###3      | Scoring GeneralizingEstimator : 413/1225 [00:06&lt;00:13,   59.99it/s]
 34%|###3      | Scoring GeneralizingEstimator : 416/1225 [00:06&lt;00:13,   59.44it/s]
 34%|###4      | Scoring GeneralizingEstimator : 420/1225 [00:06&lt;00:13,   61.30it/s]
 35%|###4      | Scoring GeneralizingEstimator : 427/1225 [00:06&lt;00:13,   58.57it/s]
 35%|###5      | Scoring GeneralizingEstimator : 432/1225 [00:06&lt;00:12,   61.16it/s]
 35%|###5      | Scoring GeneralizingEstimator : 433/1225 [00:06&lt;00:13,   60.18it/s]
 35%|###5      | Scoring GeneralizingEstimator : 434/1225 [00:06&lt;00:13,   58.76it/s]
 36%|###5      | Scoring GeneralizingEstimator : 438/1225 [00:06&lt;00:13,   57.33it/s]
 36%|###6      | Scoring GeneralizingEstimator : 442/1225 [00:06&lt;00:13,   56.23it/s]
 37%|###6      | Scoring GeneralizingEstimator : 449/1225 [00:06&lt;00:12,   60.59it/s]
 37%|###6      | Scoring GeneralizingEstimator : 451/1225 [00:06&lt;00:14,   54.90it/s]
 37%|###7      | Scoring GeneralizingEstimator : 454/1225 [00:06&lt;00:13,   55.80it/s]
 37%|###7      | Scoring GeneralizingEstimator : 457/1225 [00:07&lt;00:13,   55.91it/s]
 37%|###7      | Scoring GeneralizingEstimator : 459/1225 [00:07&lt;00:14,   54.43it/s]
 38%|###7      | Scoring GeneralizingEstimator : 460/1225 [00:07&lt;00:14,   51.41it/s]
 38%|###7      | Scoring GeneralizingEstimator : 462/1225 [00:07&lt;00:15,   50.46it/s]
 38%|###7      | Scoring GeneralizingEstimator : 463/1225 [00:07&lt;00:15,   49.67it/s]
 38%|###8      | Scoring GeneralizingEstimator : 466/1225 [00:07&lt;00:15,   49.08it/s]
 38%|###8      | Scoring GeneralizingEstimator : 468/1225 [00:07&lt;00:15,   49.34it/s]
 38%|###8      | Scoring GeneralizingEstimator : 469/1225 [00:07&lt;00:15,   48.13it/s]
 38%|###8      | Scoring GeneralizingEstimator : 471/1225 [00:07&lt;00:15,   48.43it/s]
 39%|###8      | Scoring GeneralizingEstimator : 474/1225 [00:07&lt;00:15,   49.60it/s]
 39%|###8      | Scoring GeneralizingEstimator : 475/1225 [00:07&lt;00:15,   48.58it/s]
 39%|###9      | Scoring GeneralizingEstimator : 478/1225 [00:07&lt;00:15,   49.77it/s]
 39%|###9      | Scoring GeneralizingEstimator : 479/1225 [00:07&lt;00:15,   47.92it/s]
 40%|###9      | Scoring GeneralizingEstimator : 484/1225 [00:07&lt;00:14,   50.96it/s]
 40%|###9      | Scoring GeneralizingEstimator : 487/1225 [00:07&lt;00:14,   49.34it/s]
 40%|####      | Scoring GeneralizingEstimator : 490/1225 [00:07&lt;00:15,   48.43it/s]
 40%|####      | Scoring GeneralizingEstimator : 496/1225 [00:07&lt;00:14,   49.22it/s]
 41%|####      | Scoring GeneralizingEstimator : 500/1225 [00:08&lt;00:14,   49.13it/s]
 41%|####1     | Scoring GeneralizingEstimator : 505/1225 [00:08&lt;00:13,   51.86it/s]
 41%|####1     | Scoring GeneralizingEstimator : 506/1225 [00:08&lt;00:14,   51.20it/s]
 41%|####1     | Scoring GeneralizingEstimator : 507/1225 [00:08&lt;00:14,   50.55it/s]
 42%|####1     | Scoring GeneralizingEstimator : 512/1225 [00:08&lt;00:14,   50.82it/s]
 42%|####2     | Scoring GeneralizingEstimator : 518/1225 [00:08&lt;00:12,   54.47it/s]
 42%|####2     | Scoring GeneralizingEstimator : 519/1225 [00:08&lt;00:13,   51.74it/s]
 43%|####2     | Scoring GeneralizingEstimator : 524/1225 [00:08&lt;00:13,   52.10it/s]
 43%|####3     | Scoring GeneralizingEstimator : 528/1225 [00:08&lt;00:12,   53.96it/s]
 43%|####3     | Scoring GeneralizingEstimator : 530/1225 [00:08&lt;00:12,   54.10it/s]
 44%|####3     | Scoring GeneralizingEstimator : 535/1225 [00:08&lt;00:12,   55.10it/s]
 44%|####3     | Scoring GeneralizingEstimator : 536/1225 [00:08&lt;00:12,   53.65it/s]
 44%|####4     | Scoring GeneralizingEstimator : 541/1225 [00:08&lt;00:12,   56.12it/s]
 44%|####4     | Scoring GeneralizingEstimator : 543/1225 [00:08&lt;00:12,   54.57it/s]
 45%|####4     | Scoring GeneralizingEstimator : 548/1225 [00:08&lt;00:11,   57.31it/s]
 45%|####4     | Scoring GeneralizingEstimator : 551/1225 [00:08&lt;00:11,   57.06it/s]
 45%|####5     | Scoring GeneralizingEstimator : 556/1225 [00:08&lt;00:11,   59.72it/s]
 46%|####5     | Scoring GeneralizingEstimator : 558/1225 [00:08&lt;00:11,   59.67it/s]
 46%|####6     | Scoring GeneralizingEstimator : 565/1225 [00:09&lt;00:11,   58.63it/s]
 47%|####6     | Scoring GeneralizingEstimator : 571/1225 [00:09&lt;00:10,   62.09it/s]
 47%|####6     | Scoring GeneralizingEstimator : 573/1225 [00:09&lt;00:10,   60.94it/s]
 47%|####6     | Scoring GeneralizingEstimator : 574/1225 [00:09&lt;00:10,   59.87it/s]
 47%|####7     | Scoring GeneralizingEstimator : 579/1225 [00:09&lt;00:10,   59.85it/s]
 48%|####7     | Scoring GeneralizingEstimator : 583/1225 [00:09&lt;00:10,   61.49it/s]
 48%|####8     | Scoring GeneralizingEstimator : 590/1225 [00:09&lt;00:09,   64.40it/s]
 48%|####8     | Scoring GeneralizingEstimator : 591/1225 [00:09&lt;00:10,   63.31it/s]
 49%|####8     | Scoring GeneralizingEstimator : 597/1225 [00:09&lt;00:09,   65.89it/s]
 49%|####8     | Scoring GeneralizingEstimator : 599/1225 [00:09&lt;00:09,   65.54it/s]
 49%|####9     | Scoring GeneralizingEstimator : 605/1225 [00:09&lt;00:08,   69.06it/s]
 49%|####9     | Scoring GeneralizingEstimator : 606/1225 [00:09&lt;00:09,   65.55it/s]
 50%|####9     | Scoring GeneralizingEstimator : 610/1225 [00:09&lt;00:09,   67.19it/s]
 50%|####9     | Scoring GeneralizingEstimator : 611/1225 [00:09&lt;00:09,   63.68it/s]
 50%|#####     | Scoring GeneralizingEstimator : 614/1225 [00:09&lt;00:09,   61.89it/s]
 50%|#####     | Scoring GeneralizingEstimator : 616/1225 [00:09&lt;00:09,   61.65it/s]
 51%|#####     | Scoring GeneralizingEstimator : 619/1225 [00:09&lt;00:09,   61.27it/s]
 51%|#####     | Scoring GeneralizingEstimator : 621/1225 [00:09&lt;00:10,   57.02it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 625/1225 [00:10&lt;00:10,   55.59it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 630/1225 [00:10&lt;00:10,   55.14it/s]
 52%|#####1    | Scoring GeneralizingEstimator : 635/1225 [00:10&lt;00:10,   54.90it/s]
 52%|#####2    | Scoring GeneralizingEstimator : 641/1225 [00:10&lt;00:10,   58.23it/s]
 52%|#####2    | Scoring GeneralizingEstimator : 642/1225 [00:10&lt;00:10,   55.25it/s]
 53%|#####2    | Scoring GeneralizingEstimator : 646/1225 [00:10&lt;00:10,   55.97it/s]
 53%|#####2    | Scoring GeneralizingEstimator : 647/1225 [00:10&lt;00:10,   55.13it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 652/1225 [00:10&lt;00:10,   54.91it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 657/1225 [00:10&lt;00:09,   57.44it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 660/1225 [00:10&lt;00:10,   56.49it/s]
 54%|#####4    | Scoring GeneralizingEstimator : 664/1225 [00:10&lt;00:09,   56.93it/s]
 54%|#####4    | Scoring GeneralizingEstimator : 666/1225 [00:10&lt;00:09,   56.95it/s]
 55%|#####4    | Scoring GeneralizingEstimator : 671/1225 [00:10&lt;00:09,   56.53it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 676/1225 [00:10&lt;00:09,   57.46it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 678/1225 [00:10&lt;00:09,   57.39it/s]
 56%|#####5    | Scoring GeneralizingEstimator : 684/1225 [00:11&lt;00:09,   57.78it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 686/1225 [00:11&lt;00:09,   57.71it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 687/1225 [00:11&lt;00:09,   55.19it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 692/1225 [00:11&lt;00:09,   57.70it/s]
 57%|#####6    | Scoring GeneralizingEstimator : 696/1225 [00:11&lt;00:09,   58.66it/s]
 57%|#####7    | Scoring GeneralizingEstimator : 700/1225 [00:11&lt;00:08,   60.27it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 705/1225 [00:11&lt;00:08,   61.41it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 710/1225 [00:11&lt;00:08,   63.91it/s]
 58%|#####8    | Scoring GeneralizingEstimator : 713/1225 [00:11&lt;00:07,   64.62it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 718/1225 [00:11&lt;00:07,   64.83it/s]
 59%|#####9    | Scoring GeneralizingEstimator : 724/1225 [00:11&lt;00:07,   66.30it/s]
 60%|#####9    | Scoring GeneralizingEstimator : 730/1225 [00:11&lt;00:07,   69.55it/s]
 60%|#####9    | Scoring GeneralizingEstimator : 732/1225 [00:11&lt;00:07,   69.09it/s]
 60%|######    | Scoring GeneralizingEstimator : 735/1225 [00:11&lt;00:07,   69.65it/s]
 60%|######    | Scoring GeneralizingEstimator : 740/1225 [00:11&lt;00:06,   71.87it/s]
 61%|######    | Scoring GeneralizingEstimator : 742/1225 [00:11&lt;00:06,   70.11it/s]
 61%|######    | Scoring GeneralizingEstimator : 747/1225 [00:11&lt;00:06,   72.56it/s]
 61%|######1   | Scoring GeneralizingEstimator : 748/1225 [00:11&lt;00:07,   67.19it/s]
 62%|######1   | Scoring GeneralizingEstimator : 754/1225 [00:11&lt;00:06,   67.71it/s]
 62%|######1   | Scoring GeneralizingEstimator : 759/1225 [00:11&lt;00:06,   70.12it/s]
 62%|######2   | Scoring GeneralizingEstimator : 762/1225 [00:12&lt;00:06,   69.21it/s]
 63%|######2   | Scoring GeneralizingEstimator : 767/1225 [00:12&lt;00:06,   71.62it/s]
 63%|######2   | Scoring GeneralizingEstimator : 768/1225 [00:12&lt;00:06,   68.25it/s]
 63%|######3   | Scoring GeneralizingEstimator : 773/1225 [00:12&lt;00:06,   68.36it/s]
 63%|######3   | Scoring GeneralizingEstimator : 775/1225 [00:12&lt;00:06,   67.58it/s]
 64%|######3   | Scoring GeneralizingEstimator : 780/1225 [00:12&lt;00:06,   66.58it/s]
 64%|######4   | Scoring GeneralizingEstimator : 787/1225 [00:12&lt;00:06,   68.77it/s]
 64%|######4   | Scoring GeneralizingEstimator : 788/1225 [00:12&lt;00:06,   67.45it/s]
 65%|######4   | Scoring GeneralizingEstimator : 794/1225 [00:12&lt;00:06,   70.80it/s]
 65%|######4   | Scoring GeneralizingEstimator : 795/1225 [00:12&lt;00:06,   67.76it/s]
 65%|######5   | Scoring GeneralizingEstimator : 801/1225 [00:12&lt;00:05,   71.07it/s]
 66%|######5   | Scoring GeneralizingEstimator : 804/1225 [00:12&lt;00:06,   69.13it/s]
 66%|######5   | Scoring GeneralizingEstimator : 808/1225 [00:12&lt;00:06,   68.99it/s]
 66%|######6   | Scoring GeneralizingEstimator : 810/1225 [00:12&lt;00:06,   68.65it/s]
 67%|######6   | Scoring GeneralizingEstimator : 816/1225 [00:12&lt;00:05,   69.99it/s]
 67%|######6   | Scoring GeneralizingEstimator : 819/1225 [00:12&lt;00:05,   70.54it/s]
 67%|######7   | Scoring GeneralizingEstimator : 825/1225 [00:12&lt;00:05,   70.52it/s]
 68%|######7   | Scoring GeneralizingEstimator : 832/1225 [00:12&lt;00:05,   74.70it/s]
 68%|######8   | Scoring GeneralizingEstimator : 834/1225 [00:13&lt;00:05,   72.34it/s]
 68%|######8   | Scoring GeneralizingEstimator : 839/1225 [00:13&lt;00:05,   74.53it/s]
 69%|######8   | Scoring GeneralizingEstimator : 841/1225 [00:13&lt;00:05,   73.10it/s]
 69%|######8   | Scoring GeneralizingEstimator : 842/1225 [00:13&lt;00:05,   71.67it/s]
 69%|######9   | Scoring GeneralizingEstimator : 847/1225 [00:13&lt;00:05,   74.10it/s]
 69%|######9   | Scoring GeneralizingEstimator : 848/1225 [00:13&lt;00:05,   72.58it/s]
 70%|######9   | Scoring GeneralizingEstimator : 855/1225 [00:13&lt;00:05,   73.83it/s]
 70%|######9   | Scoring GeneralizingEstimator : 856/1225 [00:13&lt;00:05,   70.43it/s]
 70%|#######   | Scoring GeneralizingEstimator : 862/1225 [00:13&lt;00:04,   73.89it/s]
 70%|#######   | Scoring GeneralizingEstimator : 863/1225 [00:13&lt;00:05,   70.22it/s]
 71%|#######   | Scoring GeneralizingEstimator : 866/1225 [00:13&lt;00:05,   70.67it/s]
 71%|#######   | Scoring GeneralizingEstimator : 868/1225 [00:13&lt;00:05,   68.53it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 871/1225 [00:13&lt;00:05,   69.17it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 875/1225 [00:13&lt;00:05,   69.72it/s]
 72%|#######1  | Scoring GeneralizingEstimator : 879/1225 [00:13&lt;00:04,   71.32it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 882/1225 [00:13&lt;00:04,   69.39it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 886/1225 [00:13&lt;00:04,   70.88it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 888/1225 [00:13&lt;00:04,   67.86it/s]
 73%|#######2  | Scoring GeneralizingEstimator : 893/1225 [00:13&lt;00:04,   70.49it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 897/1225 [00:13&lt;00:04,   70.03it/s]
 74%|#######3  | Scoring GeneralizingEstimator : 902/1225 [00:14&lt;00:04,   70.38it/s]
 74%|#######3  | Scoring GeneralizingEstimator : 905/1225 [00:14&lt;00:04,   70.91it/s]
 74%|#######4  | Scoring GeneralizingEstimator : 910/1225 [00:14&lt;00:04,   70.47it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 913/1225 [00:14&lt;00:04,   71.02it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 916/1225 [00:14&lt;00:04,   70.22it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 921/1225 [00:14&lt;00:04,   72.75it/s]
 76%|#######5  | Scoring GeneralizingEstimator : 925/1225 [00:14&lt;00:04,   72.03it/s]
 76%|#######5  | Scoring GeneralizingEstimator : 928/1225 [00:14&lt;00:04,   72.54it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 932/1225 [00:14&lt;00:04,   71.27it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 936/1225 [00:14&lt;00:03,   72.39it/s]
 77%|#######6  | Scoring GeneralizingEstimator : 939/1225 [00:14&lt;00:03,   71.64it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 944/1225 [00:14&lt;00:03,   74.16it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 949/1225 [00:14&lt;00:03,   73.15it/s]
 78%|#######7  | Scoring GeneralizingEstimator : 954/1225 [00:14&lt;00:03,   75.44it/s]
 78%|#######8  | Scoring GeneralizingEstimator : 958/1225 [00:14&lt;00:03,   75.24it/s]
 78%|#######8  | Scoring GeneralizingEstimator : 961/1225 [00:14&lt;00:03,   75.62it/s]
 79%|#######8  | Scoring GeneralizingEstimator : 965/1225 [00:14&lt;00:03,   75.30it/s]
 79%|#######8  | Scoring GeneralizingEstimator : 966/1225 [00:14&lt;00:03,   73.69it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 972/1225 [00:14&lt;00:03,   74.86it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 973/1225 [00:14&lt;00:03,   73.26it/s]
 80%|#######9  | Scoring GeneralizingEstimator : 978/1225 [00:15&lt;00:03,   73.17it/s]
 80%|########  | Scoring GeneralizingEstimator : 980/1225 [00:15&lt;00:03,   72.65it/s]
 80%|########  | Scoring GeneralizingEstimator : 985/1225 [00:15&lt;00:03,   73.17it/s]
 81%|########  | Scoring GeneralizingEstimator : 987/1225 [00:15&lt;00:03,   72.63it/s]
 81%|########  | Scoring GeneralizingEstimator : 991/1225 [00:15&lt;00:03,   69.99it/s]
 81%|########1 | Scoring GeneralizingEstimator : 997/1225 [00:15&lt;00:03,   70.87it/s]
 82%|########1 | Scoring GeneralizingEstimator : 1002/1225 [00:15&lt;00:03,   73.32it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1006/1225 [00:15&lt;00:03,   72.50it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1010/1225 [00:15&lt;00:02,   73.92it/s]
 83%|########2 | Scoring GeneralizingEstimator : 1014/1225 [00:15&lt;00:02,   73.18it/s]
 83%|########3 | Scoring GeneralizingEstimator : 1019/1225 [00:15&lt;00:02,   75.57it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1023/1225 [00:15&lt;00:02,   74.69it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1027/1225 [00:15&lt;00:02,   75.97it/s]
 84%|########4 | Scoring GeneralizingEstimator : 1032/1225 [00:15&lt;00:02,   76.10it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1037/1225 [00:15&lt;00:02,   78.08it/s]
 85%|########5 | Scoring GeneralizingEstimator : 1042/1225 [00:15&lt;00:02,   75.15it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1048/1225 [00:15&lt;00:02,   76.49it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1053/1225 [00:15&lt;00:02,   78.71it/s]
 86%|########6 | Scoring GeneralizingEstimator : 1058/1225 [00:16&lt;00:02,   78.56it/s]
 87%|########6 | Scoring GeneralizingEstimator : 1064/1225 [00:16&lt;00:01,   81.63it/s]
 87%|########7 | Scoring GeneralizingEstimator : 1067/1225 [00:16&lt;00:01,   79.47it/s]
 88%|########7 | Scoring GeneralizingEstimator : 1072/1225 [00:16&lt;00:01,   81.62it/s]
 88%|########7 | Scoring GeneralizingEstimator : 1076/1225 [00:16&lt;00:01,   79.76it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1082/1225 [00:16&lt;00:01,   82.85it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1084/1225 [00:16&lt;00:01,   80.55it/s]
 89%|########8 | Scoring GeneralizingEstimator : 1088/1225 [00:16&lt;00:01,   81.73it/s]
 89%|########9 | Scoring GeneralizingEstimator : 1094/1225 [00:16&lt;00:01,   82.31it/s]
 90%|########9 | Scoring GeneralizingEstimator : 1099/1225 [00:16&lt;00:01,   84.40it/s]
 90%|######### | Scoring GeneralizingEstimator : 1104/1225 [00:16&lt;00:01,   83.90it/s]
 91%|######### | Scoring GeneralizingEstimator : 1109/1225 [00:16&lt;00:01,   85.95it/s]
 91%|######### | Scoring GeneralizingEstimator : 1113/1225 [00:16&lt;00:01,   82.21it/s]
 91%|#########1| Scoring GeneralizingEstimator : 1118/1225 [00:16&lt;00:01,   84.28it/s]
 92%|#########1| Scoring GeneralizingEstimator : 1123/1225 [00:16&lt;00:01,   83.34it/s]
 92%|#########1| Scoring GeneralizingEstimator : 1126/1225 [00:16&lt;00:01,   80.63it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1128/1225 [00:16&lt;00:01,   79.86it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1132/1225 [00:16&lt;00:01,   79.12it/s]
 93%|#########2| Scoring GeneralizingEstimator : 1137/1225 [00:16&lt;00:01,   81.27it/s]
 93%|#########3| Scoring GeneralizingEstimator : 1140/1225 [00:17&lt;00:01,   79.01it/s]
 93%|#########3| Scoring GeneralizingEstimator : 1144/1225 [00:17&lt;00:01,   80.24it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1147/1225 [00:17&lt;00:01,   77.91it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1149/1225 [00:17&lt;00:00,   77.26it/s]
 94%|#########4| Scoring GeneralizingEstimator : 1153/1225 [00:17&lt;00:00,   75.97it/s]
 95%|#########4| Scoring GeneralizingEstimator : 1159/1225 [00:17&lt;00:00,   79.20it/s]
 95%|#########4| Scoring GeneralizingEstimator : 1163/1225 [00:17&lt;00:00,   77.78it/s]
 95%|#########5| Scoring GeneralizingEstimator : 1168/1225 [00:17&lt;00:00,   80.00it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1171/1225 [00:17&lt;00:00,   78.75it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1173/1225 [00:17&lt;00:00,   78.06it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1178/1225 [00:17&lt;00:00,   77.96it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1180/1225 [00:17&lt;00:00,   77.15it/s]
 97%|#########6| Scoring GeneralizingEstimator : 1187/1225 [00:17&lt;00:00,   79.18it/s]
 97%|#########6| Scoring GeneralizingEstimator : 1188/1225 [00:17&lt;00:00,   77.35it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1193/1225 [00:17&lt;00:00,   75.19it/s]
 98%|#########7| Scoring GeneralizingEstimator : 1198/1225 [00:17&lt;00:00,   77.47it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1201/1225 [00:17&lt;00:00,   75.73it/s]
 99%|#########8| Scoring GeneralizingEstimator : 1207/1225 [00:17&lt;00:00,   75.67it/s]
 99%|#########8| Scoring GeneralizingEstimator : 1211/1225 [00:17&lt;00:00,   76.58it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1216/1225 [00:18&lt;00:00,   76.95it/s]
100%|#########9| Scoring GeneralizingEstimator : 1221/1225 [00:18&lt;00:00,   79.17it/s]
100%|##########| Scoring GeneralizingEstimator : 1225/1225 [00:18&lt;00:00,   80.95it/s]
100%|##########| Scoring GeneralizingEstimator : 1225/1225 [00:18&lt;00:00,   67.77it/s]
</pre></div>
</div>
<p>Plot</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.matshow.html#matplotlib.axes.Axes.matshow" title="matplotlib.axes.Axes.matshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">matshow</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span>
                <span class="n">extent</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs.times" title="mne.Epochs.times" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">epochs</span><span class="o">.</span><span class="n">times</span></a><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axis.XAxis.set_ticks_position.html#matplotlib.axis.XAxis.set_ticks_position" title="matplotlib.axis.XAxis.set_ticks_position" class="sphx-glr-backref-module-matplotlib-axis sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span></a><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Testing Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Generalization across time and condition&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html#matplotlib.pyplot.colorbar" title="matplotlib.pyplot.colorbar" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span></a><span class="p">(</span><a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_decoding_time_generalization_conditions_001.png" srcset="../../_images/sphx_glr_decoding_time_generalization_conditions_001.png" alt="Generalization across time and condition" class = "sphx-glr-single-img"/><div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="kingdehaene2014"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jean-Rémi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. <em>Trends in Cognitive Sciences</em>, 18(4):203–210, 2014. <a class="reference external" href="https://doi.org/10.1016/j.tics.2014.01.002">doi:10.1016/j.tics.2014.01.002</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  34.539 seconds)</p>
<p><strong>Estimated memory usage:</strong>  128 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ab6282967a162922fd7405f0d8568e07/decoding_time_generalization_conditions.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">decoding_time_generalization_conditions.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/00e78bba5d10188fcf003ef05e32a6f7/decoding_time_generalization_conditions.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">decoding_time_generalization_conditions.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="decoding_spoc_CMC.html" title="previous page">Continuous Target Decoding with SPoC</a>
    <a class='right-next' id="next-link" href="decoding_unsupervised_spatial_filter.html" title="next page">Analysis of evoked response using ICA and PCA reduction techniques</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-07-26T06:28:55.544964+00:00" class="localized">2021-07-26 06:28 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>