
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Decoding sensor space data with generalization across time and conditions &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Analysis of evoked response using ICA and PCA reduction techniques" href="decoding_unsupervised_spatial_filter.html" />
    <link rel="prev" title="Continuous Target Decoding with SPoC" href="decoding_spoc_CMC.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne-tools.github.io/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="decoding-sensor-space-data-with-generalization-across-time-and-conditions">
<span id="sphx-glr-auto-examples-decoding-decoding-time-generalization-conditions-py"></span><h1>Decoding sensor space data with generalization across time and conditions<a class="headerlink" href="#decoding-sensor-space-data-with-generalization-across-time-and-conditions" title="Permalink to this headline">¶</a></h1>
<p>This example runs the analysis described in <a class="footnote-reference brackets" href="#kingdehaene2014" id="id1">1</a>. It
illustrates how one can
fit a linear classifier to identify a discriminatory topography at a given time
instant and subsequently assess whether this linear model can accurately
predict all of the time samples of a second set of conditions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Jean-Remi King &lt;jeanremi.king@gmail.com&gt;</span>
<span class="c1">#          Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Denis Engemann &lt;denis.engemann@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="kn">import</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a>

<span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># Preprocess data</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<span class="c1"># Load and filter data, set up epochs</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw.fif&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif&#39;</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a> <span class="o">=</span> <a href="../../generated/mne.pick_types.html#mne.pick_types" title="mne.pick_types" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">pick_types</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">meg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;bads&#39;</span><span class="p">)</span>  <span class="c1"># Pick MEG channels</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.filter" title="mne.io.Raw.filter" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">filter</span></a><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">30.</span><span class="p">,</span> <span class="n">fir_design</span><span class="o">=</span><span class="s1">&#39;firwin&#39;</span><span class="p">)</span>  <span class="c1"># Band pass filtering signals</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.read_events.html#mne.read_events" title="mne.read_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_events</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Auditory/Left&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Auditory/Right&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;Visual/Left&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;Visual/Right&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.050</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="mf">0.400</span>
<span class="c1"># decimate to make the example faster to run, but then use verbose=&#39;error&#39; in</span>
<span class="c1"># the Epochs constructor to suppress warning about decimation causing aliasing</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a> <span class="o">=</span> <span class="mi">2</span>
<a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span>
                    <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">mag</span><span class="o">=</span><span class="mf">5e-12</span><span class="p">),</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
Reading 0 ... 41699  =      0.000 ...   277.709 secs...
Filtering raw data in 1 contiguous segment
Setting up band-pass filter from 1 - 30 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 1.00
- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)
- Upper passband edge: 30.00 Hz
- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)
- Filter length: 497 samples (3.310 sec)
</pre></div>
</div>
<p>We will train the classifier on all left visual vs auditory trials
and test on all right visual vs auditory trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a><span class="p">(),</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_gen</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Fit classifiers on the epochs where the stimulus was presented to the left.</span>
<span class="c1"># Note that the experimental condition y indicates auditory or visual</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.fit" title="mne.decoding.GeneralizingEstimator.fit" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
             <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting GeneralizingEstimator : 0/35 [00:00&lt;?,       ?it/s]
  3%|2         | Fitting GeneralizingEstimator : 1/35 [00:00&lt;00:01,   28.70it/s]
  6%|5         | Fitting GeneralizingEstimator : 2/35 [00:00&lt;00:01,   21.45it/s]
  9%|8         | Fitting GeneralizingEstimator : 3/35 [00:00&lt;00:01,   22.31it/s]
 11%|#1        | Fitting GeneralizingEstimator : 4/35 [00:00&lt;00:01,   17.67it/s]
 14%|#4        | Fitting GeneralizingEstimator : 5/35 [00:00&lt;00:01,   15.05it/s]
 17%|#7        | Fitting GeneralizingEstimator : 6/35 [00:00&lt;00:02,   13.31it/s]
 20%|##        | Fitting GeneralizingEstimator : 7/35 [00:00&lt;00:01,   14.64it/s]
 23%|##2       | Fitting GeneralizingEstimator : 8/35 [00:00&lt;00:01,   14.96it/s]
 26%|##5       | Fitting GeneralizingEstimator : 9/35 [00:00&lt;00:01,   13.88it/s]
 29%|##8       | Fitting GeneralizingEstimator : 10/35 [00:00&lt;00:01,   13.32it/s]
 31%|###1      | Fitting GeneralizingEstimator : 11/35 [00:00&lt;00:01,   13.59it/s]
 34%|###4      | Fitting GeneralizingEstimator : 12/35 [00:00&lt;00:01,   14.38it/s]
 37%|###7      | Fitting GeneralizingEstimator : 13/35 [00:00&lt;00:01,   14.51it/s]
 40%|####      | Fitting GeneralizingEstimator : 14/35 [00:00&lt;00:01,   15.26it/s]
 43%|####2     | Fitting GeneralizingEstimator : 15/35 [00:01&lt;00:01,   13.42it/s]
 46%|####5     | Fitting GeneralizingEstimator : 16/35 [00:01&lt;00:01,   13.09it/s]
 49%|####8     | Fitting GeneralizingEstimator : 17/35 [00:01&lt;00:01,   13.64it/s]
 51%|#####1    | Fitting GeneralizingEstimator : 18/35 [00:01&lt;00:01,   13.98it/s]
 54%|#####4    | Fitting GeneralizingEstimator : 19/35 [00:01&lt;00:01,   14.60it/s]
 57%|#####7    | Fitting GeneralizingEstimator : 20/35 [00:01&lt;00:01,   14.44it/s]
 60%|######    | Fitting GeneralizingEstimator : 21/35 [00:01&lt;00:01,   13.97it/s]
 66%|######5   | Fitting GeneralizingEstimator : 23/35 [00:01&lt;00:00,   15.55it/s]
 71%|#######1  | Fitting GeneralizingEstimator : 25/35 [00:01&lt;00:00,   15.87it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 26/35 [00:01&lt;00:00,   14.60it/s]
 80%|########  | Fitting GeneralizingEstimator : 28/35 [00:01&lt;00:00,   15.81it/s]
 83%|########2 | Fitting GeneralizingEstimator : 29/35 [00:01&lt;00:00,   15.31it/s]
 86%|########5 | Fitting GeneralizingEstimator : 30/35 [00:02&lt;00:00,   15.02it/s]
 89%|########8 | Fitting GeneralizingEstimator : 31/35 [00:02&lt;00:00,   15.45it/s]
 91%|#########1| Fitting GeneralizingEstimator : 32/35 [00:02&lt;00:00,   14.54it/s]
 94%|#########4| Fitting GeneralizingEstimator : 33/35 [00:02&lt;00:00,   14.90it/s]
 97%|#########7| Fitting GeneralizingEstimator : 34/35 [00:02&lt;00:00,   15.03it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:02&lt;00:00,   15.43it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:02&lt;00:00,   15.08it/s]
</pre></div>
</div>
<p>Score on the epochs where the stimulus was presented to the right.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.score" title="mne.decoding.GeneralizingEstimator.score" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">score</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
                        <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Scoring GeneralizingEstimator : 0/1225 [00:00&lt;?,       ?it/s]
  1%|1         | Scoring GeneralizingEstimator : 13/1225 [00:00&lt;00:03,  375.68it/s]
  2%|2         | Scoring GeneralizingEstimator : 26/1225 [00:00&lt;00:03,  323.34it/s]
  3%|2         | Scoring GeneralizingEstimator : 34/1225 [00:00&lt;00:04,  293.38it/s]
  3%|3         | Scoring GeneralizingEstimator : 42/1225 [00:00&lt;00:05,  231.35it/s]
  4%|4         | Scoring GeneralizingEstimator : 51/1225 [00:00&lt;00:04,  236.75it/s]
  5%|4         | Scoring GeneralizingEstimator : 57/1225 [00:00&lt;00:05,  200.04it/s]
  5%|5         | Scoring GeneralizingEstimator : 65/1225 [00:00&lt;00:05,  204.48it/s]
  6%|5         | Scoring GeneralizingEstimator : 72/1225 [00:00&lt;00:06,  184.26it/s]
  7%|6         | Scoring GeneralizingEstimator : 81/1225 [00:00&lt;00:05,  192.31it/s]
  7%|6         | Scoring GeneralizingEstimator : 84/1225 [00:00&lt;00:06,  165.65it/s]
  8%|7         | Scoring GeneralizingEstimator : 93/1225 [00:00&lt;00:06,  173.95it/s]
  8%|8         | Scoring GeneralizingEstimator : 99/1225 [00:00&lt;00:06,  163.26it/s]
  9%|8         | Scoring GeneralizingEstimator : 107/1225 [00:00&lt;00:06,  168.57it/s]
  9%|9         | Scoring GeneralizingEstimator : 113/1225 [00:00&lt;00:07,  158.39it/s]
 10%|9         | Scoring GeneralizingEstimator : 120/1225 [00:00&lt;00:06,  161.52it/s]
 10%|#         | Scoring GeneralizingEstimator : 126/1225 [00:00&lt;00:07,  151.38it/s]
 11%|#1        | Scoring GeneralizingEstimator : 136/1225 [00:00&lt;00:06,  159.99it/s]
 11%|#1        | Scoring GeneralizingEstimator : 139/1225 [00:00&lt;00:07,  147.77it/s]
 12%|#2        | Scoring GeneralizingEstimator : 149/1225 [00:00&lt;00:06,  155.85it/s]
 13%|#2        | Scoring GeneralizingEstimator : 155/1225 [00:00&lt;00:07,  150.44it/s]
 13%|#3        | Scoring GeneralizingEstimator : 163/1225 [00:01&lt;00:06,  154.96it/s]
 14%|#3        | Scoring GeneralizingEstimator : 171/1225 [00:01&lt;00:06,  151.65it/s]
 15%|#4        | Scoring GeneralizingEstimator : 180/1225 [00:01&lt;00:06,  157.37it/s]
 15%|#5        | Scoring GeneralizingEstimator : 184/1225 [00:01&lt;00:07,  148.71it/s]
 16%|#5        | Scoring GeneralizingEstimator : 193/1225 [00:01&lt;00:06,  154.27it/s]
 16%|#6        | Scoring GeneralizingEstimator : 201/1225 [00:01&lt;00:06,  150.14it/s]
 17%|#7        | Scoring GeneralizingEstimator : 209/1225 [00:01&lt;00:06,  154.02it/s]
 18%|#7        | Scoring GeneralizingEstimator : 218/1225 [00:01&lt;00:06,  153.17it/s]
 19%|#8        | Scoring GeneralizingEstimator : 227/1225 [00:01&lt;00:06,  158.15it/s]
 19%|#9        | Scoring GeneralizingEstimator : 235/1225 [00:01&lt;00:06,  154.48it/s]
 20%|#9        | Scoring GeneralizingEstimator : 243/1225 [00:01&lt;00:06,  158.00it/s]
 21%|##        | Scoring GeneralizingEstimator : 252/1225 [00:01&lt;00:06,  157.00it/s]
 21%|##1       | Scoring GeneralizingEstimator : 260/1225 [00:01&lt;00:06,  160.32it/s]
 22%|##1       | Scoring GeneralizingEstimator : 266/1225 [00:01&lt;00:06,  154.79it/s]
 22%|##2       | Scoring GeneralizingEstimator : 274/1225 [00:01&lt;00:06,  158.14it/s]
 23%|##2       | Scoring GeneralizingEstimator : 281/1225 [00:01&lt;00:06,  154.06it/s]
 24%|##3       | Scoring GeneralizingEstimator : 289/1225 [00:01&lt;00:05,  157.37it/s]
 24%|##4       | Scoring GeneralizingEstimator : 299/1225 [00:01&lt;00:05,  156.91it/s]
 25%|##5       | Scoring GeneralizingEstimator : 309/1225 [00:01&lt;00:05,  162.39it/s]
 26%|##5       | Scoring GeneralizingEstimator : 314/1225 [00:01&lt;00:05,  155.85it/s]
 26%|##6       | Scoring GeneralizingEstimator : 322/1225 [00:02&lt;00:05,  158.90it/s]
 27%|##6       | Scoring GeneralizingEstimator : 327/1225 [00:02&lt;00:05,  154.88it/s]
 27%|##7       | Scoring GeneralizingEstimator : 336/1225 [00:02&lt;00:05,  159.20it/s]
 28%|##8       | Scoring GeneralizingEstimator : 344/1225 [00:02&lt;00:05,  154.31it/s]
 29%|##8       | Scoring GeneralizingEstimator : 352/1225 [00:02&lt;00:05,  157.40it/s]
 29%|##9       | Scoring GeneralizingEstimator : 359/1225 [00:02&lt;00:05,  153.00it/s]
 30%|##9       | Scoring GeneralizingEstimator : 367/1225 [00:02&lt;00:05,  156.10it/s]
 31%|###       | Scoring GeneralizingEstimator : 375/1225 [00:02&lt;00:05,  153.61it/s]
 31%|###1      | Scoring GeneralizingEstimator : 384/1225 [00:02&lt;00:05,  157.75it/s]
 32%|###1      | Scoring GeneralizingEstimator : 389/1225 [00:02&lt;00:05,  151.31it/s]
 32%|###2      | Scoring GeneralizingEstimator : 398/1225 [00:02&lt;00:05,  155.40it/s]
 33%|###2      | Scoring GeneralizingEstimator : 403/1225 [00:02&lt;00:05,  151.08it/s]
 33%|###3      | Scoring GeneralizingEstimator : 409/1225 [00:02&lt;00:05,  151.82it/s]
 34%|###3      | Scoring GeneralizingEstimator : 416/1225 [00:02&lt;00:05,  148.28it/s]
 35%|###4      | Scoring GeneralizingEstimator : 424/1225 [00:02&lt;00:05,  151.25it/s]
 35%|###5      | Scoring GeneralizingEstimator : 431/1225 [00:02&lt;00:05,  148.32it/s]
 36%|###5      | Scoring GeneralizingEstimator : 439/1225 [00:02&lt;00:05,  151.44it/s]
 36%|###6      | Scoring GeneralizingEstimator : 446/1225 [00:02&lt;00:05,  147.11it/s]
 37%|###7      | Scoring GeneralizingEstimator : 454/1225 [00:02&lt;00:05,  150.26it/s]
 38%|###7      | Scoring GeneralizingEstimator : 460/1225 [00:02&lt;00:05,  146.85it/s]
 38%|###8      | Scoring GeneralizingEstimator : 467/1225 [00:03&lt;00:05,  148.95it/s]
 39%|###8      | Scoring GeneralizingEstimator : 476/1225 [00:03&lt;00:05,  148.70it/s]
 39%|###9      | Scoring GeneralizingEstimator : 483/1225 [00:03&lt;00:04,  150.28it/s]
 40%|####      | Scoring GeneralizingEstimator : 491/1225 [00:03&lt;00:04,  151.26it/s]
 41%|####      | Scoring GeneralizingEstimator : 498/1225 [00:03&lt;00:04,  152.69it/s]
 41%|####1     | Scoring GeneralizingEstimator : 508/1225 [00:03&lt;00:04,  150.63it/s]
 42%|####2     | Scoring GeneralizingEstimator : 518/1225 [00:03&lt;00:04,  155.71it/s]
 43%|####2     | Scoring GeneralizingEstimator : 521/1225 [00:03&lt;00:04,  148.28it/s]
 43%|####3     | Scoring GeneralizingEstimator : 529/1225 [00:03&lt;00:04,  151.20it/s]
 44%|####3     | Scoring GeneralizingEstimator : 535/1225 [00:03&lt;00:04,  147.28it/s]
 44%|####4     | Scoring GeneralizingEstimator : 543/1225 [00:03&lt;00:04,  150.36it/s]
 45%|####4     | Scoring GeneralizingEstimator : 551/1225 [00:03&lt;00:04,  147.24it/s]
 46%|####5     | Scoring GeneralizingEstimator : 558/1225 [00:03&lt;00:04,  149.28it/s]
 46%|####6     | Scoring GeneralizingEstimator : 565/1225 [00:03&lt;00:04,  148.20it/s]
 47%|####6     | Scoring GeneralizingEstimator : 572/1225 [00:03&lt;00:04,  150.23it/s]
 47%|####7     | Scoring GeneralizingEstimator : 579/1225 [00:03&lt;00:04,  146.67it/s]
 48%|####8     | Scoring GeneralizingEstimator : 589/1225 [00:03&lt;00:04,  151.82it/s]
 49%|####8     | Scoring GeneralizingEstimator : 595/1225 [00:03&lt;00:04,  146.58it/s]
 49%|####9     | Scoring GeneralizingEstimator : 603/1225 [00:03&lt;00:04,  149.63it/s]
 50%|####9     | Scoring GeneralizingEstimator : 607/1225 [00:03&lt;00:04,  147.31it/s]
 50%|####9     | Scoring GeneralizingEstimator : 611/1225 [00:03&lt;00:04,  146.27it/s]
 51%|#####     | Scoring GeneralizingEstimator : 622/1225 [00:04&lt;00:04,  145.22it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 630/1225 [00:04&lt;00:04,  147.49it/s]
 52%|#####1    | Scoring GeneralizingEstimator : 636/1225 [00:04&lt;00:04,  144.62it/s]
 53%|#####2    | Scoring GeneralizingEstimator : 644/1225 [00:04&lt;00:03,  147.72it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 654/1225 [00:04&lt;00:03,  148.02it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 660/1225 [00:04&lt;00:03,  148.92it/s]
 55%|#####4    | Scoring GeneralizingEstimator : 668/1225 [00:04&lt;00:03,  147.18it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 676/1225 [00:04&lt;00:03,  150.22it/s]
 56%|#####5    | Scoring GeneralizingEstimator : 684/1225 [00:04&lt;00:03,  148.31it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 691/1225 [00:04&lt;00:03,  150.26it/s]
 57%|#####7    | Scoring GeneralizingEstimator : 701/1225 [00:04&lt;00:03,  150.39it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 710/1225 [00:04&lt;00:03,  154.35it/s]
 58%|#####8    | Scoring GeneralizingEstimator : 714/1225 [00:04&lt;00:03,  149.36it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 722/1225 [00:04&lt;00:03,  152.30it/s]
 59%|#####9    | Scoring GeneralizingEstimator : 728/1225 [00:04&lt;00:03,  146.50it/s]
 60%|######    | Scoring GeneralizingEstimator : 736/1225 [00:04&lt;00:03,  149.46it/s]
 61%|######    | Scoring GeneralizingEstimator : 746/1225 [00:04&lt;00:03,  150.28it/s]
 62%|######1   | Scoring GeneralizingEstimator : 756/1225 [00:04&lt;00:03,  155.24it/s]
 62%|######2   | Scoring GeneralizingEstimator : 762/1225 [00:04&lt;00:03,  151.61it/s]
 63%|######2   | Scoring GeneralizingEstimator : 770/1225 [00:05&lt;00:02,  154.42it/s]
 63%|######3   | Scoring GeneralizingEstimator : 776/1225 [00:05&lt;00:02,  150.60it/s]
 64%|######4   | Scoring GeneralizingEstimator : 785/1225 [00:05&lt;00:02,  154.55it/s]
 65%|######4   | Scoring GeneralizingEstimator : 793/1225 [00:05&lt;00:02,  152.06it/s]
 65%|######5   | Scoring GeneralizingEstimator : 801/1225 [00:05&lt;00:02,  154.48it/s]
 66%|######5   | Scoring GeneralizingEstimator : 806/1225 [00:05&lt;00:02,  148.57it/s]
 66%|######6   | Scoring GeneralizingEstimator : 814/1225 [00:05&lt;00:02,  151.43it/s]
 67%|######7   | Scoring GeneralizingEstimator : 822/1225 [00:05&lt;00:02,  149.56it/s]
 68%|######7   | Scoring GeneralizingEstimator : 831/1225 [00:05&lt;00:02,  153.49it/s]
 68%|######8   | Scoring GeneralizingEstimator : 836/1225 [00:05&lt;00:02,  149.01it/s]
 69%|######8   | Scoring GeneralizingEstimator : 845/1225 [00:05&lt;00:02,  152.96it/s]
 69%|######9   | Scoring GeneralizingEstimator : 848/1225 [00:05&lt;00:02,  145.35it/s]
 70%|######9   | Scoring GeneralizingEstimator : 857/1225 [00:05&lt;00:02,  149.45it/s]
 70%|#######   | Scoring GeneralizingEstimator : 859/1225 [00:05&lt;00:02,  142.77it/s]
 71%|#######   | Scoring GeneralizingEstimator : 867/1225 [00:05&lt;00:02,  145.96it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 874/1225 [00:05&lt;00:02,  142.21it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 882/1225 [00:05&lt;00:02,  145.40it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 888/1225 [00:05&lt;00:02,  142.37it/s]
 73%|#######2  | Scoring GeneralizingEstimator : 894/1225 [00:05&lt;00:02,  143.50it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 900/1225 [00:05&lt;00:02,  139.57it/s]
 74%|#######4  | Scoring GeneralizingEstimator : 909/1225 [00:06&lt;00:02,  143.82it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 916/1225 [00:06&lt;00:02,  142.51it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 923/1225 [00:06&lt;00:02,  144.64it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 933/1225 [00:06&lt;00:02,  144.57it/s]
 77%|#######6  | Scoring GeneralizingEstimator : 940/1225 [00:06&lt;00:01,  146.67it/s]
 78%|#######7  | Scoring GeneralizingEstimator : 951/1225 [00:06&lt;00:01,  147.98it/s]
 78%|#######8  | Scoring GeneralizingEstimator : 958/1225 [00:06&lt;00:01,  149.98it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 968/1225 [00:06&lt;00:01,  150.08it/s]
 80%|#######9  | Scoring GeneralizingEstimator : 976/1225 [00:06&lt;00:01,  152.99it/s]
 80%|########  | Scoring GeneralizingEstimator : 983/1225 [00:06&lt;00:01,  152.36it/s]
 81%|########  | Scoring GeneralizingEstimator : 988/1225 [00:06&lt;00:01,  151.84it/s]
 82%|########1 | Scoring GeneralizingEstimator : 999/1225 [00:06&lt;00:01,  151.33it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1007/1225 [00:06&lt;00:01,  154.22it/s]
 83%|########2 | Scoring GeneralizingEstimator : 1016/1225 [00:06&lt;00:01,  152.42it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1024/1225 [00:06&lt;00:01,  154.85it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1028/1225 [00:06&lt;00:01,  148.52it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1038/1225 [00:06&lt;00:01,  153.47it/s]
 85%|########5 | Scoring GeneralizingEstimator : 1042/1225 [00:06&lt;00:01,  148.01it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1050/1225 [00:06&lt;00:01,  150.93it/s]
 86%|########6 | Scoring GeneralizingEstimator : 1057/1225 [00:06&lt;00:01,  149.13it/s]
 87%|########6 | Scoring GeneralizingEstimator : 1064/1225 [00:07&lt;00:01,  151.08it/s]
 88%|########7 | Scoring GeneralizingEstimator : 1073/1225 [00:07&lt;00:01,  149.61it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1078/1225 [00:07&lt;00:00,  149.53it/s]
 89%|########8 | Scoring GeneralizingEstimator : 1088/1225 [00:07&lt;00:00,  148.50it/s]
 89%|########9 | Scoring GeneralizingEstimator : 1096/1225 [00:07&lt;00:00,  151.43it/s]
 90%|######### | Scoring GeneralizingEstimator : 1104/1225 [00:07&lt;00:00,  150.09it/s]
 91%|######### | Scoring GeneralizingEstimator : 1113/1225 [00:07&lt;00:00,  154.02it/s]
 91%|#########1| Scoring GeneralizingEstimator : 1120/1225 [00:07&lt;00:00,  150.29it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1129/1225 [00:07&lt;00:00,  153.85it/s]
 93%|#########2| Scoring GeneralizingEstimator : 1135/1225 [00:07&lt;00:00,  150.68it/s]
 93%|#########3| Scoring GeneralizingEstimator : 1142/1225 [00:07&lt;00:00,  152.56it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1150/1225 [00:07&lt;00:00,  151.12it/s]
 94%|#########4| Scoring GeneralizingEstimator : 1157/1225 [00:07&lt;00:00,  153.01it/s]
 95%|#########5| Scoring GeneralizingEstimator : 1167/1225 [00:07&lt;00:00,  152.30it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1173/1225 [00:07&lt;00:00,  153.13it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1179/1225 [00:07&lt;00:00,  147.89it/s]
 97%|#########6| Scoring GeneralizingEstimator : 1187/1225 [00:07&lt;00:00,  150.87it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1194/1225 [00:07&lt;00:00,  149.13it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1202/1225 [00:07&lt;00:00,  152.03it/s]
 99%|#########8| Scoring GeneralizingEstimator : 1208/1225 [00:07&lt;00:00,  148.07it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1216/1225 [00:08&lt;00:00,  151.07it/s]
100%|#########9| Scoring GeneralizingEstimator : 1223/1225 [00:08&lt;00:00,  147.53it/s]
100%|##########| Scoring GeneralizingEstimator : 1225/1225 [00:08&lt;00:00,  151.44it/s]
</pre></div>
</div>
<p>Plot</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.matshow.html#matplotlib.axes.Axes.matshow" title="matplotlib.axes.Axes.matshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">matshow</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span>
                <span class="n">extent</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs.times" title="mne.Epochs.times" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">epochs</span><span class="o">.</span><span class="n">times</span></a><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axis.XAxis.set_ticks_position.html#matplotlib.axis.XAxis.set_ticks_position" title="matplotlib.axis.XAxis.set_ticks_position" class="sphx-glr-backref-module-matplotlib-axis sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span></a><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Testing Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Generalization across time and condition&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html#matplotlib.pyplot.colorbar" title="matplotlib.pyplot.colorbar" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span></a><span class="p">(</span><a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="Generalization across time and condition" class="sphx-glr-single-img" src="../../_images/sphx_glr_decoding_time_generalization_conditions_001.png" />
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="kingdehaene2014"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jean-Rémi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. <em>Trends in Cognitive Sciences</em>, 18(4):203–210, 2014. <a class="reference external" href="https://doi.org/10.1016/j.tics.2014.01.002">doi:10.1016/j.tics.2014.01.002</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  17.296 seconds)</p>
<p><strong>Estimated memory usage:</strong>  129 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ab6282967a162922fd7405f0d8568e07/decoding_time_generalization_conditions.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">decoding_time_generalization_conditions.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/00e78bba5d10188fcf003ef05e32a6f7/decoding_time_generalization_conditions.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">decoding_time_generalization_conditions.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="decoding_spoc_CMC.html" title="previous page">Continuous Target Decoding with SPoC</a>
    <a class='right-next' id="next-link" href="decoding_unsupervised_spatial_filter.html" title="next page">Analysis of evoked response using ICA and PCA reduction techniques</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-05-02T14:37:51.196388+00:00" class="localized">2021-05-02 14:37 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>