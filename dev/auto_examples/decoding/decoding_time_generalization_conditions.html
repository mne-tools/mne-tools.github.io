
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Decoding sensor space data with generalization across time and conditions &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Analysis of evoked response using ICA and PCA reduction techniques" href="decoding_unsupervised_spatial_filter.html" />
    <link rel="prev" title="Continuous Target Decoding with SPoC" href="decoding_spoc_CMC.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/10_ieeg_localize.html">
     Locating Intracranial Electrode Contacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../auto_tutorials/simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/cwt_sensor_connectivity.html">
     Compute seed-based time-frequency connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mixed_source_space_connectivity.html">
     Compute mixed source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_coherence_epochs.html">
     Compute coherence in source space using a MNE inverse solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_connectivity_spectrum.html">
     Compute full spectrum source space connectivity between labels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation.html">
     Compute envelope correlations in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_envelope_correlation_volume.html">
     Compute envelope correlations in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_label_connectivity.html">
     Compute source space connectivity and visualize it using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/mne_inverse_psi_visual.html">
     Compute Phase Slope Index (PSI) in source space for a visual stimulus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/sensor_connectivity.html">
     Compute all-to-all connectivity in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="decoding-sensor-space-data-with-generalization-across-time-and-conditions">
<span id="sphx-glr-auto-examples-decoding-decoding-time-generalization-conditions-py"></span><h1>Decoding sensor space data with generalization across time and conditions<a class="headerlink" href="#decoding-sensor-space-data-with-generalization-across-time-and-conditions" title="Permalink to this headline">¶</a></h1>
<p>This example runs the analysis described in <a class="footnote-reference brackets" href="#kingdehaene2014" id="id1">1</a>. It
illustrates how one can
fit a linear classifier to identify a discriminatory topography at a given time
instant and subsequently assess whether this linear model can accurately
predict all of the time samples of a second set of conditions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Jean-Remi King &lt;jeanremi.king@gmail.com&gt;</span>
<span class="c1">#          Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="c1">#          Denis Engemann &lt;denis.engemann@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="kn">import</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a>

<span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># Preprocess data</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<span class="c1"># Load and filter data, set up epochs</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw.fif&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif&#39;</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a> <span class="o">=</span> <a href="../../generated/mne.pick_types.html#mne.pick_types" title="mne.pick_types" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">pick_types</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">meg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;bads&#39;</span><span class="p">)</span>  <span class="c1"># Pick MEG channels</span>
<a href="../../generated/mne.io.Raw.html#mne.io.Raw.filter" title="mne.io.Raw.filter" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">filter</span></a><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">30.</span><span class="p">,</span> <span class="n">fir_design</span><span class="o">=</span><span class="s1">&#39;firwin&#39;</span><span class="p">)</span>  <span class="c1"># Band pass filtering signals</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.read_events.html#mne.read_events" title="mne.read_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_events</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events_fname</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Auditory/Left&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Auditory/Right&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;Visual/Left&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;Visual/Right&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.050</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="mf">0.400</span>
<span class="c1"># decimate to make the example faster to run, but then use verbose=&#39;error&#39; in</span>
<span class="c1"># the Epochs constructor to suppress warning about decimation causing aliasing</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a> <span class="o">=</span> <span class="mi">2</span>
<a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><a href="../../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span>
                    <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="o">=</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">picks</span></a><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">mag</span><span class="o">=</span><span class="mf">5e-12</span><span class="p">),</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">decim</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
Reading 0 ... 41699  =      0.000 ...   277.709 secs...
Filtering raw data in 1 contiguous segment
Setting up band-pass filter from 1 - 30 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 1.00
- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)
- Upper passband edge: 30.00 Hz
- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)
- Filter length: 497 samples (3.310 sec)
</pre></div>
</div>
<p>We will train the classifier on all left visual vs auditory trials
and test on all right visual vs auditory trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="sklearn.pipeline.make_pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-function"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler" class="sphx-glr-backref-module-sklearn-preprocessing sphx-glr-backref-type-py-class"><span class="n">StandardScaler</span></a><span class="p">(),</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression" class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">time_gen</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-class"><span class="n">GeneralizingEstimator</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline" class="sphx-glr-backref-module-sklearn-pipeline sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">clf</span></a><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Fit classifiers on the epochs where the stimulus was presented to the left.</span>
<span class="c1"># Note that the experimental condition y indicates auditory or visual</span>
<a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.fit" title="mne.decoding.GeneralizingEstimator.fit" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
             <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Left&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Fitting GeneralizingEstimator : 0/35 [00:00&lt;?,       ?it/s]
  3%|2         | Fitting GeneralizingEstimator : 1/35 [00:00&lt;00:02,   14.07it/s]
  6%|5         | Fitting GeneralizingEstimator : 2/35 [00:00&lt;00:02,   11.60it/s]
  9%|8         | Fitting GeneralizingEstimator : 3/35 [00:00&lt;00:03,    8.75it/s]
 11%|#1        | Fitting GeneralizingEstimator : 4/35 [00:00&lt;00:03,    9.06it/s]
 14%|#4        | Fitting GeneralizingEstimator : 5/35 [00:00&lt;00:03,    9.25it/s]
 17%|#7        | Fitting GeneralizingEstimator : 6/35 [00:00&lt;00:03,    9.31it/s]
 20%|##        | Fitting GeneralizingEstimator : 7/35 [00:00&lt;00:03,    9.00it/s]
 23%|##2       | Fitting GeneralizingEstimator : 8/35 [00:00&lt;00:02,    9.14it/s]
 26%|##5       | Fitting GeneralizingEstimator : 9/35 [00:00&lt;00:02,    9.21it/s]
 29%|##8       | Fitting GeneralizingEstimator : 10/35 [00:01&lt;00:02,    9.34it/s]
 31%|###1      | Fitting GeneralizingEstimator : 11/35 [00:01&lt;00:02,    9.38it/s]
 34%|###4      | Fitting GeneralizingEstimator : 12/35 [00:01&lt;00:02,    9.82it/s]
 37%|###7      | Fitting GeneralizingEstimator : 13/35 [00:01&lt;00:02,   10.52it/s]
 40%|####      | Fitting GeneralizingEstimator : 14/35 [00:01&lt;00:02,   10.44it/s]
 43%|####2     | Fitting GeneralizingEstimator : 15/35 [00:01&lt;00:01,   10.30it/s]
 46%|####5     | Fitting GeneralizingEstimator : 16/35 [00:01&lt;00:01,   10.35it/s]
 49%|####8     | Fitting GeneralizingEstimator : 17/35 [00:01&lt;00:01,   10.95it/s]
 51%|#####1    | Fitting GeneralizingEstimator : 18/35 [00:01&lt;00:01,   11.26it/s]
 54%|#####4    | Fitting GeneralizingEstimator : 19/35 [00:01&lt;00:01,   11.16it/s]
 57%|#####7    | Fitting GeneralizingEstimator : 20/35 [00:01&lt;00:01,   11.04it/s]
 60%|######    | Fitting GeneralizingEstimator : 21/35 [00:01&lt;00:01,   10.95it/s]
 63%|######2   | Fitting GeneralizingEstimator : 22/35 [00:02&lt;00:01,   10.35it/s]
 66%|######5   | Fitting GeneralizingEstimator : 23/35 [00:02&lt;00:01,   10.83it/s]
 69%|######8   | Fitting GeneralizingEstimator : 24/35 [00:02&lt;00:01,   10.75it/s]
 71%|#######1  | Fitting GeneralizingEstimator : 25/35 [00:02&lt;00:00,   10.74it/s]
 74%|#######4  | Fitting GeneralizingEstimator : 26/35 [00:02&lt;00:00,   10.62it/s]
 77%|#######7  | Fitting GeneralizingEstimator : 27/35 [00:02&lt;00:00,   10.64it/s]
 80%|########  | Fitting GeneralizingEstimator : 28/35 [00:02&lt;00:00,   10.60it/s]
 83%|########2 | Fitting GeneralizingEstimator : 29/35 [00:02&lt;00:00,   10.56it/s]
 86%|########5 | Fitting GeneralizingEstimator : 30/35 [00:02&lt;00:00,   10.49it/s]
 89%|########8 | Fitting GeneralizingEstimator : 31/35 [00:02&lt;00:00,   10.47it/s]
 91%|#########1| Fitting GeneralizingEstimator : 32/35 [00:03&lt;00:00,   10.41it/s]
 94%|#########4| Fitting GeneralizingEstimator : 33/35 [00:03&lt;00:00,   10.42it/s]
 97%|#########7| Fitting GeneralizingEstimator : 34/35 [00:03&lt;00:00,   10.40it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:03&lt;00:00,   10.46it/s]
100%|##########| Fitting GeneralizingEstimator : 35/35 [00:03&lt;00:00,   10.42it/s]
</pre></div>
</div>
<p>Score on the epochs where the stimulus was presented to the right.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator.score" title="mne.decoding.GeneralizingEstimator.score" class="sphx-glr-backref-module-mne-decoding sphx-glr-backref-type-py-method"><span class="n">time_gen</span><span class="o">.</span><span class="n">score</span></a><span class="p">(</span><span class="n">X</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span>
                        <span class="n">y</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">[</span><span class="s1">&#39;Right&#39;</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | Scoring GeneralizingEstimator : 0/1225 [00:00&lt;?,       ?it/s]
  0%|          | Scoring GeneralizingEstimator : 2/1225 [00:00&lt;00:21,   56.06it/s]
  1%|          | Scoring GeneralizingEstimator : 7/1225 [00:00&lt;00:17,   71.03it/s]
  1%|1         | Scoring GeneralizingEstimator : 13/1225 [00:00&lt;00:12,   98.88it/s]
  1%|1         | Scoring GeneralizingEstimator : 15/1225 [00:00&lt;00:16,   75.04it/s]
  2%|1         | Scoring GeneralizingEstimator : 21/1225 [00:00&lt;00:13,   91.02it/s]
  2%|1         | Scoring GeneralizingEstimator : 23/1225 [00:00&lt;00:15,   76.19it/s]
  2%|2         | Scoring GeneralizingEstimator : 29/1225 [00:00&lt;00:13,   87.91it/s]
  3%|2         | Scoring GeneralizingEstimator : 31/1225 [00:00&lt;00:15,   76.75it/s]
  3%|3         | Scoring GeneralizingEstimator : 37/1225 [00:00&lt;00:13,   86.16it/s]
  3%|3         | Scoring GeneralizingEstimator : 39/1225 [00:00&lt;00:14,   83.48it/s]
  3%|3         | Scoring GeneralizingEstimator : 40/1225 [00:00&lt;00:15,   78.65it/s]
  4%|3         | Scoring GeneralizingEstimator : 46/1225 [00:00&lt;00:13,   86.81it/s]
  4%|3         | Scoring GeneralizingEstimator : 47/1225 [00:00&lt;00:14,   81.98it/s]
  4%|4         | Scoring GeneralizingEstimator : 49/1225 [00:00&lt;00:14,   79.87it/s]
  4%|4         | Scoring GeneralizingEstimator : 54/1225 [00:00&lt;00:13,   84.73it/s]
  4%|4         | Scoring GeneralizingEstimator : 55/1225 [00:00&lt;00:15,   77.00it/s]
  5%|4         | Scoring GeneralizingEstimator : 61/1225 [00:00&lt;00:13,   83.81it/s]
  5%|5         | Scoring GeneralizingEstimator : 63/1225 [00:00&lt;00:15,   77.30it/s]
  6%|5         | Scoring GeneralizingEstimator : 69/1225 [00:00&lt;00:13,   83.34it/s]
  6%|5         | Scoring GeneralizingEstimator : 71/1225 [00:00&lt;00:14,   81.74it/s]
  6%|5         | Scoring GeneralizingEstimator : 72/1225 [00:00&lt;00:14,   78.45it/s]
  6%|6         | Scoring GeneralizingEstimator : 78/1225 [00:00&lt;00:13,   84.17it/s]
  6%|6         | Scoring GeneralizingEstimator : 79/1225 [00:00&lt;00:14,   77.26it/s]
  7%|6         | Scoring GeneralizingEstimator : 85/1225 [00:01&lt;00:13,   82.81it/s]
  7%|7         | Scoring GeneralizingEstimator : 87/1225 [00:01&lt;00:14,   77.44it/s]
  8%|7         | Scoring GeneralizingEstimator : 93/1225 [00:01&lt;00:13,   82.65it/s]
  8%|7         | Scoring GeneralizingEstimator : 95/1225 [00:01&lt;00:14,   77.67it/s]
  8%|8         | Scoring GeneralizingEstimator : 100/1225 [00:01&lt;00:13,   81.11it/s]
  8%|8         | Scoring GeneralizingEstimator : 103/1225 [00:01&lt;00:14,   77.68it/s]
  9%|8         | Scoring GeneralizingEstimator : 107/1225 [00:01&lt;00:14,   79.35it/s]
  9%|8         | Scoring GeneralizingEstimator : 109/1225 [00:01&lt;00:14,   75.04it/s]
  9%|9         | Scoring GeneralizingEstimator : 115/1225 [00:01&lt;00:13,   79.70it/s]
 10%|9         | Scoring GeneralizingEstimator : 117/1225 [00:01&lt;00:14,   75.63it/s]
 10%|9         | Scoring GeneralizingEstimator : 122/1225 [00:01&lt;00:14,   78.50it/s]
 10%|#         | Scoring GeneralizingEstimator : 124/1225 [00:01&lt;00:14,   74.90it/s]
 11%|#         | Scoring GeneralizingEstimator : 129/1225 [00:01&lt;00:14,   77.99it/s]
 11%|#         | Scoring GeneralizingEstimator : 132/1225 [00:01&lt;00:14,   75.36it/s]
 11%|#1        | Scoring GeneralizingEstimator : 136/1225 [00:01&lt;00:14,   77.05it/s]
 11%|#1        | Scoring GeneralizingEstimator : 138/1225 [00:01&lt;00:14,   73.39it/s]
 12%|#1        | Scoring GeneralizingEstimator : 144/1225 [00:01&lt;00:13,   77.61it/s]
 12%|#1        | Scoring GeneralizingEstimator : 145/1225 [00:01&lt;00:14,   72.81it/s]
 12%|#2        | Scoring GeneralizingEstimator : 151/1225 [00:01&lt;00:13,   76.96it/s]
 12%|#2        | Scoring GeneralizingEstimator : 153/1225 [00:01&lt;00:14,   73.44it/s]
 13%|#2        | Scoring GeneralizingEstimator : 159/1225 [00:02&lt;00:13,   77.47it/s]
 13%|#3        | Scoring GeneralizingEstimator : 161/1225 [00:02&lt;00:13,   76.67it/s]
 14%|#3        | Scoring GeneralizingEstimator : 167/1225 [00:02&lt;00:13,   77.46it/s]
 14%|#3        | Scoring GeneralizingEstimator : 169/1225 [00:02&lt;00:14,   74.36it/s]
 14%|#4        | Scoring GeneralizingEstimator : 175/1225 [00:02&lt;00:13,   78.23it/s]
 14%|#4        | Scoring GeneralizingEstimator : 177/1225 [00:02&lt;00:14,   74.70it/s]
 15%|#4        | Scoring GeneralizingEstimator : 183/1225 [00:02&lt;00:13,   78.53it/s]
 15%|#5        | Scoring GeneralizingEstimator : 185/1225 [00:02&lt;00:13,   75.19it/s]
 16%|#5        | Scoring GeneralizingEstimator : 191/1225 [00:02&lt;00:13,   78.87it/s]
 16%|#5        | Scoring GeneralizingEstimator : 193/1225 [00:02&lt;00:13,   78.05it/s]
 16%|#5        | Scoring GeneralizingEstimator : 194/1225 [00:02&lt;00:13,   76.12it/s]
 16%|#6        | Scoring GeneralizingEstimator : 199/1225 [00:02&lt;00:13,   78.79it/s]
 16%|#6        | Scoring GeneralizingEstimator : 200/1225 [00:02&lt;00:13,   74.64it/s]
 17%|#6        | Scoring GeneralizingEstimator : 205/1225 [00:02&lt;00:13,   77.36it/s]
 17%|#6        | Scoring GeneralizingEstimator : 208/1225 [00:02&lt;00:13,   77.73it/s]
 17%|#7        | Scoring GeneralizingEstimator : 209/1225 [00:02&lt;00:13,   75.69it/s]
 17%|#7        | Scoring GeneralizingEstimator : 214/1225 [00:02&lt;00:12,   78.31it/s]
 18%|#7        | Scoring GeneralizingEstimator : 215/1225 [00:02&lt;00:13,   74.17it/s]
 18%|#8        | Scoring GeneralizingEstimator : 221/1225 [00:02&lt;00:12,   78.08it/s]
 18%|#8        | Scoring GeneralizingEstimator : 223/1225 [00:02&lt;00:13,   74.63it/s]
 19%|#8        | Scoring GeneralizingEstimator : 229/1225 [00:02&lt;00:12,   78.53it/s]
 19%|#8        | Scoring GeneralizingEstimator : 231/1225 [00:02&lt;00:13,   75.06it/s]
 19%|#9        | Scoring GeneralizingEstimator : 237/1225 [00:03&lt;00:12,   78.92it/s]
 20%|#9        | Scoring GeneralizingEstimator : 239/1225 [00:03&lt;00:12,   78.05it/s]
 20%|#9        | Scoring GeneralizingEstimator : 240/1225 [00:03&lt;00:12,   76.09it/s]
 20%|##        | Scoring GeneralizingEstimator : 246/1225 [00:03&lt;00:12,   79.95it/s]
 20%|##        | Scoring GeneralizingEstimator : 247/1225 [00:03&lt;00:12,   75.57it/s]
 21%|##        | Scoring GeneralizingEstimator : 253/1225 [00:03&lt;00:12,   79.49it/s]
 21%|##        | Scoring GeneralizingEstimator : 255/1225 [00:03&lt;00:12,   78.62it/s]
 21%|##1       | Scoring GeneralizingEstimator : 261/1225 [00:03&lt;00:12,   79.30it/s]
 21%|##1       | Scoring GeneralizingEstimator : 263/1225 [00:03&lt;00:12,   75.95it/s]
 22%|##1       | Scoring GeneralizingEstimator : 269/1225 [00:03&lt;00:11,   79.67it/s]
 22%|##2       | Scoring GeneralizingEstimator : 271/1225 [00:03&lt;00:12,   76.31it/s]
 23%|##2       | Scoring GeneralizingEstimator : 276/1225 [00:03&lt;00:12,   78.72it/s]
 23%|##2       | Scoring GeneralizingEstimator : 279/1225 [00:03&lt;00:12,   76.61it/s]
 23%|##3       | Scoring GeneralizingEstimator : 285/1225 [00:03&lt;00:11,   80.28it/s]
 23%|##3       | Scoring GeneralizingEstimator : 287/1225 [00:03&lt;00:12,   76.79it/s]
 24%|##3       | Scoring GeneralizingEstimator : 293/1225 [00:03&lt;00:11,   80.45it/s]
 24%|##4       | Scoring GeneralizingEstimator : 296/1225 [00:03&lt;00:11,   78.00it/s]
 25%|##4       | Scoring GeneralizingEstimator : 301/1225 [00:03&lt;00:11,   80.42it/s]
 25%|##4       | Scoring GeneralizingEstimator : 303/1225 [00:03&lt;00:11,   77.02it/s]
 25%|##5       | Scoring GeneralizingEstimator : 309/1225 [00:03&lt;00:11,   80.61it/s]
 25%|##5       | Scoring GeneralizingEstimator : 311/1225 [00:03&lt;00:11,   79.74it/s]
 26%|##5       | Scoring GeneralizingEstimator : 317/1225 [00:04&lt;00:11,   80.09it/s]
 26%|##5       | Scoring GeneralizingEstimator : 318/1225 [00:04&lt;00:11,   76.18it/s]
 26%|##6       | Scoring GeneralizingEstimator : 324/1225 [00:04&lt;00:11,   79.76it/s]
 27%|##6       | Scoring GeneralizingEstimator : 327/1225 [00:04&lt;00:11,   77.46it/s]
 27%|##7       | Scoring GeneralizingEstimator : 332/1225 [00:04&lt;00:11,   79.89it/s]
 27%|##7       | Scoring GeneralizingEstimator : 334/1225 [00:04&lt;00:11,   76.54it/s]
 28%|##7       | Scoring GeneralizingEstimator : 340/1225 [00:04&lt;00:11,   80.07it/s]
 28%|##7       | Scoring GeneralizingEstimator : 342/1225 [00:04&lt;00:11,   79.26it/s]
 28%|##8       | Scoring GeneralizingEstimator : 348/1225 [00:04&lt;00:10,   79.84it/s]
 28%|##8       | Scoring GeneralizingEstimator : 349/1225 [00:04&lt;00:11,   75.77it/s]
 29%|##8       | Scoring GeneralizingEstimator : 355/1225 [00:04&lt;00:10,   79.27it/s]
 29%|##9       | Scoring GeneralizingEstimator : 357/1225 [00:04&lt;00:11,   78.44it/s]
 29%|##9       | Scoring GeneralizingEstimator : 358/1225 [00:04&lt;00:11,   76.62it/s]
 30%|##9       | Scoring GeneralizingEstimator : 364/1225 [00:04&lt;00:11,   75.22it/s]
 30%|###       | Scoring GeneralizingEstimator : 369/1225 [00:04&lt;00:11,   77.67it/s]
 30%|###       | Scoring GeneralizingEstimator : 371/1225 [00:04&lt;00:11,   74.64it/s]
 31%|###       | Scoring GeneralizingEstimator : 377/1225 [00:04&lt;00:10,   78.17it/s]
 31%|###       | Scoring GeneralizingEstimator : 379/1225 [00:04&lt;00:11,   74.98it/s]
 31%|###1      | Scoring GeneralizingEstimator : 384/1225 [00:04&lt;00:10,   77.44it/s]
 32%|###1      | Scoring GeneralizingEstimator : 388/1225 [00:05&lt;00:10,   76.17it/s]
 32%|###2      | Scoring GeneralizingEstimator : 394/1225 [00:05&lt;00:10,   79.62it/s]
 32%|###2      | Scoring GeneralizingEstimator : 396/1225 [00:05&lt;00:10,   76.52it/s]
 33%|###2      | Scoring GeneralizingEstimator : 401/1225 [00:05&lt;00:10,   78.91it/s]
 33%|###2      | Scoring GeneralizingEstimator : 404/1225 [00:05&lt;00:10,   76.86it/s]
 33%|###3      | Scoring GeneralizingEstimator : 409/1225 [00:05&lt;00:10,   79.20it/s]
 34%|###3      | Scoring GeneralizingEstimator : 411/1225 [00:05&lt;00:10,   76.06it/s]
 34%|###4      | Scoring GeneralizingEstimator : 417/1225 [00:05&lt;00:10,   79.50it/s]
 34%|###4      | Scoring GeneralizingEstimator : 419/1225 [00:05&lt;00:10,   78.69it/s]
 35%|###4      | Scoring GeneralizingEstimator : 425/1225 [00:05&lt;00:10,   79.57it/s]
 35%|###4      | Scoring GeneralizingEstimator : 427/1225 [00:05&lt;00:10,   76.39it/s]
 35%|###5      | Scoring GeneralizingEstimator : 433/1225 [00:05&lt;00:09,   79.80it/s]
 36%|###5      | Scoring GeneralizingEstimator : 435/1225 [00:05&lt;00:10,   76.55it/s]
 36%|###5      | Scoring GeneralizingEstimator : 440/1225 [00:05&lt;00:09,   78.80it/s]
 36%|###6      | Scoring GeneralizingEstimator : 442/1225 [00:05&lt;00:10,   75.71it/s]
 36%|###6      | Scoring GeneralizingEstimator : 446/1225 [00:05&lt;00:10,   77.10it/s]
 37%|###6      | Scoring GeneralizingEstimator : 448/1225 [00:05&lt;00:10,   74.12it/s]
 37%|###7      | Scoring GeneralizingEstimator : 454/1225 [00:05&lt;00:09,   77.60it/s]
 37%|###7      | Scoring GeneralizingEstimator : 456/1225 [00:05&lt;00:10,   74.59it/s]
 38%|###7      | Scoring GeneralizingEstimator : 462/1225 [00:05&lt;00:09,   78.06it/s]
 38%|###7      | Scoring GeneralizingEstimator : 464/1225 [00:05&lt;00:10,   74.96it/s]
 38%|###8      | Scoring GeneralizingEstimator : 470/1225 [00:06&lt;00:09,   78.38it/s]
 39%|###8      | Scoring GeneralizingEstimator : 472/1225 [00:06&lt;00:10,   75.27it/s]
 39%|###9      | Scoring GeneralizingEstimator : 478/1225 [00:06&lt;00:09,   78.69it/s]
 39%|###9      | Scoring GeneralizingEstimator : 480/1225 [00:06&lt;00:09,   77.93it/s]
 40%|###9      | Scoring GeneralizingEstimator : 486/1225 [00:06&lt;00:09,   78.55it/s]
 40%|###9      | Scoring GeneralizingEstimator : 487/1225 [00:06&lt;00:09,   74.59it/s]
 40%|####      | Scoring GeneralizingEstimator : 493/1225 [00:06&lt;00:09,   78.05it/s]
 40%|####      | Scoring GeneralizingEstimator : 494/1225 [00:06&lt;00:09,   74.14it/s]
 41%|####      | Scoring GeneralizingEstimator : 500/1225 [00:06&lt;00:09,   77.56it/s]
 41%|####1     | Scoring GeneralizingEstimator : 503/1225 [00:06&lt;00:09,   75.56it/s]
 41%|####1     | Scoring GeneralizingEstimator : 508/1225 [00:06&lt;00:09,   77.95it/s]
 42%|####1     | Scoring GeneralizingEstimator : 510/1225 [00:06&lt;00:09,   74.76it/s]
 42%|####2     | Scoring GeneralizingEstimator : 516/1225 [00:06&lt;00:09,   78.15it/s]
 42%|####2     | Scoring GeneralizingEstimator : 518/1225 [00:06&lt;00:09,   75.23it/s]
 43%|####2     | Scoring GeneralizingEstimator : 524/1225 [00:06&lt;00:08,   78.68it/s]
 43%|####2     | Scoring GeneralizingEstimator : 525/1225 [00:06&lt;00:09,   74.35it/s]
 43%|####3     | Scoring GeneralizingEstimator : 531/1225 [00:06&lt;00:08,   77.80it/s]
 44%|####3     | Scoring GeneralizingEstimator : 533/1225 [00:06&lt;00:09,   74.95it/s]
 44%|####4     | Scoring GeneralizingEstimator : 539/1225 [00:06&lt;00:08,   78.38it/s]
 44%|####4     | Scoring GeneralizingEstimator : 541/1225 [00:06&lt;00:09,   75.25it/s]
 45%|####4     | Scoring GeneralizingEstimator : 546/1225 [00:07&lt;00:08,   77.60it/s]
 45%|####4     | Scoring GeneralizingEstimator : 548/1225 [00:07&lt;00:09,   74.66it/s]
 45%|####5     | Scoring GeneralizingEstimator : 554/1225 [00:07&lt;00:08,   78.13it/s]
 45%|####5     | Scoring GeneralizingEstimator : 556/1225 [00:07&lt;00:08,   74.83it/s]
 46%|####5     | Scoring GeneralizingEstimator : 562/1225 [00:07&lt;00:08,   78.00it/s]
 46%|####6     | Scoring GeneralizingEstimator : 564/1225 [00:07&lt;00:08,   77.29it/s]
 46%|####6     | Scoring GeneralizingEstimator : 569/1225 [00:07&lt;00:08,   77.71it/s]
 47%|####6     | Scoring GeneralizingEstimator : 571/1225 [00:07&lt;00:08,   74.60it/s]
 47%|####7     | Scoring GeneralizingEstimator : 577/1225 [00:07&lt;00:08,   78.02it/s]
 47%|####7     | Scoring GeneralizingEstimator : 579/1225 [00:07&lt;00:08,   74.99it/s]
 48%|####7     | Scoring GeneralizingEstimator : 585/1225 [00:07&lt;00:08,   78.31it/s]
 48%|####7     | Scoring GeneralizingEstimator : 587/1225 [00:07&lt;00:08,   75.31it/s]
 48%|####8     | Scoring GeneralizingEstimator : 593/1225 [00:07&lt;00:08,   78.75it/s]
 49%|####8     | Scoring GeneralizingEstimator : 595/1225 [00:07&lt;00:08,   75.60it/s]
 49%|####9     | Scoring GeneralizingEstimator : 601/1225 [00:07&lt;00:07,   79.02it/s]
 49%|####9     | Scoring GeneralizingEstimator : 603/1225 [00:07&lt;00:07,   78.26it/s]
 50%|####9     | Scoring GeneralizingEstimator : 609/1225 [00:07&lt;00:07,   78.85it/s]
 50%|####9     | Scoring GeneralizingEstimator : 611/1225 [00:07&lt;00:08,   76.03it/s]
 50%|#####     | Scoring GeneralizingEstimator : 616/1225 [00:07&lt;00:07,   78.26it/s]
 50%|#####     | Scoring GeneralizingEstimator : 618/1225 [00:07&lt;00:08,   75.27it/s]
 51%|#####     | Scoring GeneralizingEstimator : 623/1225 [00:08&lt;00:07,   77.65it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 625/1225 [00:08&lt;00:08,   74.64it/s]
 51%|#####1    | Scoring GeneralizingEstimator : 630/1225 [00:08&lt;00:07,   77.01it/s]
 52%|#####1    | Scoring GeneralizingEstimator : 632/1225 [00:08&lt;00:07,   74.14it/s]
 52%|#####2    | Scoring GeneralizingEstimator : 638/1225 [00:08&lt;00:07,   77.60it/s]
 52%|#####2    | Scoring GeneralizingEstimator : 640/1225 [00:08&lt;00:07,   73.96it/s]
 53%|#####2    | Scoring GeneralizingEstimator : 646/1225 [00:08&lt;00:07,   77.30it/s]
 53%|#####2    | Scoring GeneralizingEstimator : 647/1225 [00:08&lt;00:07,   73.90it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 653/1225 [00:08&lt;00:07,   77.38it/s]
 53%|#####3    | Scoring GeneralizingEstimator : 655/1225 [00:08&lt;00:07,   74.38it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 659/1225 [00:08&lt;00:07,   75.78it/s]
 54%|#####3    | Scoring GeneralizingEstimator : 661/1225 [00:08&lt;00:07,   72.90it/s]
 54%|#####4    | Scoring GeneralizingEstimator : 666/1225 [00:08&lt;00:07,   75.39it/s]
 55%|#####4    | Scoring GeneralizingEstimator : 668/1225 [00:08&lt;00:07,   72.44it/s]
 55%|#####4    | Scoring GeneralizingEstimator : 672/1225 [00:08&lt;00:07,   73.95it/s]
 55%|#####5    | Scoring GeneralizingEstimator : 674/1225 [00:08&lt;00:07,   71.10it/s]
 56%|#####5    | Scoring GeneralizingEstimator : 680/1225 [00:08&lt;00:07,   74.64it/s]
 56%|#####5    | Scoring GeneralizingEstimator : 682/1225 [00:08&lt;00:07,   71.64it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 688/1225 [00:08&lt;00:07,   75.14it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 690/1225 [00:08&lt;00:07,   74.54it/s]
 56%|#####6    | Scoring GeneralizingEstimator : 691/1225 [00:09&lt;00:07,   72.89it/s]
 57%|#####6    | Scoring GeneralizingEstimator : 697/1225 [00:09&lt;00:06,   76.47it/s]
 57%|#####6    | Scoring GeneralizingEstimator : 698/1225 [00:09&lt;00:07,   73.03it/s]
 57%|#####7    | Scoring GeneralizingEstimator : 704/1225 [00:09&lt;00:06,   76.59it/s]
 58%|#####7    | Scoring GeneralizingEstimator : 705/1225 [00:09&lt;00:07,   72.55it/s]
 58%|#####8    | Scoring GeneralizingEstimator : 711/1225 [00:09&lt;00:06,   76.19it/s]
 58%|#####8    | Scoring GeneralizingEstimator : 713/1225 [00:09&lt;00:06,   73.16it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 719/1225 [00:09&lt;00:06,   76.80it/s]
 59%|#####8    | Scoring GeneralizingEstimator : 721/1225 [00:09&lt;00:06,   73.50it/s]
 59%|#####9    | Scoring GeneralizingEstimator : 727/1225 [00:09&lt;00:06,   77.11it/s]
 60%|#####9    | Scoring GeneralizingEstimator : 729/1225 [00:09&lt;00:06,   74.13it/s]
 60%|######    | Scoring GeneralizingEstimator : 735/1225 [00:09&lt;00:06,   77.69it/s]
 60%|######    | Scoring GeneralizingEstimator : 737/1225 [00:09&lt;00:06,   76.97it/s]
 60%|######    | Scoring GeneralizingEstimator : 738/1225 [00:09&lt;00:06,   75.15it/s]
 61%|######    | Scoring GeneralizingEstimator : 743/1225 [00:09&lt;00:06,   77.73it/s]
 61%|######    | Scoring GeneralizingEstimator : 745/1225 [00:09&lt;00:06,   74.86it/s]
 61%|######1   | Scoring GeneralizingEstimator : 751/1225 [00:09&lt;00:06,   78.54it/s]
 61%|######1   | Scoring GeneralizingEstimator : 753/1225 [00:09&lt;00:06,   75.23it/s]
 62%|######1   | Scoring GeneralizingEstimator : 759/1225 [00:09&lt;00:05,   78.82it/s]
 62%|######2   | Scoring GeneralizingEstimator : 761/1225 [00:09&lt;00:05,   78.03it/s]
 62%|######2   | Scoring GeneralizingEstimator : 762/1225 [00:09&lt;00:06,   76.15it/s]
 63%|######2   | Scoring GeneralizingEstimator : 767/1225 [00:09&lt;00:05,   78.78it/s]
 63%|######2   | Scoring GeneralizingEstimator : 769/1225 [00:09&lt;00:05,   77.96it/s]
 63%|######2   | Scoring GeneralizingEstimator : 770/1225 [00:10&lt;00:05,   76.01it/s]
 63%|######3   | Scoring GeneralizingEstimator : 776/1225 [00:10&lt;00:05,   79.86it/s]
 64%|######3   | Scoring GeneralizingEstimator : 782/1225 [00:10&lt;00:05,   78.50it/s]
 64%|######4   | Scoring GeneralizingEstimator : 784/1225 [00:10&lt;00:05,   75.13it/s]
 64%|######4   | Scoring GeneralizingEstimator : 789/1225 [00:10&lt;00:05,   77.73it/s]
 65%|######4   | Scoring GeneralizingEstimator : 791/1225 [00:10&lt;00:05,   74.45it/s]
 65%|######5   | Scoring GeneralizingEstimator : 797/1225 [00:10&lt;00:05,   78.14it/s]
 65%|######5   | Scoring GeneralizingEstimator : 799/1225 [00:10&lt;00:05,   74.85it/s]
 66%|######5   | Scoring GeneralizingEstimator : 805/1225 [00:10&lt;00:05,   78.50it/s]
 66%|######5   | Scoring GeneralizingEstimator : 807/1225 [00:10&lt;00:05,   75.23it/s]
 66%|######6   | Scoring GeneralizingEstimator : 813/1225 [00:10&lt;00:05,   78.83it/s]
 67%|######6   | Scoring GeneralizingEstimator : 815/1225 [00:10&lt;00:05,   78.05it/s]
 67%|######7   | Scoring GeneralizingEstimator : 821/1225 [00:10&lt;00:05,   78.40it/s]
 67%|######7   | Scoring GeneralizingEstimator : 823/1225 [00:10&lt;00:05,   75.70it/s]
 68%|######7   | Scoring GeneralizingEstimator : 829/1225 [00:10&lt;00:04,   79.25it/s]
 68%|######7   | Scoring GeneralizingEstimator : 831/1225 [00:10&lt;00:05,   76.04it/s]
 68%|######8   | Scoring GeneralizingEstimator : 836/1225 [00:10&lt;00:04,   78.41it/s]
 68%|######8   | Scoring GeneralizingEstimator : 838/1225 [00:10&lt;00:05,   75.27it/s]
 69%|######8   | Scoring GeneralizingEstimator : 844/1225 [00:10&lt;00:04,   78.82it/s]
 69%|######9   | Scoring GeneralizingEstimator : 846/1225 [00:10&lt;00:05,   75.61it/s]
 70%|######9   | Scoring GeneralizingEstimator : 852/1225 [00:11&lt;00:04,   79.13it/s]
 70%|######9   | Scoring GeneralizingEstimator : 854/1225 [00:11&lt;00:04,   75.77it/s]
 70%|#######   | Scoring GeneralizingEstimator : 860/1225 [00:11&lt;00:04,   79.25it/s]
 70%|#######   | Scoring GeneralizingEstimator : 862/1225 [00:11&lt;00:04,   76.14it/s]
 71%|#######   | Scoring GeneralizingEstimator : 868/1225 [00:11&lt;00:04,   79.61it/s]
 71%|#######1  | Scoring GeneralizingEstimator : 870/1225 [00:11&lt;00:04,   76.37it/s]
 72%|#######1  | Scoring GeneralizingEstimator : 876/1225 [00:11&lt;00:04,   79.84it/s]
 72%|#######1  | Scoring GeneralizingEstimator : 878/1225 [00:11&lt;00:04,   76.54it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 884/1225 [00:11&lt;00:04,   79.91it/s]
 72%|#######2  | Scoring GeneralizingEstimator : 886/1225 [00:11&lt;00:04,   76.76it/s]
 73%|#######2  | Scoring GeneralizingEstimator : 892/1225 [00:11&lt;00:04,   80.17it/s]
 73%|#######2  | Scoring GeneralizingEstimator : 894/1225 [00:11&lt;00:04,   79.35it/s]
 73%|#######3  | Scoring GeneralizingEstimator : 900/1225 [00:11&lt;00:04,   79.87it/s]
 74%|#######3  | Scoring GeneralizingEstimator : 902/1225 [00:11&lt;00:04,   76.98it/s]
 74%|#######4  | Scoring GeneralizingEstimator : 908/1225 [00:11&lt;00:03,   80.41it/s]
 74%|#######4  | Scoring GeneralizingEstimator : 910/1225 [00:11&lt;00:04,   77.07it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 916/1225 [00:11&lt;00:03,   80.49it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 917/1225 [00:11&lt;00:03,   78.65it/s]
 75%|#######4  | Scoring GeneralizingEstimator : 918/1225 [00:11&lt;00:03,   76.83it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 922/1225 [00:11&lt;00:03,   78.27it/s]
 75%|#######5  | Scoring GeneralizingEstimator : 924/1225 [00:11&lt;00:03,   75.30it/s]
 76%|#######5  | Scoring GeneralizingEstimator : 929/1225 [00:12&lt;00:03,   77.63it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 931/1225 [00:12&lt;00:03,   74.54it/s]
 76%|#######6  | Scoring GeneralizingEstimator : 937/1225 [00:12&lt;00:03,   78.11it/s]
 77%|#######6  | Scoring GeneralizingEstimator : 939/1225 [00:12&lt;00:03,   74.51it/s]
 77%|#######7  | Scoring GeneralizingEstimator : 946/1225 [00:12&lt;00:03,   78.89it/s]
 78%|#######7  | Scoring GeneralizingEstimator : 952/1225 [00:12&lt;00:03,   77.81it/s]
 78%|#######7  | Scoring GeneralizingEstimator : 954/1225 [00:12&lt;00:03,   74.72it/s]
 78%|#######8  | Scoring GeneralizingEstimator : 960/1225 [00:12&lt;00:03,   78.14it/s]
 79%|#######8  | Scoring GeneralizingEstimator : 962/1225 [00:12&lt;00:03,   75.04it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 968/1225 [00:12&lt;00:03,   78.44it/s]
 79%|#######9  | Scoring GeneralizingEstimator : 969/1225 [00:12&lt;00:03,   74.43it/s]
 80%|#######9  | Scoring GeneralizingEstimator : 975/1225 [00:12&lt;00:03,   77.86it/s]
 80%|#######9  | Scoring GeneralizingEstimator : 977/1225 [00:12&lt;00:03,   74.80it/s]
 80%|########  | Scoring GeneralizingEstimator : 982/1225 [00:12&lt;00:03,   77.19it/s]
 80%|########  | Scoring GeneralizingEstimator : 984/1225 [00:12&lt;00:03,   74.19it/s]
 81%|########  | Scoring GeneralizingEstimator : 990/1225 [00:12&lt;00:03,   77.63it/s]
 81%|########  | Scoring GeneralizingEstimator : 992/1225 [00:12&lt;00:03,   74.58it/s]
 81%|########1 | Scoring GeneralizingEstimator : 998/1225 [00:12&lt;00:02,   78.02it/s]
 82%|########1 | Scoring GeneralizingEstimator : 1000/1225 [00:12&lt;00:03,   74.95it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1006/1225 [00:13&lt;00:02,   78.25it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1008/1225 [00:13&lt;00:02,   77.42it/s]
 82%|########2 | Scoring GeneralizingEstimator : 1009/1225 [00:13&lt;00:02,   75.64it/s]
 83%|########2 | Scoring GeneralizingEstimator : 1015/1225 [00:13&lt;00:02,   79.03it/s]
 83%|########3 | Scoring GeneralizingEstimator : 1021/1225 [00:13&lt;00:02,   77.40it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1023/1225 [00:13&lt;00:02,   76.70it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1024/1225 [00:13&lt;00:02,   74.95it/s]
 84%|########3 | Scoring GeneralizingEstimator : 1028/1225 [00:13&lt;00:02,   76.21it/s]
 84%|########4 | Scoring GeneralizingEstimator : 1030/1225 [00:13&lt;00:02,   73.98it/s]
 84%|########4 | Scoring GeneralizingEstimator : 1033/1225 [00:13&lt;00:02,   74.38it/s]
 85%|########4 | Scoring GeneralizingEstimator : 1036/1225 [00:13&lt;00:02,   72.29it/s]
 85%|########5 | Scoring GeneralizingEstimator : 1043/1225 [00:13&lt;00:02,   76.97it/s]
 85%|########5 | Scoring GeneralizingEstimator : 1044/1225 [00:13&lt;00:02,   73.44it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1049/1225 [00:13&lt;00:02,   75.96it/s]
 86%|########5 | Scoring GeneralizingEstimator : 1052/1225 [00:13&lt;00:02,   73.98it/s]
 86%|########6 | Scoring GeneralizingEstimator : 1058/1225 [00:13&lt;00:02,   77.57it/s]
 87%|########6 | Scoring GeneralizingEstimator : 1060/1225 [00:13&lt;00:02,   74.45it/s]
 87%|########7 | Scoring GeneralizingEstimator : 1066/1225 [00:13&lt;00:02,   77.99it/s]
 87%|########7 | Scoring GeneralizingEstimator : 1068/1225 [00:13&lt;00:02,   74.85it/s]
 88%|########7 | Scoring GeneralizingEstimator : 1073/1225 [00:13&lt;00:01,   77.35it/s]
 88%|########7 | Scoring GeneralizingEstimator : 1076/1225 [00:14&lt;00:01,   75.14it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1081/1225 [00:14&lt;00:01,   77.60it/s]
 88%|########8 | Scoring GeneralizingEstimator : 1084/1225 [00:14&lt;00:01,   77.93it/s]
 89%|########8 | Scoring GeneralizingEstimator : 1089/1225 [00:14&lt;00:01,   78.03it/s]
 89%|########9 | Scoring GeneralizingEstimator : 1091/1225 [00:14&lt;00:01,   74.77it/s]
 89%|########9 | Scoring GeneralizingEstimator : 1094/1225 [00:14&lt;00:01,   75.17it/s]
 90%|########9 | Scoring GeneralizingEstimator : 1097/1225 [00:14&lt;00:01,   73.32it/s]
 90%|########9 | Scoring GeneralizingEstimator : 1101/1225 [00:14&lt;00:01,   74.80it/s]
 90%|######### | Scoring GeneralizingEstimator : 1103/1225 [00:14&lt;00:01,   71.46it/s]
 90%|######### | Scoring GeneralizingEstimator : 1107/1225 [00:14&lt;00:01,   73.03it/s]
 91%|######### | Scoring GeneralizingEstimator : 1109/1225 [00:14&lt;00:01,   70.55it/s]
 91%|######### | Scoring GeneralizingEstimator : 1114/1225 [00:14&lt;00:01,   73.15it/s]
 91%|#########1| Scoring GeneralizingEstimator : 1115/1225 [00:14&lt;00:01,   69.48it/s]
 92%|#########1| Scoring GeneralizingEstimator : 1121/1225 [00:14&lt;00:01,   73.09it/s]
 92%|#########1| Scoring GeneralizingEstimator : 1124/1225 [00:14&lt;00:01,   71.38it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1130/1225 [00:14&lt;00:01,   74.96it/s]
 92%|#########2| Scoring GeneralizingEstimator : 1131/1225 [00:14&lt;00:01,   71.06it/s]
 93%|#########2| Scoring GeneralizingEstimator : 1137/1225 [00:14&lt;00:01,   74.58it/s]
 93%|#########2| Scoring GeneralizingEstimator : 1139/1225 [00:14&lt;00:01,   71.73it/s]
 93%|#########3| Scoring GeneralizingEstimator : 1144/1225 [00:14&lt;00:01,   74.22it/s]
 94%|#########3| Scoring GeneralizingEstimator : 1147/1225 [00:14&lt;00:01,   74.65it/s]
 94%|#########4| Scoring GeneralizingEstimator : 1152/1225 [00:15&lt;00:00,   74.79it/s]
 94%|#########4| Scoring GeneralizingEstimator : 1154/1225 [00:15&lt;00:00,   74.12it/s]
 94%|#########4| Scoring GeneralizingEstimator : 1155/1225 [00:15&lt;00:00,   72.43it/s]
 95%|#########4| Scoring GeneralizingEstimator : 1161/1225 [00:15&lt;00:00,   76.11it/s]
 95%|#########5| Scoring GeneralizingEstimator : 1167/1225 [00:15&lt;00:00,   74.99it/s]
 95%|#########5| Scoring GeneralizingEstimator : 1169/1225 [00:15&lt;00:00,   72.17it/s]
 96%|#########5| Scoring GeneralizingEstimator : 1175/1225 [00:15&lt;00:00,   75.71it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1177/1225 [00:15&lt;00:00,   75.04it/s]
 96%|#########6| Scoring GeneralizingEstimator : 1178/1225 [00:15&lt;00:00,   73.37it/s]
 97%|#########6| Scoring GeneralizingEstimator : 1184/1225 [00:15&lt;00:00,   76.77it/s]
 97%|#########6| Scoring GeneralizingEstimator : 1188/1225 [00:15&lt;00:00,   73.63it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1190/1225 [00:15&lt;00:00,   70.67it/s]
 97%|#########7| Scoring GeneralizingEstimator : 1194/1225 [00:15&lt;00:00,   72.20it/s]
 98%|#########7| Scoring GeneralizingEstimator : 1196/1225 [00:15&lt;00:00,   71.70it/s]
 98%|#########7| Scoring GeneralizingEstimator : 1197/1225 [00:15&lt;00:00,   70.15it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1201/1225 [00:15&lt;00:00,   71.74it/s]
 98%|#########8| Scoring GeneralizingEstimator : 1202/1225 [00:15&lt;00:00,   68.49it/s]
 99%|#########8| Scoring GeneralizingEstimator : 1208/1225 [00:15&lt;00:00,   72.30it/s]
 99%|#########8| Scoring GeneralizingEstimator : 1210/1225 [00:15&lt;00:00,   69.42it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1216/1225 [00:15&lt;00:00,   73.15it/s]
 99%|#########9| Scoring GeneralizingEstimator : 1218/1225 [00:15&lt;00:00,   72.59it/s]
100%|#########9| Scoring GeneralizingEstimator : 1223/1225 [00:16&lt;00:00,   73.01it/s]
100%|##########| Scoring GeneralizingEstimator : 1225/1225 [00:16&lt;00:00,   76.36it/s]
</pre></div>
</div>
<p>Plot</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.matshow.html#matplotlib.axes.Axes.matshow" title="matplotlib.axes.Axes.matshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">matshow</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scores</span></a><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span>
                <span class="n">extent</span><span class="o">=</span><a href="../../generated/mne.Epochs.html#mne.Epochs.times" title="mne.Epochs.times" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">epochs</span><span class="o">.</span><span class="n">times</span></a><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhline.html#matplotlib.axes.Axes.axhline" title="matplotlib.axes.Axes.axhline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axhline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html#matplotlib.axes.Axes.axvline" title="matplotlib.axes.Axes.axvline" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axvline</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axis.XAxis.set_ticks_position.html#matplotlib.axis.XAxis.set_ticks_position" title="matplotlib.axis.XAxis.set_ticks_position" class="sphx-glr-backref-module-matplotlib-axis sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span></a><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel" title="matplotlib.axes.Axes.set_xlabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span></a><span class="p">(</span><span class="s1">&#39;Testing Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title" title="matplotlib.axes.Axes.set_title" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_title</span></a><span class="p">(</span><span class="s1">&#39;Generalization across time and condition&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html#matplotlib.pyplot.colorbar" title="matplotlib.pyplot.colorbar" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span></a><span class="p">(</span><a href="https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage" title="matplotlib.image.AxesImage" class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">im</span></a><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="matplotlib.pyplot.show" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_decoding_time_generalization_conditions_001.png" srcset="../../_images/sphx_glr_decoding_time_generalization_conditions_001.png" alt="Generalization across time and condition" class = "sphx-glr-single-img"/><div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="kingdehaene2014"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jean-Rémi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. <em>Trends in Cognitive Sciences</em>, 18(4):203–210, 2014. <a class="reference external" href="https://doi.org/10.1016/j.tics.2014.01.002">doi:10.1016/j.tics.2014.01.002</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  32.370 seconds)</p>
<p><strong>Estimated memory usage:</strong>  128 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-decoding-decoding-time-generalization-conditions-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ab6282967a162922fd7405f0d8568e07/decoding_time_generalization_conditions.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">decoding_time_generalization_conditions.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/00e78bba5d10188fcf003ef05e32a6f7/decoding_time_generalization_conditions.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">decoding_time_generalization_conditions.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="decoding_spoc_CMC.html" title="previous page">Continuous Target Decoding with SPoC</a>
    <a class='right-next' id="next-link" href="decoding_unsupervised_spatial_filter.html" title="next page">Analysis of evoked response using ICA and PCA reduction techniques</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-07-27T07:59:01.875635+00:00" class="localized">2021-07-27 07:59 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>