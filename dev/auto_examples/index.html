
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="auto">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Examples Gallery &#8212; MNE 1.11.0.dev4+g85e675985 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "auto";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=1395d0ad" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=6b4d2b6d"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-5TBCPCRB6X"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/index';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://mne.tools/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.11';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Input/Output" href="io/index.html" />
    <link rel="prev" title="Using the event system to link figures" href="../auto_tutorials/visualization/20_ui_events.html" />
    <link rel="canonical" href="https://mne.tools/stable/auto_examples/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.11" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="auto">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/mne_logo_small.svg" class="logo__image only-light" alt="MNE 1.11.0.dev4+g85e675985 documentation - Home"/>
    <img src="../_static/mne_logo_small.svg" class="logo__image only-dark pst-js-only" alt="MNE 1.11.0.dev4+g85e675985 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help/index.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/index.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../documentation/index.html">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/python_reference.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help/index.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-mastodon fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-fw fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_tutorials/index.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/intro/index.html">Introductory tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/10_overview.html">Overview of MEG/EEG analysis with MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/15_inplace.html">Modifying data in-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/20_events_from_raw.html">Parsing events from raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/30_info.html">The Info data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/40_sensor_locations.html">Working with sensor locations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/50_configure_mne.html">Configuring MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/70_report.html">Getting started with mne.Report</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/io/index.html">Reading data for different recording systems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/10_reading_meg_data.html">Importing data from MEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/20_reading_eeg_data.html">Importing data from EEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/30_reading_fnirs_data.html">Importing data from fNIRS devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/60_ctf_bst_auditory.html">Working with CTF data: the Brainstorm auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/70_reading_eyetracking_data.html">Importing Data from Eyetracking devices</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/raw/index.html">Working with continuous data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/10_raw_overview.html">The Raw data structure: continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/20_event_arrays.html">Working with events</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/30_annotate_raw.html">Annotating continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/40_visualize_raw.html">Built-in plotting methods for Raw objects</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/10_preprocessing_overview.html">Overview of artifact detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/15_handling_bad_channels.html">Handling bad channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/20_rejecting_bad_data.html">Rejecting bad data spans and breaks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/25_background_filtering.html">Background information on filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/30_filtering_resampling.html">Filtering and resampling data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/35_artifact_correction_regression.html">Repairing artifacts with regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/40_artifact_correction_ica.html">Repairing artifacts with ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/45_projectors_background.html">Background on projectors and projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">Repairing artifacts with SSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/55_setting_eeg_reference.html">Setting the EEG reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/59_head_positions.html">Extracting and visualizing subject head movement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">Signal-space separation (SSS) and Maxwell filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/70_fnirs_processing.html">Preprocessing functional near-infrared spectroscopy (fNIRS) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/80_opm_processing.html">Preprocessing optically pumped magnetometer (OPM) MEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/90_eyetracking_data.html">Working with eye tracker data in MNE-Python</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/epochs/index.html">Segmenting continuous data into epochs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/10_epochs_overview.html">The Epochs data structure: discontinuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/15_baseline_regression.html">Regression-based baseline correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/20_visualize_epochs.html">Visualizing epoched data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/30_epochs_metadata.html">Working with Epoch metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/40_autogenerate_metadata.html">Auto-generating Epochs metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/50_epochs_to_data_frame.html">Exporting Epochs to Pandas DataFrames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/60_make_fixed_length_epochs.html">Divide continuous data into equally-spaced epochs</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/evoked/index.html">Estimating evoked responses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/10_evoked_overview.html">The Evoked data structure: evoked/averaged data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/20_visualize_evoked.html">Visualizing Evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/30_eeg_erp.html">EEG analysis - Event-Related Potentials (ERPs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/40_whitened.html">Plotting whitened data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/time-freq/index.html">Time-frequency analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/10_spectrum_class.html">The Spectrum and EpochsSpectrum classes: frequency-domain data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/20_sensors_time_frequency.html">Frequency and time-frequency sensor analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/50_ssvep.html">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/forward/index.html">Forward models and source spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/10_background_freesurfer.html">FreeSurfer MRI reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/20_source_alignment.html">Source alignment and coordinate frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/25_automated_coreg.html">Using an automated approach to coregistration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/30_forward.html">Head model and forward computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/35_eeg_no_mri.html">EEG forward operator with a template MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/50_background_freesurfer_mne.html">How MNE uses FreeSurfer’s outputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/80_fix_bem_in_blender.html">Fixing BEM and head surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/90_compute_covariance.html">Computing a covariance matrix</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/inverse/index.html">Source localization and inverses</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/10_stc_class.html">The SourceEstimate data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/20_dipole_fit.html">Source localization with equivalent current dipole (ECD) fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/30_mne_dspm_loreta.html">Source localization with MNE, dSPM, sLORETA, and eLORETA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/35_dipole_orientations.html">The role of dipole orientations in distributed source localization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/40_mne_fixed_free.html">Computing various MNE solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/50_beamformer_lcmv.html">Source reconstruction using an LCMV beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/60_visualize_stc.html">Visualize source time courses (stcs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/70_eeg_mri_coords.html">EEG source localization given electrode locations on an MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">Brainstorm Elekta phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">Brainstorm CTF phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/90_phantom_4DBTi.html">4D Neuroimaging/BTi phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/95_phantom_KIT.html">KIT phantom dataset tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/index.html">Statistical analysis of sensor data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/10_background_stats.html">Statistical inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/20_erp_stats.html">Visualising statistical significance thresholds on EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">Non-parametric 1 sample cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">Non-parametric between conditions cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/70_cluster_rmANOVA_time_freq.html">Mass-univariate twoway repeated measures ANOVA on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">Spatiotemporal permutation F-test on full sensor data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/stats-source-space/index.html">Statistical analysis of source estimates</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">Permutation t-test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">2 samples permutation test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">Repeated measures ANOVA on source data with spatio-temporal clustering</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/machine-learning/index.html">Machine learning models of neural activity</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/machine-learning/30_strf.html">Spectro-temporal receptive field (STRF) estimation on continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/machine-learning/50_decoding.html">Decoding (MVPA)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/clinical/index.html">Clinical applications</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/20_seeg.html">Working with sEEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/30_ecog.html">Working with ECoG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/60_sleep.html">Sleep stage classification from polysomnography (PSG) data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/simulation/index.html">Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/10_array_objs.html">Creating MNE-Python data structures from scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/70_point_spread.html">Corrupt known signal with point spread</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/80_dics.html">DICS for power mapping</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/visualization/index.html">Visualization tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/visualization/10_publication_figure.html">Make figures more publication ready</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/visualization/20_ui_events.html">Using the event system to link figures</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Examples</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="io/index.html">Input/Output</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="io/elekta_epochs.html">Getting averaging info from .fif files</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/read_impedances.html">Getting impedances from raw files</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/read_neo_format.html">How to use data in neural ensemble (NEO) format</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/read_noise_covariance_matrix.html">Reading/Writing a noise covariance matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="io/read_xdf.html">Reading XDF EEG data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="simulation/index.html">Data Simulation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="simulation/plot_stc_metrics.html">Compare simulated and estimated source activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/simulate_evoked_data.html">Generate simulated evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/simulate_raw_data.html">Generate simulated raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/simulated_raw_data_using_subject_anatomy.html">Simulate raw data using subject anatomy</a></li>
<li class="toctree-l3"><a class="reference internal" href="simulation/source_simulator.html">Generate simulated source data</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/contralateral_referencing.html">Using contralateral referencing for EEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/css.html">Cortical Signal Suppression (CSS) for removal of cortical signals</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/define_target_events.html">Define target events based on time lag, plot evoked response</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/eeg_bridging.html">Identify EEG Electrodes Bridged by too much Gel</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/eeg_csd.html">Transform EEG data using current source density (CSD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/eog_artifact_histogram.html">Show EOG artifact timing</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/eog_regression.html">Reduce EOG artifacts through regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/epochs_metadata.html">Automated epochs metadata generation with variable time windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/esg_rm_heart_artefact_pcaobs.html">Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/find_ref_artifacts.html">Find MEG reference channel artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/fnirs_artifact_removal.html">Visualise NIRS artifact correction methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/ica_comparison.html">Compare the different ICA algorithms in MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/interpolate_bad_channels.html">Interpolate bad channels for MEG/EEG channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/interpolate_to.html">Interpolate EEG data to any montage</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/movement_compensation.html">Maxwell filter data with movement compensation</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/movement_detection.html">Annotate movement artifacts and reestimate dev_head_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/muscle_detection.html">Annotate muscle artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/muscle_ica.html">Removing muscle ICA components</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/otp.html">Plot sensor denoising using oversampled temporal projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/shift_evoked.html">Shifting time-scale in evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/virtual_evoked.html">Remap MEG channel types</a></li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing/xdawn_denoising.html">XDAWN Denoising</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="visualization/index.html">Visualization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="visualization/3d_to_2d.html">How to convert 3D electrode positions to a 2D image</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/brain.html">Plotting with <code class="docutils literal notranslate"><span class="pre">mne.viz.Brain</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/channel_epochs_image.html">Visualize channel over epochs as an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/eeg_on_scalp.html">Plotting EEG sensors on the scalp</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/evoked_arrowmap.html">Plotting topographic arrowmaps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/evoked_topomap.html">Plotting topographic maps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/evoked_whitening.html">Whitening evoked data with a noise covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/eyetracking_plot_heatmap.html">Plotting eye-tracking heatmaps in MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/meg_sensors.html">Plotting sensor layouts of MEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/mne_helmet.html">Plot the MNE brain and helmet</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/montage_sgskip.html">Plotting sensor layouts of EEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/parcellation.html">Plot a cortical parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/roi_erpimage_by_rt.html">Plot single trial activity, grouped by ROI and sorted by RT</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/ssp_projs_sensitivity_map.html">Sensitivity map of SSP projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/topo_compare_conditions.html">Compare evoked responses for different conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/topo_customized.html">Plot custom topographies for MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="visualization/xhemi.html">Cross-hemisphere comparison</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="time_frequency/index.html">Time-Frequency Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/compute_csd.html">Compute a cross-spectral density (CSD) matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/compute_source_psd_epochs.html">Compute Power Spectral Density of inverse solution from single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/source_label_time_frequency.html">Compute power and phase lock in label of the source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/source_power_spectrum.html">Compute source power spectral density (PSD) in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/source_power_spectrum_opm.html">Compute source power spectral density (PSD) of VectorView and OPM data</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/source_space_time_frequency.html">Compute induced power in the source space with dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/temporal_whitening.html">Temporal whitening with AR model</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/time_frequency_erds.html">Compute and visualize ERDS maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/time_frequency_global_field_power.html">Explore event-related dynamics for specific frequency bands</a></li>
<li class="toctree-l3"><a class="reference internal" href="time_frequency/time_frequency_simulated.html">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="stats/index.html">Statistics Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="stats/cluster_stats_evoked.html">Permutation F-test on sensor data with 1D cluster level</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats/fdr_stats_evoked.html">FDR correction on T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats/linear_regression_raw.html">Regression on continuous data (rER[P/F])</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats/sensor_permutation_test.html">Permutation T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="stats/sensor_regression.html">Analysing continuous features with binning and regression in sensor space</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="decoding/index.html">Machine Learning (Decoding, Encoding, and MVPA)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_csp_eeg.html">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_csp_timefreq.html">Decoding in time-frequency space using Common Spatial Patterns (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_rsa_sgskip.html">Representational Similarity Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_spatio_temporal_source.html">Decoding source space data</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_spoc_CMC.html">Continuous Target Decoding with SPoC</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_time_generalization_conditions.html">Decoding sensor space data with generalization across time and conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_unsupervised_spatial_filter.html">Analysis of evoked response using ICA and PCA reduction techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_xdawn_eeg.html">XDAWN Decoding From EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/ems_filtering.html">Compute effect-matched-spatial filtering (EMS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/linear_model_patterns.html">Linear classifier on sensor data with plot patterns and filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/receptive_field_mtrf.html">Receptive Field Estimation and Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/ssd_spatial_filters.html">Compute spatial filters with Spatio-Spectral Decomposition (SSD)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/index.html">Connectivity Analysis Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="forward/index.html">Forward modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="forward/forward_sensitivity_maps.html">Display sensitivity maps for EEG and MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/left_cerebellum_volume_source.html">Generate a left cerebellum volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="forward/source_space_morphing.html">Use source space morphing</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="inverse/index.html">Inverse problem and source analysis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="inverse/compute_mne_inverse_epochs_in_label.html">Compute MNE-dSPM inverse solution on single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/compute_mne_inverse_raw_in_label.html">Compute sLORETA inverse solution on raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/compute_mne_inverse_volume.html">Compute MNE-dSPM inverse solution on evoked data in volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/custom_inverse_solver.html">Source localization with a custom inverse solver</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/dics_epochs.html">Compute source level time-frequency timecourses using a DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/dics_source_power.html">Compute source power using DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/evoked_ers_source_power.html">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/gamma_map_inverse.html">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/label_activation_from_stc.html">Extracting time course from source_estimate object</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/label_from_stc.html">Generate a functional label from source estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/label_source_activations.html">Extracting the time series of activations in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/mixed_norm_inverse.html">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/mixed_source_space_inverse.html">Compute MNE inverse solution on evoked data with a mixed source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/mne_cov_power.html">Compute source power estimate by projecting the covariance with MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/morph_surface_stc.html">Morph surface source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/morph_volume_stc.html">Morph volumetric source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/multi_dipole_model.html">Computing source timecourses with an XFit-like multi-dipole model</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/multidict_reweighted_tfmxne.html">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/psf_ctf_label_leakage.html">Visualize source leakage among labels using a circular graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/psf_ctf_vertices.html">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/psf_ctf_vertices_lcmv.html">Compute cross-talk functions for LCMV beamformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/psf_volume.html">Plot point-spread functions (PSFs) for a volume</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/rap_music.html">Compute Rap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/read_inverse.html">Reading an inverse operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/read_stc.html">Reading an STC file</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/resolution_metrics.html">Compute spatial resolution metrics in source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/resolution_metrics_eegmeg.html">Compute spatial resolution metrics to compare MEG with EEG+MEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/snr_estimate.html">Estimate data SNR using an inverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/source_space_snr.html">Computing source space SNR</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/time_frequency_mixed_norm_inverse.html">Compute MxNE with time-frequency sparse prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/trap_music.html">Compute Trap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="inverse/vector_mne_solution.html">Plotting the full vector-valued MNE solution</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="datasets/index.html">Examples on open datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/brainstorm_data.html">Brainstorm raw (median nerve) dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/hf_sef_data.html">HF-SEF dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/kernel_phantom.html">Kernel OPM phantom data</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/limo_data.html">Single trial linear regression analysis with the LIMO dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/opm_data.html">Optically pumped magnetometer (OPM) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/spm_faces_dataset.html">From raw data to dSPM on SPM Faces dataset</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/implementation.html">Implementation details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/design_philosophy.html">Design philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/datasets.html">Example datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/commands.html">Command-line tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help/migrating.html">Migrating from other analysis software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cookbook.html">The typical M/EEG workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cite.html">How to cite MNE-Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation/cited.html">Papers citing MNE-Python</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none"></div>
              
              
<div>
  
  <section id="examples-gallery">
<h1>Examples Gallery<a class="headerlink" href="#examples-gallery" title="Link to this heading">#</a></h1>
<p>The examples gallery provides working code samples demonstrating various
analysis and visualization techniques. These examples often lack the narrative
explanations seen in the tutorials, and do not follow any specific order. These
examples are a useful way to discover new analysis or plotting ideas, or to see
how a particular technique you’ve read about can be applied using MNE-Python.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If example-scripts contain plots and are run locally, using the
interactive interactive flag with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-i</span> <span class="pre">tutorial_script.py</span></code>
keeps them open.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>These examples sometimes use simulations or shortcuts (such as intentionally
adding noise to recordings) to illustrate a point. Use caution when
copy-pasting code samples.</p>
</div>
<div class="sphx-glr-thumbnails"></div><section id="input-output">
<h2>Input/Output<a class="headerlink" href="#input-output" title="Link to this heading">#</a></h2>
<p>Recipes for reading and writing files. See also our <a class="reference internal" href="../auto_tutorials/io/index.html#tut-data-formats"><span class="std std-ref">tutorials on reading
data from various recording systems</span></a> and our <a class="reference internal" href="../auto_tutorials/simulation/10_array_objs.html#tut-creating-data-structures"><span class="std std-ref">tutorial
on manipulating MNE-Python data structures</span></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Parse averaging information defined in Elekta Vectorview/TRIUX DACQ (data acquisition). Extract and average epochs accordingly. Modify some averaging parameters and get epochs."><img alt="" src="../_images/sphx_glr_elekta_epochs_thumb.png" />
<p><a class="reference internal" href="io/elekta_epochs.html#sphx-glr-auto-examples-io-elekta-epochs-py"><span class="std std-ref">Getting averaging info from .fif files</span></a></p>
  <div class="sphx-glr-thumbnail-title">Getting averaging info from .fif files</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Many EEG systems provide impedance measurements for each channel within their file format. MNE does not parse this information and does not store it in the Raw object. However, it is possible to extract this information from the raw data and store it in a separate data structure."><img alt="" src="../_images/sphx_glr_read_impedances_thumb.png" />
<p><a class="reference internal" href="io/read_impedances.html#sphx-glr-auto-examples-io-read-impedances-py"><span class="std std-ref">Getting impedances from raw files</span></a></p>
  <div class="sphx-glr-thumbnail-title">Getting impedances from raw files</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to create an MNE-Python Raw object from data in the neural ensemble format. For general information on creating MNE-Python&#x27;s data objects from NumPy arrays, see tut-creating-data-structures."><img alt="" src="../_images/sphx_glr_read_neo_format_thumb.png" />
<p><a class="reference internal" href="io/read_neo_format.html#sphx-glr-auto-examples-io-read-neo-format-py"><span class="std std-ref">How to use data in neural ensemble (NEO) format</span></a></p>
  <div class="sphx-glr-thumbnail-title">How to use data in neural ensemble (NEO) format</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="How to plot a noise covariance matrix."><img alt="" src="../_images/sphx_glr_read_noise_covariance_matrix_thumb.png" />
<p><a class="reference internal" href="io/read_noise_covariance_matrix.html#sphx-glr-auto-examples-io-read-noise-covariance-matrix-py"><span class="std std-ref">Reading/Writing a noise covariance matrix</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reading/Writing a noise covariance matrix</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we read some sample XDF data. Although we do not analyze it here, this recording is of a short parallel auditory response (pABR) experiment PolonenkoMaddox2019 and was provided by the Maddox Lab."><img alt="" src="../_images/sphx_glr_read_xdf_thumb.png" />
<p><a class="reference internal" href="io/read_xdf.html#sphx-glr-auto-examples-io-read-xdf-py"><span class="std std-ref">Reading XDF EEG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reading XDF EEG data</div>
</div></div></section>
<section id="data-simulation">
<h2>Data Simulation<a class="headerlink" href="#data-simulation" title="Link to this heading">#</a></h2>
<p>Tools to generate simulation data.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to compare the simulated and estimated source time courses (STC) by computing different metrics. Simulated source is a cortical region or dipole. It is meant to be a brief introduction and only highlights the simplest use case."><img alt="" src="../_images/sphx_glr_plot_stc_metrics_thumb.png" />
<p><a class="reference internal" href="simulation/plot_stc_metrics.html#sphx-glr-auto-examples-simulation-plot-stc-metrics-py"><span class="std std-ref">Compare simulated and estimated source activity</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compare simulated and estimated source activity</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Use simulate_sparse_stc to simulate evoked data."><img alt="" src="../_images/sphx_glr_simulate_evoked_data_thumb.png" />
<p><a class="reference internal" href="simulation/simulate_evoked_data.html#sphx-glr-auto-examples-simulation-simulate-evoked-data-py"><span class="std std-ref">Generate simulated evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Generate simulated evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example generates raw data by repeating a desired source activation multiple times."><img alt="" src="../_images/sphx_glr_simulate_raw_data_thumb.png" />
<p><a class="reference internal" href="simulation/simulate_raw_data.html#sphx-glr-auto-examples-simulation-simulate-raw-data-py"><span class="std std-ref">Generate simulated raw data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Generate simulated raw data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to generate source estimates and simulate raw data using subject anatomy with the mne.simulation.SourceSimulator class. Once the raw data is simulated, generated source estimates are reconstructed using dynamic statistical parametric mapping (dSPM) inverse operator."><img alt="" src="../_images/sphx_glr_simulated_raw_data_using_subject_anatomy_thumb.png" />
<p><a class="reference internal" href="simulation/simulated_raw_data_using_subject_anatomy.html#sphx-glr-auto-examples-simulation-simulated-raw-data-using-subject-anatomy-py"><span class="std std-ref">Simulate raw data using subject anatomy</span></a></p>
  <div class="sphx-glr-thumbnail-title">Simulate raw data using subject anatomy</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the mne.simulation.SourceSimulator class to generate source estimates and raw data. It is meant to be a brief introduction and only highlights the simplest use case."><img alt="" src="../_images/sphx_glr_source_simulator_thumb.png" />
<p><a class="reference internal" href="simulation/source_simulator.html#sphx-glr-auto-examples-simulation-source-simulator-py"><span class="std std-ref">Generate simulated source data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Generate simulated source data</div>
</div></div></section>
<section id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Link to this heading">#</a></h2>
<p>Examples related to data preprocessing (artifact detection / rejection etc.)</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="When intracranial electrode contacts are very small, sometimes..." onclick="window.location.href = 'https://mne.tools/mne-gui-addons/auto_examples/locate_ieeg_micro.html';"><img alt="" src="https://mne.tools/mne-gui-addons/_images/sphx_glr_locate_ieeg_micro_001.png" />
<p><a class="reference external" href="https://mne.tools/mne-gui-addons/auto_examples/locate_ieeg_micro.html#ex-ieeg-micro" title="(in MNE-GUI-Addons v0.2)"><span>Locating micro-scale intracranial electrode contacts</span></a></p>
  <div class="sphx-glr-thumbnail-title">Locating micro-scale intracranial electrode contacts</div>
</div></div><div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Instead of using a single reference electrode for all channels, some researchers reference the EEG electrodes in each hemisphere to an electrode in the contralateral hemisphere (often an electrode over the mastoid bone; this is common in sleep research for example). Here we demonstrate how to set a contralateral EEG reference."><img alt="" src="../_images/sphx_glr_contralateral_referencing_thumb.png" />
<p><a class="reference internal" href="preprocessing/contralateral_referencing.html#sphx-glr-auto-examples-preprocessing-contralateral-referencing-py"><span class="std std-ref">Using contralateral referencing for EEG</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using contralateral referencing for EEG</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows an example of how to use CSS Samuelsson2019 . CSS suppresses the cortical contribution to the signal subspace in EEG data using MEG data, facilitating detection of subcortical signals. We will illustrate how it works by simulating one cortical and one subcortical oscillation at different frequencies; 40 Hz and 239 Hz for cortical and subcortical activity, respectively, then process it with CSS and look at the power spectral density of the raw and processed data."><img alt="" src="../_images/sphx_glr_css_thumb.png" />
<p><a class="reference internal" href="preprocessing/css.html#sphx-glr-auto-examples-preprocessing-css-py"><span class="std std-ref">Cortical Signal Suppression (CSS) for removal of cortical signals</span></a></p>
  <div class="sphx-glr-thumbnail-title">Cortical Signal Suppression (CSS) for removal of cortical signals</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows how to define higher order events based on time lag between reference and target events. For illustration, we will put face stimuli presented into two classes, that is 1) followed by an early button press (within 590 milliseconds) and followed by a late button press (later than 590 milliseconds). Finally, we will visualize the evoked responses to both &#x27;quickly-processed&#x27; and &#x27;slowly-processed&#x27; face stimuli."><img alt="" src="../_images/sphx_glr_define_target_events_thumb.png" />
<p><a class="reference internal" href="preprocessing/define_target_events.html#sphx-glr-auto-examples-preprocessing-define-target-events-py"><span class="std std-ref">Define target events based on time lag, plot evoked response</span></a></p>
  <div class="sphx-glr-thumbnail-title">Define target events based on time lag, plot evoked response</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Research-grade EEG often uses a gel based system, and when too much gel is applied the gel conducting signal from the scalp to the electrode for one electrode connects with the gel conducting signal from another electrode &quot;bridging&quot; the two signals. This is undesirable because the signals from the two (or more) electrodes are not as independent as they would otherwise be; they are very similar to each other introducing additional spatial smearing. An algorithm has been developed to detect electrode bridging TenkeKayser2001, which has been implemented in EEGLAB DelormeMakeig2004. Unfortunately, there is not a lot to be done about electrode brigding once the data has been collected as far as preprocessing other than interpolating bridged channels. Therefore, our recommendation is to check for electrode bridging early in data collection and address the problem. Or, if the data has already been collected, quantify the extent of the bridging so as not to introduce bias into the data from this effect and exclude subjects with bridging that might effect the outcome of a study. Preventing electrode bridging is ideal but awareness of the problem at least will mitigate its potential as a confound to a study. This tutorial follows the eBridge tutorial from https://psychophysiology.cpmc.columbia.edu."><img alt="" src="../_images/sphx_glr_eeg_bridging_thumb.png" />
<p><a class="reference internal" href="preprocessing/eeg_bridging.html#sphx-glr-auto-examples-preprocessing-eeg-bridging-py"><span class="std std-ref">Identify EEG Electrodes Bridged by too much Gel</span></a></p>
  <div class="sphx-glr-thumbnail-title">Identify EEG Electrodes Bridged by too much Gel</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows an example of how to use CSD PerrinEtAl1987,PerrinEtAl1989,Cohen2014,KayserTenke2015. CSD takes the spatial Laplacian of the sensor signal (derivative in both x and y). It does what a planar gradiometer does in MEG. Computing these spatial derivatives reduces point spread. CSD transformed data have a sharper or more distinct topography, reducing the negative impact of volume conduction."><img alt="" src="../_images/sphx_glr_eeg_csd_thumb.png" />
<p><a class="reference internal" href="preprocessing/eeg_csd.html#sphx-glr-auto-examples-preprocessing-eeg-csd-py"><span class="std std-ref">Transform EEG data using current source density (CSD)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Transform EEG data using current source density (CSD)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute the distribution of timing for EOG artifacts."><img alt="" src="../_images/sphx_glr_eog_artifact_histogram_thumb.png" />
<p><a class="reference internal" href="preprocessing/eog_artifact_histogram.html#sphx-glr-auto-examples-preprocessing-eog-artifact-histogram-py"><span class="std std-ref">Show EOG artifact timing</span></a></p>
  <div class="sphx-glr-thumbnail-title">Show EOG artifact timing</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Reduce artifacts by regressing the EOG channels onto the rest of the channels and then subtracting the EOG signal."><img alt="" src="../_images/sphx_glr_eog_regression_thumb.png" />
<p><a class="reference internal" href="preprocessing/eog_regression.html#sphx-glr-auto-examples-preprocessing-eog-regression-py"><span class="std std-ref">Reduce EOG artifacts through regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reduce EOG artifacts through regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When working with Epochs, tut-epochs-metadata can be invaluable. There is an extensive tutorial on how it can be generated automatically &lt;tut-autogenerate-metadata&gt;. In the brief examples below, we will demonstrate different ways to bound the time windows used to generate the metadata."><img alt="" src="../_images/sphx_glr_epochs_metadata_thumb.png" />
<p><a class="reference internal" href="preprocessing/epochs_metadata.html#sphx-glr-auto-examples-preprocessing-epochs-metadata-py"><span class="std std-ref">Automated epochs metadata generation with variable time windows</span></a></p>
  <div class="sphx-glr-thumbnail-title">Automated epochs metadata generation with variable time windows</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script shows an example of how to use an adaptation of PCA-OBS NiazyEtAl2005. PCA-OBS was originally designed to remove the ballistocardiographic artefact in simultaneous EEG-fMRI. Here, it has been adapted to remove the delay between the detected R-peak and the ballistocardiographic artefact such that the algorithm can be applied to remove the cardiac artefact in EEG (electroencephalography) and ESG (electrospinography) data. We will illustrate how it works by applying the algorithm to ESG data, where the effect of removal is most pronounced."><img alt="" src="../_images/sphx_glr_esg_rm_heart_artefact_pcaobs_thumb.png" />
<p><a class="reference internal" href="preprocessing/esg_rm_heart_artefact_pcaobs.html#sphx-glr-auto-examples-preprocessing-esg-rm-heart-artefact-pcaobs-py"><span class="std std-ref">Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact</span></a></p>
  <div class="sphx-glr-thumbnail-title">Principal Component Analysis - Optimal Basis Sets (PCA-OBS) removing cardiac artefact</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Use ICA decompositions of MEG reference channels to remove intermittent noise."><img alt="" src="../_images/sphx_glr_find_ref_artifacts_thumb.png" />
<p><a class="reference internal" href="preprocessing/find_ref_artifacts.html#sphx-glr-auto-examples-preprocessing-find-ref-artifacts-py"><span class="std std-ref">Find MEG reference channel artifacts</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find MEG reference channel artifacts</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we artificially introduce several fNIRS artifacts and observe how artifact correction techniques attempt to correct the data."><img alt="" src="../_images/sphx_glr_fnirs_artifact_removal_thumb.png" />
<p><a class="reference internal" href="preprocessing/fnirs_artifact_removal.html#sphx-glr-auto-examples-preprocessing-fnirs-artifact-removal-py"><span class="std std-ref">Visualise NIRS artifact correction methods</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualise NIRS artifact correction methods</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Different ICA algorithms are fit to raw MEG data, and the corresponding maps are displayed."><img alt="" src="../_images/sphx_glr_ica_comparison_thumb.png" />
<p><a class="reference internal" href="preprocessing/ica_comparison.html#sphx-glr-auto-examples-preprocessing-ica-comparison-py"><span class="std std-ref">Compare the different ICA algorithms in MNE</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compare the different ICA algorithms in MNE</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to interpolate bad MEG/EEG channels"><img alt="" src="../_images/sphx_glr_interpolate_bad_channels_thumb.png" />
<p><a class="reference internal" href="preprocessing/interpolate_bad_channels.html#sphx-glr-auto-examples-preprocessing-interpolate-bad-channels-py"><span class="std std-ref">Interpolate bad channels for MEG/EEG channels</span></a></p>
  <div class="sphx-glr-thumbnail-title">Interpolate bad channels for MEG/EEG channels</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to interpolate EEG channels to match a given montage. This can be useful for standardizing EEG channel layouts across different datasets (see MellotEtAl2024)."><img alt="" src="../_images/sphx_glr_interpolate_to_thumb.png" />
<p><a class="reference internal" href="preprocessing/interpolate_to.html#sphx-glr-auto-examples-preprocessing-interpolate-to-py"><span class="std std-ref">Interpolate EEG data to any montage</span></a></p>
  <div class="sphx-glr-thumbnail-title">Interpolate EEG data to any montage</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstrate movement compensation on simulated data. The simulated data contains bilateral activation of auditory cortices, repeated over 14 different head rotations (head center held fixed). See the following for details:"><img alt="" src="../_images/sphx_glr_movement_compensation_thumb.png" />
<p><a class="reference internal" href="preprocessing/movement_compensation.html#sphx-glr-auto-examples-preprocessing-movement-compensation-py"><span class="std std-ref">Maxwell filter data with movement compensation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Maxwell filter data with movement compensation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Periods, where the participant moved considerably, are contaminated by low amplitude artifacts. When averaging the magnetic fields, the more spread the head position, the bigger the cancellation due to different locations. Similarly, the covariance will also be affected by severe head movement, and source estimation will suffer low/smeared coregistration accuracy."><img alt="" src="../_images/sphx_glr_movement_detection_thumb.png" />
<p><a class="reference internal" href="preprocessing/movement_detection.html#sphx-glr-auto-examples-preprocessing-movement-detection-py"><span class="std std-ref">Annotate movement artifacts and reestimate dev_head_t</span></a></p>
  <div class="sphx-glr-thumbnail-title">Annotate movement artifacts and reestimate dev_head_t</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Muscle contractions produce high frequency activity that can mask brain signal of interest. Muscle artifacts can be produced when clenching the jaw, swallowing, or twitching a cranial muscle. Muscle artifacts are most noticeable in the range of 110-140 Hz."><img alt="" src="../_images/sphx_glr_muscle_detection_thumb.png" />
<p><a class="reference internal" href="preprocessing/muscle_detection.html#sphx-glr-auto-examples-preprocessing-muscle-detection-py"><span class="std std-ref">Annotate muscle artifacts</span></a></p>
  <div class="sphx-glr-thumbnail-title">Annotate muscle artifacts</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Gross movements produce widespread high-frequency activity across all channels that is usually not recoverable and so the epoch must be rejected as shown in ex-muscle-artifacts. More ubiquitously than gross movements, muscle artifact is produced during postural maintenance. This is more appropriately removed by ICA otherwise there wouldn&#x27;t be any epochs left! Note that muscle artifacts of this kind are much more pronounced in EEG than they are in MEG."><img alt="" src="../_images/sphx_glr_muscle_ica_thumb.png" />
<p><a class="reference internal" href="preprocessing/muscle_ica.html#sphx-glr-auto-examples-preprocessing-muscle-ica-py"><span class="std std-ref">Removing muscle ICA components</span></a></p>
  <div class="sphx-glr-thumbnail-title">Removing muscle ICA components</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This demonstrates denoising using the OTP algorithm LarsonTaulu2018 on data with with sensor artifacts (flux jumps) and random noise."><img alt="" src="../_images/sphx_glr_otp_thumb.png" />
<p><a class="reference internal" href="preprocessing/otp.html#sphx-glr-auto-examples-preprocessing-otp-py"><span class="std std-ref">Plot sensor denoising using oversampled temporal projection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot sensor denoising using oversampled temporal projection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Shifting time-scale in evoked data"><img alt="" src="../_images/sphx_glr_shift_evoked_thumb.png" />
<p><a class="reference internal" href="preprocessing/shift_evoked.html#sphx-glr-auto-examples-preprocessing-shift-evoked-py"><span class="std std-ref">Shifting time-scale in evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Shifting time-scale in evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, MEG data are remapped from one channel type to another. This is useful to:"><img alt="" src="../_images/sphx_glr_virtual_evoked_thumb.png" />
<p><a class="reference internal" href="preprocessing/virtual_evoked.html#sphx-glr-auto-examples-preprocessing-virtual-evoked-py"><span class="std std-ref">Remap MEG channel types</span></a></p>
  <div class="sphx-glr-thumbnail-title">Remap MEG channel types</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="XDAWN filters are trained from epochs, signal is projected in the sources space and then projected back in the sensor space using only the first two XDAWN components. The process is similar to an ICA, but is supervised in order to maximize the signal to signal + noise ratio of the evoked response RivetEtAl2009, RivetEtAl2011."><img alt="" src="../_images/sphx_glr_xdawn_denoising_thumb.png" />
<p><a class="reference internal" href="preprocessing/xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-xdawn-denoising-py"><span class="std std-ref">XDAWN Denoising</span></a></p>
  <div class="sphx-glr-thumbnail-title">XDAWN Denoising</div>
</div></div></section>
<section id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Link to this heading">#</a></h2>
<p>Looking at data and processing output.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Sometimes we want to convert a 3D representation of electrodes into a 2D image. For example, if we are using electrocorticography it is common to create scatterplots on top of a brain, with each point representing an electrode."><img alt="" src="../_images/sphx_glr_3d_to_2d_thumb.png" />
<p><a class="reference internal" href="visualization/3d_to_2d.html#sphx-glr-auto-examples-visualization-3d-to-2d-py"><span class="std std-ref">How to convert 3D electrode positions to a 2D image</span></a></p>
  <div class="sphx-glr-thumbnail-title">How to convert 3D electrode positions to a 2D image</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we&#x27;ll show how to use mne.viz.Brain."><img alt="" src="../_images/sphx_glr_brain_thumb.png" />
<p><a class="reference internal" href="visualization/brain.html#sphx-glr-auto-examples-visualization-brain-py"><span class="std std-ref">Plotting with mne.viz.Brain</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting with mne.viz.Brain</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This will produce what is sometimes called an event related potential / field (ERP/ERF) image."><img alt="" src="../_images/sphx_glr_channel_epochs_image_thumb.png" />
<p><a class="reference internal" href="visualization/channel_epochs_image.html#sphx-glr-auto-examples-visualization-channel-epochs-image-py"><span class="std std-ref">Visualize channel over epochs as an image</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualize channel over epochs as an image</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, digitized EEG sensor locations are shown on the scalp surface."><img alt="" src="../_images/sphx_glr_eeg_on_scalp_thumb.png" />
<p><a class="reference internal" href="visualization/eeg_on_scalp.html#sphx-glr-auto-examples-visualization-eeg-on-scalp-py"><span class="std std-ref">Plotting EEG sensors on the scalp</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting EEG sensors on the scalp</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Load evoked data and plot arrowmaps along with the topomap for selected time points. An arrowmap is based upon the Hosaka-Cohen transformation and represents an estimation of the current flow underneath the MEG sensors. They are a poor man&#x27;s MNE."><img alt="" src="../_images/sphx_glr_evoked_arrowmap_thumb.png" />
<p><a class="reference internal" href="visualization/evoked_arrowmap.html#sphx-glr-auto-examples-visualization-evoked-arrowmap-py"><span class="std std-ref">Plotting topographic arrowmaps of evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting topographic arrowmaps of evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Load evoked data and plot topomaps for selected time points using multiple additional options."><img alt="" src="../_images/sphx_glr_evoked_topomap_thumb.png" />
<p><a class="reference internal" href="visualization/evoked_topomap.html#sphx-glr-auto-examples-visualization-evoked-topomap-py"><span class="std std-ref">Plotting topographic maps of evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting topographic maps of evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Evoked data are loaded and then whitened using a given noise covariance matrix. It&#x27;s an excellent quality check to see if baseline signals match the assumption of Gaussian white noise during the baseline period."><img alt="" src="../_images/sphx_glr_evoked_whitening_thumb.png" />
<p><a class="reference internal" href="visualization/evoked_whitening.html#sphx-glr-auto-examples-visualization-evoked-whitening-py"><span class="std std-ref">Whitening evoked data with a noise covariance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Whitening evoked data with a noise covariance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial covers plotting eye-tracking position data as a heatmap."><img alt="" src="../_images/sphx_glr_eyetracking_plot_heatmap_thumb.png" />
<p><a class="reference internal" href="visualization/eyetracking_plot_heatmap.html#sphx-glr-auto-examples-visualization-eyetracking-plot-heatmap-py"><span class="std std-ref">Plotting eye-tracking heatmaps in MNE-Python</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting eye-tracking heatmaps in MNE-Python</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Show sensor layouts of different MEG systems."><img alt="" src="../_images/sphx_glr_meg_sensors_thumb.png" />
<p><a class="reference internal" href="visualization/meg_sensors.html#sphx-glr-auto-examples-visualization-meg-sensors-py"><span class="std std-ref">Plotting sensor layouts of MEG systems</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting sensor layouts of MEG systems</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial shows how to make the MNE helmet + brain image."><img alt="" src="../_images/sphx_glr_mne_helmet_thumb.png" />
<p><a class="reference internal" href="visualization/mne_helmet.html#sphx-glr-auto-examples-visualization-mne-helmet-py"><span class="std std-ref">Plot the MNE brain and helmet</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot the MNE brain and helmet</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to load all the EEG system montages shipped in MNE-python, and display it on the fsaverage template subject."><img alt="" src="../_images/sphx_glr_montage_sgskip_thumb.png" />
<p><a class="reference internal" href="visualization/montage_sgskip.html#sphx-glr-auto-examples-visualization-montage-sgskip-py"><span class="std std-ref">Plotting sensor layouts of EEG systems</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting sensor layouts of EEG systems</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we download the HCP-MMP1.0 parcellation GlasserEtAl2016 and show it on fsaverage. We will also download the customized 448-label aparc parcellation from KhanEtAl2018."><img alt="" src="../_images/sphx_glr_parcellation_thumb.png" />
<p><a class="reference internal" href="visualization/parcellation.html#sphx-glr-auto-examples-visualization-parcellation-py"><span class="std std-ref">Plot a cortical parcellation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot a cortical parcellation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This will produce what is sometimes called an event related potential / field (ERP/ERF) image."><img alt="" src="../_images/sphx_glr_roi_erpimage_by_rt_thumb.png" />
<p><a class="reference internal" href="visualization/roi_erpimage_by_rt.html#sphx-glr-auto-examples-visualization-roi-erpimage-by-rt-py"><span class="std std-ref">Plot single trial activity, grouped by ROI and sorted by RT</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot single trial activity, grouped by ROI and sorted by RT</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the sources that have a forward field similar to the first SSP vector correcting for ECG."><img alt="" src="../_images/sphx_glr_ssp_projs_sensitivity_map_thumb.png" />
<p><a class="reference internal" href="visualization/ssp_projs_sensitivity_map.html#sphx-glr-auto-examples-visualization-ssp-projs-sensitivity-map-py"><span class="std std-ref">Sensitivity map of SSP projections</span></a></p>
  <div class="sphx-glr-thumbnail-title">Sensitivity map of SSP projections</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, an Epochs object for visual and auditory responses is created. Both conditions are then accessed by their respective names to create a sensor layout plot of the related evoked responses."><img alt="" src="../_images/sphx_glr_topo_compare_conditions_thumb.png" />
<p><a class="reference internal" href="visualization/topo_compare_conditions.html#sphx-glr-auto-examples-visualization-topo-compare-conditions-py"><span class="std std-ref">Compare evoked responses for different conditions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compare evoked responses for different conditions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example exposes the iter_topography function that makes it very easy to generate custom sensor topography plots. Here we will plot the power spectrum of each channel on a topographic layout."><img alt="" src="../_images/sphx_glr_topo_customized_thumb.png" />
<p><a class="reference internal" href="visualization/topo_customized.html#sphx-glr-auto-examples-visualization-topo-customized-py"><span class="std std-ref">Plot custom topographies for MEG sensors</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot custom topographies for MEG sensors</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to visualize the difference between activity in the left and the right hemisphere. The data from the right hemisphere is mapped to the left hemisphere, and then the difference is plotted. For more information see mne.compute_source_morph."><img alt="" src="../_images/sphx_glr_xhemi_thumb.png" />
<p><a class="reference internal" href="visualization/xhemi.html#sphx-glr-auto-examples-visualization-xhemi-py"><span class="std std-ref">Cross-hemisphere comparison</span></a></p>
  <div class="sphx-glr-thumbnail-title">Cross-hemisphere comparison</div>
</div></div></section>
<section id="time-frequency-examples">
<h2>Time-Frequency Examples<a class="headerlink" href="#time-frequency-examples" title="Link to this heading">#</a></h2>
<p>Some examples of how to explore time-frequency content of M/EEG data with MNE.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="A cross-spectral density (CSD) matrix is similar to a covariance matrix, but in the time-frequency domain. It is the first step towards computing sensor-to-sensor coherence or a DICS beamformer."><img alt="" src="../_images/sphx_glr_compute_csd_thumb.png" />
<p><a class="reference internal" href="time_frequency/compute_csd.html#sphx-glr-auto-examples-time-frequency-compute-csd-py"><span class="std std-ref">Compute a cross-spectral density (CSD) matrix</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute a cross-spectral density (CSD) matrix</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute PSD of dSPM inverse solution on single trial epochs restricted to a brain label. The PSD is computed using a multi-taper method with Discrete Prolate Spheroidal Sequence (DPSS) windows."><img alt="" src="../_images/sphx_glr_compute_source_psd_epochs_thumb.png" />
<p><a class="reference internal" href="time_frequency/compute_source_psd_epochs.html#sphx-glr-auto-examples-time-frequency-compute-source-psd-epochs-py"><span class="std std-ref">Compute Power Spectral Density of inverse solution from single epochs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute Power Spectral Density of inverse solution from single epochs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute time-frequency maps of power and phase lock in the source space. The inverse method is linear based on dSPM inverse operator."><img alt="" src="../_images/sphx_glr_source_label_time_frequency_thumb.png" />
<p><a class="reference internal" href="time_frequency/source_label_time_frequency.html#sphx-glr-auto-examples-time-frequency-source-label-time-frequency-py"><span class="std std-ref">Compute power and phase lock in label of the source space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute power and phase lock in label of the source space</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Returns an STC file containing the PSD (in dB) of each of the sources within a label."><img alt="" src="../_images/sphx_glr_source_power_spectrum_thumb.png" />
<p><a class="reference internal" href="time_frequency/source_power_spectrum.html#sphx-glr-auto-examples-time-frequency-source-power-spectrum-py"><span class="std std-ref">Compute source power spectral density (PSD) in a label</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute source power spectral density (PSD) in a label</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compute the resting state from raw for data recorded using a Neuromag VectorView system and a custom OPM system. The pipeline is meant to mostly follow the Brainstorm TadelEtAl2011 OMEGA resting tutorial pipeline. The steps we use are:"><img alt="" src="../_images/sphx_glr_source_power_spectrum_opm_thumb.png" />
<p><a class="reference internal" href="time_frequency/source_power_spectrum_opm.html#sphx-glr-auto-examples-time-frequency-source-power-spectrum-opm-py"><span class="std std-ref">Compute source power spectral density (PSD) of VectorView and OPM data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute source power spectral density (PSD) of VectorView and OPM data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Returns STC files ie source estimates of induced power for different bands in the source space. The inverse method is linear based on dSPM inverse operator."><img alt="" src="../_images/sphx_glr_source_space_time_frequency_thumb.png" />
<p><a class="reference internal" href="time_frequency/source_space_time_frequency.html#sphx-glr-auto-examples-time-frequency-source-space-time-frequency-py"><span class="std std-ref">Compute induced power in the source space with dSPM</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute induced power in the source space with dSPM</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we fit an AR model to the data and use it to temporally whiten the signals."><img alt="" src="../_images/sphx_glr_temporal_whitening_thumb.png" />
<p><a class="reference internal" href="time_frequency/temporal_whitening.html#sphx-glr-auto-examples-time-frequency-temporal-whitening-py"><span class="std std-ref">Temporal whitening with AR model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Temporal whitening with AR model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example calculates and displays ERDS maps of event-related EEG data. ERDS (sometimes also written as ERD/ERS) is short for event-related desynchronization (ERD) and event-related synchronization (ERS) PfurtschellerLopesdaSilva1999. Conceptually, ERD corresponds to a decrease in power in a specific frequency band relative to a baseline. Similarly, ERS corresponds to an increase in power. An ERDS map is a time/frequency representation of ERD/ERS over a range of frequencies GraimannEtAl2002. ERDS maps are also known as ERSP (event-related spectral perturbation) Makeig1993."><img alt="" src="../_images/sphx_glr_time_frequency_erds_thumb.png" />
<p><a class="reference internal" href="time_frequency/time_frequency_erds.html#sphx-glr-auto-examples-time-frequency-time-frequency-erds-py"><span class="std std-ref">Compute and visualize ERDS maps</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute and visualize ERDS maps</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The objective is to show you how to explore spectrally localized effects. For this purpose we adapt the method described in HariSalmelin1997 and use it on the somato dataset. The idea is to track the band-limited temporal evolution of spatial patterns by using the global field power (GFP)."><img alt="" src="../_images/sphx_glr_time_frequency_global_field_power_thumb.png" />
<p><a class="reference internal" href="time_frequency/time_frequency_global_field_power.html#sphx-glr-auto-examples-time-frequency-time-frequency-global-field-power-py"><span class="std std-ref">Explore event-related dynamics for specific frequency bands</span></a></p>
  <div class="sphx-glr-thumbnail-title">Explore event-related dynamics for specific frequency bands</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the different time-frequency estimation methods on simulated data. It shows the time-frequency resolution trade-off and the problem of estimation variance. In addition it highlights alternative functions for generating TFRs without averaging across trials, or by operating on numpy arrays."><img alt="" src="../_images/sphx_glr_time_frequency_simulated_thumb.png" />
<p><a class="reference internal" href="time_frequency/time_frequency_simulated.html#sphx-glr-auto-examples-time-frequency-time-frequency-simulated-py"><span class="std std-ref">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</div>
</div></div></section>
<section id="statistics-examples">
<h2>Statistics Examples<a class="headerlink" href="#statistics-examples" title="Link to this heading">#</a></h2>
<p>Some examples of how to compute statistics on M/EEG data with MNE.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="One tests if the evoked response is significantly different between conditions. Multiple comparison problem is addressed with cluster level permutation test."><img alt="" src="../_images/sphx_glr_cluster_stats_evoked_thumb.png" />
<p><a class="reference internal" href="stats/cluster_stats_evoked.html#sphx-glr-auto-examples-stats-cluster-stats-evoked-py"><span class="std std-ref">Permutation F-test on sensor data with 1D cluster level</span></a></p>
  <div class="sphx-glr-thumbnail-title">Permutation F-test on sensor data with 1D cluster level</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="One tests if the evoked response significantly deviates from 0. Multiple comparison problem is addressed with False Discovery Rate (FDR) correction."><img alt="" src="../_images/sphx_glr_fdr_stats_evoked_thumb.png" />
<p><a class="reference internal" href="stats/fdr_stats_evoked.html#sphx-glr-auto-examples-stats-fdr-stats-evoked-py"><span class="std std-ref">FDR correction on T-test on sensor data</span></a></p>
  <div class="sphx-glr-thumbnail-title">FDR correction on T-test on sensor data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This demonstrates how rER[P/F]s - regressing the continuous data - is a generalisation of traditional averaging. If all preprocessing steps are the same, no overlap between epochs exists, and if all predictors are binary, regression is virtually identical to traditional averaging. If overlap exists and/or predictors are continuous, traditional averaging is inapplicable, but regression can estimate effects, including those of continuous predictors."><img alt="" src="../_images/sphx_glr_linear_regression_raw_thumb.png" />
<p><a class="reference internal" href="stats/linear_regression_raw.html#sphx-glr-auto-examples-stats-linear-regression-raw-py"><span class="std std-ref">Regression on continuous data (rER[P/F])</span></a></p>
  <div class="sphx-glr-thumbnail-title">Regression on continuous data (rER[P/F])</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="One tests if the signal significantly deviates from 0 during a fixed time window of interest. Here computation is performed on MNE sample dataset between 40 and 60 ms."><img alt="" src="../_images/sphx_glr_sensor_permutation_test_thumb.png" />
<p><a class="reference internal" href="stats/sensor_permutation_test.html#sphx-glr-auto-examples-stats-sensor-permutation-test-py"><span class="std std-ref">Permutation T-test on sensor data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Permutation T-test on sensor data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Predict single trial activity from a continuous variable. A single-trial regression is performed in each sensor and timepoint individually, resulting in an mne.Evoked object which contains the regression coefficient (beta value) for each combination of sensor and timepoint. This example shows the regression coefficient; the t and p values are also calculated automatically."><img alt="" src="../_images/sphx_glr_sensor_regression_thumb.png" />
<p><a class="reference internal" href="stats/sensor_regression.html#sphx-glr-auto-examples-stats-sensor-regression-py"><span class="std std-ref">Analysing continuous features with binning and regression in sensor space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Analysing continuous features with binning and regression in sensor space</div>
</div></div></section>
<section id="machine-learning-decoding-encoding-and-mvpa">
<h2>Machine Learning (Decoding, Encoding, and MVPA)<a class="headerlink" href="#machine-learning-decoding-encoding-and-mvpa" title="Link to this heading">#</a></h2>
<p>Decoding, encoding, and general machine learning examples.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Decoding of motor imagery applied to EEG data decomposed using CSP. A classifier is then applied to features extracted on CSP-filtered signals."><img alt="" src="../_images/sphx_glr_decoding_csp_eeg_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-decoding-csp-eeg-py"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The time-frequency decomposition is estimated by iterating over raw data that has been band-passed at different frequencies. This is used to compute a covariance matrix over each epoch or a rolling time-window and extract the CSP filtered signals. A linear discriminant classifier is then applied to these signals."><img alt="" src="../_images/sphx_glr_decoding_csp_timefreq_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_csp_timefreq.html#sphx-glr-auto-examples-decoding-decoding-csp-timefreq-py"><span class="std std-ref">Decoding in time-frequency space using Common Spatial Patterns (CSP)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding in time-frequency space using Common Spatial Patterns (CSP)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Representational Similarity Analysis is used to perform summary statistics on supervised classifications where the number of classes is relatively high. It consists in characterizing the structure of the confusion matrix to infer the similarity between brain responses and serves as a proxy for characterizing the space of mental representations Shepard1980,LaaksoCottrell2000,KriegeskorteEtAl2008."><img alt="" src="../_images/sphx_glr_decoding_rsa_sgskip_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_rsa_sgskip.html#sphx-glr-auto-examples-decoding-decoding-rsa-sgskip-py"><span class="std std-ref">Representational Similarity Analysis</span></a></p>
  <div class="sphx-glr-thumbnail-title">Representational Similarity Analysis</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Decoding to MEG data in source space on the left cortical surface. Here univariate feature selection is employed for speed purposes to confine the classification to a small number of potentially relevant features. The classifier then is trained to selected features of epochs in source space."><img alt="" src="../_images/sphx_glr_decoding_spatio_temporal_source_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_spatio_temporal_source.html#sphx-glr-auto-examples-decoding-decoding-spatio-temporal-source-py"><span class="std std-ref">Decoding source space data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding source space data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Source Power Comodulation (SPoC) DahneEtAl2014 allows to identify the composition of orthogonal spatial filters that maximally correlate with a continuous target."><img alt="" src="../_images/sphx_glr_decoding_spoc_CMC_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_spoc_CMC.html#sphx-glr-auto-examples-decoding-decoding-spoc-cmc-py"><span class="std std-ref">Continuous Target Decoding with SPoC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Continuous Target Decoding with SPoC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example runs the analysis described in KingDehaene2014. It illustrates how one can fit a linear classifier to identify a discriminatory topography at a given time instant and subsequently assess whether this linear model can accurately predict all of the time samples of a second set of conditions."><img alt="" src="../_images/sphx_glr_decoding_time_generalization_conditions_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_time_generalization_conditions.html#sphx-glr-auto-examples-decoding-decoding-time-generalization-conditions-py"><span class="std std-ref">Decoding sensor space data with generalization across time and conditions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decoding sensor space data with generalization across time and conditions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example computes PCA and ICA of evoked or epochs data. Then the PCA / ICA components, a.k.a. spatial filters, are used to transform the channel data to new sources / virtual channels. The output is visualized on the average of all the epochs."><img alt="" src="../_images/sphx_glr_decoding_unsupervised_spatial_filter_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_unsupervised_spatial_filter.html#sphx-glr-auto-examples-decoding-decoding-unsupervised-spatial-filter-py"><span class="std std-ref">Analysis of evoked response using ICA and PCA reduction techniques</span></a></p>
  <div class="sphx-glr-thumbnail-title">Analysis of evoked response using ICA and PCA reduction techniques</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="ERP decoding with Xdawn RivetEtAl2009,RivetEtAl2011. For each event type, a set of spatial Xdawn filters are trained and applied on the signal. Channels are concatenated and rescaled to create features vectors that will be fed into a logistic regression."><img alt="" src="../_images/sphx_glr_decoding_xdawn_eeg_thumb.png" />
<p><a class="reference internal" href="decoding/decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-decoding-xdawn-eeg-py"><span class="std std-ref">XDAWN Decoding From EEG data</span></a></p>
  <div class="sphx-glr-thumbnail-title">XDAWN Decoding From EEG data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example computes the EMS to reconstruct the time course of the experimental effect as described in SchurgerEtAl2013."><img alt="" src="../_images/sphx_glr_ems_filtering_thumb.png" />
<p><a class="reference internal" href="decoding/ems_filtering.html#sphx-glr-auto-examples-decoding-ems-filtering-py"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute effect-matched-spatial filtering (EMS)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here decoding, a.k.a MVPA or supervised machine learning, is applied to M/EEG data in sensor space. Fit a linear classifier with the LinearModel object providing topographical patterns which are more neurophysiologically interpretable HaufeEtAl2014 than the classifier filters (weight vectors). The patterns explain how the MEG and EEG data were generated from the discriminant neural sources which are extracted by the filters. Note patterns/filters in MEG data are more similar than EEG data because the noise is less spatially correlated in MEG than EEG."><img alt="" src="../_images/sphx_glr_linear_model_patterns_thumb.png" />
<p><a class="reference internal" href="decoding/linear_model_patterns.html#sphx-glr-auto-examples-decoding-linear-model-patterns-py"><span class="std std-ref">Linear classifier on sensor data with plot patterns and filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Linear classifier on sensor data with plot patterns and filters</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces figures from Lalor et al.&#x27;s mTRF toolbox in MATLAB CrosseEtAl2016. We will show how the mne.decoding.ReceptiveField class can perform a similar function along with scikit-learn. We will first fit a linear encoding model using the continuously-varying speech envelope to predict activity of a 128 channel EEG system. Then, we will take the reverse approach and try to predict the speech envelope from the EEG (known in the literature as a decoding model, or simply stimulus reconstruction)."><img alt="" src="../_images/sphx_glr_receptive_field_mtrf_thumb.png" />
<p><a class="reference internal" href="decoding/receptive_field_mtrf.html#sphx-glr-auto-examples-decoding-receptive-field-mtrf-py"><span class="std std-ref">Receptive Field Estimation and Prediction</span></a></p>
  <div class="sphx-glr-thumbnail-title">Receptive Field Estimation and Prediction</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will compute spatial filters for retaining oscillatory brain activity and down-weighting 1/f background signals as proposed by NikulinEtAl2011. The idea is to learn spatial filters that separate oscillatory dynamics from surrounding non-oscillatory noise based on the covariance in the frequency band of interest and the noise covariance based on surrounding frequencies."><img alt="" src="../_images/sphx_glr_ssd_spatial_filters_thumb.png" />
<p><a class="reference internal" href="decoding/ssd_spatial_filters.html#sphx-glr-auto-examples-decoding-ssd-spatial-filters-py"><span class="std std-ref">Compute spatial filters with Spatio-Spectral Decomposition (SSD)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute spatial filters with Spatio-Spectral Decomposition (SSD)</div>
</div></div></section>
<section id="connectivity-analysis-examples">
<h2>Connectivity Analysis Examples<a class="headerlink" href="#connectivity-analysis-examples" title="Link to this heading">#</a></h2>
<p>Examples demonstrating connectivity analysis in sensor and source space.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Connectivity functionality has moved into the
<a class="reference external" href="https://mne.tools/mne-connectivity/stable/api.html#module-mne_connectivity" title="(in MNE-Connectivity v0.7)"><code class="docutils literal notranslate"><span class="pre">mne_connectivity</span></code></a> package. Examples can be found at
<a class="reference external" href="https://mne.tools/mne-connectivity/stable/auto_examples/index.html" title="(in MNE-Connectivity v0.7)"><span>Examples</span></a>.</p>
</div>
<div class="sphx-glr-thumbnails"></div></section>
<section id="forward-modeling">
<h2>Forward modeling<a class="headerlink" href="#forward-modeling" title="Link to this heading">#</a></h2>
<p>From BEM segmentation, coregistration, setting up source spaces
to actual computation of forward solution.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Sensitivity maps can be produced from forward operators that indicate how well different sensor types will be able to detect neural currents from different regions of the brain."><img alt="" src="../_images/sphx_glr_forward_sensitivity_maps_thumb.png" />
<p><a class="reference internal" href="forward/forward_sensitivity_maps.html#sphx-glr-auto-examples-forward-forward-sensitivity-maps-py"><span class="std std-ref">Display sensitivity maps for EEG and MEG sensors</span></a></p>
  <div class="sphx-glr-thumbnail-title">Display sensitivity maps for EEG and MEG sensors</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Generate a volume source space of the left cerebellum and plot its vertices relative to the left cortical surface source space and the FreeSurfer segmentation file."><img alt="" src="../_images/sphx_glr_left_cerebellum_volume_source_thumb.png" />
<p><a class="reference internal" href="forward/left_cerebellum_volume_source.html#sphx-glr-auto-examples-forward-left-cerebellum-volume-source-py"><span class="std std-ref">Generate a left cerebellum volume source space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Generate a left cerebellum volume source space</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use source space morphing (as opposed to SourceEstimate morphing) to create data that can be compared between subjects."><img alt="" src="../_images/sphx_glr_source_space_morphing_thumb.png" />
<p><a class="reference internal" href="forward/source_space_morphing.html#sphx-glr-auto-examples-forward-source-space-morphing-py"><span class="std std-ref">Use source space morphing</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use source space morphing</div>
</div></div></section>
<section id="inverse-problem-and-source-analysis">
<h2>Inverse problem and source analysis<a class="headerlink" href="#inverse-problem-and-source-analysis" title="Link to this heading">#</a></h2>
<p>Estimate source activations, extract activations in
labels, morph data between subjects etc.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Compute dSPM inverse solution on single trial epochs restricted to a brain label."><img alt="" src="../_images/sphx_glr_compute_mne_inverse_epochs_in_label_thumb.png" />
<p><a class="reference internal" href="inverse/compute_mne_inverse_epochs_in_label.html#sphx-glr-auto-examples-inverse-compute-mne-inverse-epochs-in-label-py"><span class="std std-ref">Compute MNE-dSPM inverse solution on single epochs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute MNE-dSPM inverse solution on single epochs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute sLORETA inverse solution on raw dataset restricted to a brain label and stores the solution in stc files for visualisation."><img alt="" src="../_images/sphx_glr_compute_mne_inverse_raw_in_label_thumb.png" />
<p><a class="reference internal" href="inverse/compute_mne_inverse_raw_in_label.html#sphx-glr-auto-examples-inverse-compute-mne-inverse-raw-in-label-py"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute sLORETA inverse solution on raw data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute dSPM inverse solution on MNE evoked dataset in a volume source space and stores the solution in a nifti file for visualisation."><img alt="" src="../_images/sphx_glr_compute_mne_inverse_volume_thumb.png" />
<p><a class="reference internal" href="inverse/compute_mne_inverse_volume.html#sphx-glr-auto-examples-inverse-compute-mne-inverse-volume-py"><span class="std std-ref">Compute MNE-dSPM inverse solution on evoked data in volume source space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute MNE-dSPM inverse solution on evoked data in volume source space</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The objective of this example is to show how to plug a custom inverse solver in MNE in order to facilate empirical comparison with the methods MNE already implements (wMNE, dSPM, sLORETA, eLORETA, LCMV, DICS, (TF-)MxNE etc.)."><img alt="" src="../_images/sphx_glr_custom_inverse_solver_thumb.png" />
<p><a class="reference internal" href="inverse/custom_inverse_solver.html#sphx-glr-auto-examples-inverse-custom-inverse-solver-py"><span class="std std-ref">Source localization with a custom inverse solver</span></a></p>
  <div class="sphx-glr-thumbnail-title">Source localization with a custom inverse solver</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, a Dynamic Imaging of Coherent Sources (DICS) GrossEtAl2001 beamformer is used to transform sensor-level time-frequency objects to the source level. We will look at the event-related synchronization (ERS) of beta band activity in the somato dataset &lt;somato-dataset&gt;."><img alt="" src="../_images/sphx_glr_dics_epochs_thumb.png" />
<p><a class="reference internal" href="inverse/dics_epochs.html#sphx-glr-auto-examples-inverse-dics-epochs-py"><span class="std std-ref">Compute source level time-frequency timecourses using a DICS beamformer</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute source level time-frequency timecourses using a DICS beamformer</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute a Dynamic Imaging of Coherent Sources (DICS) GrossEtAl2001 filter from single-trial activity to estimate source power across a frequency band. This example demonstrates how to source localize the event-related synchronization (ERS) of beta band activity in the somato dataset &lt;somato-dataset&gt;."><img alt="" src="../_images/sphx_glr_dics_source_power_thumb.png" />
<p><a class="reference internal" href="inverse/dics_source_power.html#sphx-glr-auto-examples-inverse-dics-source-power-py"><span class="std std-ref">Compute source power using DICS beamformer</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute source power using DICS beamformer</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we examine 3 ways of localizing event-related synchronization (ERS) of beta band activity in this dataset: somato-dataset using DICS, LCMV beamformer, and dSPM applied to active and baseline covariance matrices."><img alt="" src="../_images/sphx_glr_evoked_ers_source_power_thumb.png" />
<p><a class="reference internal" href="inverse/evoked_ers_source_power.html#sphx-glr-auto-examples-inverse-evoked-ers-source-power-py"><span class="std std-ref">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="See WipfNagarajan2009 for details."><img alt="" src="../_images/sphx_glr_gamma_map_inverse_thumb.png" />
<p><a class="reference internal" href="inverse/gamma_map_inverse.html#sphx-glr-auto-examples-inverse-gamma-map-inverse-py"><span class="std std-ref">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Load a SourceEstimate object from stc files and extract the time course of activation in individual labels, as well as in a complex label formed through merging two labels."><img alt="" src="../_images/sphx_glr_label_activation_from_stc_thumb.png" />
<p><a class="reference internal" href="inverse/label_activation_from_stc.html#sphx-glr-auto-examples-inverse-label-activation-from-stc-py"><span class="std std-ref">Extracting time course from source_estimate object</span></a></p>
  <div class="sphx-glr-thumbnail-title">Extracting time course from source_estimate object</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Threshold source estimates and produce a functional label. The label is typically the region of interest that contains high values. Here we compare the average time course in the anatomical label obtained by FreeSurfer segmentation and the average time course from the functional label. As expected the time course in the functional label yields higher values."><img alt="" src="../_images/sphx_glr_label_from_stc_thumb.png" />
<p><a class="reference internal" href="inverse/label_from_stc.html#sphx-glr-auto-examples-inverse-label-from-stc-py"><span class="std std-ref">Generate a functional label from source estimates</span></a></p>
  <div class="sphx-glr-thumbnail-title">Generate a functional label from source estimates</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We first apply a dSPM inverse operator to get signed activations in a label (with positive and negative values) and we then compare different strategies to average the times series in a label. We compare a simple average, with an averaging using the dipoles normal (flip mode) and then a PCA, also using a sign flip."><img alt="" src="../_images/sphx_glr_label_source_activations_thumb.png" />
<p><a class="reference internal" href="inverse/label_source_activations.html#sphx-glr-auto-examples-inverse-label-source-activations-py"><span class="std std-ref">Extracting the time series of activations in a label</span></a></p>
  <div class="sphx-glr-thumbnail-title">Extracting the time series of activations in a label</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Runs an (ir)MxNE (L1/L2 GramfortEtAl2012 or L0.5/L2 StrohmeierEtAl2014 mixed norm) inverse solver. L0.5/L2 is done with irMxNE which allows for sparser source estimates with less amplitude bias due to the non-convexity of the L0.5/L2 mixed norm penalty."><img alt="" src="../_images/sphx_glr_mixed_norm_inverse_thumb.png" />
<p><a class="reference internal" href="inverse/mixed_norm_inverse.html#sphx-glr-auto-examples-inverse-mixed-norm-inverse-py"><span class="std std-ref">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Create a mixed source space and compute an MNE inverse solution on an evoked dataset."><img alt="" src="../_images/sphx_glr_mixed_source_space_inverse_thumb.png" />
<p><a class="reference internal" href="inverse/mixed_source_space_inverse.html#sphx-glr-auto-examples-inverse-mixed-source-space-inverse-py"><span class="std std-ref">Compute MNE inverse solution on evoked data with a mixed source space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute MNE inverse solution on evoked data with a mixed source space</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We can apply the MNE inverse operator to a covariance matrix to obtain an estimate of source power. This is computationally more efficient than first estimating the source timecourses and then computing their power. This code is based on the code from Sabbagh2020 and has been useful to correct for individual field spread using source localization in the context of predictive modeling."><img alt="" src="../_images/sphx_glr_mne_cov_power_thumb.png" />
<p><a class="reference internal" href="inverse/mne_cov_power.html#sphx-glr-auto-examples-inverse-mne-cov-power-py"><span class="std std-ref">Compute source power estimate by projecting the covariance with MNE</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute source power estimate by projecting the covariance with MNE</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to morph an individual subject&#x27;s mne.SourceEstimate to a common reference space. We achieve this using mne.SourceMorph. Pre-computed data will be morphed based on a spherical representation of the cortex computed using the spherical registration of tut-freesurfer-mne (https://surfer.nmr.mgh.harvard.edu/fswiki/SurfaceRegAndTemplates) GreveEtAl2013. This transform will be used to morph the surface vertices of the subject towards the reference vertices. Here we will use &#x27;fsaverage&#x27; as a reference space (see https://surfer.nmr.mgh.harvard.edu/fswiki/FsAverage)."><img alt="" src="../_images/sphx_glr_morph_surface_stc_thumb.png" />
<p><a class="reference internal" href="inverse/morph_surface_stc.html#sphx-glr-auto-examples-inverse-morph-surface-stc-py"><span class="std std-ref">Morph surface source estimate</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morph surface source estimate</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to morph an individual subject&#x27;s mne.VolSourceEstimate to a common reference space. We achieve this using mne.SourceMorph. Data will be morphed based on an affine transformation and a nonlinear registration method known as Symmetric Diffeomorphic Registration (SDR) by AvantsEtAl2008."><img alt="" src="../_images/sphx_glr_morph_volume_stc_thumb.png" />
<p><a class="reference internal" href="inverse/morph_volume_stc.html#sphx-glr-auto-examples-inverse-morph-volume-stc-py"><span class="std std-ref">Morph volumetric source estimate</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morph volumetric source estimate</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="MEGIN&#x27;s XFit program offers a &quot;guided ECD modeling&quot; interface, where multiple dipoles can be fitted interactively. By manually selecting subsets of sensors and time ranges, dipoles can be fitted to specific signal components. Then, source timecourses can be computed using a multi-dipole model. The advantage of using a multi-dipole model over fitting each dipole in isolation, is that when multiple dipoles contribute to the same signal component, the model can make sure that activity assigned to one dipole is not also assigned to another. This example shows how to build a multi-dipole model for estimating source timecourses for evokeds or single epochs."><img alt="" src="../_images/sphx_glr_multi_dipole_model_thumb.png" />
<p><a class="reference internal" href="inverse/multi_dipole_model.html#sphx-glr-auto-examples-inverse-multi-dipole-model-py"><span class="std std-ref">Computing source timecourses with an XFit-like multi-dipole model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Computing source timecourses with an XFit-like multi-dipole model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The iterative reweighted TF-MxNE solver is a distributed inverse method based on the TF-MxNE solver, which promotes focal (sparse) sources StrohmeierEtAl2015. The benefits of this approach are that:"><img alt="" src="../_images/sphx_glr_multidict_reweighted_tfmxne_thumb.png" />
<p><a class="reference internal" href="inverse/multidict_reweighted_tfmxne.html#sphx-glr-auto-examples-inverse-multidict-reweighted-tfmxne-py"><span class="std std-ref">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example computes all-to-all pairwise leakage among 68 regions in source space based on MNE inverse solutions and a FreeSurfer cortical parcellation. Label-to-label leakage is estimated as the correlation among the labels&#x27; point-spread functions (PSFs). It is visualized using a circular graph which is ordered based on the locations of the regions in the axial plane."><img alt="" src="../_images/sphx_glr_psf_ctf_label_leakage_thumb.png" />
<p><a class="reference internal" href="inverse/psf_ctf_label_leakage.html#sphx-glr-auto-examples-inverse-psf-ctf-label-leakage-py"><span class="std std-ref">Visualize source leakage among labels using a circular graph</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualize source leakage among labels using a circular graph</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualise PSF and CTF at one vertex for sLORETA."><img alt="" src="../_images/sphx_glr_psf_ctf_vertices_thumb.png" />
<p><a class="reference internal" href="inverse/psf_ctf_vertices.html#sphx-glr-auto-examples-inverse-psf-ctf-vertices-py"><span class="std std-ref">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualise cross-talk functions at one vertex for LCMV beamformers computed with different data covariance matrices, which affects their cross-talk functions."><img alt="" src="../_images/sphx_glr_psf_ctf_vertices_lcmv_thumb.png" />
<p><a class="reference internal" href="inverse/psf_ctf_vertices_lcmv.html#sphx-glr-auto-examples-inverse-psf-ctf-vertices-lcmv-py"><span class="std std-ref">Compute cross-talk functions for LCMV beamformers</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute cross-talk functions for LCMV beamformers</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualise PSF at one volume vertex for sLORETA."><img alt="" src="../_images/sphx_glr_psf_volume_thumb.png" />
<p><a class="reference internal" href="inverse/psf_volume.html#sphx-glr-auto-examples-inverse-psf-volume-py"><span class="std std-ref">Plot point-spread functions (PSFs) for a volume</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot point-spread functions (PSFs) for a volume</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute a Recursively Applied and Projected MUltiple Signal Classification (RAP-MUSIC) MosherLeahy1999 on evoked data."><img alt="" src="../_images/sphx_glr_rap_music_thumb.png" />
<p><a class="reference internal" href="inverse/rap_music.html#sphx-glr-auto-examples-inverse-rap-music-py"><span class="std std-ref">Compute Rap-Music on evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute Rap-Music on evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The inverse operator&#x27;s source space is shown in 3D."><img alt="" src="../_images/sphx_glr_read_inverse_thumb.png" />
<p><a class="reference internal" href="inverse/read_inverse.html#sphx-glr-auto-examples-inverse-read-inverse-py"><span class="std std-ref">Reading an inverse operator</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reading an inverse operator</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="STC files contain activations on cortex ie. source reconstructions"><img alt="" src="../_images/sphx_glr_read_stc_thumb.png" />
<p><a class="reference internal" href="inverse/read_stc.html#sphx-glr-auto-examples-inverse-read-stc-py"><span class="std std-ref">Reading an STC file</span></a></p>
  <div class="sphx-glr-thumbnail-title">Reading an STC file</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute peak localisation error and spatial deviation for the point-spread functions of dSPM and MNE. Plot their distributions and difference of distributions. This example mimics some results from HaukEtAl2019, namely Figure 3 (peak localisation error for PSFs, L2-MNE vs dSPM) and Figure 4 (spatial deviation for PSFs, L2-MNE vs dSPM)."><img alt="" src="../_images/sphx_glr_resolution_metrics_thumb.png" />
<p><a class="reference internal" href="inverse/resolution_metrics.html#sphx-glr-auto-examples-inverse-resolution-metrics-py"><span class="std std-ref">Compute spatial resolution metrics in source space</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute spatial resolution metrics in source space</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute peak localisation error and spatial deviation for the point-spread functions of dSPM and MNE. Plot their distributions and difference of distributions. This example mimics some results from HaukEtAl2019, namely Figure 3 (peak localisation error for PSFs, L2-MNE vs dSPM) and Figure 4 (spatial deviation for PSFs, L2-MNE vs dSPM). It shows that combining MEG with EEG reduces the point-spread function and increases the spatial resolution of source imaging, especially for deeper sources."><img alt="" src="../_images/sphx_glr_resolution_metrics_eegmeg_thumb.png" />
<p><a class="reference internal" href="inverse/resolution_metrics_eegmeg.html#sphx-glr-auto-examples-inverse-resolution-metrics-eegmeg-py"><span class="std std-ref">Compute spatial resolution metrics to compare MEG with EEG+MEG</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute spatial resolution metrics to compare MEG with EEG+MEG</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This estimates the SNR as a function of time for a set of data using a minimum-norm inverse operator."><img alt="" src="../_images/sphx_glr_snr_estimate_thumb.png" />
<p><a class="reference internal" href="inverse/snr_estimate.html#sphx-glr-auto-examples-inverse-snr-estimate-py"><span class="std std-ref">Estimate data SNR using an inverse</span></a></p>
  <div class="sphx-glr-thumbnail-title">Estimate data SNR using an inverse</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute and plot source space SNR as in GoldenholzEtAl2009."><img alt="" src="../_images/sphx_glr_source_space_snr_thumb.png" />
<p><a class="reference internal" href="inverse/source_space_snr.html#sphx-glr-auto-examples-inverse-source-space-snr-py"><span class="std std-ref">Computing source space SNR</span></a></p>
  <div class="sphx-glr-thumbnail-title">Computing source space SNR</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The TF-MxNE solver is a distributed inverse method (like dSPM or sLORETA) that promotes focal (sparse) sources (such as dipole fitting techniques) GramfortEtAl2013b,GramfortEtAl2011. The benefit of this approach is that:"><img alt="" src="../_images/sphx_glr_time_frequency_mixed_norm_inverse_thumb.png" />
<p><a class="reference internal" href="inverse/time_frequency_mixed_norm_inverse.html#sphx-glr-auto-examples-inverse-time-frequency-mixed-norm-inverse-py"><span class="std std-ref">Compute MxNE with time-frequency sparse prior</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute MxNE with time-frequency sparse prior</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compute a Truncated Recursively Applied and Projected MUltiple Signal Classification (TRAP-MUSIC) Makela2018 on evoked data."><img alt="" src="../_images/sphx_glr_trap_music_thumb.png" />
<p><a class="reference internal" href="inverse/trap_music.html#sphx-glr-auto-examples-inverse-trap-music-py"><span class="std std-ref">Compute Trap-Music on evoked data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compute Trap-Music on evoked data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The source space that is used for the inverse computation defines a set of dipoles, distributed across the cortex. When visualizing a source estimate, it is sometimes useful to show the dipole directions in addition to their estimated magnitude. This can be accomplished by computing a mne.VectorSourceEstimate and plotting it with mne.VectorSourceEstimate.plot, which uses plot_vector_source_estimates under the hood rather than plot_source_estimates."><img alt="" src="../_images/sphx_glr_vector_mne_solution_thumb.gif" />
<p><a class="reference internal" href="inverse/vector_mne_solution.html#sphx-glr-auto-examples-inverse-vector-mne-solution-py"><span class="std std-ref">Plotting the full vector-valued MNE solution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting the full vector-valued MNE solution</div>
</div></div></section>
<section id="examples-on-open-datasets">
<h2>Examples on open datasets<a class="headerlink" href="#examples-on-open-datasets" title="Link to this heading">#</a></h2>
<p>Some demos on common/public datasets using MNE.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Here we compute the evoked from raw for the Brainstorm tutorial dataset. For comparison, see TadelEtAl2011 and https://neuroimage.usc.edu/brainstorm/Tutorials/MedianNerveCtf."><img alt="" src="../_images/sphx_glr_brainstorm_data_thumb.png" />
<p><a class="reference internal" href="datasets/brainstorm_data.html#sphx-glr-auto-examples-datasets-brainstorm-data-py"><span class="std std-ref">Brainstorm raw (median nerve) dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Brainstorm raw (median nerve) dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example looks at high-frequency SEF responses."><img alt="" src="../_images/sphx_glr_hf_sef_data_thumb.png" />
<p><a class="reference internal" href="datasets/hf_sef_data.html#sphx-glr-auto-examples-datasets-hf-sef-data-py"><span class="std std-ref">HF-SEF dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">HF-SEF dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this dataset, a Neuromag phantom was placed inside the Kernel OPM helmet and stimulated with 7 modules active (121 channels). Here we show some example traces."><img alt="" src="../_images/sphx_glr_kernel_phantom_thumb.png" />
<p><a class="reference internal" href="datasets/kernel_phantom.html#sphx-glr-auto-examples-datasets-kernel-phantom-py"><span class="std std-ref">Kernel OPM phantom data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Kernel OPM phantom data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we explore the structure of the data contained in the `LIMO dataset`_. This example replicates and extends some of the main analysis and tools integrated in `LIMO MEEG`_, a MATLAB toolbox originally designed to interface with EEGLAB_."><img alt="" src="../_images/sphx_glr_limo_data_thumb.png" />
<p><a class="reference internal" href="datasets/limo_data.html#sphx-glr-auto-examples-datasets-limo-data-py"><span class="std std-ref">Single trial linear regression analysis with the LIMO dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Single trial linear regression analysis with the LIMO dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this dataset, electrical median nerve stimulation was delivered to the left wrist of the subject. Somatosensory evoked fields were measured using nine QuSpin SERF OPMs placed over the right-hand side somatomotor area. Here we demonstrate how to localize these custom OPM data in MNE."><img alt="" src="../_images/sphx_glr_opm_data_thumb.png" />
<p><a class="reference internal" href="datasets/opm_data.html#sphx-glr-auto-examples-datasets-opm-data-py"><span class="std std-ref">Optically pumped magnetometer (OPM) data</span></a></p>
  <div class="sphx-glr-thumbnail-title">Optically pumped magnetometer (OPM) data</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Runs a full pipeline using MNE-Python. This example does quite a bit of processing, so even on a fast machine it can take several minutes to complete."><img alt="" src="../_images/sphx_glr_spm_faces_dataset_thumb.png" />
<p><a class="reference internal" href="datasets/spm_faces_dataset.html#sphx-glr-auto-examples-datasets-spm-faces-dataset-py"><span class="std std-ref">From raw data to dSPM on SPM Faces dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">From raw data to dSPM on SPM Faces dataset</div>
</div></div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-footer sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/07fcc19ba03226cd3d83d4e40ec44385/auto_examples_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">auto_examples_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6f1e7a639e0699d6164445b55e6c116d/auto_examples_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">auto_examples_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../auto_tutorials/visualization/20_ui_events.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Using the event system to link figures</p>
      </div>
    </a>
    <a class="right-next"
       href="io/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Input/Output</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-output">Input/Output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-simulation">Data Simulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization">Visualization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-frequency-examples">Time-Frequency Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-examples">Statistics Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-decoding-encoding-and-mvpa">Machine Learning (Decoding, Encoding, and MVPA)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectivity-analysis-examples">Connectivity Analysis Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-modeling">Forward modeling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inverse-problem-and-source-analysis">Inverse problem and source analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-on-open-datasets">Examples on open datasets</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://mne.tools/versionwarning.js"></script>
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center small">&copy; Copyright 2012–2025, MNE Developers. Last updated <time datetime="2025-07-17T06:36:01.123229+00:00" class="localized">2025-07-17 06:36 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>