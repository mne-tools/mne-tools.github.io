
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Glossary &#8212; MNE 1.0.dev0 documentation</title>
    
    <link href="_static/styles/theme.css?digest=3c0a44d549fc2482317d" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=3c0a44d549fc2482317d" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/pydata-sphinx-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    
    <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=3c0a44d549fc2482317d">
  
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/bootstrap_divs.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithms and other implementation details" href="overview/implementation.html" />
    <link rel="prev" title="From raw data to dSPM on SPM Faces dataset" href="auto_examples/datasets/spm_faces_dataset_sgskip.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        dev  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables glossary and {'json_url': 'https://mne.tools/dev/_static/versions.json', 'url_template': 'https://mne.tools/{version}/', 'version_match': 'dev'}.
-->

<script type="text/javascript">
// Construct the target URL from the JSON components
function buildURL(entry) {
    var template = "https://mne.tools/{version}/";  // supplied by jinja
    template = template.replace("{version}", entry.version);
    return template;
}

// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "glossary.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://mne.tools/dev/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "glossary.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            // get the base URL for that doc version, add the current page's
            // path to it, and set as `href`
            entry.url = buildURL(entry);
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's 1.0 variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "dev") {
                node.classList.add("active");
                $("#version_switcher_button").text(entry.name);
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/intro/index.html">
     Introductory tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/10_overview.html">
       Overview of MEG/EEG analysis with MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/15_inplace.html">
       Modifying data in-place
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html">
       Parsing events from raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/30_info.html">
       The Info data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/40_sensor_locations.html">
       Working with sensor locations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/50_configure_mne.html">
       Configuring MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/intro/70_report.html">
       Getting started with mne.Report
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/io/index.html">
     Reading data for different recording systems
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/io/10_reading_meg_data.html">
       Importing data from MEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/io/20_reading_eeg_data.html">
       Importing data from EEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/io/30_reading_fnirs_data.html">
       Importing data from fNIRS devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/io/60_ctf_bst_auditory.html">
       Working with CTF data: the Brainstorm auditory dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/raw/index.html">
     Working with continuous data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/raw/10_raw_overview.html">
       The Raw data structure: continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/raw/20_event_arrays.html">
       Working with events
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/raw/30_annotate_raw.html">
       Annotating continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/raw/40_visualize_raw.html">
       Built-in plotting methods for Raw objects
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/preprocessing/index.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/10_preprocessing_overview.html">
       Overview of artifact detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/15_handling_bad_channels.html">
       Handling bad channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/20_rejecting_bad_data.html">
       Rejecting bad data spans and breaks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/25_background_filtering.html">
       Background information on filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/30_filtering_resampling.html">
       Filtering and resampling data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/35_artifact_correction_regression.html">
       Repairing artifacts with regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/40_artifact_correction_ica.html">
       Repairing artifacts with ICA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/45_projectors_background.html">
       Background on projectors and projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
       Repairing artifacts with SSP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/55_setting_eeg_reference.html">
       Setting the EEG reference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/59_head_positions.html">
       Extracting and visualizing subject head movement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
       Signal-space separation (SSS) and Maxwell filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/preprocessing/70_fnirs_processing.html">
       Preprocessing functional near-infrared spectroscopy (fNIRS) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/epochs/index.html">
     Segmenting continuous data into epochs
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/10_epochs_overview.html">
       The Epochs data structure: discontinuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/20_visualize_epochs.html">
       Visualizing epoched data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/30_epochs_metadata.html">
       Working with Epoch metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/40_autogenerate_metadata.html">
       Auto-generating Epochs metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/50_epochs_to_data_frame.html">
       Exporting Epochs to Pandas DataFrames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/epochs/60_make_fixed_length_epochs.html">
       Divide continuous data into equally-spaced epochs
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/evoked/index.html">
     Estimating evoked responses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/evoked/10_evoked_overview.html">
       The Evoked data structure: evoked/averaged data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/evoked/20_visualize_evoked.html">
       Visualizing Evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/evoked/30_eeg_erp.html">
       EEG processing and Event Related Potentials (ERPs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/evoked/40_whitened.html">
       Plotting whitened data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/time-freq/index.html">
     Time-frequency analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/time-freq/20_sensors_time_frequency.html">
       Frequency and time-frequency sensor analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/time-freq/50_ssvep.html">
       Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/forward/index.html">
     Forward models and source spaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/10_background_freesurfer.html">
       FreeSurfer MRI reconstruction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/20_source_alignment.html">
       Source alignment and coordinate frames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/25_automated_coreg.html">
       Using an automated approach to coregistration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/30_forward.html">
       Head model and forward computation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/35_eeg_no_mri.html">
       EEG forward operator with a template MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/50_background_freesurfer_mne.html">
       How MNE uses FreeSurferâ€™s outputs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/80_fix_bem_in_blender.html">
       Editing BEM surfaces in Blender
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/forward/90_compute_covariance.html">
       Computing a covariance matrix
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/inverse/index.html">
     Source localization and inverses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/10_stc_class.html">
       The SourceEstimate data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/20_dipole_fit.html">
       Source localization with equivalent current dipole (ECD) fit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/30_mne_dspm_loreta.html">
       Source localization with MNE, dSPM, sLORETA, and eLORETA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/35_dipole_orientations.html">
       The role of dipole orientations in distributed source localization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/40_mne_fixed_free.html">
       Computing various MNE solutions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/50_beamformer_lcmv.html">
       Source reconstruction using an LCMV beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/60_visualize_stc.html">
       Visualize source time courses (stcs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/70_eeg_mri_coords.html">
       EEG source localization given electrode locations on an MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
       Brainstorm Elekta phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
       Brainstorm CTF phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/inverse/90_phantom_4DBTi.html">
       4D Neuroimaging/BTi phantom dataset tutorial
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/index.html">
     Statistical analysis of sensor data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-sensor-space/10_background_stats.html">
       Statistical inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-sensor-space/20_erp_stats.html">
       Visualising statistical significance thresholds on EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
       Non-parametric 1 sample cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
       Non-parametric between conditions cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
       Spatiotemporal permutation F-test on full sensor data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/stats-source-space/index.html">
     Statistical analysis of source estimates
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
       Permutation t-test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
       2 samples permutation test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
       Repeated measures ANOVA on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/stats-source-space/70_cluster_rmANOVA_time_freq.html">
       Mass-univariate twoway repeated measures ANOVA on single trial power
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/machine-learning/index.html">
     Machine learning models of neural activity
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/machine-learning/30_strf.html">
       Spectro-temporal receptive field (STRF) estimation on continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/machine-learning/50_decoding.html">
       Decoding (MVPA)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/clinical/index.html">
     Clinical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/clinical/10_ieeg_localize.html">
       Locating intracranial electrode contacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/clinical/20_seeg.html">
       Working with sEEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/clinical/30_ecog.html">
       Working with ECoG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/clinical/60_sleep.html">
       Sleep stage classification from polysomnography (PSG) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_tutorials/simulation/index.html">
     Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/simulation/10_array_objs.html">
       Creating MNE-Python data structures from scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/simulation/70_point_spread.html">
       Corrupt known signal with point spread
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_tutorials/simulation/80_dics.html">
       DICS for power mapping
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/io/index.html">
     Input/Output
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/io/elekta_epochs.html">
       Getting averaging info from .fif files
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/io/read_neo_format.html">
       How to use data in neural ensemble (NEO) format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/io/read_noise_covariance_matrix.html">
       Reading/Writing a noise covariance matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/io/read_xdf.html">
       Reading XDF EEG data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/simulation/index.html">
     Data Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/simulation/simulate_evoked_data.html">
       Generate simulated evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/simulation/simulate_raw_data.html">
       Generate simulated raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
       Simulate raw data using subject anatomy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/simulation/source_simulator.html">
       Generate simulated source data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/preprocessing/index.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/css.html">
       Cortical Signal Suppression (CSS) for removal of cortical signals
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/define_target_events.html">
       Define target events based on time lag, plot evoked response
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/eeg_csd.html">
       Transform EEG data using current source density (CSD)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/eog_artifact_histogram.html">
       Show EOG artifact timing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/find_ref_artifacts.html">
       Find MEG reference channel artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/fnirs_artifact_removal.html">
       Visualise NIRS artifact correction methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/ica_comparison.html">
       Compare the different ICA algorithms in MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/interpolate_bad_channels.html">
       Interpolate bad channels for MEG/EEG channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/movement_compensation.html">
       Maxwell filter data with movement compensation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/movement_detection.html">
       Annotate movement artifacts and reestimate dev_head_t
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/muscle_detection.html">
       Annotate muscle artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/otp.html">
       Plot sensor denoising using oversampled temporal projection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/shift_evoked.html">
       Shifting time-scale in evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/virtual_evoked.html">
       Remap MEG channel types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/preprocessing/xdawn_denoising.html">
       XDAWN Denoising
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/visualization/index.html">
     Visualization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/3d_to_2d.html">
       How to convert 3D electrode positions to a 2D image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/brain.html">
       Plotting with
       <code class="docutils literal notranslate">
        <span class="pre">
         mne.viz.Brain
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/channel_epochs_image.html">
       Visualize channel over epochs as an image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/eeg_on_scalp.html">
       Plotting EEG sensors on the scalp
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/eeglab_head_sphere.html">
       How to plot topomaps the way EEGLAB does
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/evoked_arrowmap.html">
       Plotting topographic arrowmaps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/evoked_topomap.html">
       Plotting topographic maps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/evoked_whitening.html">
       Whitening evoked data with a noise covariance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/meg_sensors.html">
       Plotting sensor layouts of MEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/mne_helmet.html">
       Plot the MNE brain and helmet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/montage_sgskip.html">
       Plotting sensor layouts of EEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/parcellation.html">
       Plot a cortical parcellation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/publication_figure.html">
       Make figures more publication ready
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/roi_erpimage_by_rt.html">
       Plot single trial activity, grouped by ROI and sorted by RT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/sensor_noise_level.html">
       Show noise levels from empty room data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/ssp_projs_sensitivity_map.html">
       Sensitivity map of SSP projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/topo_compare_conditions.html">
       Compare evoked responses for different conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/topo_customized.html">
       Plot custom topographies for MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/visualization/xhemi.html">
       Cross-hemisphere comparison
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/time_frequency/index.html">
     Time-Frequency Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/compute_csd.html">
       Compute a cross-spectral density (CSD) matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/compute_source_psd_epochs.html">
       Compute Power Spectral Density of inverse solution from single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/source_label_time_frequency.html">
       Compute power and phase lock in label of the source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/source_power_spectrum.html">
       Compute source power spectral density (PSD) in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/source_power_spectrum_opm.html">
       Compute source power spectral density (PSD) of VectorView and OPM data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/source_space_time_frequency.html">
       Compute induced power in the source space with dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/temporal_whitening.html">
       Temporal whitening with AR model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/time_frequency_erds.html">
       Compute and visualize ERDS maps
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/time_frequency_global_field_power.html">
       Explore event-related dynamics for specific frequency bands
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/time_frequency/time_frequency_simulated.html">
       Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/stats/index.html">
     Statistics Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/stats/cluster_stats_evoked.html">
       Permutation F-test on sensor data with 1D cluster level
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/stats/fdr_stats_evoked.html">
       FDR correction on T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/stats/linear_regression_raw.html">
       Regression on continuous data (rER[P/F])
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/stats/sensor_permutation_test.html">
       Permutation T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/stats/sensor_regression.html">
       Analysing continuous features with binning and regression in sensor space
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/decoding/index.html">
     Machine Learning (Decoding, Encoding, and MVPA)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_csp_eeg.html">
       Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_csp_timefreq.html">
       Decoding in time-frequency space using Common Spatial Patterns (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_rsa_sgskip.html">
       Representational Similarity Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_spatio_temporal_source.html">
       Decoding source space data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_spoc_CMC.html">
       Continuous Target Decoding with SPoC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_time_generalization_conditions.html">
       Decoding sensor space data with generalization across time and conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
       Analysis of evoked response using ICA and PCA reduction techniques
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/decoding_xdawn_eeg.html">
       XDAWN Decoding From EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/ems_filtering.html">
       Compute effect-matched-spatial filtering (EMS)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/linear_model_patterns.html">
       Linear classifier on sensor data with plot patterns and filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/receptive_field_mtrf.html">
       Receptive Field Estimation and Prediction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/decoding/ssd_spatial_filters.html">
       Compute Spectro-Spatial Decomposition (SSD) spatial filters
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/connectivity/index.html">
     Connectivity Analysis Examples
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/forward/index.html">
     Forward modeling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/forward/forward_sensitivity_maps.html">
       Display sensitivity maps for EEG and MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/forward/left_cerebellum_volume_source.html">
       Generate a left cerebellum volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/forward/source_space_morphing.html">
       Use source space morphing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/inverse/index.html">
     Inverse problem and source analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
       Compute MNE-dSPM inverse solution on single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
       Compute sLORETA inverse solution on raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_volume.html">
       Compute MNE-dSPM inverse solution on evoked data in volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/custom_inverse_solver.html">
       Source localization with a custom inverse solver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/dics_source_power.html">
       Compute source power using DICS beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/evoked_ers_source_power.html">
       Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/gamma_map_inverse.html">
       Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/label_activation_from_stc.html">
       Extracting time course from source_estimate object
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/label_from_stc.html">
       Generate a functional label from source estimates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/label_source_activations.html">
       Extracting the time series of activations in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/mixed_norm_inverse.html">
       Compute sparse inverse solution with mixed norm: MxNE and irMxNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/mixed_source_space_inverse.html">
       Compute MNE inverse solution on evoked data with a mixed source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/mne_cov_power.html">
       Compute source power estimate by projecting the covariance with MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/morph_surface_stc.html">
       Morph surface source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/morph_volume_stc.html">
       Morph volumetric source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/multidict_reweighted_tfmxne.html">
       Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/psf_ctf_label_leakage.html">
       Visualize source leakage among labels using a circular graph
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/psf_ctf_vertices.html">
       Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/psf_ctf_vertices_lcmv.html">
       Compute cross-talk functions for LCMV beamformers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/rap_music.html">
       Compute Rap-Music on evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/read_inverse.html">
       Reading an inverse operator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/read_stc.html">
       Reading an STC file
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/resolution_metrics.html">
       Compute spatial resolution metrics in source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/resolution_metrics_eegmeg.html">
       Compute spatial resolution metrics to compare MEG with EEG+MEG
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/snr_estimate.html">
       Estimate data SNR using an inverse
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/source_space_snr.html">
       Computing source space SNR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
       Compute MxNE with time-frequency sparse prior
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/inverse/vector_mne_solution.html">
       Plotting the full vector-valued MNE solution
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="auto_examples/datasets/index.html">
     Examples on open datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
    <label for="toctree-checkbox-26">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/datasets/brainstorm_data.html">
       Brainstorm raw (median nerve) dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/datasets/hf_sef_data.html">
       HF-SEF dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/datasets/limo_data.html">
       Single trial linear regression analysis with the LIMO dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/datasets/opm_data.html">
       Optically pumped magnetometer (OPM) data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="auto_examples/datasets/spm_faces_dataset_sgskip.html">
       From raw data to dSPM on SPM Faces dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <section id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">Â¶</a></h1>
<p>The Glossary provides short definitions of vocabulary specific to MNE-Python and
general neuroimaging concepts. If you think a term is missing, please consider
<a class="reference external" href="https://github.com/mne-tools/mne-python/issues/new?template=glossary.md">creating a new issue</a> or <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/new/main">opening a pull request</a> to add it.</p>
<dl class="glossary">
<dt id="term-annotations">annotations<a class="headerlink" href="#term-annotations" title="Permalink to this term">Â¶</a></dt><dd><p>An annotation is defined by an onset, a duration, and a textual
description. It can contain information about the experiment, but
also details on signals marked by a human such as bad data segments,
sleep stages, sleep events (spindles, K-complex), and so on.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container for multiple annotations,
which is available as the <code class="docutils literal notranslate"><span class="pre">annotations</span></code> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects. See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> for the class definition and
<a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html#tut-events-vs-annotations"><span class="std std-ref">Parsing events from raw data</span></a> for a short tutorial.
See also <a class="reference internal" href="#term-events"><span class="xref std std-term">events</span></a>.</p>
</dd>
<dt id="term-array-like">array-like<a class="headerlink" href="#term-array-like" title="Permalink to this term">Â¶</a></dt><dd><p>Something that acts like â€“ or can be converted to â€“ a
<a class="reference external" href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.23.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">NumPy</span> <span class="pre">array</span></code></a>.
This includes (but is not limited to)
<a class="reference external" href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.23.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">arrays</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lists</span></code></a>, and
<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuples</span></code></a>.</p>
</dd>
<dt id="term-beamformer">beamformer<a class="headerlink" href="#term-beamformer" title="Permalink to this term">Â¶</a></dt><dd><p>A beamformer is a popular source estimation approach that uses a set of
spatial filters (beamformer weights) to compute time courses of sources
at predefined locations. See <a class="reference internal" href="generated/mne.beamformer.Beamformer.html#mne.beamformer.Beamformer" title="mne.beamformer.Beamformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">beamformer.Beamformer</span></code></a> for the class
definition. See also <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>.</p>
</dd>
<dt id="term-BEM">BEM<a class="headerlink" href="#term-BEM" title="Permalink to this term">Â¶</a></dt><dt id="term-boundary-element-model">boundary element model<a class="headerlink" href="#term-boundary-element-model" title="Permalink to this term">Â¶</a></dt><dt id="term-boundary-element-method">boundary element method<a class="headerlink" href="#term-boundary-element-method" title="Permalink to this term">Â¶</a></dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the definion of the conductor model in the
forward model computation. The boundary element model consists of surfaces
such as the inner skull, outer skull, and outer skin (scalp) that define
compartments of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for a usage demo.</p>
</dd>
<dt id="term-channels">channels<a class="headerlink" href="#term-channels" title="Permalink to this term">Â¶</a></dt><dd><p>Channels refer to MEG sensors, EEG electrodes or other sensors such as
EOG, ECG, sEEG, ECoG, etc. Channels usually have
a type (such as gradiometer), and a unit (such as T/m) used e.g. for
plotting. See also <a class="reference internal" href="#term-data-channels"><span class="xref std std-term">data channels</span></a>.</p>
</dd>
<dt id="term-data-channels">data channels<a class="headerlink" href="#term-data-channels" title="Permalink to this term">Â¶</a></dt><dd><p>Many functions in MNE-Python operate on â€œdata channelsâ€ by default. These
are channels that contain electrophysiological data from the brain,
as opposed to other channel types such as EOG, ECG, stimulus/trigger,
or acquisition system status data. The set of channels considered
â€œdata channelsâ€ in MNE contains the following types (together with scale
factors for plotting):</p>
<div class="compound">
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'mag'</span></code>: <strong>Magnetometers</strong> (scaled by 1e+15 to plot in <em>fT</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'grad'</span></code>: <strong>Gradiometers</strong> (scaled by 1e+13 to plot in <em>fT/cm</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'eeg'</span></code>: <strong>EEG</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'csd'</span></code>: <strong>Current source density</strong> (scaled by 1000 to plot in <em>mV/mÂ²</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'seeg'</span></code>: <strong>sEEG</strong> (scaled by 1000 to plot in <em>mV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ecog'</span></code>: <strong>ECoG</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dbs'</span></code>: <strong>DBS</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbo'</span></code>: <strong>Oxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>ÂµM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbr'</span></code>: <strong>Deoxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>ÂµM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_cw_amplitude'</span></code>: <strong>fNIRS (CW amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_ac_amplitude'</span></code>: <strong>fNIRS (FD AC amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_phase'</span></code>: <strong>fNIRS (FD phase)</strong> (scaled by 1 to plot in <em>rad</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_od'</span></code>: <strong>fNIRS (OD)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
</ul>
</div>
</dd>
<dt id="term-DICS">DICS<a class="headerlink" href="#term-DICS" title="Permalink to this term">Â¶</a></dt><dt id="term-dynamic-imaging-of-coherent-sources">dynamic imaging of coherent sources<a class="headerlink" href="#term-dynamic-imaging-of-coherent-sources" title="Permalink to this term">Â¶</a></dt><dd><p>Dynamic Imaging of Coherent Sources is a method for computing source
power in different frequency bands. See <a class="reference internal" href="auto_examples/inverse/dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a>
and <a class="reference internal" href="generated/mne.beamformer.make_dics.html#mne.beamformer.make_dics" title="mne.beamformer.make_dics"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_dics()</span></code></a> for more details.</p>
</dd>
<dt id="term-digitization">digitization<a class="headerlink" href="#term-digitization" title="Permalink to this term">Â¶</a></dt><dd><p>Digitization is a procedure of recording the head shape and locations of
fiducial coils (or <a class="reference internal" href="#term-HPI"><span class="xref std std-term">HPI</span></a>) and/or EEG electrodes on the head. They
are represented as a set of points in 3D space.
See <a class="reference internal" href="auto_tutorials/intro/40_sensor_locations.html#reading-dig-montages"><span class="std std-ref">Reading sensor digitization files</span></a> and <a class="reference internal" href="overview/implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>.</p>
</dd>
<dt id="term-dipole">dipole<a class="headerlink" href="#term-dipole" title="Permalink to this term">Â¶</a></dt><dt id="term-ECD">ECD<a class="headerlink" href="#term-ECD" title="Permalink to this term">Â¶</a></dt><dt id="term-equivalent-current-dipole">equivalent current dipole<a class="headerlink" href="#term-equivalent-current-dipole" title="Permalink to this term">Â¶</a></dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small cortical region. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by these techniques
are well approximated by (i.e., equivalent to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-dSPM">dSPM<a class="headerlink" href="#term-dSPM" title="Permalink to this term">Â¶</a></dt><dt id="term-dynamic-statistical-parametric-mapping">dynamic statistical parametric mapping<a class="headerlink" href="#term-dynamic-statistical-parametric-mapping" title="Permalink to this term">Â¶</a></dt><dd><p>Dynamic statistical parametric mapping (dSPM) gives a noise-normalized
minimum-norm estimate at a given source location. It is calculated by
dividing the activity estimate at each source location by the baseline
standard deviation of the noise.</p>
</dd>
<dt id="term-eLORETA">eLORETA<a class="headerlink" href="#term-eLORETA" title="Permalink to this term">Â¶</a></dt><dt id="term-sLORETA">sLORETA<a class="headerlink" href="#term-sLORETA" title="Permalink to this term">Â¶</a></dt><dd><p>eLORETA and sLORETA (exact and standardized low resolution brain
electromagnetic tomography) are linear source estimation techniques
like <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a> and <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>. sLORETA outputs
standardized values (like dSPM), while eLORETA generates normalized
current estimates. See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>,
<a class="reference internal" href="auto_tutorials/inverse/30_mne_dspm_loreta.html#tut-inverse-methods"><span class="std std-ref">Source localization with MNE, dSPM, sLORETA, and eLORETA</span></a>, and <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_raw_in_label.html#example-sloreta"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a>.</p>
</dd>
<dt id="term-epochs">epochs<a class="headerlink" href="#term-epochs" title="Permalink to this term">Â¶</a></dt><dd><p>Epochs (sometimes called â€œtrialsâ€ in other software packages) are
equal-length segments of data extracted from continuous data. Usually,
epochs are extracted around stimulus events or responses,
though sometimes sequential or overlapping epochs are used (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
class definition and <a class="reference internal" href="auto_tutorials/epochs/10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-events">events<a class="headerlink" href="#term-events" title="Permalink to this term">Â¶</a></dt><dd><p>Events correspond to specific time points in raw data, such as triggers,
experimental condition events, etc. MNE-Python represents events with
integers stored in NumPy arrays of shape <code class="docutils literal notranslate"><span class="pre">(n_events,</span> <span class="pre">3)</span></code>. The first
column contains the event onset (in samples) with <a class="reference internal" href="#term-first_samp"><span class="xref std std-term">first_samp</span></a>
included. The last column contains the event code. The second
column contains the signal value of the immediately preceding sample,
and reflects the fact that event arrays sometimes originate from
analog voltage channels (â€œtrigger channelsâ€ or â€œstim channelsâ€). In
most cases, the second column is all zeros and can be ignored.
Event arrays can be created with <a class="reference internal" href="generated/mne.make_fixed_length_events.html#mne.make_fixed_length_events" title="mne.make_fixed_length_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.make_fixed_length_events()</span></code></a>,
<a class="reference internal" href="generated/mne.read_events.html#mne.read_events" title="mne.read_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.read_events()</span></code></a>, and <a class="reference internal" href="generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.find_events()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html#tut-events-vs-annotations"><span class="std std-ref">Parsing events from raw data</span></a> for a short tutorial.
See also <a class="reference internal" href="#term-events"><span class="xref std std-term">events</span></a>.</p>
</dd>
<dt id="term-evoked">evoked<a class="headerlink" href="#term-evoked" title="Permalink to this term">Â¶</a></dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked objects over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the class definition and
<a class="reference internal" href="auto_tutorials/evoked/10_evoked_overview.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-fiducial">fiducial<a class="headerlink" href="#term-fiducial" title="Permalink to this term">Â¶</a></dt><dt id="term-fiducial-point">fiducial point<a class="headerlink" href="#term-fiducial-point" title="Permalink to this term">Â¶</a></dt><dt id="term-anatomical-landmark">anatomical landmark<a class="headerlink" href="#term-anatomical-landmark" title="Permalink to this term">Â¶</a></dt><dd><p>Fiducials are objects placed in the field of view of an imaging system
to act as known spatial references that are easy to localize.
In neuroimaging, fiducials are often placed on anatomical landmarks
such as the nasion (NAS) or left/right preauricular points (LPA and
RPA).</p>
<p>These known reference locations are used to define a coordinate system
for localizing sensors (hence NAS, LPA and RPA are often
called â€œcardinal pointsâ€ because they define the cardinal directions of
the head coordinate system). The cardinal points are also useful when
co-registering measurements in different coordinate systems (such as
aligning EEG sensor locations to an MRI of the head).</p>
<p>Due to the common neuroimaging practice of placing fiducial objects on
anatomical landmarks, the terms â€œfiducialâ€, â€œanatomical landmarkâ€, and
â€œcardinal pointâ€ are often (erroneously) used interchangeably.</p>
</dd>
<dt id="term-first_samp">first_samp<a class="headerlink" href="#term-first_samp" title="Permalink to this term">Â¶</a></dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data recording started. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files. See also
<a class="reference internal" href="#term-last_samp"><span class="xref std std-term">last_samp</span></a>.</p>
</dd>
<dt id="term-forward">forward<a class="headerlink" href="#term-forward" title="Permalink to this term">Â¶</a></dt><dt id="term-forward-solution">forward solution<a class="headerlink" href="#term-forward-solution" title="Permalink to this term">Â¶</a></dt><dd><p>The forward solution is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors
(the â€œlead field matrixâ€). Calculating a forward solution requires a
conductivity model of the head, which encapsulates the geometries and
electrical conductivities of the different tissue compartments (see
<a class="reference internal" href="#term-boundary-element-model"><span class="xref std std-term">boundary element model</span></a> and <a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-FreeSurfer-LUT">FreeSurfer LUT<a class="headerlink" href="#term-FreeSurfer-LUT" title="Permalink to this term">Â¶</a></dt><dt id="term-LUT">LUT<a class="headerlink" href="#term-LUT" title="Permalink to this term">Â¶</a></dt><dd><p>A FreeSurfer lookup table (LUT) provides a mapping between a given
volumetric atlas or surface label name, its integer value
(e.g., in <code class="docutils literal notranslate"><span class="pre">aparc+aseg.mgz</span></code>), and its standard color (see the
<a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT">FreeSurfer wiki</a>
for more information). Custom LUTs can be also be created from different
surface parcellations, see for example <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/7639#issuecomment-625907891">this comment about HCPMMP</a>.</p>
</dd>
<dt id="term-GFP">GFP<a class="headerlink" href="#term-GFP" title="Permalink to this term">Â¶</a></dt><dt id="term-global-field-power">global field power<a class="headerlink" href="#term-global-field-power" title="Permalink to this term">Â¶</a></dt><dd><p>Global Field Power (GFP) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point. Thus,
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-HED">HED<a class="headerlink" href="#term-HED" title="Permalink to this term">Â¶</a></dt><dt id="term-hierarchical-event-descriptors">hierarchical event descriptors<a class="headerlink" href="#term-hierarchical-event-descriptors" title="Permalink to this term">Â¶</a></dt><dd><p>Hierarchical event descriptors (HED) are tags that use
keywords separated by slashes (/) to describe different types of
experimental events (for example, <code class="docutils literal notranslate"><span class="pre">stimulus/circle/red/left</span></code> and
<code class="docutils literal notranslate"><span class="pre">stimulus/circle/blue/left</span></code>). These tags can be used to group
experimental events and select event types for analysis.</p>
</dd>
<dt id="term-HPI">HPI<a class="headerlink" href="#term-HPI" title="Permalink to this term">Â¶</a></dt><dt id="term-cHPI">cHPI<a class="headerlink" href="#term-cHPI" title="Permalink to this term">Â¶</a></dt><dt id="term-head-position-indicator">head position indicator<a class="headerlink" href="#term-head-position-indicator" title="Permalink to this term">Â¶</a></dt><dd><p>Head position indicators (HPI, sometimes cHPI for
<em>continuous</em> head position indicators) are small coils attached to a
subjectâ€™s head during MEG acquisition. Each coil emits a sinusoidal
signal of a different frequency, which is picked up by the MEG sensors
and can be used to infer the head position. With cHPI, the sinusoidal
signals are typically set at frequencies above any neural signal of
interest, and thus can be removed after head position correction via
low-pass filtering. See <a class="reference internal" href="auto_tutorials/preprocessing/59_head_positions.html#tut-head-pos"><span class="std std-ref">Extracting and visualizing subject head movement</span></a>.</p>
</dd>
<dt id="term-info">info<a class="headerlink" href="#term-info" title="Permalink to this term">Â¶</a></dt><dt id="term-measurement-info">measurement info<a class="headerlink" href="#term-measurement-info" title="Permalink to this term">Â¶</a></dt><dd><p>A â€œmeasurement infoâ€ (or short â€œinfoâ€) object is a collection of metadata
related to <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a>, or <a class="reference internal" href="generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a>
objects. It contains channel locations and types, sampling frequency,
preprocessing history such as filters, etc.
See <a class="reference internal" href="auto_tutorials/intro/30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse">inverse<a class="headerlink" href="#term-inverse" title="Permalink to this term">Â¶</a></dt><dt id="term-inverse-operator">inverse operator<a class="headerlink" href="#term-inverse-operator" title="Permalink to this term">Â¶</a></dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>, <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>, <a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, and
<a class="reference internal" href="#term-eLORETA"><span class="xref std std-term">eLORETA</span></a>. See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>.</p>
</dd>
<dt id="term-label">label<a class="headerlink" href="#term-label" title="Permalink to this term">Â¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a defined region in the cortex, often called
a region of interest (ROI) in the literature. Labels can be defined
anatomically (based on the physical structure of the cortex) or functionally
(based on cortical responses to specific stimuli). See also <a class="reference internal" href="#term-ROI"><span class="xref std std-term">ROI</span></a>.</p>
</dd>
<dt id="term-last_samp">last_samp<a class="headerlink" href="#term-last_samp" title="Permalink to this term">Â¶</a></dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.last_samp" title="mne.io.Raw.last_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">last_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the start and end of data recording. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. See also <a class="reference internal" href="#term-first_samp"><span class="xref std std-term">first_samp</span></a>.</p>
</dd>
<dt id="term-layout">layout<a class="headerlink" href="#term-layout" title="Permalink to this term">Â¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> gives sensor positions in two
dimensions (defined by <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code>, and <code class="docutils literal notranslate"><span class="pre">height</span></code> values for
each sensor). It is primarily used for illustrative purposes (i.e., making
diagrams of approximate sensor positions in cartoons of the head,
so-called topographies or topomaps). See also <a class="reference internal" href="#term-montage"><span class="xref std std-term">montage</span></a>.</p>
</dd>
<dt id="term-LCMV">LCMV<a class="headerlink" href="#term-LCMV" title="Permalink to this term">Â¶</a></dt><dt id="term-LCMV-beamformer">LCMV beamformer<a class="headerlink" href="#term-LCMV-beamformer" title="Permalink to this term">Â¶</a></dt><dd><p>Linearly constrained minimum variance beamformer attempt to
estimate activity for a given source while suppressing cross-talk from
other regions (<a class="reference internal" href="generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_lcmv()</span></code></a>). See also
<a class="reference internal" href="#term-beamformer"><span class="xref std std-term">beamformer</span></a>.</p>
</dd>
<dt id="term-maximum-intensity-projection">maximum intensity projection<a class="headerlink" href="#term-maximum-intensity-projection" title="Permalink to this term">Â¶</a></dt><dd><p>A method to display pixel-wise activity within some volume by
finding the maximum value along a vector from the viewer to the pixel
(i.e., along the vector pependicular to the view plane).</p>
</dd>
<dt id="term-MNE">MNE<a class="headerlink" href="#term-MNE" title="Permalink to this term">Â¶</a></dt><dt id="term-minimum-norm-estimate">minimum-norm estimate<a class="headerlink" href="#term-minimum-norm-estimate" title="Permalink to this term">Â¶</a></dt><dt id="term-minimum-norm-estimation">minimum-norm estimation<a class="headerlink" href="#term-minimum-norm-estimation" title="Permalink to this term">Â¶</a></dt><dd><p>Minimum-norm estimation (MNE) can be used to generate a distributed
map of activation on a <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a> (usually on a cortical surface).
MNE uses a linear <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project sensor measurements
into the source space. The <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> is computed from the
<a class="reference internal" href="#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for a subject and an estimate of the
<a class="reference internal" href="#term-noise-covariance"><span class="xref std std-term">noise covariance</span></a> of sensor measurements.</p>
</dd>
<dt id="term-montage">montage<a class="headerlink" href="#term-montage" title="Permalink to this term">Â¶</a></dt><dd><p>EEG channel names and relative positions of sensors on the scalp.
While layouts are 2D locations, montages are 3D locations. A montage
can also contain locations for HPI points, fiducial points, or
extra head shape points.
See <a class="reference internal" href="generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">DigMontage</span></code></a> for the class definition. See also
<a class="reference internal" href="#term-layout"><span class="xref std std-term">layout</span></a>.</p>
</dd>
<dt id="term-morphing">morphing<a class="headerlink" href="#term-morphing" title="Permalink to this term">Â¶</a></dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is known as realignment in the fMRI
literature. This operation is necessary for group studies to get the
data into a common space for statistical analysis.
See <a class="reference internal" href="overview/implementation.html#ch-morph"><span class="std std-ref">Morphing and averaging source estimates</span></a> for more details.</p>
</dd>
<dt id="term-noise-covariance">noise covariance<a class="headerlink" href="#term-noise-covariance" title="Permalink to this term">Â¶</a></dt><dd><p>The noise covariance is a matrix that contains the covariance between data
channels. It is a square matrix with shape <code class="docutils literal notranslate"><span class="pre">n_channels</span></code> <span class="math notranslate nohighlight">\(\times\)</span>
<code class="docutils literal notranslate"><span class="pre">n_channels</span></code>. It is especially useful when working with multiple sensor
types (e.g. EEG and MEG). In practice, the matrix is estimated from baseline
periods or empty room measurements, and it also provides a noise model
that can be used for subsequent analysis (like source imaging).</p>
</dd>
<dt id="term-path-like">path-like<a class="headerlink" href="#term-path-like" title="Permalink to this term">Â¶</a></dt><dd><p>Something that acts like a path in a file system. This can be a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>
or a <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.10)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pathlib.Path</span></code></a>.</p>
</dd>
<dt id="term-pick">pick<a class="headerlink" href="#term-pick" title="Permalink to this term">Â¶</a></dt><dd><p>An integer that is the index of a channel in the <a class="reference internal" href="#term-measurement-info"><span class="xref std std-term">measurement info</span></a>.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector<a class="headerlink" href="#term-projector" title="Permalink to this term">Â¶</a></dt><dt id="term-SSP">SSP<a class="headerlink" href="#term-SSP" title="Permalink to this term">Â¶</a></dt><dd><p>A projector, also referred to as Signal Space
Projection (SSP), defines a linear operation applied spatially to EEG
or MEG data. A matrix multiplication of an SSP projector with the data
will reduce the rank of the data by projecting it to a
lower-dimensional subspace. Such projections are typically applied to
both the data and the forward operator when performing
source localization. Note that EEG average referencing can be done
using such a projection operator. Projectors are stored alongside data
in the <a class="reference internal" href="#term-measurement-info"><span class="xref std std-term">measurement info</span></a> in the field <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-RAS">RAS<a class="headerlink" href="#term-RAS" title="Permalink to this term">Â¶</a></dt><dd><p>Right-Anterior-Superior, denoting the standard way to define coordinate
frames in MNE-Python:</p>
<dl class="simple">
<dt>R</dt><dd><p>+X is right, -X is left</p>
</dd>
<dt>A</dt><dd><p>+Y is anterior (front), -Y is posterior (rear)</p>
</dd>
<dt>S</dt><dd><p>+Z is superior (top), -Z is inferior (bottom)</p>
</dd>
</dl>
</dd>
<dt id="term-raw">raw<a class="headerlink" href="#term-raw" title="Permalink to this term">Â¶</a></dt><dd><p><a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects hold continuous data (preprocessed or not), typically
obtained from reading recordings stored in a file.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the class definition and <a class="reference internal" href="auto_tutorials/raw/10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a>
for a narrative overview.</p>
</dd>
<dt id="term-ROI">ROI<a class="headerlink" href="#term-ROI" title="Permalink to this term">Â¶</a></dt><dt id="term-region-of-interest">region of interest<a class="headerlink" href="#term-region-of-interest" title="Permalink to this term">Â¶</a></dt><dd><p>A spatial region where an experimental effect is expected to manifest.
This can be a collection of sensors or, when performing inverse imaging,
a set of vertices on the cortical surface or within the cortical volume.
See also <a class="reference internal" href="#term-label"><span class="xref std std-term">label</span></a>.</p>
</dd>
<dt id="term-selection">selection<a class="headerlink" href="#term-selection" title="Permalink to this term">Â¶</a></dt><dd><p>A selection is a set of picked channels (for example, all sensors
falling within a <a class="reference internal" href="#term-region-of-interest"><span class="xref std std-term">region of interest</span></a>).</p>
</dd>
<dt id="term-source-space">source space<a class="headerlink" href="#term-source-space" title="Permalink to this term">Â¶</a></dt><dd><p>A source space specifies where in the brain source amplitudes are
estimated. It corresponds to locations of a set of
candidate <a class="reference internal" href="#term-ECD"><span class="xref std std-term">equivalent current dipoles</span></a>. MNE-Python mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See <a class="reference internal" href="auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>
to read about how to compute a forward operator in a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the class definition.</p>
</dd>
<dt id="term-STC">STC<a class="headerlink" href="#term-STC" title="Permalink to this term">Â¶</a></dt><dt id="term-source-estimate">source estimate<a class="headerlink" href="#term-source-estimate" title="Permalink to this term">Â¶</a></dt><dt id="term-source-time-course">source time course<a class="headerlink" href="#term-source-time-course" title="Permalink to this term">Â¶</a></dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods such as <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>,
<a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>, or MxNE.
STCs contain the amplitudes of the neural sources over time.
In MNE-Python, <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a> objects only store the
amplitudes of activation but not the locations of the sources. The
locations are stored separately in the <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> object
that was used to compute the forward operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>,
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, and <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>.</p>
</dd>
<dt id="term-stim-channel">stim channel<a class="headerlink" href="#term-stim-channel" title="Permalink to this term">Â¶</a></dt><dt id="term-trigger-channel">trigger channel<a class="headerlink" href="#term-trigger-channel" title="Permalink to this term">Â¶</a></dt><dd><p>A stim channel or trigger channel is a channel that encodes
events during the recording. It is typically a channel that is always
zero and takes positive values when something happens (such as the
onset of a stimulus or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-tfr">tfr<a class="headerlink" href="#term-tfr" title="Permalink to this term">Â¶</a></dt><dd><p>A time-frequency representation (TFR) is often a spectrogram (STFT) or
scaleogram (wavelet) showing the frequency content as a function of
time.</p>
</dd>
<dt id="term-trans">trans<a class="headerlink" href="#term-trans" title="Permalink to this term">Â¶</a></dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
<dt id="term-whitening">whitening<a class="headerlink" href="#term-whitening" title="Permalink to this term">Â¶</a></dt><dd><p>A linear operation that transforms data with a known covariance
structure into â€œwhitened dataâ€, which has a covariance structure equal to
the identity matrix. In other words, whitening creates virtual channels that
are uncorrelated and have unit variance. This is also known as a
sphering transformation.</p>
<p>The term â€œwhiteningâ€ comes from the fact that light with a flat
frequency spectrum in the visible range is white, whereas
non-uniform frequency spectra lead to perception of different colors
(e.g., â€œpink noiseâ€ has a <code class="docutils literal notranslate"><span class="pre">1/f</span></code> characteristic, which for visible
light would appear pink).</p>
</dd>
</dl>
</section>


  
</div>

              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="auto_examples/datasets/spm_faces_dataset_sgskip.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">From raw data to dSPM on SPM Faces dataset</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="overview/implementation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Algorithms and other implementation details</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
    <script src="_static/scripts/pydata-sphinx-theme.js?digest=3c0a44d549fc2482317d"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012â€“2022, MNE Developers. Last updated <time datetime="2022-03-19T15:48:13.342818+00:00" class="localized">2022-03-19 15:48 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>