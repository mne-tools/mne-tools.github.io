
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Glossary &#8212; MNE 0.24.dev0 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/bootstrap_divs.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithms and other implementation details" href="overview/implementation.html" />
    <link rel="prev" title="From raw data to dSPM on SPM Faces dataset" href="auto_examples/datasets/spm_faces_dataset_sgskip.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/mne_logo_small.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="overview/development.html">
  Development
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown">
    <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
        v0.24.dev0
        <span class="caret"></span>
    </button>
    <div class="dropdown-menu list-group-flush py-0" aria-labelledby="dLabelMore">
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/dev/index.html">v0.24 (devel)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/stable/index.html">v0.23 (stable)</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.22/index.html">v0.22</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.21/index.html">v0.21</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.20/index.html">v0.20</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.19/index.html">v0.19</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.18/index.html">v0.18</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.17/index.html">v0.17</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.16/index.html">v0.16</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.15/index.html">v0.15</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.14/index.html">v0.14</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.13/index.html">v0.13</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.12/index.html">v0.12</a>
        <a class="list-group-item list-group-item-action py-1" href="https://mne.tools/0.11/index.html">v0.11</a>
    </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mne-tools/mne-python" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/mne_python" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mne.discourse.group/" rel="noopener" target="_blank" title="Discourse">
            <span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://discord.gg/rKfvxTuATa" rel="noopener" target="_blank" title="Discord">
            <span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/10_overview.html">
     Overview of MEG/EEG analysis with MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/15_inplace.html">
     Modifying data in-place
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html">
     Parsing events from raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/30_info.html">
     The Info data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/40_sensor_locations.html">
     Working with sensor locations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/50_configure_mne.html">
     Configuring MNE-Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/intro/70_report.html">
     Getting started with
     <code class="docutils literal notranslate">
      <span class="pre">
       mne.Report
      </span>
     </code>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/io/10_reading_meg_data.html">
     Importing data from MEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/io/20_reading_eeg_data.html">
     Importing data from EEG devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/io/30_reading_fnirs_data.html">
     Importing data from fNIRS devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/io/60_ctf_bst_auditory.html">
     Working with CTF data: the Brainstorm auditory dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/raw/10_raw_overview.html">
     The Raw data structure: continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/raw/20_event_arrays.html">
     Working with events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/raw/30_annotate_raw.html">
     Annotating continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/raw/40_visualize_raw.html">
     Built-in plotting methods for Raw objects
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/10_preprocessing_overview.html">
     Overview of artifact detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/15_handling_bad_channels.html">
     Handling bad channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/20_rejecting_bad_data.html">
     Rejecting bad data spans and breaks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/25_background_filtering.html">
     Background information on filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/30_filtering_resampling.html">
     Filtering and resampling data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/35_artifact_correction_regression.html">
     Repairing artifacts with regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/40_artifact_correction_ica.html">
     Repairing artifacts with ICA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/45_projectors_background.html">
     Background on projectors and projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
     Repairing artifacts with SSP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/55_setting_eeg_reference.html">
     Setting the EEG reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/59_head_positions.html">
     Extracting and visualizing subject head movement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
     Signal-space separation (SSS) and Maxwell filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/preprocessing/70_fnirs_processing.html">
     Preprocessing functional near-infrared spectroscopy (fNIRS) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/10_epochs_overview.html">
     The Epochs data structure: discontinuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/20_visualize_epochs.html">
     Visualizing epoched data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/30_epochs_metadata.html">
     Working with Epoch metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/40_autogenerate_metadata.html">
     Auto-generating
     <code class="docutils literal notranslate">
      <span class="pre">
       Epochs
      </span>
     </code>
     metadata
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/50_epochs_to_data_frame.html">
     Exporting Epochs to Pandas DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/epochs/60_make_fixed_length_epochs.html">
     Creating epochs of equal length
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/evoked/10_evoked_overview.html">
     The Evoked data structure: evoked/averaged data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/evoked/20_visualize_evoked.html">
     Visualizing Evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/evoked/30_eeg_erp.html">
     EEG processing and Event Related Potentials (ERPs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/evoked/40_whitened.html">
     Plotting whitened data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/time-freq/20_sensors_time_frequency.html">
     Frequency and time-frequency sensor analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/time-freq/50_ssvep.html">
     Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/10_background_freesurfer.html">
     FreeSurfer MRI reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/20_source_alignment.html">
     Source alignment and coordinate frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/25_automated_coreg.html">
     Using an automated approach to coregistration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/30_forward.html">
     Head model and forward computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/35_eeg_no_mri.html">
     EEG forward operator with a template MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/50_background_freesurfer_mne.html">
     How MNE uses FreeSurfer’s outputs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/80_fix_bem_in_blender.html">
     Editing BEM surfaces in Blender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/forward/90_compute_covariance.html">
     Computing a covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/10_stc_class.html">
     The
     <code class="xref py py-class docutils literal notranslate">
      <span class="pre">
       SourceEstimate
      </span>
     </code>
     data structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/20_dipole_fit.html">
     Source localization with equivalent current dipole (ECD) fit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/30_mne_dspm_loreta.html">
     Source localization with MNE/dSPM/sLORETA/eLORETA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/35_dipole_orientations.html">
     The role of dipole orientations in distributed source localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/40_mne_fixed_free.html">
     Computing various MNE solutions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/50_beamformer_lcmv.html">
     Source reconstruction using an LCMV beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/60_visualize_stc.html">
     Visualize source time courses (stcs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/70_eeg_mri_coords.html">
     EEG source localization given electrode locations on an MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
     Brainstorm Elekta phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
     Brainstorm CTF phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/inverse/90_phantom_4DBTi.html">
     4D Neuroimaging/BTi phantom dataset tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/10_background_stats.html">
     Statistical inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/20_erp_stats.html">
     Visualising statistical significance thresholds on EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
     Non-parametric 1 sample cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
     Non-parametric between conditions cluster statistic on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
     Spatiotemporal permutation F-test on full sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
     Permutation t-test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
     2 samples permutation test on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
     Repeated measures ANOVA on source data with spatio-temporal clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/stats-source-space/70_cluster_rmANOVA_time_freq.html">
     Mass-univariate twoway repeated measures ANOVA on single trial power
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/machine-learning/30_strf.html">
     Spectro-temporal receptive field (STRF) estimation on continuous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/machine-learning/50_decoding.html">
     Decoding (MVPA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/clinical/10_ieeg_localize.html">
     Locating Intracranial Electrode Contacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/clinical/20_seeg.html">
     Working with sEEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/clinical/30_ecog.html">
     Working with ECoG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/clinical/60_sleep.html">
     Sleep stage classification from polysomnography (PSG) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/simulation/10_array_objs.html">
     Creating MNE-Python data structures from scratch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/simulation/70_point_spread.html">
     Corrupt known signal with point spread
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_tutorials/simulation/80_dics.html">
     DICS for power mapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="auto_examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/io/elekta_epochs.html">
     Getting averaging info from .fif files
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/io/read_neo_format.html">
     How to use data in neural ensemble (NEO) format
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/io/read_noise_covariance_matrix.html">
     Reading/Writing a noise covariance matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/io/read_xdf.html">
     Reading XDF EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/simulation/simulate_evoked_data.html">
     Generate simulated evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/simulation/simulate_raw_data.html">
     Generate simulated raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">
     Simulate raw data using subject anatomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/simulation/source_simulator.html">
     Generate simulated source data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/define_target_events.html">
     Define target events based on time lag, plot evoked response
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/eeg_csd.html">
     Transform EEG data using current source density (CSD)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/eog_artifact_histogram.html">
     Show EOG artifact timing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/find_ref_artifacts.html">
     Find MEG reference channel artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/fnirs_artifact_removal.html">
     Visualise NIRS artifact correction methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/ica_comparison.html">
     Compare the different ICA algorithms in MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/interpolate_bad_channels.html">
     Interpolate bad channels for MEG/EEG channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/movement_compensation.html">
     Maxwell filter data with movement compensation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/movement_detection.html">
     Annotate movement artifacts and reestimate dev_head_t
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/muscle_detection.html">
     Annotate muscle artifacts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/otp.html">
     Plot sensor denoising using oversampled temporal projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/shift_evoked.html">
     Shifting time-scale in evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/virtual_evoked.html">
     Remap MEG channel types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/preprocessing/xdawn_denoising.html">
     XDAWN Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/3d_to_2d.html">
     How to convert 3D electrode positions to a 2D image.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/channel_epochs_image.html">
     Visualize channel over epochs as an image
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/eeg_on_scalp.html">
     Plotting EEG sensors on the scalp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/eeglab_head_sphere.html">
     How to plot topomaps the way EEGLAB does
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/evoked_arrowmap.html">
     Plotting topographic arrowmaps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/evoked_topomap.html">
     Plotting topographic maps of evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/evoked_whitening.html">
     Whitening evoked data with a noise covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/meg_sensors.html">
     Plotting sensor layouts of MEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/mne_helmet.html">
     Plot the MNE brain and helmet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/montage_sgskip.html">
     Plotting sensor layouts of EEG systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/parcellation.html">
     Plot a cortical parcellation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/publication_figure.html">
     Make figures more publication ready
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/roi_erpimage_by_rt.html">
     Plot single trial activity, grouped by ROI and sorted by RT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/sensor_noise_level.html">
     Show noise levels from empty room data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/ssp_projs_sensitivity_map.html">
     Sensitivity map of SSP projections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/topo_compare_conditions.html">
     Compare evoked responses for different conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/topo_customized.html">
     Plot custom topographies for MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/visualization/xhemi.html">
     Cross-hemisphere comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/compute_csd.html">
     Compute a cross-spectral density (CSD) matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/compute_source_psd_epochs.html">
     Compute Power Spectral Density of inverse solution from single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/source_label_time_frequency.html">
     Compute power and phase lock in label of the source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/source_power_spectrum.html">
     Compute source power spectral density (PSD) in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/source_power_spectrum_opm.html">
     Compute source power spectral density (PSD) of VectorView and OPM data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/source_space_time_frequency.html">
     Compute induced power in the source space with dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/temporal_whitening.html">
     Temporal whitening with AR model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/time_frequency_erds.html">
     Compute and visualize ERDS maps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/time_frequency_global_field_power.html">
     Explore event-related dynamics for specific frequency bands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/time_frequency/time_frequency_simulated.html">
     Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/stats/cluster_stats_evoked.html">
     Permutation F-test on sensor data with 1D cluster level
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/stats/fdr_stats_evoked.html">
     FDR correction on T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/stats/linear_regression_raw.html">
     Regression on continuous data (rER[P/F])
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/stats/sensor_permutation_test.html">
     Permutation T-test on sensor data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/stats/sensor_regression.html">
     Analysing continuous features with binning and regression in sensor space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_csp_eeg.html">
     Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_csp_timefreq.html">
     Decoding in time-frequency space using Common Spatial Patterns (CSP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_rsa_sgskip.html">
     Representational Similarity Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_spatio_temporal_source.html">
     Decoding source space data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_spoc_CMC.html">
     Continuous Target Decoding with SPoC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_time_generalization_conditions.html">
     Decoding sensor space data with generalization across time and conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_unsupervised_spatial_filter.html">
     Analysis of evoked response using ICA and PCA reduction techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/decoding_xdawn_eeg.html">
     XDAWN Decoding From EEG data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/ems_filtering.html">
     Compute effect-matched-spatial filtering (EMS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/linear_model_patterns.html">
     Linear classifier on sensor data with plot patterns and filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/receptive_field_mtrf.html">
     Receptive Field Estimation and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/decoding/ssd_spatial_filters.html">
     Compute Spectro-Spatial Decomposition (SSD) spatial filters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/forward/forward_sensitivity_maps.html">
     Display sensitivity maps for EEG and MEG sensors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/forward/left_cerebellum_volume_source.html">
     Generate a left cerebellum volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/forward/source_space_morphing.html">
     Use source space morphing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">
     Compute MNE-dSPM inverse solution on single epochs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_raw_in_label.html">
     Compute sLORETA inverse solution on raw data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_volume.html">
     Compute MNE-dSPM inverse solution on evoked data in volume source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/covariance_whitening_dspm.html">
     Demonstrate impact of whitening on source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/custom_inverse_solver.html">
     Source localization with a custom inverse solver
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/dics_source_power.html">
     Compute source power using DICS beamformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/evoked_ers_source_power.html">
     Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/gamma_map_inverse.html">
     Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/label_activation_from_stc.html">
     Extracting time course from source_estimate object
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/label_from_stc.html">
     Generate a functional label from source estimates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/label_source_activations.html">
     Extracting the time series of activations in a label
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/mixed_norm_inverse.html">
     Compute sparse inverse solution with mixed norm: MxNE and irMxNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/mixed_source_space_inverse.html">
     Compute MNE inverse solution on evoked data with a mixed source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/mne_cov_power.html">
     Compute source power estimate by projecting the covariance with MNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/morph_surface_stc.html">
     Morph surface source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/morph_volume_stc.html">
     Morph volumetric source estimate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/multidict_reweighted_tfmxne.html">
     Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/psf_ctf_label_leakage.html">
     Visualize source leakage among labels using a circular graph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/psf_ctf_vertices.html">
     Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/psf_ctf_vertices_lcmv.html">
     Compute cross-talk functions for LCMV beamformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/rap_music.html">
     Compute Rap-Music on evoked data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/read_inverse.html">
     Reading an inverse operator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/read_stc.html">
     Reading an STC file
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/resolution_metrics.html">
     Compute spatial resolution metrics in source space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/resolution_metrics_eegmeg.html">
     Compute spatial resolution metrics to compare MEG with EEG+MEG
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/snr_estimate.html">
     Estimate data SNR using an inverse
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/source_space_snr.html">
     Computing source space SNR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/time_frequency_mixed_norm_inverse.html">
     Compute MxNE with time-frequency sparse prior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/inverse/vector_mne_solution.html">
     Plotting the full vector-valued MNE solution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/datasets/brainstorm_data.html">
     Brainstorm raw (median nerve) dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/datasets/hf_sef_data.html">
     HF-SEF dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/datasets/limo_data.html">
     Single trial linear regression analysis with the LIMO dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/datasets/opm_data.html">
     Optically pumped magnetometer (OPM) data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="auto_examples/datasets/spm_faces_dataset_sgskip.html">
     From raw data to dSPM on SPM Faces dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="section" id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">¶</a></h1>
<p>The Glossary provides short definitions of MNE-Python-specific vocabulary and
general neuroimaging concepts. If you think a term is missing, please consider
<a class="reference external" href="https://github.com/mne-tools/mne-python/issues/new?template=glossary.md">creating a new issue</a> or <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/new/main">opening a pull request</a> to add it.</p>
<dl class="glossary">
<dt id="term-annotations">annotations<a class="headerlink" href="#term-annotations" title="Permalink to this term">¶</a></dt><dd><p>An annotation is defined by an onset, a duration, and a string
description. It can contain information about the experiments, but
also details on signals marked by a human: bad data segments,
sleep scores, sleep events (spindles, K-complex) etc.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container of multiple annotations.
See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> page for the API of the corresponding
object class and <a class="reference external" href="https://docs.python.org/3/tutorial/controlflow.html#tut-annotations" title="(in Python v3.9)"><span>Function Annotations</span></a>
for a tutorial on how to manipulate such objects.</p>
</dd>
<dt id="term-beamformer">beamformer<a class="headerlink" href="#term-beamformer" title="Permalink to this term">¶</a></dt><dd><p>Beamformer is a popular source estimation approach that uses a set of
spatial filters (beamformer weights) to compute time courses of sources
at predefined coordinates. See <a class="reference internal" href="generated/mne.beamformer.Beamformer.html#mne.beamformer.Beamformer" title="mne.beamformer.Beamformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">beamformer.Beamformer</span></code></a>. See
also <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>.</p>
</dd>
<dt id="term-BEM">BEM<a class="headerlink" href="#term-BEM" title="Permalink to this term">¶</a></dt><dt id="term-boundary-element-model">boundary element model<a class="headerlink" href="#term-boundary-element-model" title="Permalink to this term">¶</a></dt><dt id="term-boundary-element-method">boundary element method<a class="headerlink" href="#term-boundary-element-method" title="Permalink to this term">¶</a></dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the forward model computation and more
specifically the definion of the conductor model. The
boundary element model consists of surfaces such as the inner skull,
outer skull and outer skin (a.k.a. scalp) that define compartments
of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for usage demo.</p>
</dd>
<dt id="term-channels">channels<a class="headerlink" href="#term-channels" title="Permalink to this term">¶</a></dt><dd><p>Channels refer to MEG sensors, EEG electrodes or any extra electrode
or sensor such as EOG, ECG or sEEG, ECoG etc. Channels usually have
a type, such as gradiometer, and a unit, such as Tesla/Meter that
is used in the code base, e.g. for plotting. See also
<a class="reference internal" href="#term-data-channels"><span class="xref std std-term">data channels</span></a>.</p>
</dd>
<dt id="term-data-channels">data channels<a class="headerlink" href="#term-data-channels" title="Permalink to this term">¶</a></dt><dd><p>Many functions in MNE operate by default on “data channels”. These are
channels that typically hold <em>brain electophysiological</em> data,
as opposed to other forms of data, such as EOG, ECG, stimulus trigger,
or acquisition system status data. The set of channels considered
“data channels” in MNE is (along with their typical scale factors for
plotting, as they are stored in objects in SI units):</p>
<div class="compound">
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'mag'</span></code>: <strong>Magnetometers</strong> (scaled by 1e+15 to plot in <em>fT</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'grad'</span></code>: <strong>Gradiometers</strong> (scaled by 1e+13 to plot in <em>fT/cm</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'eeg'</span></code>: <strong>EEG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'csd'</span></code>: <strong>Current source density</strong> (scaled by 1000 to plot in <em>mV/m²</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'seeg'</span></code>: <strong>sEEG</strong> (scaled by 1000 to plot in <em>mV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ecog'</span></code>: <strong>ECoG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dbs'</span></code>: <strong>DBS</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbo'</span></code>: <strong>Oxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbr'</span></code>: <strong>Deoxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_cw_amplitude'</span></code>: <strong>fNIRS (CW amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_ac_amplitude'</span></code>: <strong>fNIRS (FD AC amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_phase'</span></code>: <strong>fNIRS (FD phase)</strong> (scaled by 1 to plot in <em>rad</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_od'</span></code>: <strong>fNIRS (OD)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
</ul>
</div>
</dd>
<dt id="term-DICS">DICS<a class="headerlink" href="#term-DICS" title="Permalink to this term">¶</a></dt><dt id="term-dynamic-imaging-of-coherent-sources">dynamic imaging of coherent sources<a class="headerlink" href="#term-dynamic-imaging-of-coherent-sources" title="Permalink to this term">¶</a></dt><dd><p>Dynamic Imaging of Coherent Sources, a method for computing source
power in different frequency bands. see <a class="reference internal" href="auto_examples/inverse/dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a>
and <a class="reference internal" href="generated/mne.beamformer.make_dics.html#mne.beamformer.make_dics" title="mne.beamformer.make_dics"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_dics()</span></code></a>.</p>
</dd>
<dt id="term-digitization">digitization<a class="headerlink" href="#term-digitization" title="Permalink to this term">¶</a></dt><dd><p>Digitization is a procedure of recording the headshape of a subject and
the fiducial coils (or <a class="reference internal" href="#term-HPI"><span class="xref std std-term">HPI</span></a>) and/or eeg electrodes locations on
the subject’s head. They are represented as a set of points in a 3D space.
See <a class="reference internal" href="auto_tutorials/intro/40_sensor_locations.html#reading-dig-montages"><span class="std std-ref">Reading sensor digitization files</span></a> and <a class="reference internal" href="overview/implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>.</p>
</dd>
<dt id="term-dipole">dipole<a class="headerlink" href="#term-dipole" title="Permalink to this term">¶</a></dt><dt id="term-ECD">ECD<a class="headerlink" href="#term-ECD" title="Permalink to this term">¶</a></dt><dt id="term-equivalent-current-dipole">equivalent current dipole<a class="headerlink" href="#term-equivalent-current-dipole" title="Permalink to this term">¶</a></dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small region of cortex. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by the techniques
are well-approximated by (i.e., “equivalent” to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-dSPM">dSPM<a class="headerlink" href="#term-dSPM" title="Permalink to this term">¶</a></dt><dt id="term-dynamic-statistical-parametric-mapping">dynamic statistical parametric mapping<a class="headerlink" href="#term-dynamic-statistical-parametric-mapping" title="Permalink to this term">¶</a></dt><dd><p>Dynamic statistical parametric mapping (abbr. <code class="docutils literal notranslate"><span class="pre">dSPM</span></code>) gives a noise-
normalized minimum-norm estimate at a given source location. dSPM is
calculated by dividing the activity estimate at each source location by
the baseline standard deviation of the noise.</p>
</dd>
<dt id="term-eLORETA">eLORETA<a class="headerlink" href="#term-eLORETA" title="Permalink to this term">¶</a></dt><dt id="term-sLORETA">sLORETA<a class="headerlink" href="#term-sLORETA" title="Permalink to this term">¶</a></dt><dd><p>eLORETA and sLORETA (exact and standardized low resolution brain
electromagnetic tomography) are linear source estimation techniques,
as are <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a> and <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>. sLORETA outputs
standardized values (like dSPM does), while eLORETA outputs normalized
current estimates. See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>,
<a class="reference internal" href="auto_tutorials/inverse/30_mne_dspm_loreta.html#tut-inverse-methods"><span class="std std-ref">Source localization with MNE/dSPM/sLORETA/eLORETA</span></a>, and <a class="reference internal" href="auto_examples/inverse/compute_mne_inverse_raw_in_label.html#example-sloreta"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a>.</p>
</dd>
<dt id="term-epochs">epochs<a class="headerlink" href="#term-epochs" title="Permalink to this term">¶</a></dt><dd><p>Epochs (sometimes called “trials” in other software packages) are
equal-length spans of data extracted from raw continuous data. Usually,
epochs are extracted around stimulus events or subject responses,
though sometimes sequential or overlapping epochs are extracted (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
API of the corresponding object class, and <a class="reference internal" href="auto_tutorials/epochs/10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a> for
a narrative overview.</p>
</dd>
<dt id="term-events">events<a class="headerlink" href="#term-events" title="Permalink to this term">¶</a></dt><dd><p>Events correspond to specific time points in raw data; e.g.,
triggers, experimental condition events, etc. MNE represents events with
integers that are stored in numpy arrays of shape (n_events, 3). Such arrays
are classically obtained from a trigger channel, also referred to as
stim channel.</p>
</dd>
<dt id="term-evoked">evoked<a class="headerlink" href="#term-evoked" title="Permalink to this term">¶</a></dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/evoked/10_evoked_overview.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-fiducial">fiducial<a class="headerlink" href="#term-fiducial" title="Permalink to this term">¶</a></dt><dt id="term-fiducial-point">fiducial point<a class="headerlink" href="#term-fiducial-point" title="Permalink to this term">¶</a></dt><dt id="term-anatomical-landmark">anatomical landmark<a class="headerlink" href="#term-anatomical-landmark" title="Permalink to this term">¶</a></dt><dd><p>Fiducials are objects placed in the field of view of an imaging system
to act as a known spatial reference location that is easy to localize.
In neuroimaging, fiducials are often placed on anatomical landmarks
such as the nasion (NAS) or left/right preauricular points (LPA and
RPA).</p>
<p>These known reference locations are used to define a coordinate system
used for localization of sensors (hence NAS, LPA and RPA are often
called “cardinal points” because they define the cardinal directions of
the “head” coordinate system). The cardinal points are also useful when
co-registering measurements in different coordinate systems (such as
aligning EEG sensor locations to an MRI of the subject’s head).</p>
<p>Due to the common neuroimaging practice of placing fiducial objects on
anatomical landmarks, the terms “fiducial”, “anatomical landmark” and
“cardinal point” are often (erroneously) used interchangeably.</p>
</dd>
<dt id="term-first_samp">first_samp<a class="headerlink" href="#term-first_samp" title="Permalink to this term">¶</a></dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data started to be recorded to disk. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files.</p>
</dd>
<dt id="term-forward">forward<a class="headerlink" href="#term-forward" title="Permalink to this term">¶</a></dt><dt id="term-forward-solution">forward solution<a class="headerlink" href="#term-forward-solution" title="Permalink to this term">¶</a></dt><dd><p>The forward solution (abbr. <code class="docutils literal notranslate"><span class="pre">fwd</span></code>) is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors (A.K.A.,
the “lead field matrix”). Calculating a forward solution requires a
conductivity model of the head, encapsulating the geometry and
electrical conductivity of the different tissue compartments (see
<a class="reference internal" href="#term-boundary-element-model"><span class="xref std std-term">boundary element model</span></a> and <a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-FreeSurfer-LUT">FreeSurfer LUT<a class="headerlink" href="#term-FreeSurfer-LUT" title="Permalink to this term">¶</a></dt><dt id="term-LUT">LUT<a class="headerlink" href="#term-LUT" title="Permalink to this term">¶</a></dt><dd><p>A FreeSurfer lookup table (LUT) provides a mapping between a given
volumetric atlas or surface label name (strings), its integer value
(e.g., in <code class="docutils literal notranslate"><span class="pre">aparc+aseg.mgz</span></code>), and its standard color. See
<a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT">the FreeSurfer wiki</a>
for more information. Custom LUTs can be also be created from different
surface parcellations, see for example <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/7639#issuecomment-625907891">this comment about HCPMMP</a>.</p>
</dd>
<dt id="term-GFP">GFP<a class="headerlink" href="#term-GFP" title="Permalink to this term">¶</a></dt><dt id="term-global-field-power">global field power<a class="headerlink" href="#term-global-field-power" title="Permalink to this term">¶</a></dt><dd><p>Global Field Power (abbr. <code class="docutils literal notranslate"><span class="pre">GFP</span></code>) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point; thus
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-HED">HED<a class="headerlink" href="#term-HED" title="Permalink to this term">¶</a></dt><dt id="term-hierarchical-event-descriptors">hierarchical event descriptors<a class="headerlink" href="#term-hierarchical-event-descriptors" title="Permalink to this term">¶</a></dt><dd><p>Hierarchical event descriptors (abbr. <code class="docutils literal notranslate"><span class="pre">HED</span></code>) are tags that use
keywords separated by ‘/’ to describe different types of
experimental events (for example, stimulus/circle/red/left and
stimulus/circle/blue/left). These tags can be used to group
experimental events and select event types for analysis.</p>
</dd>
<dt id="term-HPI">HPI<a class="headerlink" href="#term-HPI" title="Permalink to this term">¶</a></dt><dt id="term-cHPI">cHPI<a class="headerlink" href="#term-cHPI" title="Permalink to this term">¶</a></dt><dt id="term-head-position-indicator">head position indicator<a class="headerlink" href="#term-head-position-indicator" title="Permalink to this term">¶</a></dt><dd><p>Head position indicators (abbr. <code class="docutils literal notranslate"><span class="pre">HPI</span></code>, or sometimes <code class="docutils literal notranslate"><span class="pre">cHPI</span></code> for
<em>continuous</em> head position indicators) are small coils attached to a
subject’s head during MEG acquisition. Each coil emits a sinusoidal
signal of a different frequency, which is picked up by the MEG sensors
and can be used to infer the head position. With cHPI, the sinusoidal
signals are typically set at frequencies above any neural signal of
interest, and thus can be removed after head position correction via
low-pass filtering. See <a class="reference internal" href="auto_tutorials/preprocessing/59_head_positions.html#tut-head-pos"><span class="std std-ref">Extracting and visualizing subject head movement</span></a>.</p>
</dd>
<dt id="term-info">info<a class="headerlink" href="#term-info" title="Permalink to this term">¶</a></dt><dd><p>Also called <code class="docutils literal notranslate"><span class="pre">measurement</span> <span class="pre">info</span></code>, it is a collection of metadata
regarding a <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> or <a class="reference internal" href="generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a>
object, containing channel locations and types, sampling frequency,
preprocessing history such as filters, etc.
See <a class="reference internal" href="auto_tutorials/intro/30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse">inverse<a class="headerlink" href="#term-inverse" title="Permalink to this term">¶</a></dt><dt id="term-inverse-operator">inverse operator<a class="headerlink" href="#term-inverse-operator" title="Permalink to this term">¶</a></dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods MNE, dSPM, sLORETA and eLORETA.
See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>.</p>
</dd>
<dt id="term-label">label<a class="headerlink" href="#term-label" title="Permalink to this term">¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a defined region in the cortex, also often called
a region of interest (ROI) in the literature. Labels can be defined
anatomically (based on physical structure of the cortex) or functionally
(based on cortical response to specific stimuli).</p>
</dd>
<dt id="term-layout">layout<a class="headerlink" href="#term-layout" title="Permalink to this term">¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> gives sensor positions in 2
dimensions (defined by <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code>, and <code class="docutils literal notranslate"><span class="pre">height</span></code> values for
each sensor). It is primarily used for illustrative purposes (i.e., making
diagrams of approximate sensor positions in top-down diagrams of the head,
so-called topographies or topomaps).</p>
</dd>
<dt id="term-LCMV">LCMV<a class="headerlink" href="#term-LCMV" title="Permalink to this term">¶</a></dt><dt id="term-LCMV-beamformer">LCMV beamformer<a class="headerlink" href="#term-LCMV-beamformer" title="Permalink to this term">¶</a></dt><dd><p>Linearly constrained minimum variance beamformer, which attempts to
estimate activity for a given source while suppressing cross-talk from
other regions, see <a class="reference internal" href="generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_lcmv()</span></code></a>. See also
<a class="reference internal" href="#term-beamformer"><span class="xref std std-term">beamformer</span></a>.</p>
</dd>
<dt id="term-maximum-intensity-projection">maximum intensity projection<a class="headerlink" href="#term-maximum-intensity-projection" title="Permalink to this term">¶</a></dt><dd><p>A method of displaying activity within some volume by, for each pixel,
finding the maximum value along vector from the viewer to the pixel
(i.e., along the vector pependicular to the view plane).</p>
</dd>
<dt id="term-MNE">MNE<a class="headerlink" href="#term-MNE" title="Permalink to this term">¶</a></dt><dt id="term-minimum-norm-estimate">minimum-norm estimate<a class="headerlink" href="#term-minimum-norm-estimate" title="Permalink to this term">¶</a></dt><dt id="term-minimum-norm-estimation">minimum-norm estimation<a class="headerlink" href="#term-minimum-norm-estimation" title="Permalink to this term">¶</a></dt><dd><p>Minimum-norm estimation (abbr. <code class="docutils literal notranslate"><span class="pre">MNE</span></code>) can be used to generate a distributed
map of activation on a <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>, usually on a cortical surface.
MNE uses a linear <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project sensor measurements
into the source space. The <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> is computed from the
<a class="reference internal" href="#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for a subject and an estimate of the
<a class="reference internal" href="#term-noise-covariance"><span class="xref std std-term">noise covariance</span></a> of sensor measurements.</p>
</dd>
<dt id="term-montage">montage<a class="headerlink" href="#term-montage" title="Permalink to this term">¶</a></dt><dd><p>EEG channel names and the relative positions of the sensor w.r.t. the scalp.
While layout are 2D locations, montages give 3D locations. A montage
can also contain locations for HPI points, fiducial points, or
extra head shape points.
See <a class="reference internal" href="generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">DigMontage</span></code></a> for the API of the corresponding object
class.</p>
</dd>
<dt id="term-morphing">morphing<a class="headerlink" href="#term-morphing" title="Permalink to this term">¶</a></dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is commonly referred as realignment in fMRI
literature. This operation is necessary for group studies (to get the
data in a common space for statistical analysis).
See <a class="reference internal" href="overview/implementation.html#ch-morph"><span class="std std-ref">Morphing and averaging source estimates</span></a> for more details.</p>
</dd>
<dt id="term-noise-covariance">noise covariance<a class="headerlink" href="#term-noise-covariance" title="Permalink to this term">¶</a></dt><dd><p>Noise covariance is a matrix that contains the covariance between data
channels. It is a square matrix with shape <code class="docutils literal notranslate"><span class="pre">n_channels</span></code> <span class="math notranslate nohighlight">\(\times\)</span>
<code class="docutils literal notranslate"><span class="pre">n_channels</span></code>. It is especially useful when working with multiple sensor
types (e.g. EEG and MEG). It is in
practice estimated from baseline periods or empty room measurements.
The matrix also provides a noise model that can be used for subsequent analysis
like source imaging.</p>
</dd>
<dt id="term-pick">pick<a class="headerlink" href="#term-pick" title="Permalink to this term">¶</a></dt><dd><p>An integer that is the index of a channel in the measurement info.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector<a class="headerlink" href="#term-projector" title="Permalink to this term">¶</a></dt><dt id="term-SSP">SSP<a class="headerlink" href="#term-SSP" title="Permalink to this term">¶</a></dt><dd><p>A projector (abbr. <code class="docutils literal notranslate"><span class="pre">proj</span></code>), also referred to as Signal Space
Projection (SSP), defines a linear operation applied spatially to EEG
or MEG data. A matrix multiplication of an SSP projector with the data
will reduce the rank of the data by projecting it to a
lower-dimensional subspace. Such projections are typically applied to
both the data and the forward operator when performing
source localization. Note that EEG average referencing can be done
using such a projection operator. Projectors are stored alongside data
in <a class="reference internal" href="#term-info"><span class="xref std std-term">the measurement info</span></a> in the field <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-raw">raw<a class="headerlink" href="#term-raw" title="Permalink to this term">¶</a></dt><dd><p><a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects hold continuous data (preprocessed or not). One typically
manipulates raw data when reading recordings in a file on disk.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/raw/10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-ROI">ROI<a class="headerlink" href="#term-ROI" title="Permalink to this term">¶</a></dt><dt id="term-region-of-interest">region of interest<a class="headerlink" href="#term-region-of-interest" title="Permalink to this term">¶</a></dt><dd><p>A spatial region where an experimental effect is expected to manifest.
This can be a collection of sensors or, when performing inverse imaging,
a set of vertices on the cortical surface or within the cortical volume.
See also <a class="reference internal" href="#term-label"><span class="xref std std-term">label</span></a>.</p>
</dd>
<dt id="term-selection">selection<a class="headerlink" href="#term-selection" title="Permalink to this term">¶</a></dt><dd><p>A selection is a set of picked channels (for example, all sensors
falling within a <a class="reference internal" href="#term-region-of-interest"><span class="xref std std-term">region of interest</span></a>).</p>
</dd>
<dt id="term-source-space">source space<a class="headerlink" href="#term-source-space" title="Permalink to this term">¶</a></dt><dd><p>A source space (abbr. <code class="docutils literal notranslate"><span class="pre">src</span></code>) specifies where in the brain one wants
to estimate the
source amplitudes. It corresponds to locations of a set of
candidate <a class="reference internal" href="#term-ECD"><span class="xref std std-term">equivalent current dipoles</span></a>. MNE mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See <a class="reference internal" href="auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>
to read about how to compute a forward operator on a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the API of the corresponding
object class.</p>
</dd>
<dt id="term-STC">STC<a class="headerlink" href="#term-STC" title="Permalink to this term">¶</a></dt><dt id="term-source-estimate">source estimate<a class="headerlink" href="#term-source-estimate" title="Permalink to this term">¶</a></dt><dt id="term-source-time-course">source time course<a class="headerlink" href="#term-source-time-course" title="Permalink to this term">¶</a></dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods such as <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>,
<a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a> or MxNE.
STCs contain the amplitudes of the neural sources over time.
In MNE-Python, <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a> objects only store the
amplitudes of activation but not the locations of the sources; the
locations are stored separately in the <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> object
that was used to compute the forward operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>,
for the API of the corresponding object classes.</p>
</dd>
<dt id="term-stim-channel">stim channel<a class="headerlink" href="#term-stim-channel" title="Permalink to this term">¶</a></dt><dt id="term-trigger-channel">trigger channel<a class="headerlink" href="#term-trigger-channel" title="Permalink to this term">¶</a></dt><dd><p>A stim channel, a.k.a. trigger channel, is a channel that encodes
events during the recording. It is typically a channel that is usually
zero and takes positive values when something happens (such as the
onset of a stimulus, or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="auto_tutorials/intro/20_events_from_raw.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-tfr">tfr<a class="headerlink" href="#term-tfr" title="Permalink to this term">¶</a></dt><dd><p>Time-frequency representation. This is often a spectrogram (STFT) or
scaleogram (wavelet), showing the frequency content as a function of
time.</p>
</dd>
<dt id="term-trans">trans<a class="headerlink" href="#term-trans" title="Permalink to this term">¶</a></dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
<dt id="term-whitening">whitening<a class="headerlink" href="#term-whitening" title="Permalink to this term">¶</a></dt><dd><p>A linear operation that transforms data with a known covariance
structure into “whitened data” which has a covariance structure that
is the identity matrix. In other words it creates virtual channels that
are uncorrelated and have unit variance. This is also known as a
sphering transformation.</p>
<p>The term “whitening” comes from the fact that light with a flat
frequency spectrum in the visible range is white, whereas
non-uniform frequency spectra lead to perception of different colors
(e.g., “pink noise” has a <code class="docutils literal notranslate"><span class="pre">1/f</span></code> characteristic, which for visible
light would appear pink).</p>
</dd>
</dl>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="auto_examples/datasets/spm_faces_dataset_sgskip.html" title="previous page">From raw data to dSPM on SPM Faces dataset</a>
    <a class='right-next' id="next-link" href="overview/implementation.html" title="next page">Algorithms and other implementation details</a>

              </div>
              
          </main>
          

      </div>
    </div>
    <script src="https://mne.tools/versionwarning.js"></script>
    
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-37225609-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-08-25T21:53:57.098096+00:00" class="localized">2021-08-25 21:53 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div>
    
  </div>
</footer>
  </body>
</html>