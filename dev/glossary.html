
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Glossary &#8212; MNE 0.23.dev0 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.951c8c8e3af89de180a2f03968e0e7cb.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
    <!-- add `style` or `link` tags with your CSS `@font-face` declarations here -->
    <!-- ... and a `style` tag with setting `font-family` in `body` and `.header-style` -->
    <!-- ... and optionally preload the `woff2` for snappier page loads -->
    <!-- or add a `style` tag with a font fallback chain with good cross-platform coverage -->
    <style>
        body,.header-style {font-family: 'Source Sans Pro', sans-serif;}
        code,kbd,pre,samp {font-family: 'Source Code Pro', monospace;}
    </style>

    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/font-source-sans-pro.css" />
    <link rel="stylesheet" type="text/css" href="_static/font-source-code-pro.css" />
    
  <link rel="preload" as="script" href="_static/js/index.014cad6f3a039303089e.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/bootstrap_divs.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithms and other implementation details" href="overview/implementation.html" />
    <link rel="prev" title="From raw data to dSPM on SPM Faces dataset" href="auto_examples/datasets/spm_faces_dataset.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <script type="text/javascript" src="_static/scrollfix.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
  
    <div class="container-fluid alert-danger devbar">
      <div class="row no-gutters">
        <div class="col-12 text-center">
          This is documentation for the <em>unstable development version</em> of MNE-Python. <a class="alert-link" href="https://mne.tools/stable">Click here</a> to switch to the stable version.
        </div>
      </div>
    </div>
  

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">
    <a class="navbar-brand" href="index.html">
        
        <img src="_static/mne_logo_small.svg" class="logo" alt="logo" />
        
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-auto col-lg-9 collapse navbar-collapse">
        <ul id="navbar-main-elements" class="navbar-nav mr-auto">
            
            
            <li class="nav-item ">
                <a class="nav-link" href="install/index.html">Install</a>
            </li>
            
            <li class="nav-item active">
                <a class="nav-link" href="overview/index.html">Documentation</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="python_reference.html">API Reference</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="overview/get_help.html">Get help</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="overview/development.html">Development</a>
            </li>
            
            
        </ul>

        

        <ul class="navbar-nav">
            <!-- version dropdown -->
            <li class="mr-2 dropdown">
                <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
                    v0.23.dev0
                    <span class="caret"></span>
                </button>
                <ul class="dropdown-menu" aria-labelledby="dLabelMore">
                    <li><a href="https://mne-tools.github.io/dev/index.html">v0.23 (devel)</a></li>
                    <li><a href="https://mne-tools.github.io/stable/index.html">v0.22 (stable)</a></li>
                    <li><a href="https://mne-tools.github.io/0.21/index.html">v0.21</a></li>
                    <li><a href="https://mne-tools.github.io/0.20/index.html">v0.20</a></li>
                    <li><a href="https://mne-tools.github.io/0.19/index.html">v0.19</a></li>
                    <li><a href="https://mne-tools.github.io/0.18/index.html">v0.18</a></li>
                    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
                    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
                    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
                    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
                    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
                    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
                    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
                </ul>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="https://github.com/mne-tools/mne-python" target="_blank" rel="noopener">
                    <span><i class="fab fa-github-square"></i></span>
                </a>
            </li>
            
            
            <li class="nav-item">
                <a class="nav-link" href="https://twitter.com/mne_python" target="_blank" rel="noopener">
                    <span><i class="fab fa-twitter-square"></i></span>
                </a>
            </li>
            
            <!-- discourse forum link -->
            <li class="nav-item">
                <a class="nav-link" href="https://mne.discourse.group" target="_blank" rel="noopener">
                    <span><i class="fab fa-discourse"></i></span>
                </a>
            </li>
        </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
      <li class="toctree-l2">
 <a class="reference internal" href="auto_tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="auto_examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l2 current active">
 <a class="current reference internal" href="#">
  Glossary
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/implementation.html">
  Implementation details
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/design_philosophy.html">
  Design philosophy
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/datasets_index.html">
  Example datasets
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="generated/commands.html">
  Command-line tools
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/migrating.html">
  Migrating from other analysis software
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/cookbook.html">
  The typical M/EEG workflow
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="overview/cite.html">
  How to cite MNE-Python
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="cited.html">
  Papers citing MNE-Python
 </a>
</li>

    </ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              



<nav id="bd-toc-nav">
    
</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="section" id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">¶</a></h1>
<p>The Glossary provides short definitions of MNE-Python-specific vocabulary and
general neuroimaging concepts. If you think a term is missing, please consider
<a class="reference external" href="https://github.com/mne-tools/mne-python/issues/new?template=glossary.md">creating a new issue</a> or <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/new/main">opening a pull request</a> to add it.</p>
<dl class="glossary">
<dt id="term-annotations">annotations<a class="headerlink" href="#term-annotations" title="Permalink to this term">¶</a></dt><dd><p>An annotation is defined by an onset, a duration, and a string
description. It can contain information about the experiments, but
also details on signals marked by a human: bad data segments,
sleep scores, sleep events (spindles, K-complex) etc.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container of multiple annotations.
See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> page for the API of the corresponding
object class and <a class="reference external" href="https://docs.python.org/3/tutorial/controlflow.html#tut-annotations" title="(in Python v3.9)"><span>Function Annotations</span></a>
for a tutorial on how to manipulate such objects.</p>
</dd>
<dt id="term-beamformer">beamformer<a class="headerlink" href="#term-beamformer" title="Permalink to this term">¶</a></dt><dd><p>Beamformer is a popular source estimation approach that uses a set of
spatial filters (beamformer weights) to compute time courses of sources
at predefined coordinates. See <a class="reference internal" href="generated/mne.beamformer.Beamformer.html#mne.beamformer.Beamformer" title="mne.beamformer.Beamformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">beamformer.Beamformer</span></code></a>. See
also <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>.</p>
</dd>
<dt id="term-BEM">BEM<a class="headerlink" href="#term-BEM" title="Permalink to this term">¶</a></dt><dt id="term-boundary-element-model">boundary element model<a class="headerlink" href="#term-boundary-element-model" title="Permalink to this term">¶</a></dt><dt id="term-boundary-element-method">boundary element method<a class="headerlink" href="#term-boundary-element-method" title="Permalink to this term">¶</a></dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the forward model computation and more
specifically the definion of the conductor model. The
boundary element model consists of surfaces such as the inner skull,
outer skull and outer skin (a.k.a. scalp) that define compartments
of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for usage demo.</p>
</dd>
<dt id="term-channels">channels<a class="headerlink" href="#term-channels" title="Permalink to this term">¶</a></dt><dd><p>Channels refer to MEG sensors, EEG electrodes or any extra electrode
or sensor such as EOG, ECG or sEEG, ECoG etc. Channels usually have
a type, such as gradiometer, and a unit, such as Tesla/Meter that
is used in the code base, e.g. for plotting. See also
<a class="reference internal" href="#term-data-channels"><span class="xref std std-term">data channels</span></a>.</p>
</dd>
<dt id="term-data-channels">data channels<a class="headerlink" href="#term-data-channels" title="Permalink to this term">¶</a></dt><dd><p>Many functions in MNE operate by default on “data channels”. These are
channels that typically hold <em>brain electophysiological</em> data,
as opposed to other forms of data, such as EOG, ECG, stimulus trigger,
or acquisition system status data. The set of channels considered
“data channels” in MNE is (along with their typical scale factors for
plotting, as they are stored in objects in SI units):</p>
<div class="compound">
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'mag'</span></code>: <strong>Magnetometers</strong> (scaled by 1e+15 to plot in <em>fT</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'grad'</span></code>: <strong>Gradiometers</strong> (scaled by 1e+13 to plot in <em>fT/cm</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'eeg'</span></code>: <strong>EEG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'csd'</span></code>: <strong>Current source density</strong> (scaled by 1000 to plot in <em>mV/m²</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'seeg'</span></code>: <strong>sEEG</strong> (scaled by 1000 to plot in <em>mV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ecog'</span></code>: <strong>ECoG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dbs'</span></code>: <strong>DBS</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbo'</span></code>: <strong>Oxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbr'</span></code>: <strong>Deoxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_cw_amplitude'</span></code>: <strong>fNIRS (CW amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_ac_amplitude'</span></code>: <strong>fNIRS (FD AC amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_phase'</span></code>: <strong>fNIRS (FD phase)</strong> (scaled by 1 to plot in <em>rad</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_od'</span></code>: <strong>fNIRS (OD)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
</ul>
</div>
</dd>
<dt id="term-DICS">DICS<a class="headerlink" href="#term-DICS" title="Permalink to this term">¶</a></dt><dt id="term-dynamic-imaging-of-coherent-sources">dynamic imaging of coherent sources<a class="headerlink" href="#term-dynamic-imaging-of-coherent-sources" title="Permalink to this term">¶</a></dt><dd><p>Dynamic Imaging of Coherent Sources, a method for computing source
power in different frequency bands. see <a class="reference internal" href="auto_examples/inverse/plot_dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a>
and <a class="reference internal" href="generated/mne.beamformer.make_dics.html#mne.beamformer.make_dics" title="mne.beamformer.make_dics"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_dics()</span></code></a>.</p>
</dd>
<dt id="term-digitization">digitization<a class="headerlink" href="#term-digitization" title="Permalink to this term">¶</a></dt><dd><p>Digitization is a procedure of recording the headshape of a subject and
the fiducial coils (or <a class="reference internal" href="#term-HPI"><span class="xref std std-term">HPI</span></a>) and/or eeg electrodes locations on
the subject’s head. They are represented as a set of points in a 3D space.
See <a class="reference internal" href="auto_tutorials/intro/plot_40_sensor_locations.html#reading-dig-montages"><span class="std std-ref">Reading sensor digitization files</span></a> and <a class="reference internal" href="overview/implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>.</p>
</dd>
<dt id="term-dipole">dipole<a class="headerlink" href="#term-dipole" title="Permalink to this term">¶</a></dt><dt id="term-ECD">ECD<a class="headerlink" href="#term-ECD" title="Permalink to this term">¶</a></dt><dt id="term-equivalent-current-dipole">equivalent current dipole<a class="headerlink" href="#term-equivalent-current-dipole" title="Permalink to this term">¶</a></dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small region of cortex. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by the techniques
are well-approximated by (i.e., “equivalent” to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-dSPM">dSPM<a class="headerlink" href="#term-dSPM" title="Permalink to this term">¶</a></dt><dt id="term-dynamic-statistical-parametric-mapping">dynamic statistical parametric mapping<a class="headerlink" href="#term-dynamic-statistical-parametric-mapping" title="Permalink to this term">¶</a></dt><dd><p>Dynamic statistical parametric mapping (abbr. <code class="docutils literal notranslate"><span class="pre">dSPM</span></code>) gives a noise-
normalized minimum-norm estimate at a given source location. dSPM is
calculated by dividing the activity estimate at each source location by
the baseline standard deviation of the noise.</p>
</dd>
<dt id="term-eLORETA">eLORETA<a class="headerlink" href="#term-eLORETA" title="Permalink to this term">¶</a></dt><dt id="term-sLORETA">sLORETA<a class="headerlink" href="#term-sLORETA" title="Permalink to this term">¶</a></dt><dd><p>eLORETA and sLORETA (exact and standardized low resolution brain
electromagnetic tomography) are linear source estimation techniques,
as are <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a> and <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>. sLORETA outputs
standardized values (like dSPM does), while eLORETA outputs normalized
current estimates. See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>,
<a class="reference internal" href="auto_tutorials/source-modeling/plot_mne_dspm_source_localization.html#tut-inverse-methods"><span class="std std-ref">Source localization with MNE/dSPM/sLORETA/eLORETA</span></a>, and <a class="reference internal" href="auto_examples/inverse/plot_compute_mne_inverse_raw_in_label.html#example-sloreta"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a>.</p>
</dd>
<dt id="term-epochs">epochs<a class="headerlink" href="#term-epochs" title="Permalink to this term">¶</a></dt><dd><p>Epochs (sometimes called “trials” in other software packages) are
equal-length spans of data extracted from raw continuous data. Usually,
epochs are extracted around stimulus events or subject responses,
though sometimes sequential or overlapping epochs are extracted (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
API of the corresponding object class, and <a class="reference internal" href="auto_tutorials/epochs/plot_10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a> for
a narrative overview.</p>
</dd>
<dt id="term-events">events<a class="headerlink" href="#term-events" title="Permalink to this term">¶</a></dt><dd><p>Events correspond to specific time points in raw data; e.g.,
triggers, experimental condition events, etc. MNE represents events with
integers that are stored in numpy arrays of shape (n_events, 3). Such arrays
are classically obtained from a trigger channel, also referred to as
stim channel.</p>
</dd>
<dt id="term-evoked">evoked<a class="headerlink" href="#term-evoked" title="Permalink to this term">¶</a></dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/evoked/plot_10_evoked_overview.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-fiducial">fiducial<a class="headerlink" href="#term-fiducial" title="Permalink to this term">¶</a></dt><dt id="term-fiducial-point">fiducial point<a class="headerlink" href="#term-fiducial-point" title="Permalink to this term">¶</a></dt><dt id="term-anatomical-landmark">anatomical landmark<a class="headerlink" href="#term-anatomical-landmark" title="Permalink to this term">¶</a></dt><dd><p>Fiducials are objects placed in the field of view of an imaging system
to act as a known spatial reference location that is easy to localize.
In neuroimaging, fiducials are often placed on anatomical landmarks
such as the nasion (NAS) or left/right preauricular points (LPA and
RPA).</p>
<p>These known reference locations are used to define a coordinate system
used for localization of sensors (hence NAS, LPA and RPA are often
called “cardinal points” because they define the cardinal directions of
the “head” coordinate system). The cardinal points are also useful when
co-registering measurements in different coordinate systems (such as
aligning EEG sensor locations to an MRI of the subject’s head).</p>
<p>Due to the common neuroimaging practice of placing fiducial objects on
anatomical landmarks, the terms “fiducial”, “anatomical landmark” and
“cardinal point” are often (erroneously) used interchangeably.</p>
</dd>
<dt id="term-first_samp">first_samp<a class="headerlink" href="#term-first_samp" title="Permalink to this term">¶</a></dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data started to be recorded to disk. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files.</p>
</dd>
<dt id="term-forward">forward<a class="headerlink" href="#term-forward" title="Permalink to this term">¶</a></dt><dt id="term-forward-solution">forward solution<a class="headerlink" href="#term-forward-solution" title="Permalink to this term">¶</a></dt><dd><p>The forward solution (abbr. <code class="docutils literal notranslate"><span class="pre">fwd</span></code>) is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors (A.K.A.,
the “lead field matrix”). Calculating a forward solution requires a
conductivity model of the head, encapsulating the geometry and
electrical conductivity of the different tissue compartments (see
<a class="reference internal" href="#term-boundary-element-model"><span class="xref std std-term">boundary element model</span></a> and <a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-GFP">GFP<a class="headerlink" href="#term-GFP" title="Permalink to this term">¶</a></dt><dt id="term-global-field-power">global field power<a class="headerlink" href="#term-global-field-power" title="Permalink to this term">¶</a></dt><dd><p>Global Field Power (abbr. <code class="docutils literal notranslate"><span class="pre">GFP</span></code>) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point; thus
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-HPI">HPI<a class="headerlink" href="#term-HPI" title="Permalink to this term">¶</a></dt><dt id="term-cHPI">cHPI<a class="headerlink" href="#term-cHPI" title="Permalink to this term">¶</a></dt><dt id="term-head-position-indicator">head position indicator<a class="headerlink" href="#term-head-position-indicator" title="Permalink to this term">¶</a></dt><dd><p>Head position indicators (abbr. <code class="docutils literal notranslate"><span class="pre">HPI</span></code>, or sometimes <code class="docutils literal notranslate"><span class="pre">cHPI</span></code> for
<em>continuous</em> head position indicators) are small coils attached to a
subject’s head during MEG acquisition. Each coil emits a sinusoidal
signal of a different frequency, which is picked up by the MEG sensors
and can be used to infer the head position. With cHPI, the sinusoidal
signals are typically set at frequencies above any neural signal of
interest, and thus can be removed after head position correction via
low-pass filtering. See <a class="reference internal" href="auto_tutorials/preprocessing/plot_59_head_positions.html#tut-head-pos"><span class="std std-ref">Extracting and visualizing subject head movement</span></a>.</p>
</dd>
<dt id="term-info">info<a class="headerlink" href="#term-info" title="Permalink to this term">¶</a></dt><dd><p>Also called <code class="docutils literal notranslate"><span class="pre">measurement</span> <span class="pre">info</span></code>, it is a collection of metadata
regarding a <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> or <a class="reference internal" href="generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a>
object, containing channel locations and types, sampling frequency,
preprocessing history such as filters, etc.
See <a class="reference internal" href="auto_tutorials/intro/plot_30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse">inverse<a class="headerlink" href="#term-inverse" title="Permalink to this term">¶</a></dt><dt id="term-inverse-operator">inverse operator<a class="headerlink" href="#term-inverse-operator" title="Permalink to this term">¶</a></dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods MNE, dSPM, sLORETA and eLORETA.
See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>.</p>
</dd>
<dt id="term-label">label<a class="headerlink" href="#term-label" title="Permalink to this term">¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a defined region in the cortex, also often called
a region of interest (ROI) in the literature. Labels can be defined
anatomically (based on physical structure of the cortex) or functionally
(based on cortical response to specific stimuli).</p>
</dd>
<dt id="term-layout">layout<a class="headerlink" href="#term-layout" title="Permalink to this term">¶</a></dt><dd><p>A <a class="reference internal" href="generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> gives sensor positions in 2
dimensions (defined by <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code>, and <code class="docutils literal notranslate"><span class="pre">height</span></code> values for
each sensor). It is primarily used for illustrative purposes (i.e., making
diagrams of approximate sensor positions in top-down diagrams of the head,
so-called topographies or topomaps).</p>
</dd>
<dt id="term-LCMV">LCMV<a class="headerlink" href="#term-LCMV" title="Permalink to this term">¶</a></dt><dt id="term-LCMV-beamformer">LCMV beamformer<a class="headerlink" href="#term-LCMV-beamformer" title="Permalink to this term">¶</a></dt><dd><p>Linearly constrained minimum variance beamformer, which attempts to
estimate activity for a given source while suppressing cross-talk from
other regions, see <a class="reference internal" href="generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_lcmv()</span></code></a>. See also
<a class="reference internal" href="#term-beamformer"><span class="xref std std-term">beamformer</span></a>.</p>
</dd>
<dt id="term-maximum-intensity-projection">maximum intensity projection<a class="headerlink" href="#term-maximum-intensity-projection" title="Permalink to this term">¶</a></dt><dd><p>A method of displaying activity within some volume by, for each pixel,
finding the maximum value along vector from the viewer to the pixel
(i.e., along the vector pependicular to the view plane).</p>
</dd>
<dt id="term-MNE">MNE<a class="headerlink" href="#term-MNE" title="Permalink to this term">¶</a></dt><dt id="term-minimum-norm-estimate">minimum-norm estimate<a class="headerlink" href="#term-minimum-norm-estimate" title="Permalink to this term">¶</a></dt><dt id="term-minimum-norm-estimation">minimum-norm estimation<a class="headerlink" href="#term-minimum-norm-estimation" title="Permalink to this term">¶</a></dt><dd><p>Minimum-norm estimation (abbr. <code class="docutils literal notranslate"><span class="pre">MNE</span></code>) can be used to generate a distributed
map of activation on a <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>, usually on a cortical surface.
MNE uses a linear <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project sensor measurements
into the source space. The <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> is computed from the
<a class="reference internal" href="#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for a subject and an estimate of the
<a class="reference internal" href="#term-noise-covariance"><span class="xref std std-term">noise covariance</span></a> of sensor measurements.</p>
</dd>
<dt id="term-montage">montage<a class="headerlink" href="#term-montage" title="Permalink to this term">¶</a></dt><dd><p>EEG channel names and the relative positions of the sensor w.r.t. the scalp.
While layout are 2D locations, montages give 3D locations. A montage
can also contain locations for HPI points, fiducial points, or
extra head shape points.
See <a class="reference internal" href="generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">DigMontage</span></code></a> for the API of the corresponding object
class.</p>
</dd>
<dt id="term-morphing">morphing<a class="headerlink" href="#term-morphing" title="Permalink to this term">¶</a></dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is commonly referred as realignment in fMRI
literature. This operation is necessary for group studies (to get the
data in a common space for statistical analysis).
See <a class="reference internal" href="overview/implementation.html#ch-morph"><span class="std std-ref">Morphing and averaging source estimates</span></a> for more details.</p>
</dd>
<dt id="term-noise-covariance">noise covariance<a class="headerlink" href="#term-noise-covariance" title="Permalink to this term">¶</a></dt><dd><p>Noise covariance is a matrix that contains the covariance between data
channels. It is a square matrix with shape <code class="docutils literal notranslate"><span class="pre">n_channels</span></code> <span class="math notranslate nohighlight">\(\times\)</span>
<code class="docutils literal notranslate"><span class="pre">n_channels</span></code>. It is especially useful when working with multiple sensor
types (e.g. EEG and MEG). It is in
practice estimated from baseline periods or empty room measurements.
The matrix also provides a noise model that can be used for subsequent analysis
like source imaging.</p>
</dd>
<dt id="term-pick">pick<a class="headerlink" href="#term-pick" title="Permalink to this term">¶</a></dt><dd><p>An integer that is the index of a channel in the measurement info.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector<a class="headerlink" href="#term-projector" title="Permalink to this term">¶</a></dt><dt id="term-SSP">SSP<a class="headerlink" href="#term-SSP" title="Permalink to this term">¶</a></dt><dd><p>A projector (abbr. <code class="docutils literal notranslate"><span class="pre">proj</span></code>), also referred to as Signal Space
Projection (SSP), defines a linear operation applied spatially to EEG
or MEG data. A matrix multiplication of an SSP projector with the data
will reduce the rank of the data by projecting it to a
lower-dimensional subspace. Such projections are typically applied to
both the data and the forward operator when performing
source localization. Note that EEG average referencing can be done
using such a projection operator. Projectors are stored alongside data
in <a class="reference internal" href="#term-info"><span class="xref std std-term">the measurement info</span></a> in the field <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-raw">raw<a class="headerlink" href="#term-raw" title="Permalink to this term">¶</a></dt><dd><p><a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects hold continuous data (preprocessed or not). One typically
manipulates raw data when reading recordings in a file on disk.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/raw/plot_10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-ROI">ROI<a class="headerlink" href="#term-ROI" title="Permalink to this term">¶</a></dt><dt id="term-region-of-interest">region of interest<a class="headerlink" href="#term-region-of-interest" title="Permalink to this term">¶</a></dt><dd><p>A spatial region where an experimental effect is expected to manifest.
This can be a collection of sensors or, when performing inverse imaging,
a set of vertices on the cortical surface or within the cortical volume.
See also <a class="reference internal" href="#term-label"><span class="xref std std-term">label</span></a>.</p>
</dd>
<dt id="term-selection">selection<a class="headerlink" href="#term-selection" title="Permalink to this term">¶</a></dt><dd><p>A selection is a set of picked channels (for example, all sensors
falling within a <a class="reference internal" href="#term-region-of-interest"><span class="xref std std-term">region of interest</span></a>).</p>
</dd>
<dt id="term-source-space">source space<a class="headerlink" href="#term-source-space" title="Permalink to this term">¶</a></dt><dd><p>A source space (abbr. <code class="docutils literal notranslate"><span class="pre">src</span></code>) specifies where in the brain one wants
to estimate the
source amplitudes. It corresponds to locations of a set of
candidate <a class="reference internal" href="#term-ECD"><span class="xref std std-term">equivalent current dipoles</span></a>. MNE mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See <a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>
to read about how to compute a forward operator on a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the API of the corresponding
object class.</p>
</dd>
<dt id="term-STC">STC<a class="headerlink" href="#term-STC" title="Permalink to this term">¶</a></dt><dt id="term-source-estimate">source estimate<a class="headerlink" href="#term-source-estimate" title="Permalink to this term">¶</a></dt><dt id="term-source-time-course">source time course<a class="headerlink" href="#term-source-time-course" title="Permalink to this term">¶</a></dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods such as <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>,
<a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a> or MxNE.
STCs contain the amplitudes of the neural sources over time.
In MNE-Python, <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a> objects only store the
amplitudes of activation but not the locations of the sources; the
locations are stored separately in the <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> object
that was used to compute the forward operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>,
for the API of the corresponding object classes.</p>
</dd>
<dt id="term-stim-channel">stim channel<a class="headerlink" href="#term-stim-channel" title="Permalink to this term">¶</a></dt><dt id="term-trigger-channel">trigger channel<a class="headerlink" href="#term-trigger-channel" title="Permalink to this term">¶</a></dt><dd><p>A stim channel, a.k.a. trigger channel, is a channel that encodes
events during the recording. It is typically a channel that is usually
zero and takes positive values when something happens (such as the
onset of a stimulus, or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="auto_tutorials/intro/plot_20_events_from_raw.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-trans">trans<a class="headerlink" href="#term-trans" title="Permalink to this term">¶</a></dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
<dt id="term-whitening">whitening<a class="headerlink" href="#term-whitening" title="Permalink to this term">¶</a></dt><dd><p>A linear operation that transforms data with a known covariance
structure into “whitened data” which has a covariance structure that
is the identity matrix. In other words it creates virtual channels that
are uncorrelated and have unit variance. This is also known as a
sphering transformation.</p>
<p>The term “whitening” comes from the fact that light with a flat
frequency spectrum in the visible range is white, whereas
non-uniform frequency spectra lead to perception of different colors
(e.g., “pink noise” has a <code class="docutils literal notranslate"><span class="pre">1/f</span></code> characteristic, which for visible
light would appear pink).</p>
</dd>
</dl>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="auto_examples/datasets/spm_faces_dataset.html" title="previous page">From raw data to dSPM on SPM Faces dataset</a>
    <a class='right-next' id="next-link" href="overview/implementation.html" title="next page">Algorithms and other implementation details</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="_static/js/index.014cad6f3a039303089e.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-37225609-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
<footer class="footer mt-5 mt-md-0">
  <div class="container institutions">
    <div class="d-flex flex-wrap flex-row justify-content-center">
      <div class="m-2">
          <a href="https://www.massgeneral.org/">
            <img class="institution" src="_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://martinos.org/">
            <img class="institution" src="_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://hms.harvard.edu/">
            <img class="institution" src="_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://web.mit.edu/">
            <img class="institution" src="_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.nyu.edu/">
            <img class="institution" src="_static/institution_logos/NYU.png" title="New York University" alt="New York University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="http://www.cea.fr/">
            <img class="institution" src="_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://sci.aalto.fi/">
            <img class="institution" src="_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.telecom-paris.fr/">
            <img class="institution" src="_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.washington.edu/">
            <img class="institution" src="_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://icm-institute.org/">
            <img class="institution" src="_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.bu.edu/">
            <img class="institution" src="_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inserm.fr/">
            <img class="institution" src="_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.fz-juelich.de/">
            <img class="institution" src="_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.tu-ilmenau.de/">
            <img class="institution" src="_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://bids.berkeley.edu/">
            <img class="institution" src="_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inria.fr/">
            <img class="institution" src="_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.au.dk/">
            <img class="institution" src="_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.uni-graz.at/">
            <img class="institution" src="_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/>
          </a>
        </div>
      
    </div>
  </div>
  <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-02-19T12:28:42.787072+00:00" class="localized">2021-02-19 12:28 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
</footer>
  <script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>