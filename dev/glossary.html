<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Glossary &#8212; MNE 0.19.dev0 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" href="_static/reset-syntax.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script type="text/javascript" src="_static/bootstrap_divs.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />

    <script type="text/javascript" src="_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="_static/style.css " type="text/css" />
    <link rel="stylesheet" href="_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>



  </head><body>

<div class="row devbar alert alert-danger">
This documentation is for <strong>development version 0.19.dev0</strong>.
</div>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.19.dev0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="install/index.html">Install</a></li>
                <li><a href="documentation.html">Documentation</a></li>
                <li><a href="python_reference.html">API</a></li>
                <li><a href="#">Glossary</a></li>
                <li><a href="auto_examples/index.html">Examples</a></li>
                <li><a href="auto_tutorials/index.html">Tutorials</a></li>
                <li><a href="install/contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-danger navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.19.dev0
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.18 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Glossary</a><ul>
<li><a class="reference internal" href="#mne-python-core-terminology-and-general-concepts">MNE-Python core terminology and general concepts</a></li>
</ul>
</li>
</ul>

<form action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="glossary">
<span id="id1"></span><h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">¶</a></h1>
<div class="section" id="mne-python-core-terminology-and-general-concepts">
<h2>MNE-Python core terminology and general concepts<a class="headerlink" href="#mne-python-core-terminology-and-general-concepts" title="Permalink to this headline">¶</a></h2>
<dl class="glossary simple">
<dt id="term-annotations">annotations</dt><dd><p>An annotation is defined by an onset, a duration, and a string
description. It can contain information about the experiments, but
also details on signals marked by a human: bad data segments,
sleep scores, sleep events (spindles, K-complex) etc.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container of multiple annotations.
See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> page for the API of the corresponding
object class and <a class="reference external" href="https://docs.python.org/3/tutorial/controlflow.html#tut-annotations" title="(in Python v3.7)"><span>Function Annotations</span></a>
for a tutorial on how to manipulate such objects.</p>
</dd>
<dt id="term-bem">BEM</dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the forward model computation and more
specifically the definion of the conductor model. The
boundary element model consists of surfaces such as the inner skull,
outer skull and outer skin (a.k.a. scalp) that define compartments
of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for usage demo.</p>
</dd>
<dt id="term-channels">channels</dt><dd><p>Channels refer to MEG sensors, EEG electrodes or any extra electrode
or sensor such as EOG, ECG or sEEG, ECoG etc. Channels usually have
a type, such as gradiometer, and a unit, such as Tesla/Meter that
is used in the code base, e.g. for plotting.</p>
</dd>
<dt id="term-dipole">dipole</dt><dd><p>See <a class="reference internal" href="#term-equivalent-current-dipole"><span class="xref std std-term">equivalent current dipole</span></a>.</p>
</dd>
<dt id="term-epochs">epochs</dt><dd><p>Epochs (sometimes called “trials” in other software packages) are
equal-length spans of data extracted from raw continuous data. Usually,
epochs are extracted around stimulus events or subject responses,
though sometimes sequential or overlapping epochs are extracted (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
API of the corresponding object class, and <a class="reference internal" href="auto_tutorials/epochs/plot_object_epochs.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: epoched data</span></a> for
a narrative overview.</p>
</dd>
<dt id="term-equivalent-current-dipole">equivalent current dipole</dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small region of cortex. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by the techniques
are well-approximated by (i.e., “equivalent” to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-events">events</dt><dd><p>Events correspond to specific time points in raw data; e.g.,
triggers, experimental condition events, etc. MNE represents events with
integers that are stored in numpy arrays of shape (n_events, 3). Such arrays
are classically obtained from a trigger channel, also referred to as
stim channel.</p>
</dd>
<dt id="term-evoked">evoked</dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/evoked/plot_object_evoked.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-first-samp">first_samp</dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data started to be recorded to disk. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files.</p>
</dd>
<dt id="term-forward-solution">forward solution</dt><dd><p>The forward solution (abbr. <code class="docutils literal notranslate"><span class="pre">fwd</span></code>) is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors (AKA,
the “lead field matrix”). Calculating a forward solution requires a
conductivity model of the head, encapsulating the geometry and
electrical conductivity of the different tissue compartments (see
<a class="reference internal" href="#term-bem"><span class="xref std std-term">boundary element model</span></a> and
<a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-gfp">GFP</dt><dd><p>Global Field Power (abbr. <code class="docutils literal notranslate"><span class="pre">GFP</span></code>) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point; thus
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-info">info</dt><dd><p>Also called <code class="docutils literal notranslate"><span class="pre">measurement</span> <span class="pre">info</span></code>, it is a collection of metadata regarding
a Raw, Epochs or Evoked object; e.g.,
channel locations and types, sampling frequency,
preprocessing history such as filters …
See <a class="reference internal" href="auto_tutorials/intro/plot_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse-operator">inverse operator</dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods MNE, dSPM, sLORETA and eLORETA.</p>
</dd>
<dt id="term-label">label</dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a region in the cortex, also often called
a region of interest (ROI) in the literature.</p>
</dd>
<dt id="term-montage">montage</dt><dd><p>EEG channel names and the relative positions of the sensor w.r.t. the scalp.
See <a class="reference internal" href="generated/mne.channels.Montage.html#mne.channels.Montage" title="mne.channels.Montage"><code class="xref py py-class docutils literal notranslate"><span class="pre">Montage</span></code></a> for the API of the corresponding object
class.</p>
</dd>
<dt id="term-morphing">morphing</dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is commonly referred as realignment in fMRI
literature. This operation is necessary for group studies.
See <a class="reference internal" href="manual/source_localization/morph_stc.html#ch-morph"><span class="std std-ref">Morphing source estimates: Moving data from one brain to another</span></a> for more details.</p>
</dd>
<dt id="term-pick">pick</dt><dd><p>An integer that is the index of a channel in the measurement info.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector</dt><dd><p>A projector (abbr. <code class="docutils literal notranslate"><span class="pre">proj</span></code>), also referred to as Signal Space
Projection (SSP), defines
a linear operation applied spatially to EEG or MEG data. You can see
this as a matrix multiplication that reduces the rank of the data by
projecting it to a lower dimensional subspace. Such a projection
operator is applied to both the data and the forward operator for
source localization. Note that EEG average referencing can be done
using such a projection operator. It is stored in the measurement
info in <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-raw">raw</dt><dd><p>It corresponds to continuous data (preprocessed or not). One typically
manipulates raw data when reading recordings in a file on disk.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/raw/plot_object_raw.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-selection-abbr-sel">selection (abbr. sel)</dt><dd><p>A set of picks. E.g., all sensors included in a Region of Interest.</p>
</dd>
<dt id="term-source-estimates-abbr-stc">source estimates (abbr. <code class="docutils literal notranslate"><span class="pre">stc</span></code>)</dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods,
such as dSPM, sLORETA, LCMV or MxNE.
It contains the amplitudes of the sources over time.
An STC object only stores the amplitudes of activations but
not the locations of the sources. To get access to the locations
you need to have the source space used to compute the forward
operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>,
for the API of the corresponding object classes.</p>
</dd>
<dt id="term-source-space">source space</dt><dd><p>A source space (abbr. <code class="docutils literal notranslate"><span class="pre">src</span></code>) specifies where in the brain one wants
to estimate the
source amplitudes. It corresponds to locations of a set of
candidate equivalent current dipoles (ECD). MNE mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See
<a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> to read on
how to compute a forward operator on a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the API of the corresponding
object class.</p>
</dd>
<dt id="term-stim-channel">stim channel</dt><dd><p>A stim channel, a.k.a. trigger channel, is a channel that encodes
events during the recording. It is typically a channel that is usually
zero and takes positive values when something happens (such as the
onset of a stimulus, or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="auto_tutorials/intro/plot_object_annotations.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-trans">trans</dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
</dl>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container institutions">
    <a href="https://www.massgeneral.org/"><img class="institution_lg" src="_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a>
    <a href="https://martinos.org/"><img class="institution_lg" src="_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a>
    <a href="https://hms.harvard.edu/"><img class="institution_lg" src="_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a>
    <a href="https://web.mit.edu/"><img class="institution_sm" src="_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a>
    <a href="https://www.nyu.edu/"><img class="institution_md" src="_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a>
    <a href="http://www.cea.fr/"><img class="institution_md" src="_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/></a>
    <a href="https://sci.aalto.fi/"><img class="institution_md" src="_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a>
    <a href="https://www.telecom-paris.fr/"><img class="institution_md" src="_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/></a>
    <a href="https://www.washington.edu/"><img class="institution_sm" src="_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a>
    <a href="https://icm-institute.org/"><img class="institution_lg" src="_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/></a>
    <a href="https://www.bu.edu/"><img class="institution_sm" src="_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a>
    <a href="https://www.inserm.fr/"><img class="institution_xs" src="_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/></a>
    <a href="https://www.fz-juelich.de/"><img class="institution_sm" src="_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/></a>
    <a href="https://www.tu-ilmenau.de/"><img class="institution_sm" src="_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/></a>
    <a href="https://bids.berkeley.edu/"><img class="institution_md" src="_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a>
    <a href="https://www.inria.fr/"><img class="institution_sm" src="_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a>
    <a href="https://www.au.dk/"><img class="institution_sm" src="_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a>
    <a href="https://www.uni-graz.at/"><img class="institution_md" src="_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/></a>
  </div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2019, MNE Developers. Last updated on 2019-06-19.</p>
  </div>
</footer>
  </body>
</html>