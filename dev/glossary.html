<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Glossary &#8212; MNE 0.23.dev0 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/bootstrap_divs.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />

    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    <script type="text/javascript" src="_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="_static/style.css " type="text/css" />
    <link rel="stylesheet" href="_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="_static/font-source-code-pro.css" type="text/css" />
    <link rel="stylesheet" href="_static/font-source-sans-pro.css" type="text/css" />
    <link rel="stylesheet" href="_static/flag-icon.css" type="text/css" />


    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>



  </head><body>

<div class="d-block devbar alert alert-danger">
This is documentation for the <em>unstable development version</em> of MNE-Python,
<a href="https://mne.tools/dev/install/advanced.html#using-the-development-version-of-mne-python-latest-master">available here</a>.
Or, switch to documentation for the <a href="https://mne.tools/stable">current stable version</a>.

</div>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/mne_logo_small.svg"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.23.dev0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="install/index.html">Install</a></li>
                <li><a href="overview/index.html">Overview</a></li>
                <li><a href="auto_tutorials/index.html">Tutorials</a></li>
                <li><a href="auto_examples/index.html">Examples</a></li>
                <li><a href="#">Glossary</a></li>
                <li><a href="python_reference.html">API</a></li>
            
            
            <li class="dropdown globaltoc-container">
              <a role="button" id="dLabelGlobalToc" data-toggle="dropdown" data-target="#" href="#">More<b class="caret"></b></a>
              <ul class="dropdown-menu globaltoc" role="menu" aria-labelledby="dLabelGlobalToc">
                <li><a href="https://github.com/mne-tools/mne-python"><i class="fa fa-github"></i> GitHub</a></li>
                <li><a href="overview/get_help.html"><i class="fa fa-question-circle"></i> Get help</a></li>
                <li><a href="install/contributing.html"><i class="fa fa-code-fork"></i> Contribute</a></li>
                <li><a href="overview/cite.html"><i class="fa fa-book"></i> Cite MNE</a></li>
              </ul>
            </li>

            <li class="dropdown">
              <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown" style="margin-left: 10px">
              v0.23.dev0
              <span class="caret"></span>
            </button>
              <ul class="dropdown-menu" aria-labelledby="dLabelMore">
                <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
                <li><a href="https://mne-tools.github.io/stable/index.html">v0.22 (stable)</a></li>
                <li><a href="https://mne-tools.github.io/0.21/index.html">v0.21</a></li>
                <li><a href="https://mne-tools.github.io/0.20/index.html">v0.20</a></li>
                <li><a href="https://mne-tools.github.io/0.19/index.html">v0.19</a></li>
                <li><a href="https://mne-tools.github.io/0.18/index.html">v0.18</a></li>
                <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
                <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
                <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
                <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
                <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
                <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
                <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
              </ul>
            </li>

            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="glossary">
<span id="id1"></span><h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">¶</a></h1>
<p>The Glossary provides short definitions of MNE-Python-specific vocabulary and
general neuroimaging concepts. If you think a term is missing, please consider
<a class="reference external" href="https://github.com/mne-tools/mne-python/issues/new?template=glossary.md">creating a new issue</a> or <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/new/master">opening a pull request</a> to add it.</p>
<dl class="glossary">
<dt id="term-annotations">annotations</dt><dd><p>An annotation is defined by an onset, a duration, and a string
description. It can contain information about the experiments, but
also details on signals marked by a human: bad data segments,
sleep scores, sleep events (spindles, K-complex) etc.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container of multiple annotations.
See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> page for the API of the corresponding
object class and <a class="reference external" href="https://docs.python.org/3/tutorial/controlflow.html#tut-annotations" title="(in Python v3.9)"><span>Function Annotations</span></a>
for a tutorial on how to manipulate such objects.</p>
</dd>
<dt id="term-Beamformer">Beamformer</dt><dd><p>Beamformer is a popular source estimation approach that uses a set of
spatial filters (beamformer weights) to compute time courses of sources
which coordinates are predefined. See <a class="reference internal" href="generated/mne.beamformer.Beamformer.html#mne.beamformer.Beamformer" title="mne.beamformer.Beamformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.beamformer.Beamformer</span></code></a>.</p>
</dd>
<dt id="term-BEM">BEM</dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the forward model computation and more
specifically the definion of the conductor model. The
boundary element model consists of surfaces such as the inner skull,
outer skull and outer skin (a.k.a. scalp) that define compartments
of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for usage demo.</p>
</dd>
<dt id="term-channels">channels</dt><dd><p>Channels refer to MEG sensors, EEG electrodes or any extra electrode
or sensor such as EOG, ECG or sEEG, ECoG etc. Channels usually have
a type, such as gradiometer, and a unit, such as Tesla/Meter that
is used in the code base, e.g. for plotting. See also
<a class="reference internal" href="#term-data-channels"><span class="xref std std-term">data channels</span></a>.</p>
</dd>
<dt id="term-data-channels">data channels</dt><dd><p>Many functions in MNE operate by default on “data channels”. These are
channels that typically hold <em>brain electophysiological</em> data,
as opposed to other forms of data, such as EOG, ECG, stimulus trigger,
or acquisition system status data. The set of channels considered
“data channels” in MNE is (along with their typical scale factors for
plotting, as they are stored in objects in SI units):</p>
<div class="compound">
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'mag'</span></code>: <strong>Magnetometers</strong> (scaled by 1e+15 to plot in <em>fT</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'grad'</span></code>: <strong>Gradiometers</strong> (scaled by 1e+13 to plot in <em>fT/cm</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'eeg'</span></code>: <strong>EEG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'csd'</span></code>: <strong>Current source density</strong> (scaled by 1000 to plot in <em>mV/m²</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'seeg'</span></code>: <strong>sEEG</strong> (scaled by 1000 to plot in <em>mV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ecog'</span></code>: <strong>ECoG</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dbs'</span></code>: <strong>DBS</strong> (scaled by 1e+06 to plot in <em>µV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbo'</span></code>: <strong>Oxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbr'</span></code>: <strong>Deoxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>µM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_cw_amplitude'</span></code>: <strong>fNIRS (CW amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_ac_amplitude'</span></code>: <strong>fNIRS (FD AC amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_phase'</span></code>: <strong>fNIRS (FD phase)</strong> (scaled by 1 to plot in <em>rad</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_od'</span></code>: <strong>fNIRS (OD)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
</ul>
</div>
</dd>
<dt id="term-DICS">DICS</dt><dd><p>Dynamic Imaging of Coherent Sources, a method for computing source
power in different frequency bands. see <a class="reference internal" href="auto_examples/inverse/plot_dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a>
and <a class="reference internal" href="generated/mne.beamformer.make_dics.html#mne.beamformer.make_dics" title="mne.beamformer.make_dics"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.beamformer.make_dics()</span></code></a>.</p>
</dd>
<dt id="term-digitization">digitization</dt><dd><p>Digitization is a procedure of recording the headshape of a subject and
the fiducial coils (or <a class="reference internal" href="#term-HPI"><span class="xref std std-term">HPI</span></a>) and/or eeg electrodes locations on
the subject’s head. They are represented as a set of points in a 3D space.
See <a class="reference internal" href="auto_tutorials/intro/plot_40_sensor_locations.html#reading-dig-montages"><span class="std std-ref">Reading sensor digitization files</span></a> and <a class="reference internal" href="overview/implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>.</p>
</dd>
<dt id="term-dipole">dipole</dt><dd><p>See <a class="reference internal" href="#term-equivalent-current-dipole"><span class="xref std std-term">equivalent current dipole</span></a>.</p>
</dd>
<dt id="term-dSPM">dSPM</dt><dd><p>Dynamic statistical parametric mapping (abbr. <code class="docutils literal notranslate"><span class="pre">dSPM</span></code>) gives a noise-
normalized minimum-norm estimate at a given source location. dSPM is
calculated by dividing the activity estimate at each source location by
the baseline standard deviation of the noise.</p>
</dd>
<dt id="term-eLORETA-and-sLORETA">eLORETA and sLORETA</dt><dd><p>eLORETA and sLORETA (exact and standardized low resolution brain
electromagnetic tomography) are linear source estimation techniques,
as are dSPM or <a class="reference internal" href="#term-minimum-norm-estimation"><span class="xref std std-term">MNE</span></a>. sLORETA outputs
standardized values (like dSPM does), while eLORETA outputs normalized
current estimates. See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.minimum_norm.apply_inverse()</span></code></a>,
<a class="reference internal" href="auto_tutorials/source-modeling/plot_mne_dspm_source_localization.html#tut-inverse-methods"><span class="std std-ref">Source localization with MNE/dSPM/sLORETA/eLORETA</span></a>, and <a class="reference internal" href="auto_examples/inverse/plot_compute_mne_inverse_raw_in_label.html#example-sloreta"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a>.</p>
</dd>
<dt id="term-epochs">epochs</dt><dd><p>Epochs (sometimes called “trials” in other software packages) are
equal-length spans of data extracted from raw continuous data. Usually,
epochs are extracted around stimulus events or subject responses,
though sometimes sequential or overlapping epochs are extracted (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
API of the corresponding object class, and <a class="reference internal" href="auto_tutorials/epochs/plot_10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a> for
a narrative overview.</p>
</dd>
<dt id="term-equivalent-current-dipole">equivalent current dipole</dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small region of cortex. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by the techniques
are well-approximated by (i.e., “equivalent” to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-events">events</dt><dd><p>Events correspond to specific time points in raw data; e.g.,
triggers, experimental condition events, etc. MNE represents events with
integers that are stored in numpy arrays of shape (n_events, 3). Such arrays
are classically obtained from a trigger channel, also referred to as
stim channel.</p>
</dd>
<dt id="term-evoked">evoked</dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/evoked/plot_10_evoked_overview.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-fiducial-point">fiducial point</dt><dd><p>There are three fiducial (a.k.a. cardinal) points: the left
preauricular point (LPA), the right preauricular point (RPA)
and the nasion.</p>
</dd>
<dt id="term-first_samp">first_samp</dt><dd><p>The <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data started to be recorded to disk. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files.</p>
</dd>
<dt id="term-forward-solution">forward solution</dt><dd><p>The forward solution (abbr. <code class="docutils literal notranslate"><span class="pre">fwd</span></code>) is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors (A.K.A.,
the “lead field matrix”). Calculating a forward solution requires a
conductivity model of the head, encapsulating the geometry and
electrical conductivity of the different tissue compartments (see
<a class="reference internal" href="#term-BEM"><span class="xref std std-term">boundary element model</span></a> and
<a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-GFP">GFP</dt><dd><p>Global Field Power (abbr. <code class="docutils literal notranslate"><span class="pre">GFP</span></code>) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point; thus
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-HPI">HPI</dt><dd><p>Head position indicators (abbr. <code class="docutils literal notranslate"><span class="pre">HPI</span></code>, or sometimes <code class="docutils literal notranslate"><span class="pre">cHPI</span></code> for
<em>continuous</em> head position indicators) are small coils attached to a
subject’s head during MEG acquisition. Each coil emits a sinusoidal
signal of a different frequency, which is picked up by the MEG sensors
and can be used to infer the head position. With cHPI, the sinusoidal
signals are typically set at frequencies above any neural signal of
interest, and thus can be removed after head position correction via
low-pass filtering. See <a class="reference internal" href="auto_tutorials/preprocessing/plot_59_head_positions.html#tut-head-pos"><span class="std std-ref">Extracting and visualizing subject head movement</span></a>.</p>
</dd>
<dt id="term-info">info</dt><dd><p>Also called <code class="docutils literal notranslate"><span class="pre">measurement</span> <span class="pre">info</span></code>, it is a collection of metadata regarding
a Raw, Epochs or Evoked object; e.g.,
channel locations and types, sampling frequency,
preprocessing history such as filters …
See <a class="reference internal" href="auto_tutorials/intro/plot_30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse-operator">inverse operator</dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods MNE, dSPM, sLORETA and eLORETA.
See <a class="reference internal" href="generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.minimum_norm.apply_inverse()</span></code></a>.</p>
</dd>
<dt id="term-label">label</dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a region in the cortex, also often called
a region of interest (ROI) in the literature.</p>
</dd>
<dt id="term-layout">layout</dt><dd><p>A <a class="reference internal" href="generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> gives sensor positions in 2
dimensions (defined by <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code>, and <code class="docutils literal notranslate"><span class="pre">height</span></code> values for
each sensor). It is primarily used for illustrative purposes (i.e., making
diagrams of approximate sensor positions in top-down diagrams of the head,
so-called topographies or topomaps).</p>
</dd>
<dt id="term-LCMV-beamformer">LCMV beamformer</dt><dd><p>Linearly constrained minimum variance beamformer, which attempts to
estimate activity for a given source while suppressing cross-talk from
other regions, see <a class="reference internal" href="generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.beamformer.make_lcmv()</span></code></a>.</p>
</dd>
<dt id="term-maximum-intensity-projection">maximum intensity projection</dt><dd><p>A method of displaying activity within some volume by, for each pixel,
finding the maximum value along vector from the viewer to the pixel
(i.e., along the vector pependicular to the view plane).</p>
</dd>
<dt id="term-minimum-norm-estimation">minimum-norm estimation</dt><dd><p>Minimum-norm estimation (abbr. <code class="docutils literal notranslate"><span class="pre">MNE</span></code>) can be used to generate a distributed
map of activation on a <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>, usually on a cortical surface.
MNE uses a linear <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project sensor measurements
into the source space. The <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> is computed from the
<a class="reference internal" href="#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for a subject and an estimate of the
<a class="reference internal" href="#term-noise-covariance"><span class="xref std std-term">noise covariance</span></a> of sensor measurements.</p>
</dd>
<dt id="term-montage">montage</dt><dd><p>EEG channel names and the relative positions of the sensor w.r.t. the scalp.
While layout are 2D locations, montages give 3D locations. A montage
can also contain locations for HPI points, fiducial points, or
extra head shape points.
See <a class="reference internal" href="generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">DigMontage</span></code></a> for the API of the corresponding object
class.</p>
</dd>
<dt id="term-morphing">morphing</dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is commonly referred as realignment in fMRI
literature. This operation is necessary for group studies (to get the
data in a common space for statistical analysis).
See <a class="reference internal" href="overview/implementation.html#ch-morph"><span class="std std-ref">Morphing and averaging source estimates</span></a> for more details.</p>
</dd>
<dt id="term-noise-covariance">noise covariance</dt><dd><p>Noise covariance is a matrix that contains the covariance between data
channels. It is a square matrix with shape <code class="docutils literal notranslate"><span class="pre">n_channels</span></code> <span class="math notranslate nohighlight">\(\times\)</span>
<code class="docutils literal notranslate"><span class="pre">n_channels</span></code>. It is especially useful when working with multiple sensor
types (e.g. EEG and MEG). It is in
practice estimated from baseline periods or empty room measurements.
The matrix also provides a noise model that can be used for subsequent analysis
like source imaging.</p>
</dd>
<dt id="term-pick">pick</dt><dd><p>An integer that is the index of a channel in the measurement info.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector</dt><dd><p>A projector (abbr. <code class="docutils literal notranslate"><span class="pre">proj</span></code>), also referred to as Signal Space
Projection (SSP), defines
a linear operation applied spatially to EEG or MEG data. You can see
this as a matrix multiplication that reduces the rank of the data by
projecting it to a lower dimensional subspace. Such a projection
operator is applied to both the data and the forward operator for
source localization. Note that EEG average referencing can be done
using such a projection operator. It is stored in the measurement
info in <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-raw">raw</dt><dd><p>It corresponds to continuous data (preprocessed or not). One typically
manipulates raw data when reading recordings in a file on disk.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/raw/plot_10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-selection-abbr.-sel">selection (abbr. sel)</dt><dd><p>A set of picks. E.g., all sensors included in a Region of Interest.</p>
</dd>
<dt id="term-source-estimates-abbr.-stc">source estimates (abbr. <code class="docutils literal notranslate"><span class="pre">stc</span></code>)</dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods,
such as dSPM, sLORETA, LCMV or MxNE.
It contains the amplitudes of the sources over time.
An STC object only stores the amplitudes of activations but
not the locations of the sources. To get access to the locations
you need to have the source space used to compute the forward
operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>,
for the API of the corresponding object classes.</p>
</dd>
<dt id="term-source-space">source space</dt><dd><p>A source space (abbr. <code class="docutils literal notranslate"><span class="pre">src</span></code>) specifies where in the brain one wants
to estimate the
source amplitudes. It corresponds to locations of a set of
candidate equivalent current dipoles (ECD). MNE mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See
<a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> to read on
how to compute a forward operator on a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the API of the corresponding
object class.</p>
</dd>
<dt id="term-stim-channel">stim channel</dt><dd><p>A stim channel, a.k.a. trigger channel, is a channel that encodes
events during the recording. It is typically a channel that is usually
zero and takes positive values when something happens (such as the
onset of a stimulus, or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="auto_tutorials/intro/plot_20_events_from_raw.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-trans">trans</dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
<dt id="term-whitening">whitening</dt><dd><p>A linear operation that transforms data with a known covariance
structure into “whitened data” which has a covariance structure that
is the identity matrix. In other words it creates virtual channels that
are uncorrelated and have unit variance. This is also known as a
sphering transformation.</p>
<p>The term “whitening” comes from the fact that light with a flat
frequency spectrum in the visible range is white, whereas
non-uniform frequency spectra lead to perception of different colors
(e.g., “pink noise” has a <code class="docutils literal notranslate"><span class="pre">1/f</span></code> characteristic, which for visible
light would appear pink).</p>
</dd>
</dl>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container"><div class="row">
    <div class="container col-md-12 institutions">
      <ul class="list-unstyled">
        <li><a href="https://www.massgeneral.org/"><img class="institution" src="_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a></li>
        <li><a href="https://martinos.org/"><img class="institution" src="_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a></li>
        <li><a href="https://hms.harvard.edu/"><img class="institution" src="_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a></li>
        <li><a href="https://web.mit.edu/"><img class="institution" src="_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a></li>
        <li><a href="https://www.nyu.edu/"><img class="institution" src="_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a></li>
        <li><a href="http://www.cea.fr/"><img class="institution" src="_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/></a></li>
        <li><a href="https://sci.aalto.fi/"><img class="institution" src="_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a></li>
        <li><a href="https://www.telecom-paris.fr/"><img class="institution" src="_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/></a></li>
        <li><a href="https://www.washington.edu/"><img class="institution" src="_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a></li>
        <li><a href="https://icm-institute.org/"><img class="institution" src="_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/></a></li>
        <li><a href="https://www.bu.edu/"><img class="institution" src="_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a></li>
        <li><a href="https://www.inserm.fr/"><img class="institution" src="_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/></a></li>
        <li><a href="https://www.fz-juelich.de/"><img class="institution" src="_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/></a></li>
        <li><a href="https://www.tu-ilmenau.de/"><img class="institution" src="_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/></a></li>
        <li><a href="https://bids.berkeley.edu/"><img class="institution" src="_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a></li>
        <li><a href="https://www.inria.fr/"><img class="institution" src="_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a></li>
        <li><a href="https://www.au.dk/"><img class="institution" src="_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a></li>
        <li><a href="https://www.uni-graz.at/"><img class="institution" src="_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/></a></li>
      </ul>
      <p class="text-center text-muted small">&copy; Copyright 2012-2020, MNE Developers. Last updated on 2020-03-27.</p>
    </div></div></div>
  </footer>
  <script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>