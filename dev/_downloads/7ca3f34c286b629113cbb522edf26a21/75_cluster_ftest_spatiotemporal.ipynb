{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Spatiotemporal permutation F-test on full sensor data\n\nTests for differential evoked responses in at least one condition using a permutation\nclustering test. The FieldTrip neighbor templates will be used to determine the\nadjacency between sensors. This serves as a spatial prior to the clustering.\nSpatiotemporal clusters will then be visualized using custom matplotlib code.\n\nHere, the unit of observation is epochs from a specific study subject.\nHowever, the same logic applies when the unit observation is\na number of study subject each of whom contribute their own averaged\ndata (i.e., an average of their epochs). This would then be considered\nan analysis at the \"2nd level\".\n\nSee the [FieldTrip tutorial](ft_cluster_) for a caveat regarding\nthe possible interpretation of \"significant\" clusters.\n\nFor more information on cluster-based permutation testing in MNE-Python,\nsee also: `tut-cluster-one-samp-tfr`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Denis Engemann <denis.engemann@gmail.com>\n#          Jona Sassenhagen <jona.sassenhagen@gmail.com>\n#          Alex Rockhill <aprockhill@mailbox.org>\n#          Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nimport mne\nfrom mne.channels import find_ch_adjacency\nfrom mne.datasets import sample\nfrom mne.stats import combine_adjacency, spatio_temporal_cluster_test\nfrom mne.viz import plot_compare_evokeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nmeg_path = data_path / \"MEG\" / \"sample\"\nraw_fname = meg_path / \"sample_audvis_filt-0-40_raw.fif\"\nevent_fname = meg_path / \"sample_audvis_filt-0-40_raw-eve.fif\"\nevent_id = {\"Aud/L\": 1, \"Aud/R\": 2, \"Vis/L\": 3, \"Vis/R\": 4}\ntmin = -0.2\ntmax = 0.5\n\n# Setup for reading the raw data\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\nraw.filter(1, 25)\nevents = mne.read_events(event_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read epochs for the channel of interest\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "picks = mne.pick_types(raw.info, meg=\"mag\", eog=True)\n\nreject = dict(mag=4e-12, eog=150e-6)\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id,\n    tmin,\n    tmax,\n    picks=picks,\n    decim=2,  # just for speed!\n    baseline=None,\n    reject=reject,\n    preload=True,\n)\n\nepochs.drop_channels([\"EOG 061\"])\nepochs.equalize_event_counts(event_id)\n\n# Obtain the data as a 3D matrix and transpose it such that\n# the dimensions are as expected for the cluster permutation test:\n# n_epochs \u00d7 n_times \u00d7 n_channels\nX = [epochs[event_name].get_data(copy=False) for event_name in event_id]\nX = [np.transpose(x, (0, 2, 1)) for x in X]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the FieldTrip neighbor definition to setup sensor adjacency\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adjacency, ch_names = find_ch_adjacency(epochs.info, ch_type=\"mag\")\n\nprint(type(adjacency))  # it's a sparse matrix!\n\nmne.viz.plot_ch_adjacency(epochs.info, adjacency, ch_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute permutation statistic\n\nHow does it work? We use clustering to \"bind\" together features which are\nsimilar. Our features are the magnetic fields measured over our sensor\narray at different times. This reduces the multiple comparison problem.\nTo compute the actual test-statistic, we first sum all F-values in all\nclusters. We end up with one statistic for each cluster.\nThen we generate a distribution from the data by shuffling our conditions\nbetween our samples and recomputing our clusters and the test statistics.\nWe test for the significance of a given cluster by computing the probability\nof observing a cluster of that size\n:footcite:`MarisOostenveld2007,Sassenhagen2019`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We are running an F test, so we look at the upper tail\n# see also: https://stats.stackexchange.com/a/73993\ntail = 1\n\n# We want to set a critical test statistic (here: F), to determine when\n# clusters are being formed. Using Scipy's percent point function of the F\n# distribution, we can conveniently select a threshold that corresponds to\n# some alpha level that we arbitrarily pick.\nalpha_cluster_forming = 0.001\n\n# For an F test we need the degrees of freedom for the numerator\n# (number of conditions - 1) and the denominator (number of observations\n# - number of conditions):\nn_conditions = len(event_id)\nn_observations = len(X[0])\ndfn = n_conditions - 1\ndfd = n_observations - n_conditions\n\n# Note: we calculate 1 - alpha_cluster_forming to get the critical value\n# on the right tail\nf_thresh = scipy.stats.f.ppf(1 - alpha_cluster_forming, dfn=dfn, dfd=dfd)\n\n# run the cluster based permutation analysis\ncluster_stats = spatio_temporal_cluster_test(\n    X,\n    n_permutations=1000,\n    threshold=f_thresh,\n    tail=tail,\n    n_jobs=None,\n    buffer_size=None,\n    adjacency=adjacency,\n)\nF_obs, clusters, p_values, _ = cluster_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Note how we only specified an adjacency for sensors! However,\n          because we used :func:`mne.stats.spatio_temporal_cluster_test`,\n          an adjacency for time points was automatically taken into\n          account. That is, at time point N, the time points N - 1 and\n          N + 1 were considered as adjacent (this is also called \"lattice\n          adjacency\"). This is only possible because we ran the analysis on\n          2D data (times \u00d7 channels) per observation ... for 3D data per\n          observation (e.g., times \u00d7 frequencies \u00d7 channels), we will need\n          to use :func:`mne.stats.combine_adjacency`, as shown further\n          below.</p></div>\n\nNote also that the same functions work with source estimates.\nThe only differences are the origin of the data, the size,\nand the adjacency definition.\nIt can be used for single trials or for groups of subjects.\n\n## Visualize clusters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We subselect clusters that we consider significant at an arbitrarily\n# picked alpha level: \"p_accept\".\n# NOTE: remember the caveats with respect to \"significant\" clusters that\n# we mentioned in the introduction of this tutorial!\np_accept = 0.01\ngood_cluster_inds = np.where(p_values < p_accept)[0]\n\n# configure variables for visualization\ncolors = {\"Aud\": \"crimson\", \"Vis\": \"steelblue\"}\nlinestyles = {\"L\": \"-\", \"R\": \"--\"}\n\n# organize data for plotting\nevokeds = {cond: epochs[cond].average() for cond in event_id}\n\n# loop over clusters\nfor i_clu, clu_idx in enumerate(good_cluster_inds):\n    # unpack cluster information, get unique indices\n    time_inds, space_inds = np.squeeze(clusters[clu_idx])\n    ch_inds = np.unique(space_inds)\n    time_inds = np.unique(time_inds)\n\n    # get topography for F stat\n    f_map = F_obs[time_inds, ...].mean(axis=0)\n\n    # get signals at the sensors contributing to the cluster\n    sig_times = epochs.times[time_inds]\n\n    # create spatial mask\n    mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n    mask[ch_inds, :] = True\n\n    # initialize figure\n    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3), layout=\"constrained\")\n\n    # plot average test statistic and mark significant sensors\n    f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs.info, tmin=0)\n    f_evoked.plot_topomap(\n        times=0,\n        mask=mask,\n        axes=ax_topo,\n        cmap=\"Reds\",\n        vlim=(np.min, np.max),\n        show=False,\n        colorbar=False,\n        mask_params=dict(markersize=10),\n    )\n    image = ax_topo.images[0]\n\n    # remove the title that would otherwise say \"0.000 s\"\n    ax_topo.set_title(\"\")\n\n    # create additional axes (for ERF and colorbar)\n    divider = make_axes_locatable(ax_topo)\n\n    # add axes for colorbar\n    ax_colorbar = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(image, cax=ax_colorbar)\n    ax_topo.set_xlabel(\n        \"Averaged F-map ({:0.3f} - {:0.3f} s)\".format(*sig_times[[0, -1]])\n    )\n\n    # add new axis for time courses and plot time courses\n    ax_signals = divider.append_axes(\"right\", size=\"300%\", pad=1.2)\n    title = f\"Cluster #{i_clu + 1}, {len(ch_inds)} sensor\"\n    if len(ch_inds) > 1:\n        title += \"s (mean)\"\n    plot_compare_evokeds(\n        evokeds,\n        title=title,\n        picks=ch_inds,\n        axes=ax_signals,\n        colors=colors,\n        linestyles=linestyles,\n        show=False,\n        split_legend=True,\n        truncate_yaxis=\"auto\",\n    )\n\n    # plot temporal cluster extent\n    ymin, ymax = ax_signals.get_ylim()\n    ax_signals.fill_betweenx(\n        (ymin, ymax), sig_times[0], sig_times[-1], color=\"orange\", alpha=0.3\n    )\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Permutation statistic for time-frequencies\n\nLet's do the same thing with the time-frequency decomposition of the data\n(see `tut-sensors-time-freq` for a tutorial and\n`ex-tfr-comparison` for a comparison of time-frequency methods) to\nshow how cluster permutations can be done on higher-dimensional data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "decim = 4\nfreqs = np.arange(7, 30, 3)  # define frequencies of interest\nn_cycles = freqs / freqs[0]\n\nepochs_power = list()\nfor condition in [epochs[k] for k in (\"Aud/L\", \"Vis/L\")]:\n    this_tfr = condition.compute_tfr(\n        method=\"morlet\",\n        freqs=freqs,\n        n_cycles=n_cycles,\n        decim=decim,\n        average=False,\n        return_itc=False,\n    )\n    this_tfr.apply_baseline(mode=\"ratio\", baseline=(None, 0))\n    epochs_power.append(this_tfr.data)\n\n# transpose again to (epochs, frequencies, times, channels)\nX = [np.transpose(x, (0, 2, 3, 1)) for x in epochs_power]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember the note on the adjacency matrix from above: For 3D data, as here,\nwe must use :func:`mne.stats.combine_adjacency` to extend the\nsensor-based adjacency to incorporate the time-frequency plane as well.\n\nHere, the integer inputs are converted into a lattice and\ncombined with the sensor adjacency matrix so that data at similar\ntimes and with similar frequencies and at close sensor locations are\nclustered together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# our data at each observation is of shape frequencies \u00d7 times \u00d7 channels\ntfr_adjacency = combine_adjacency(len(freqs), len(this_tfr.times), adjacency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can run the cluster permutation test, but first we have to set a\nthreshold. This example decimates in time and uses few frequencies so we need\nto increase the threshold from the default value in order to have\ndifferentiated clusters (i.e., so that our algorithm doesn't just find one\nlarge cluster). For a more principled method of setting this parameter,\nthreshold-free cluster enhancement may be used.\nSee `disc-stats` for a discussion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This time we don't calculate a threshold based on the F distribution.\n# We might as well select an arbitrary threshold for cluster forming\ntfr_threshold = 15.0\n\n# run cluster based permutation analysis\ncluster_stats = spatio_temporal_cluster_test(\n    X,\n    n_permutations=1000,\n    threshold=tfr_threshold,\n    tail=1,\n    n_jobs=None,\n    buffer_size=None,\n    adjacency=tfr_adjacency,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can plot our results. It is difficult to visualize clusters in\ntime-frequency-sensor space; plotting time-frequency spectrograms and\nplotting topomaps display time-frequency and sensor space respectively\nbut they are difficult to combine. We will plot topomaps with the clustered\nsensors colored in white adjacent to spectrograms in order to provide a\nvisualization of the results. This is a dimensionally limited view, however.\nEach sensor has its own significant time-frequencies, but, in order to\ndisplay a single spectrogram, all the time-frequencies that are significant\nfor any sensor in the cluster are plotted as significant. This is a\ndifficulty inherent to visualizing high-dimensional data and should be taken\ninto consideration when interpreting results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "F_obs, clusters, p_values, _ = cluster_stats\ngood_cluster_inds = np.where(p_values < p_accept)[0]\n\nfor i_clu, clu_idx in enumerate(good_cluster_inds):\n    # unpack cluster information, get unique indices\n    freq_inds, time_inds, space_inds = clusters[clu_idx]\n    ch_inds = np.unique(space_inds)\n    time_inds = np.unique(time_inds)\n    freq_inds = np.unique(freq_inds)\n\n    # get topography for F stat\n    f_map = F_obs[freq_inds].mean(axis=0)\n    f_map = f_map[time_inds].mean(axis=0)\n\n    # get signals at the sensors contributing to the cluster\n    sig_times = epochs.times[time_inds]\n\n    # initialize figure\n    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3), layout=\"constrained\")\n\n    # create spatial mask\n    mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n    mask[ch_inds, :] = True\n\n    # plot average test statistic and mark significant sensors\n    f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs.info, tmin=0)\n    f_evoked.plot_topomap(\n        times=0,\n        mask=mask,\n        axes=ax_topo,\n        cmap=\"Reds\",\n        vlim=(np.min, np.max),\n        show=False,\n        colorbar=False,\n        mask_params=dict(markersize=10),\n    )\n    image = ax_topo.images[0]\n\n    # create additional axes (for ERF and colorbar)\n    divider = make_axes_locatable(ax_topo)\n\n    # add axes for colorbar\n    ax_colorbar = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(image, cax=ax_colorbar)\n    ax_topo.set_xlabel(\n        \"Averaged F-map ({:0.3f} - {:0.3f} s)\".format(*sig_times[[0, -1]])\n    )\n\n    # remove the title that would otherwise say \"0.000 s\"\n    ax_topo.set_title(\"\")\n\n    # add new axis for spectrogram\n    ax_spec = divider.append_axes(\"right\", size=\"300%\", pad=1.2)\n    title = f\"Cluster #{i_clu + 1}, {len(ch_inds)} spectrogram\"\n    if len(ch_inds) > 1:\n        title += \" (max over channels)\"\n    F_obs_plot = F_obs[..., ch_inds].max(axis=-1)\n    F_obs_plot_sig = np.zeros(F_obs_plot.shape) * np.nan\n    F_obs_plot_sig[tuple(np.meshgrid(freq_inds, time_inds))] = F_obs_plot[\n        tuple(np.meshgrid(freq_inds, time_inds))\n    ]\n\n    for f_image, cmap in zip([F_obs_plot, F_obs_plot_sig], [\"gray\", \"autumn\"]):\n        c = ax_spec.imshow(\n            f_image,\n            cmap=cmap,\n            aspect=\"auto\",\n            origin=\"lower\",\n            extent=[epochs.times[0], epochs.times[-1], freqs[0], freqs[-1]],\n        )\n    ax_spec.set_xlabel(\"Time (ms)\")\n    ax_spec.set_ylabel(\"Frequency (Hz)\")\n    ax_spec.set_title(title)\n\n    # add another colorbar\n    ax_colorbar2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(c, cax=ax_colorbar2)\n    ax_colorbar2.set_ylabel(\"F-stat\")\n\n    # clean up viz\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n- What is the smallest p-value you can obtain, given the finite number of\n  permutations? You can find the answers in the references\n  :footcite:`MarisOostenveld2007,Sassenhagen2019`.\n\n## References\n.. footbibliography::\n\n.. include:: ../../links.inc\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}