{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# XDAWN Decoding From EEG data\n\n\nERP decoding with Xdawn ([1]_, [2]_). For each event type, a set of\nspatial Xdawn filters are trained and applied on the signal. Channels are\nconcatenated and rescaled to create features vectors that will be fed into\na logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom mne import io, pick_types, read_events, Epochs, EvokedArray\nfrom mne.datasets import sample\nfrom mne.preprocessing import Xdawn\nfrom mne.decoding import Vectorizer\n\n\nprint(__doc__)\n\ndata_path = sample.data_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set parameters and read data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\ntmin, tmax = -0.1, 0.3\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2,\n            'Visual/Left': 3, 'Visual/Right': 4}\nn_filter = 3\n\n# Setup for reading the raw data\nraw = io.read_raw_fif(raw_fname, preload=True)\nraw.filter(1, 20, fir_design='firwin')\nevents = read_events(event_fname)\n\npicks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n                   exclude='bads')\n\nepochs = Epochs(raw, events, event_id, tmin, tmax, proj=False,\n                picks=picks, baseline=None, preload=True,\n                verbose=False)\n\n# Create classification pipeline\nclf = make_pipeline(Xdawn(n_components=n_filter),\n                    Vectorizer(),\n                    MinMaxScaler(),\n                    LogisticRegression(penalty='l1', solver='liblinear',\n                                       multi_class='auto'))\n\n# Get the labels\nlabels = epochs.events[:, -1]\n\n# Cross validator\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# Do cross-validation\npreds = np.empty(len(labels))\nfor train, test in cv.split(epochs, labels):\n    clf.fit(epochs[train], labels[train])\n    preds[test] = clf.predict(epochs[test])\n\n# Classification report\ntarget_names = ['aud_l', 'aud_r', 'vis_l', 'vis_r']\nreport = classification_report(labels, preds, target_names=target_names)\nprint(report)\n\n# Normalized confusion matrix\ncm = confusion_matrix(labels, preds)\ncm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n\n# Plot confusion matrix\nfig, ax = plt.subplots(1)\nim = ax.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\nax.set(title='Normalized Confusion matrix')\nfig.colorbar(im)\ntick_marks = np.arange(len(target_names))\nplt.xticks(tick_marks, target_names, rotation=45)\nplt.yticks(tick_marks, target_names)\nfig.tight_layout()\nax.set(ylabel='True label', xlabel='Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``patterns_`` attribute of a fitted Xdawn instance (here from the last\ncross-validation fold) can be used for visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=len(event_id), ncols=n_filter,\n                         figsize=(n_filter, len(event_id) * 2))\nfitted_xdawn = clf.steps[0][1]\ntmp_info = epochs.info.copy()\ntmp_info['sfreq'] = 1.\nfor ii, cur_class in enumerate(sorted(event_id)):\n    cur_patterns = fitted_xdawn.patterns_[cur_class]\n    pattern_evoked = EvokedArray(cur_patterns[:n_filter].T, tmp_info, tmin=0)\n    pattern_evoked.plot_topomap(\n        times=np.arange(n_filter),\n        time_format='Component %d' if ii == 0 else '', colorbar=False,\n        show_names=False, axes=axes[ii], show=False)\n    axes[ii, 0].set(ylabel=cur_class)\nfig.tight_layout(h_pad=1.0, w_pad=1.0, pad=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n.. [1] Rivet, B., Souloumiac, A., Attina, V., & Gibert, G. (2009). xDAWN\n       algorithm to enhance evoked potentials: application to brain-computer\n       interface. Biomedical Engineering, IEEE Transactions on, 56(8),\n       2035-2043.\n.. [2] Rivet, B., Cecotti, H., Souloumiac, A., Maby, E., & Mattout, J. (2011,\n       August). Theoretical analysis of xDAWN algorithm: application to an\n       efficient sensor selection in a P300 BCI. In Signal Processing\n       Conference, 2011 19th European (pp. 1382-1386). IEEE.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}