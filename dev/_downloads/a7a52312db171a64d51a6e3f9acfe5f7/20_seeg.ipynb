{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with sEEG data\n\nMNE supports working with more than just MEG and EEG data. Here we show some\nof the functions that can be used to facilitate working with\nstereoelectroencephalography (sEEG) data.\n\nThis example shows how to use:\n\n- sEEG data\n- channel locations in MNI space\n- projection into a volume\n\nNote that our sample sEEG electrodes are already assumed to be in MNI\nspace. If you want to map positions from your subject MRI space to MNI\nfsaverage space, you must apply the FreeSurfer's talairach.xfm transform\nfor your dataset. You can take a look at `tut-freesurfer-mne` for\nmore information.\n\nFor an example that involves ECoG data, channel locations in a\nsubject-specific MRI, or projection into a surface, see\n`tut-working-with-ecog`. In the ECoG example, we show\nhow to visualize surface grid channels on the brain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Eric Larson <larson.eric.d@gmail.com>\n#          Adam Li <adam2392@gmail.com>\n#          Alex Rockhill <aprockhill@mailbox.org>\n#\n# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport mne\nfrom mne.datasets import fetch_fsaverage\n\nnp.set_printoptions(suppress=True)  # suppress scientific notation\n\n# paths to mne datasets - sample sEEG and FreeSurfer's fsaverage subject\n# which is in MNI space\nmisc_path = mne.datasets.misc.data_path()\nsample_path = mne.datasets.sample.data_path()\nsubjects_dir = op.join(sample_path, 'subjects')\n\n# use mne-python's fsaverage data\nfetch_fsaverage(subjects_dir=subjects_dir, verbose=True)  # downloads if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load some sEEG electrode locations and names, and turn them into\na :class:`mne.channels.DigMontage` class. First, use pandas to read in the\n``.tsv`` file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "elec_df = pd.read_csv(misc_path + '/seeg/sample_seeg_electrodes.tsv',\n                      sep='\\t', header=0, index_col=None)\nch_names = elec_df['name'].tolist()\nch_coords = elec_df[['R', 'A', 'S']].to_numpy(dtype=float) / 1000.  # mm -> m\n\n# sort channels based on alphabetical and numeric portion\nsort_idx = sorted(\n    range(len(ch_names)),  # make index to sort by\n    # sort first by the name, the then by the number using a tuple\n    key=lambda idx: (''.join([letter for letter in ch_names[idx] if\n                              not letter.isdigit() and letter != ' ']),\n                     int(''.join([digit for digit in ch_names[idx] if\n                                  digit.isdigit() and digit != ' ']))))\nch_names = [ch_names[idx] for idx in sort_idx]\nch_coords = [ch_coords[idx] for idx in sort_idx]\n\n# apply the Freesurfer surface RAS ('mri') to MNI ('mni_tal') transform\nmri_mni_t = mne.read_talxfm('sample_seeg', op.join(misc_path, 'seeg'))\nch_coords = mne.transforms.apply_trans(mri_mni_t, ch_coords)\n\n# create dictionary of channels and their xyz coordinates (now in MNI space)\nch_pos = dict(zip(ch_names, ch_coords))\n\n# Ideally the nasion/LPA/RPA will also be present from the digitization, here\n# we use fiducials estimated from the subject's FreeSurfer MNI transformation:\nlpa, nasion, rpa = mne.coreg.get_mni_fiducials(\n    'fsaverage', subjects_dir=subjects_dir)\nlpa, nasion, rpa = lpa['r'], nasion['r'], rpa['r']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we make a :class:`mne.channels.DigMontage` stating that the sEEG\ncontacts are in the FreeSurfer surface RAS (i.e., MRI) coordinate system\nfor the given subject. Keep in mind that ``fsaverage`` is special in that\nit is already in MNI space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = mne.channels.make_dig_montage(\n    ch_pos, coord_frame='mri', nasion=nasion, lpa=lpa, rpa=rpa)\nprint(f'Created {len(ch_names)} channel positions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we get the :term:`trans` that transforms from our MRI coordinate system\nto the head coordinate frame. This transform will be applied to the\ndata when applying the montage so that standard plotting functions like\n:func:`mne.viz.plot_evoked_topomap` will be aligned properly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trans = mne.channels.compute_native_head_t(montage)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our montage, we can load in our corresponding\ntime-series data and set the montage to the raw data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# first we'll load in the sample dataset\nraw = mne.io.read_raw(op.join(misc_path, 'seeg', 'sample_seeg_ieeg.fif'))\n\n# drop bad channels\nraw.info['bads'].extend([ch for ch in raw.ch_names if ch not in ch_names])\nraw.load_data()\nraw.drop_channels(raw.info['bads'])\nevents, event_id = mne.events_from_annotations(raw)\nepochs = mne.Epochs(raw, events, event_id, detrend=1, baseline=None)\nepochs = epochs['Response'][0]  # just process one epoch of data for speed\n\n# attach montage\nepochs.set_montage(montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check to make sure everything is aligned.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The most rostral electrode in the temporal lobe is outside the\n   fsaverage template brain. This is not ideal but it is the best that\n   the linear talairach transform can accomplish. A more complex\n   transform is necessary for more accurate warping.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(epochs.info, trans, 'fsaverage',\n                             subjects_dir=subjects_dir, show_axes=True,\n                             surfaces=['pial', 'head'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also look at which regions of interest are nearby our electrode\ncontacts.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aseg = 'aparc+aseg'  # parcellation/anatomical segmentation atlas\nlabels, colors = mne.get_montage_volume_labels(\n    montage, 'fsaverage', subjects_dir=subjects_dir, aseg=aseg)\n\n# separate by electrodes which have names like LAMY 1\nelectrodes = set([''.join([lttr for lttr in ch_name\n                           if not lttr.isdigit() and lttr != ' '])\n                  for ch_name in montage.ch_names])\nprint(f'Electrodes in the dataset: {electrodes}')\n\nelectrodes = ('LPM', 'LSMA')  # choose two for this example\nfor elec in electrodes:\n    picks = [ch_name for ch_name in ch_names if elec in ch_name]\n    fig = plt.figure(num=None, figsize=(8, 8), facecolor='black')\n    mne.viz.plot_channel_labels_circle(labels, colors, picks=picks, fig=fig)\n    fig.text(0.3, 0.9, 'Anatomical Labels', color='white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's the electrodes and a few regions of interest that the contacts\nof the electrode are proximal to.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "picks = [ch_name for ch_name in epochs.ch_names if\n         any([elec in ch_name for elec in electrodes])]\nlabels = ('ctx-lh-caudalmiddlefrontal', 'ctx-lh-precentral',\n          'ctx-lh-superiorfrontal', 'Left-Putamen')\n\nfig = mne.viz.plot_alignment(epochs.info.copy().pick_channels(picks), trans,\n                             'fsaverage', subjects_dir=subjects_dir,\n                             surfaces=[])\n\nbrain = mne.viz.Brain('fsaverage', alpha=0.1, cortex='low_contrast',\n                      subjects_dir=subjects_dir, units='m', figure=fig)\nbrain.add_volume_labels(aseg='aparc+aseg', labels=labels)\nbrain.show_view(dict(azimuth=120, elevation=90, distance=0.25))\nbrain.enable_depth_peeling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll get the epoch data and plot its amplitude over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize this raw data on the ``fsaverage`` brain (in MNI space) as\na heatmap. This works by first creating an ``Evoked`` data structure\nfrom the data of interest (in this example, it is just the raw LFP).\nThen one should generate a ``stc`` data structure, which will be able\nto visualize source activity on the brain in various different formats.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get standard fsaverage volume (5mm grid) source space\nfname_src = op.join(subjects_dir, 'fsaverage', 'bem',\n                    'fsaverage-vol-5-src.fif')\nvol_src = mne.read_source_spaces(fname_src)\n\nevoked = epochs.average()\nstc = mne.stc_near_sensors(\n    evoked, trans, 'fsaverage', subjects_dir=subjects_dir, src=vol_src,\n    verbose='error')  # ignore missing electrode warnings\nstc = abs(stc)  # just look at magnitude\nclim = dict(kind='value', lims=np.percentile(abs(evoked.data), [10, 50, 75]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot 3D source (brain region) visualization:\n\nBy default, `stc.plot_3d() <mne.VolSourceEstimate.plot_3d>` will show a time\ncourse of the source with the largest absolute value across any time point.\nIn this example, it is simply the source with the largest raw signal value.\nIts location is marked on the brain by a small blue sphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = stc.plot_3d(\n    src=vol_src, subjects_dir=subjects_dir,\n    view_layout='horizontal', views=['axial', 'coronal', 'sagittal'],\n    size=(800, 300), show_traces=0.4, clim=clim,\n    add_data_kwargs=dict(colorbar_kwargs=dict(label_font_size=8)))\n\n# You can save a movie like the one on our documentation website with:\n# brain.save_movie(time_dilation=3, interpolation='linear', framerate=10,\n#                  time_viewer=True, filename='./mne-test-seeg.m4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we used a BEM surface for the ``fsaverage`` subject from\nFreeSurfer.\n\nFor additional common analyses of interest, see the following:\n\n- For volumetric plotting options, including limiting to a specific area of\n  the volume specified by say an atlas, or plotting different types of\n  source visualizations see:\n  `tut-viz-stcs`.\n- For extracting activation within a specific FreeSurfer volume and using\n  different FreeSurfer volumes, see: `tut-freesurfer-mne`.\n- For working with BEM surfaces and using FreeSurfer, or mne to generate\n  them, see: `tut-forward`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}