{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# XDAWN Decoding From EEG data\n\nERP decoding with Xdawn :footcite:`RivetEtAl2009,RivetEtAl2011`. For each event\ntype, a set of spatial Xdawn filters are trained and applied on the signal.\nChannels are concatenated and rescaled to create features vectors that will be\nfed into a logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom mne import Epochs, io, pick_types, read_events\nfrom mne.datasets import sample\nfrom mne.decoding import Vectorizer, XdawnTransformer, get_spatial_filter_from_estimator\n\nprint(__doc__)\n\ndata_path = sample.data_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set parameters and read data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meg_path = data_path / \"MEG\" / \"sample\"\nraw_fname = meg_path / \"sample_audvis_filt-0-40_raw.fif\"\nevent_fname = meg_path / \"sample_audvis_filt-0-40_raw-eve.fif\"\ntmin, tmax = -0.1, 0.3\nevent_id = {\n    \"Auditory/Left\": 1,\n    \"Auditory/Right\": 2,\n    \"Visual/Left\": 3,\n    \"Visual/Right\": 4,\n}\nn_filter = 3\n\n# Setup for reading the raw data\nraw = io.read_raw_fif(raw_fname, preload=True)\nraw.filter(1, 20, fir_design=\"firwin\")\nevents = read_events(event_fname)\n\npicks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n\nepochs = Epochs(\n    raw,\n    events,\n    event_id,\n    tmin,\n    tmax,\n    proj=False,\n    picks=picks,\n    baseline=None,\n    preload=True,\n    verbose=False,\n)\n\n# Create classification pipeline\nclf = make_pipeline(\n    XdawnTransformer(n_components=n_filter),\n    Vectorizer(),\n    MinMaxScaler(),\n    OneVsRestClassifier(LogisticRegression(penalty=\"l1\", solver=\"liblinear\")),\n)\n\n# Get the data and labels\n# X is of shape (n_epochs, n_channels, n_times)\nX = epochs.get_data(copy=False)\ny = epochs.events[:, -1]\n\n# Cross validator\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# Do cross-validation\npreds = np.empty(len(y))\nfor train, test in cv.split(epochs, y):\n    clf.fit(X[train], y[train])\n    preds[test] = clf.predict(X[test])\n\n# Classification report\ntarget_names = [\"aud_l\", \"aud_r\", \"vis_l\", \"vis_r\"]\nreport = classification_report(y, preds, target_names=target_names)\nprint(report)\n\n# Normalized confusion matrix\ncm = confusion_matrix(y, preds)\ncm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n\n# Plot confusion matrix\nfig, ax = plt.subplots(1, layout=\"constrained\")\nim = ax.imshow(cm_normalized, interpolation=\"nearest\", cmap=plt.cm.Blues)\nax.set(title=\"Normalized Confusion matrix\")\nfig.colorbar(im)\ntick_marks = np.arange(len(target_names))\nplt.xticks(tick_marks, target_names, rotation=45)\nplt.yticks(tick_marks, target_names)\nax.set(ylabel=\"True label\", xlabel=\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Patterns of a fitted XdawnTransformer instance (here from the last\ncross-validation fold) can be visualized using SpatialFilter container.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Instantiate SpatialFilter\nspf = get_spatial_filter_from_estimator(\n    clf, info=epochs.info, step_name=\"xdawntransformer\"\n)\n\n# Let's first examine the scree plot of generalized eigenvalues\n# for each class.\nspf.plot_scree(title=\"\")\n\n# We can see that for all four classes ~five largest components\n# capture most of the variance, let's plot their patterns.\n# Each class will now return its own figure\ncomponents_to_plot = np.arange(5)\nfigs = spf.plot_patterns(\n    # Indices of patterns to plot,\n    # we will plot the first three for each class\n    components=components_to_plot,\n    show=False,  # to set the titles below\n)\n\n# Set the class titles\nevent_id_reversed = {v: k for k, v in event_id.items()}\nfor fig, class_idx in zip(figs, clf[0].classes_):\n    class_name = event_id_reversed[class_idx]\n    fig.suptitle(class_name, fontsize=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}