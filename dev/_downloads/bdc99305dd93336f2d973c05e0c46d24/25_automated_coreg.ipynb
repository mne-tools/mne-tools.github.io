{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Using an automated approach to coregistration\n\nThis example shows how to use the coregistration functions to perform an\nautomated MEG-MRI coregistration via scripting. Generally the results of\nthis approach are consistent with those obtained from manual\ncoregistration :footcite:`HouckClaus2020`.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The quality of the coregistration depends heavily upon the\n             quality of the head shape points (HSP) collected during subject\n             prepration and the quality of your T1-weighted MRI. Use with\n             caution and check the coregistration error.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Jon Houck <jon.houck@gmail.com>\n#         Guillaume Favelier <guillaume.favelier@gmail.com>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors.\n\nimport numpy as np\n\nimport mne\nfrom mne.coreg import Coregistration\nfrom mne.io import read_info\n\ndata_path = mne.datasets.sample.data_path()\n# data_path and all paths built from it are pathlib.Path objects\nsubjects_dir = data_path / \"subjects\"\nsubject = \"sample\"\n\nfname_raw = data_path / \"MEG\" / subject / f\"{subject}_audvis_raw.fif\"\ninfo = read_info(fname_raw)\nplot_kwargs = dict(\n    subject=subject,\n    subjects_dir=subjects_dir,\n    surfaces=\"head-dense\",\n    dig=True,\n    eeg=[],\n    meg=\"sensors\",\n    show_axes=True,\n    coord_frame=\"meg\",\n)\nview_kwargs = dict(azimuth=45, elevation=90, distance=0.6, focalpoint=(0.0, 0.0, 0.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the coregistration model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fiducials = \"estimated\"  # get fiducials from fsaverage\ncoreg = Coregistration(info, subject, subjects_dir, fiducials=fiducials)\nfig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial fit with fiducials\nDo first a coregistration fit using only 3 fiducial points. This allows\nto find a good initial solution before further optimization using\nhead shape points. This can also be useful to detect outlier head shape\npoints which are too far from the skin surface. One can see for example\nthat on this dataset there is one such point and we will omit it from\nthe subsequent fit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coreg.fit_fiducials(verbose=True)\nfig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refining with ICP\nNext we refine the transformation using a few iteration of the\nIterative Closest Point (ICP) algorithm. As the initial fiducials\nare obtained from fsaverage and not from precise manual picking in the\nGUI we do a fit with reduced weight for the nasion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coreg.fit_icp(n_iterations=6, nasion_weight=2.0, verbose=True)\nfig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Omitting bad points\nIt is now very clear that we have one point that is an outlier\nand that should be removed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coreg.omit_head_shape_points(distance=5.0 / 1000)  # distance is in meters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final coregistration fit\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coreg.fit_icp(n_iterations=20, nasion_weight=10.0, verbose=True)\nfig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\nmne.viz.set_3d_view(fig, **view_kwargs)\n\ndists = coreg.compute_dig_mri_distances() * 1e3  # in mm\nprint(\n    f\"Distance between HSP and MRI (mean/min/max):\\n{np.mean(dists):.2f} mm \"\n    f\"/ {np.min(dists):.2f} mm / {np.max(dists):.2f} mm\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Don't forget to save the resulting ``trans`` matrix!\n\n```python\nmne.write_trans('/path/to/filename-trans.fif', coreg.trans)</p></div>\n```\n<div class=\"alert alert-info\"><h4>Note</h4><p>The :class:`mne.coreg.Coregistration` class has the ability to\n          compute MRI scale factors using\n          :meth:`~mne.coreg.Coregistration.set_scale_mode` that is useful\n          for creating surrogate MRI subjects, i.e., using a template MRI\n          (such as one from :func:`mne.datasets.fetch_infant_template`)\n          matched to a subject's head digitization. When scaling is desired,\n          a scaled surrogate MRI should be created using\n          :func:`mne.scale_mri`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}