{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with sensor locations\n\nThis tutorial describes how to read and plot sensor locations, and how\nMNE-Python handles physical locations of sensors.\nAs usual we'll start by importing the modules we need:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n# the following import is required for matplotlib < 3.2:\nfrom mpl_toolkits.mplot3d import Axes3D  # noqa\n\nimport mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About montages and layouts\n\n`Montages <mne.channels.DigMontage>` contain sensor positions in 3D (x, y, z\nin meters), which can be assigned to existing EEG/MEG data. By specifying the\nlocations of sensors relative to the brain,\n`Montages <mne.channels.DigMontage>` play an important role in computing the\nforward solution and inverse estimates.\n\nIn contrast, `Layouts <mne.channels.Layout>` are *idealized* 2D\nrepresentations of sensor positions. They are primarily used for arranging\nindividual sensor subplots in a topoplot or for showing the *approximate*\nrelative arrangement of sensors as seen from above.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you're working with EEG data exclusively, you'll want to use\n   `Montages <mne.channels.DigMontage>`, not layouts. Idealized montages\n   (e.g., those provided by the manufacturer, or the ones shipping with\n   MNE-Python mentioned below) are typically referred to as\n   :term:`template montages <template montage>`.</p></div>\n\n## Working with built-in montages\n.. admonition:: Computing sensor locations\n    :class: sidebar note\n\n    If you are interested in how standard (idealized) EEG sensor positions\n    are computed on a spherical head model, make sure to check out the\n    `eeg_positions`_ repository.\n\nThe 3D coordinates of MEG sensors are included in the raw recordings from MEG\nsystems. They are automatically stored in the ``info`` attribute of the\n`~mne.io.Raw` object upon loading. EEG electrode locations are much more\nvariable because of differences in head shape. Idealized montages\n(\":term:`template montages <template montage>`\") for many EEG systems are\nincluded in MNE-Python, and you can get an overview of them by using\n:func:`mne.channels.get_builtin_montages`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "builtin_montages = mne.channels.get_builtin_montages(descriptions=True)\nfor montage_name, montage_description in builtin_montages:\n    print(f'{montage_name}: {montage_description}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These built-in EEG montages can be loaded with\n`mne.channels.make_standard_montage`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "easycap_montage = mne.channels.make_standard_montage('easycap-M1')\nprint(easycap_montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Montage <mne.channels.DigMontage>` objects have a\n`~mne.channels.DigMontage.plot` method for visualizing the sensor locations\nin 2D or 3D:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "easycap_montage.plot()  # 2D\nfig = easycap_montage.plot(kind='3d', show=False)  # 3D\nfig = fig.gca().view_init(azim=70, elev=15)  # set view angle for tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once loaded, a montage can be applied to data with the\n`~mne.io.Raw.set_montage` method, for example\n`raw.set_montage() <mne.io.Raw.set_montage>`,\n`epochs.set_montage() <mne.Epochs.set_montage>`, or\n`evoked.set_montage() <mne.Evoked.set_montage>`. This will only work with\ndata whose EEG channel names correspond to those in the montage.\n(Therefore, we're loading some EEG data below, and not the usual MNE \"sample\"\ndataset.)\n\nYou can then visualize the sensor locations via the\n:meth:`~mne.io.Raw.plot_sensors` method.\n\nIt is also possible to skip the manual montage loading step by passing the\nmontage name directly to the :meth:`~mne.io.Raw.set_montage` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ssvep_folder = mne.datasets.ssvep.data_path()\nssvep_data_raw_path = (ssvep_folder / 'sub-02' / 'ses-01' / 'eeg' /\n                       'sub-02_ses-01_task-ssvep_eeg.vhdr')\nssvep_raw = mne.io.read_raw_brainvision(ssvep_data_raw_path, verbose=False)\n\n# Use the preloaded montage\nssvep_raw.set_montage(easycap_montage)\nfig = ssvep_raw.plot_sensors(show_names=True)\n\n# Apply a template montage directly, without preloading\nssvep_raw.set_montage('easycap-M1')\nfig = ssvep_raw.plot_sensors(show_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>You may have noticed that the figures created via\n   :meth:`~mne.io.Raw.plot_sensors` contain fewer sensors than the result of\n   `easycap_montage.plot() <mne.channels.DigMontage.plot>`. This is because\n   the montage contains *all channels defined for that EEG system*; but not\n   all recordings will necessarily use all possible channels. Thus when\n   applying a montage to an actual EEG dataset, information about sensors\n   that are not actually present in the data is removed.</p></div>\n\n## Plotting 2D sensor locations like EEGLAB\n\n.. admonition:: The ``sphere`` keyword is available in many places!\n    :class: sidebar hint\n\n    All MNE plotting functions for EEG topographies and sensor locations\n    support the ``sphere`` keyword argument, and therefore allow for\n    adjustment of the way the sensors are projected onto the head circle.\n\nIn MNE-Python, by default the head center is calculated using\n:term:`fiducial points <fiducial>`. This means that\nthe head circle represents the head circumference **at the nasion and ear\nlevel,** and not where it is commonly measured in the 10\u201320 EEG system\n(i.e., above the nasion at T4/T8, T3/T7, Oz, and Fpz).\n\nIf you prefer to draw the head circle using 10\u201320 conventions (which are also\nused by EEGLAB), you can pass ``sphere='eeglab'``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ssvep_raw.plot_sensors(show_names=True, sphere='eeglab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the data we're using here doesn't contain an Fpz channel, its\nputative location was approximated automatically.\n\n\n## Manually controlling 2D channel projection\n\nChannel positions in 2D space are obtained by projecting their actual 3D\npositions onto a sphere, then projecting the sphere onto a plane.\nBy default, a sphere with origin at ``(0, 0, 0)`` (x, y, z coordinates) and\nradius of ``0.095`` meters (9.5 cm) is used. You can use a different sphere\nradius by passing a single value as the  ``sphere`` argument in any function\nthat plots channels in 2D (like `~mne.channels.DigMontage.plot` that we use\nhere, but also for example `mne.viz.plot_topomap`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig1 = easycap_montage.plot()  # default radius of 0.095\nfig2 = easycap_montage.plot(sphere=0.07)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To change not only the radius, but also the sphere origin, pass a\n``(x, y, z, radius)`` tuple as the ``sphere`` argument:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = easycap_montage.plot(sphere=(0.03, 0.02, 0.01, 0.075))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Reading sensor digitization files\n\nIn the sample data, the sensor positions are already available in the\n``info`` attribute of the `~mne.io.Raw` object (see the documentation of the\nreading functions and :meth:`~mne.io.Raw.set_montage` for details on how that\nworks). Therefore, we can plot sensor locations directly from the\n`~mne.io.Raw` object using :meth:`~mne.io.Raw.plot_sensors`, which provides\nsimilar functionality to `montage.plot() <mne.channels.DigMontage.plot>`. In\naddition, :meth:`~mne.io.Raw.plot_sensors` supports channel selection by\ntype, color-coding channels in various ways (by default, channels listed in\n``raw.info['bads']`` will be plotted in red), and drawing in an existing\nMatplotlib ``Axes`` object (so the channel positions can easily be added as a\nsubplot in a multi-panel figure):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_path = (sample_data_folder / 'MEG' / 'sample' /\n                        'sample_audvis_raw.fif')\nsample_raw = mne.io.read_raw_fif(\n    sample_data_raw_path, preload=False, verbose=False\n)\n\nfig = plt.figure()\nax2d = fig.add_subplot(121)\nax3d = fig.add_subplot(122, projection='3d')\nsample_raw.plot_sensors(ch_type='eeg', axes=ax2d)\nsample_raw.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\nax3d.view_init(azim=70, elev=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous 2D topomap reveals irregularities in the EEG sensor positions in\nthe `sample dataset <sample-dataset>` \u2014 this is because the sensor\npositions in that dataset are digitizations of actual sensor positions on the\nhead rather than idealized sensor positions based on a spherical head model.\nDepending on the digitization device (e.g., a Polhemus Fastrak digitizer),\nyou need to use different montage reading functions (see `dig-formats`).\nThe resulting `montage <mne.channels.DigMontage>` can then be added to\n`~mne.io.Raw` objects by passing it as an argument to the\n:meth:`~mne.io.Raw.set_montage` method (just as we did before with the name\nof the predefined ``'standard_1020'`` montage). Once loaded, locations can be\nplotted with the :meth:`~mne.channels.DigMontage.plot` method and saved with\nthe :meth:`~mne.channels.DigMontage.save` method of the\n`montage <mne.channels.DigMontage>` object.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>When setting a montage with :meth:`~mne.io.Raw.set_montage`, the\n    measurement info is updated in two places (both ``chs`` and ``dig``\n    entries are updated) \u2013 see `tut-info-class` for more details. Note\n    that ``dig`` may contain HPI, fiducial, or head shape points in addition\n    to electrode locations.</p></div>\n\n\n## Visualizing sensors in 3D surface renderings\n\nIt is also possible to render an image of an MEG sensor helmet using 3D\nsurface rendering instead of matplotlib. This works by calling\n:func:`mne.viz.plot_alignment`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(\n    sample_raw.info, dig=False, eeg=False,\n    surfaces=[], meg=['helmet', 'sensors'],\n    coord_frame='meg'\n)\nmne.viz.set_3d_view(fig, azimuth=50, elevation=90, distance=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that :func:`~mne.viz.plot_alignment` requires an `~mne.Info` object, and\ncan also render MRI surfaces of the scalp, skull, and brain (by passing a\ndict with keys like ``'head'``, ``'outer_skull'`` or ``'brain'`` to the\n``surfaces`` parameter). This makes the function useful for\n`assessing coordinate frame transformations <tut-source-alignment>`.\nFor examples of various uses of :func:`~mne.viz.plot_alignment`, see\n`plot_montage`, `ex-eeg-on-scalp`, and `ex-plot-meg-sensors`.\n\n\n## Working with layout files\n\nSimilar to montages, many layout files are included with MNE-Python. They are\nstored in the :file:`mne/channels/data/layouts` folder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_dir = Path(mne.__file__).parent / 'channels' / 'data' / 'layouts'\nlayouts = sorted(path.name for path in layout_dir.iterdir())\nprint(\n    '\\n'\n    'BUILT-IN LAYOUTS\\n'\n    '================'\n)\nprint('\\n'.join(layouts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load a layout file, use the `mne.channels.read_layout` function.\nYou can then visualize the layout using its\n`~mne.channels.Layout.plot` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_layout = mne.channels.read_layout('biosemi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the ``picks`` argument for selecting channels from `~mne.io.Raw`\nobjects, the :meth:`~mne.channels.Layout.plot` method of\n`~mne.channels.Layout` objects also has a ``picks`` argument. However,\nbecause layouts only contain information about sensor name and location (not\nsensor type), the :meth:`~mne.channels.Layout.plot` method only supports\npicking channels by index (not by name or by type). In the following example,\nwe find the desired indices using :func:`numpy.where`; selection by name or\ntype is possible with :func:`mne.pick_channels` or :func:`mne.pick_types`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "midline = np.where([name.endswith('z') for name in biosemi_layout.names])[0]\nbiosemi_layout.plot(picks=midline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have a `~mne.io.Raw` object that contains sensor positions, you can\ncreate a `~mne.channels.Layout` object with either\n:func:`mne.channels.make_eeg_layout` or :func:`mne.channels.find_layout`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_from_raw = mne.channels.make_eeg_layout(sample_raw.info)\n# same result as mne.channels.find_layout(raw.info, ch_type='eeg')\nlayout_from_raw.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There is no corresponding ``make_meg_layout()`` function because sensor\n    locations are fixed in an MEG system (unlike in EEG, where sensor caps\n    deform to fit snugly on a specific head). Therefore, MEG layouts are\n    consistent (constant) for a given system and you can simply load them\n    with :func:`mne.channels.read_layout` or use\n    :func:`mne.channels.find_layout` with\n    the ``ch_type`` parameter (as previously demonstrated for EEG).</p></div>\n\nAll `~mne.channels.Layout` objects have a `~mne.channels.Layout.save` method\nthat writes layouts to disk as either :file:`.lout` or :file:`.lay` formats\n(inferred from the file extension contained in the ``fname`` argument). The\nchoice between :file:`.lout` and :file:`.lay` format only matters if you need\nto load the layout file in some other application (MNE-Python can read both\nformats).\n\n\n.. LINKS\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}