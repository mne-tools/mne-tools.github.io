{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with sensor locations\n\nThis tutorial describes how to read and plot sensor locations, and how MNE-Python\nhandles physical locations of sensors. As usual we'll start by importing the modules we\nneed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The MNE-Python contributors.\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About montages and layouts\n\n`Montages <mne.channels.DigMontage>` contain sensor positions in 3D (x, y, z in\nmeters), which can be assigned to existing EEG/MEG data. By specifying the locations\nof sensors relative to the brain, `Montages <mne.channels.DigMontage>` play an\nimportant role in computing the forward solution and inverse estimates.\n\nIn contrast, `Layouts <mne.channels.Layout>` are *idealized* 2D representations of\nsensor positions. They are primarily used for arranging individual sensor subplots in\na topoplot or for showing the *approximate* relative arrangement of sensors as seen\nfrom above.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you're working with EEG data exclusively, you'll want to use `Montages\n   <mne.channels.DigMontage>`, not layouts. Idealized montages (e.g., those provided\n   by the manufacturer, or the ones shipping with MNE-Python mentioned below) are\n   typically referred to as :term:`template montages <template montage>`.</p></div>\n\n## Working with built-in montages\n.. admonition:: Computing sensor locations\n    :class: sidebar note\n\n    If you are interested in how standard (idealized) EEG sensor positions are\n    computed on a spherical head model, make sure to check out the `eeg_positions`_\n    repository.\n\nThe 3D coordinates of MEG sensors are included in the raw recordings from MEG systems.\nThey are automatically stored in the ``info`` attribute of the `~mne.io.Raw` object\nupon loading. EEG electrode locations are much more variable because of differences in\nhead shape. Idealized montages (\":term:`template montages <template montage>`\") for\nmany EEG systems are included in MNE-Python, and you can get an overview of them by\nusing :func:`mne.channels.get_builtin_montages`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "builtin_montages = mne.channels.get_builtin_montages(descriptions=True)\nfor montage_name, montage_description in builtin_montages:\n    print(f\"{montage_name}: {montage_description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These built-in EEG montages can be loaded with `mne.channels.make_standard_montage`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "easycap_montage = mne.channels.make_standard_montage(\"easycap-M1\")\nprint(easycap_montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Montage <mne.channels.DigMontage>` objects have a `~mne.channels.DigMontage.plot`\nmethod for visualizing the sensor locations in 2D or 3D:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "easycap_montage.plot()  # 2D\nfig = easycap_montage.plot(kind=\"3d\", show=False)  # 3D\nfig = fig.gca().view_init(azim=70, elev=15)  # set view angle for tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once loaded, a montage can be applied to data with the `~mne.io.Raw.set_montage`\nmethod, for example `raw.set_montage() <mne.io.Raw.set_montage>`,\n`epochs.set_montage() <mne.Epochs.set_montage>`, or `evoked.set_montage()\n<mne.Evoked.set_montage>`. This will only work with data whose EEG channel names\ncorrespond to those in the montage. (Therefore, we're loading some EEG data below, and\nnot the usual MNE \"sample\" dataset.)\n\nYou can then visualize the sensor locations via the :meth:`~mne.io.Raw.plot_sensors`\nmethod.\n\nIt is also possible to skip the manual montage loading step by passing the montage\nname directly to the :meth:`~mne.io.Raw.set_montage` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ssvep_folder = mne.datasets.ssvep.data_path()\nssvep_data_raw_path = (\n    ssvep_folder / \"sub-02\" / \"ses-01\" / \"eeg\" / \"sub-02_ses-01_task-ssvep_eeg.vhdr\"\n)\nssvep_raw = mne.io.read_raw_brainvision(ssvep_data_raw_path, verbose=False)\n\n# Use the preloaded montage\nssvep_raw.set_montage(easycap_montage)\nfig = ssvep_raw.plot_sensors(show_names=True)\n\n# Apply a template montage directly, without preloading\nssvep_raw.set_montage(\"easycap-M1\")\nfig = ssvep_raw.plot_sensors(show_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>You may have noticed that the figures created via :meth:`~mne.io.Raw.plot_sensors`\n   contain fewer sensors than the result of `easycap_montage.plot()\n   <mne.channels.DigMontage.plot>`. This is because the montage contains *all channels\n   defined for that EEG system*; but not all recordings will necessarily use all\n   possible channels. Thus when applying a montage to an actual EEG dataset,\n   information about sensors that are not actually present in the data is removed.</p></div>\n\n## Plotting 2D sensor locations like EEGLAB\n\n.. admonition:: The ``sphere`` keyword is available in many places!\n    :class: sidebar hint\n\n    All MNE plotting functions for EEG topographies and sensor locations support the\n    ``sphere`` keyword argument, and therefore allow for adjustment of the way the\n    sensors are projected onto the head circle.\n\nIn MNE-Python, by default the head center is calculated using :term:`fiducial points\n<fiducial>`. This means that the head circle represents the head circumference **at\nthe nasion and ear level,** and not where it is commonly measured in the 10\u201320 EEG\nsystem (i.e., above the nasion at T4/T8, T3/T7, Oz, and Fpz).\n\nIf you prefer to draw the head circle using 10\u201320 conventions (which are also used by\nEEGLAB), you can pass ``sphere='eeglab'``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ssvep_raw.plot_sensors(show_names=True, sphere=\"eeglab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the data we're using here doesn't contain an Fpz channel, its putative\nlocation was approximated automatically.\n\n\n## Manually controlling 2D channel projection\n\nChannel positions in 2D space are obtained by projecting their actual 3D positions\nonto a sphere, then projecting the sphere onto a plane. By default, a sphere with\norigin at ``(0, 0, 0)`` (x, y, z coordinates) and radius of ``0.095`` meters (9.5 cm)\nis used. You can use a different sphere radius by passing a single value as the\n``sphere`` argument in any function that plots channels in 2D (like\n`~mne.channels.DigMontage.plot` that we use here, but also for example\n`mne.viz.plot_topomap`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig1 = easycap_montage.plot()  # default radius of 0.095\nfig2 = easycap_montage.plot(sphere=0.07)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To change not only the radius, but also the sphere origin, pass a\n``(x, y, z, radius)`` tuple as the ``sphere`` argument:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = easycap_montage.plot(sphere=(0.03, 0.02, 0.01, 0.075))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Reading sensor digitization files\n\nIn the sample data, the sensor positions are already available in the ``info``\nattribute of the `~mne.io.Raw` object (see the documentation of the reading functions\nand :meth:`~mne.io.Raw.set_montage` for details on how that works). Therefore, we can\nplot sensor locations directly from the `~mne.io.Raw` object using\n:meth:`~mne.io.Raw.plot_sensors`, which provides similar functionality to\n`montage.plot() <mne.channels.DigMontage.plot>`. In addition,\n:meth:`~mne.io.Raw.plot_sensors` supports channel selection by type, color-coding\nchannels in various ways (by default, channels listed in ``raw.info['bads']`` will be\nplotted in red), and drawing in an existing Matplotlib ``Axes`` object (so the channel\npositions can easily be added as a subplot in a multi-panel figure):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_path = sample_data_folder / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\nsample_raw = mne.io.read_raw_fif(sample_data_raw_path, preload=False, verbose=False)\n\nfig = plt.figure()\nax2d = fig.add_subplot(121)\nax3d = fig.add_subplot(122, projection=\"3d\")\nsample_raw.plot_sensors(ch_type=\"eeg\", axes=ax2d)\nsample_raw.plot_sensors(ch_type=\"eeg\", axes=ax3d, kind=\"3d\")\nax3d.view_init(azim=70, elev=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous 2D topomap reveals irregularities in the EEG sensor positions in the\n`sample dataset <sample-dataset>` \u2014 this is because the sensor positions in that\ndataset are digitizations of actual sensor positions on the head rather than idealized\nsensor positions based on a spherical head model. Depending on the digitization device\n(e.g., a Polhemus Fastrak digitizer), you need to use different montage reading\nfunctions (see `dig-formats`). The resulting `montage <mne.channels.DigMontage>`\ncan then be added to `~mne.io.Raw` objects by passing it as an argument to the\n:meth:`~mne.io.Raw.set_montage` method (just as we did before with the name of the\npredefined ``'standard_1020'`` montage). Once loaded, locations can be plotted with\nthe :meth:`~mne.channels.DigMontage.plot` method and saved with the\n:meth:`~mne.channels.DigMontage.save` method of the\n`montage <mne.channels.DigMontage>` object.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>When setting a montage with :meth:`~mne.io.Raw.set_montage`, the measurement info\n    is updated in two places (both ``chs`` and ``dig`` entries are updated) \u2013 see\n    `tut-info-class` for more details. Note that ``dig`` may contain HPI,\n    fiducial, or head shape points in addition to electrode locations.</p></div>\n\n\n## Visualizing sensors in 3D surface renderings\n\nIt is also possible to render an image of an MEG sensor helmet using 3D surface\nrendering instead of matplotlib. This works by calling :func:`mne.viz.plot_alignment`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(\n    sample_raw.info,\n    dig=False,\n    eeg=False,\n    surfaces=[],\n    meg=[\"helmet\", \"sensors\"],\n    coord_frame=\"meg\",\n)\nmne.viz.set_3d_view(fig, azimuth=50, elevation=90, distance=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that :func:`~mne.viz.plot_alignment` requires an `~mne.Info` object, and can also\nrender MRI surfaces of the scalp, skull, and brain (by passing a dict with keys like\n``'head'``, ``'outer_skull'`` or ``'brain'`` to the ``surfaces`` parameter). This\nmakes the function useful for `assessing coordinate frame transformations\n<tut-source-alignment>`. For examples of various uses of\n:func:`~mne.viz.plot_alignment`, see `plot_montage`, `ex-eeg-on-scalp`, and\n`ex-plot-meg-sensors`.\n\n\n## Working with layout files\n\nSimilar to montages, many layout files are included with MNE-Python. They are stored\nin the :file:`mne/channels/data/layouts` folder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_dir = Path(mne.__file__).parent / \"channels\" / \"data\" / \"layouts\"\nlayouts = sorted(path.name for path in layout_dir.iterdir())\nprint(\"\\nBUILT-IN LAYOUTS\\n================\")\nprint(\"\\n\".join(layouts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load a layout file, use the `mne.channels.read_layout` function. You can then\nvisualize the layout using its `~mne.channels.Layout.plot` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "biosemi_layout = mne.channels.read_layout(\"biosemi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the ``picks`` argument for selecting channels from `~mne.io.Raw` objects,\nthe :meth:`~mne.channels.Layout.plot` method of `~mne.channels.Layout` objects also\nhas a ``picks`` argument. However, because layouts only contain information about\nsensor name and location (not sensor type), the :meth:`~mne.channels.Layout.plot`\nmethod only supports picking channels by index (not by name or by type). In the\nfollowing example, we find the desired indices using :func:`numpy.where`; selection by\nname or type is possible with :func:`mne.pick_channels` or :func:`mne.pick_types`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "midline = np.where([name.endswith(\"z\") for name in biosemi_layout.names])[0]\nbiosemi_layout.plot(picks=midline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have a `~mne.io.Raw` object that contains sensor positions, you can create a\n`~mne.channels.Layout` object with either :func:`mne.channels.make_eeg_layout` or\n:func:`mne.channels.find_layout`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout_from_raw = mne.channels.make_eeg_layout(sample_raw.info)\n# same result as mne.channels.find_layout(raw.info, ch_type='eeg')\nlayout_from_raw.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There is no corresponding ``make_meg_layout()`` function because sensor locations\n    are fixed in an MEG system (unlike in EEG, where sensor caps deform to fit snugly\n    on a specific head). Therefore, MEG layouts are consistent (constant) for a given\n    system and you can simply load them with :func:`mne.channels.read_layout` or use\n    :func:`mne.channels.find_layout` with the ``ch_type`` parameter (as previously\n    demonstrated for EEG).</p></div>\n\nAll `~mne.channels.Layout` objects have a `~mne.channels.Layout.save` method that\nwrites layouts to disk as either :file:`.lout` or :file:`.lay` formats (inferred from\nthe file extension contained in the ``fname`` argument). The choice between\n:file:`.lout` and :file:`.lay` format only matters if you need to load the layout file\nin some other application (MNE-Python can read both formats).\n\n\n.. LINKS\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}