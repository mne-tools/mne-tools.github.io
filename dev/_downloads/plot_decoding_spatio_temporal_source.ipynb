{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Decoding source space data\n\n\nDecoding to MEG data in source space on the left cortical surface. Here\nunivariate feature selection is employed for speed purposes to confine the\nclassification to a small number of potentially relevant features. The\nclassifier then is trained to selected features of epochs in source space.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Author: Denis A. Engemann <denis.engemann@gmail.com>\n#         Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#         Jean-Remi King <jeanremi.king@gmail.com>\n#\n# License: BSD (3-clause)\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.linear_model import LogisticRegression\nimport mne\nfrom mne import io\nfrom mne.datasets import sample\nfrom mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\nfrom mne.decoding import (cross_val_multiscore, LinearModel, SlidingEstimator,\n                          get_coef)\n\nprint(__doc__)\n\ndata_path = sample.data_path()\nfname_fwd = data_path + 'MEG/sample/sample_audvis-meg-oct-6-fwd.fif'\nfname_evoked = data_path + '/MEG/sample/sample_audvis-ave.fif'\nsubjects_dir = data_path + '/subjects'\nsubject = os.environ['SUBJECT'] = subjects_dir + '/sample'\nos.environ['SUBJECTS_DIR'] = subjects_dir"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Set parameters\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\nfname_cov = data_path + '/MEG/sample/sample_audvis-cov.fif'\nlabel_names = 'Aud-rh', 'Vis-rh'\nfname_inv = data_path + '/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif'\n\ntmin, tmax = -0.2, 0.5\nevent_id = dict(aud_r=2, vis_r=4)  # load contra-lateral conditions\n\n# Setup for reading the raw data\nraw = io.read_raw_fif(raw_fname, preload=True)\nraw.filter(0.1, None, fir_design='firwin')\nevents = mne.read_events(event_fname)\n\n# Set up pick list: MEG - bad channels (modify to your needs)\nraw.info['bads'] += ['MEG 2443']  # mark bads\npicks = mne.pick_types(raw.info, meg=True, eeg=False, stim=True, eog=True,\n                       exclude='bads')\n\n# Read epochs\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True,\n                    picks=picks, baseline=None, preload=True,\n                    reject=dict(grad=4000e-13, eog=150e-6),\n                    decim=5)  # decimate to save memory and increase speed"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Compute inverse solution\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "snr = 3.0\nnoise_cov = mne.read_cov(fname_cov)\ninverse_operator = read_inverse_operator(fname_inv)\n\nstcs = apply_inverse_epochs(epochs, inverse_operator,\n                            lambda2=1.0 / snr ** 2, verbose=False,\n                            method=\"dSPM\", pick_ori=\"normal\")"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Decoding in sensor space using a logistic regression\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Retrieve source space data into an array\nX = np.array([stc.lh_data for stc in stcs])  # only keep left hemisphere\ny = epochs.events[:, 2]\n\n# prepare a series of classifier applied at each time sample\nclf = make_pipeline(StandardScaler(),  # z-score normalization\n                    SelectKBest(f_classif, k=500),  # select features for speed\n                    LinearModel(LogisticRegression(C=1)))\ntime_decod = SlidingEstimator(clf, scoring='roc_auc')\n\n# Run cross-validated decoding analyses:\nscores = cross_val_multiscore(time_decod, X, y, cv=5, n_jobs=1)\n\n# Plot average decoding scores of 5 splits\nfig, ax = plt.subplots(1)\nax.plot(epochs.times, scores.mean(0), label='score')\nax.axhline(.5, color='k', linestyle='--', label='chance')\nax.axvline(0, color='k')\nplt.legend()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "To investigate weights, we need to retrieve the patterns of a fitted model\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# The fitting needs not be cross validated because the weights are based on\n# the training sets\ntime_decod.fit(X, y)\n\n# Retrieve patterns after inversing the z-score normalization step:\npatterns = get_coef(time_decod, 'patterns_', inverse_transform=True)\n\nstc = stcs[0]  # for convenience, lookup parameters from first stc\nvertices = [stc.lh_vertno, np.array([], int)]  # empty array for right hemi\nstc_feat = mne.SourceEstimate(np.abs(patterns), vertices=vertices,\n                              tmin=stc.tmin, tstep=stc.tstep, subject='sample')\n\nbrain = stc_feat.plot(views=['lat'], transparent=True,\n                      initial_time=0.1, time_unit='s')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.13", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}