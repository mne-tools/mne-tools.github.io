{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Receptive Field Estimation and Prediction\n\n\nThis example reproduces figures from Lalor et al's mTRF toolbox in\nmatlab [1]_. We will show how the :class:`mne.decoding.ReceptiveField` class\ncan perform a similar function along with :mod:`sklearn`. We will fit a\nlinear encoding model using the continuously-varying speech envelope to\npredict activity of a 128 channel EEG system.\n\nReferences\n----------\n.. [1] Crosse, M. J., Di Liberto, G. M., Bednar, A. & Lalor, E. C. (2016).\n       The Multivariate Temporal Response Function (mTRF) Toolbox:\n       A MATLAB Toolbox for Relating Neural Signals to Continuous Stimuli.\n       Frontiers in Human Neuroscience 10, 604. doi:10.3389/fnhum.2016.00604\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Authors: Chris Holdgraf <choldgraf@gmail.com>\n#\n# License: BSD (3-clause)\n# sphinx_gallery_thumbnail_number = 3\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom os.path import join\n\nimport mne\nfrom mne.decoding import ReceptiveField\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import scale"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Load the data from the publication\n----------------------------------\n\nFirst we will load the data collected in [1]_. In this experiment subjects\nlistened to natural speech. Raw EEG and the speech stimulus was collected.\nWe will load these below, downsampling the data in order to speed up\ncomputation since we know that our features are primarily low-frequency in\nnature. Then we'll visualize both the EEG and speech envelope.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "path = mne.datasets.mtrf.data_path()\ndecim = 2\ndata = loadmat(join(path, 'speech_data.mat'))\nraw = data['EEG'].T\nspeech = data['envelope'].T\nsfreq = float(data['Fs'])\nsfreq /= decim\nspeech = mne.filter.resample(speech, down=decim, npad='auto')\nraw = mne.filter.resample(raw, down=decim, npad='auto')\n\n\n# Read in channel positions and create our MNE objects from the raw data\nmontage = mne.channels.read_montage('biosemi128')\nmontage.selection = montage.selection[:128]\ninfo = mne.create_info(montage.ch_names[:128], sfreq, 'eeg', montage=montage)\nraw = mne.io.RawArray(raw, info)\nn_channels = len(raw.ch_names)\n\n# Plot a sample of brain and stimulus activity\nfig, ax = plt.subplots()\nlns = ax.plot(scale(raw[:, :800][0].T), color='k', alpha=.1)\nln1 = ax.plot(scale(speech[0, :800]), color='r', lw=2)\nax.legend([lns[0], ln1[0]], ['EEG', 'Speech Envelope'], frameon=False)\nax.set(title=\"Sample activity\", xlabel=\"Time (s)\")\nmne.viz.tight_layout()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Create and fit a receptive field model\n--------------------------------------\n\nWe will construct a model to find the linear relationship between the EEG\nsignal and a time-delayed version of the speech envelope. This allows\nus to make predictions about the response to new stimuli.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Define the delays that we will use in the receptive field\ntmin, tmax = -.4, .2\n\n# Initialize the model\nrf = ReceptiveField(tmin, tmax, sfreq, feature_names=['envelope'],\n                    estimator=1., scoring='corrcoef')\n# We'll have (tmax - tmin) * sfreq delays\n# and an extra 2 delays since we are inclusive on the beginning / end index\nn_delays = int((tmax - tmin) * sfreq) + 2\n\nn_splits = 3\ncv = KFold(n_splits)\n\n# Prepare model data (make time the first dimension)\nspeech = speech.T\nY, _ = raw[:]  # Outputs for the model\nY = Y.T\n\n# Iterate through splits, fit the model, and predict/test on held-out data\ncoefs = np.zeros((n_splits, n_channels, n_delays))\nscores = np.zeros((n_splits, n_channels))\nfor ii, (train, test) in enumerate(cv.split(speech)):\n    print('split %s / %s' % (ii, n_splits))\n    rf.fit(speech[train], Y[train])\n    scores[ii] = rf.score(speech[test], Y[test])\n    # coef_ is shape (n_outputs, n_features, n_delays). we only have 1 feature\n    coefs[ii] = rf.coef_[:, 0, :]\ntimes = rf.delays_ / float(rf.sfreq)\n\n# Average scores and coefficients across CV splits\nmean_coefs = coefs.mean(axis=0)\nmean_scores = scores.mean(axis=0)\n\n# Plot mean prediction scores across all channels\nfig, ax = plt.subplots()\nix_chs = np.arange(n_channels)\nax.plot(ix_chs, mean_scores)\nax.axhline(0, ls='--', color='r')\nax.set(title=\"Mean prediction score\", xlabel=\"Channel\", ylabel=\"Score ($r$)\")\nmne.viz.tight_layout()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Investigate model coefficients\n------------------------------\n\nFinally, we will look at how the linear coefficients (sometimes\nreferred to as beta values) are distributed across time delays as well as\nacross the scalp. We will recreate `figure 1`_ and `figure 2`_ from [1]_.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Print mean coefficients across all time delays / channels (see Fig 1 in [1])\ntime_plot = -.180  # For highlighting a specific time.\nfig, ax = plt.subplots(figsize=(4, 8))\nmax_coef = mean_coefs.max()\nax.pcolormesh(times, ix_chs, mean_coefs, cmap='RdBu_r',\n              vmin=-max_coef, vmax=max_coef)\nax.axvline(time_plot, ls='--', color='k', lw=2)\nax.set(xlabel='Delay (s)', ylabel='Channel', title=\"Mean Model\\nCoefficients\",\n       xlim=times[[0, -1]], ylim=[len(ix_chs) - 1, 0],\n       xticks=np.arange(tmin, tmax + .2, .2))\nplt.setp(ax.get_xticklabels(), rotation=45)\nmne.viz.tight_layout()\n\n# Make a topographic map of coefficients for a given delay (see Fig 2C in [1])\nix_plot = np.argmin(np.abs(time_plot - times))\nfig, ax = plt.subplots()\nmne.viz.plot_topomap(mean_coefs[:, ix_plot], pos=info, axes=ax, show=False,\n                     vmin=-max_coef, vmax=max_coef)\nax.set(title=\"Topomap of model coefficients\\nfor delay %s\" % time_plot)\nmne.viz.tight_layout()\n\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.13", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}