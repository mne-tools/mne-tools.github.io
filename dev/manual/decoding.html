<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Decoding &#8212; MNE 0.14.dev0 documentation</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/flatly/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/style.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.14.dev0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

<link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,400,700' rel='stylesheet' type='text/css'>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>


  </head>
  <body role="document">

<div class="row devbar alert alert-danger">
This documentation is for the <strong>development version (0.14.dev0)</strong> - <a href="http://martinos.org/mne/stable">switch to Stable</a>
</div>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.14.dev0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../getting_started.html">Get started</a></li>
                <li><a href="../tutorials.html">Tutorials</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../python_reference.html">API</a></li>
                <li><a href="index.html">Manual</a></li>
                <li><a href="../contribute_to_mne.html">Contribute</a></li>
                <li><a href="../faq.html">FAQ</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Decoding</a><ul>
<li><a class="reference internal" href="#basic-estimators">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler">Scaler</a></li>
<li><a class="reference internal" href="#vectorizer">Vectorizer</a></li>
<li><a class="reference internal" href="#psdestimator">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#xdawn">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#generalization-across-time">Generalization Across Time</a></li>
<li><a class="reference internal" href="#time-decoding">Time Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding">Source-space decoding</a></li>
</ul>
</li>
</ul>

<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-12 content">
      
  <div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#decoding" id="id2">Decoding</a><ul>
<li><a class="reference internal" href="#basic-estimators" id="id3">Basic Estimators</a><ul>
<li><a class="reference internal" href="#scaler" id="id4">Scaler</a></li>
<li><a class="reference internal" href="#vectorizer" id="id5">Vectorizer</a></li>
<li><a class="reference internal" href="#psdestimator" id="id6">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator" id="id7">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters" id="id8">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern" id="id9">Common Spatial Pattern</a></li>
<li><a class="reference internal" href="#xdawn" id="id10">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering" id="id11">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters" id="id12">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sensor-space-decoding" id="id13">Sensor-space decoding</a><ul>
<li><a class="reference internal" href="#generalization-across-time" id="id14">Generalization Across Time</a></li>
<li><a class="reference internal" href="#time-decoding" id="id15">Time Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding" id="id16">Source-space decoding</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="decoding">
<span id="id1"></span><h1><a class="toc-backref" href="#id2">Decoding</a><a class="headerlink" href="#decoding" title="Permalink to this headline">¶</a></h1>
<p>For maximal compatibility with the Scikit-learn package, we follow the same API. Each estimator implements a <code class="docutils literal"><span class="pre">fit</span></code>, a <code class="docutils literal"><span class="pre">transform</span></code> and a <code class="docutils literal"><span class="pre">fit_transform</span></code> method. In some cases, they also implement an <code class="docutils literal"><span class="pre">inverse_transform</span></code> method. For more details, visit the Scikit-learn page.</p>
<p>For ease of comprehension, we will denote instantiations of the class using the same name as the class but in small caps instead of camel cases.</p>
<div class="section" id="basic-estimators">
<h2><a class="toc-backref" href="#id3">Basic Estimators</a><a class="headerlink" href="#basic-estimators" title="Permalink to this headline">¶</a></h2>
<div class="section" id="scaler">
<h3><a class="toc-backref" href="#id4">Scaler</a><a class="headerlink" href="#scaler" title="Permalink to this headline">¶</a></h3>
<p>This will standardize data across channels. Each channel type (mag, grad or eeg) is treated separately. During training time, the mean (<cite>ch_mean_</cite>) and standard deviation (<cite>std_</cite>) is computed in the <code class="docutils literal"><span class="pre">fit</span></code> method and stored as an attribute to the object. The <code class="docutils literal"><span class="pre">transform</span></code> method is called to transform the training set. To perform both the <code class="docutils literal"><span class="pre">fit</span></code> and <code class="docutils literal"><span class="pre">transform</span></code> operations in a single call, the <code class="docutils literal"><span class="pre">fit_transform</span></code> method may be used. During test time, the stored mean and standard deviation are used in the <code class="docutils literal"><span class="pre">transform</span></code> method. To recover the original data, you can use <code class="docutils literal"><span class="pre">inverse_transform</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is different from the <code class="docutils literal"><span class="pre">StandarScaler</span></code> estimator offered by Scikit-Learn. The <code class="docutils literal"><span class="pre">StandardScaler</span></code> standardizes each feature, whereas the <code class="docutils literal"><span class="pre">Scaler</span></code> object standardizes by channel type.</p>
</div>
</div>
<div class="section" id="vectorizer">
<h3><a class="toc-backref" href="#id5">Vectorizer</a><a class="headerlink" href="#vectorizer" title="Permalink to this headline">¶</a></h3>
<p>Scikit-learn API provides functionality to chain transformers and estimators by using <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.18.1)"><code class="xref py py-class docutils literal"><span class="pre">sklearn.pipeline.Pipeline</span></code></a>. We can construct decoding pipelines and perform cross-validation and grid-search. However scikit-learn transformers and estimators generally expect 2D data (n_samples * n_features), whereas MNE transformers typically output data with a higher dimensionality (e.g. n_samples * n_channels * n_frequencies * n_times). A Vectorizer therefore needs to be applied between the MNE and the scikit-learn steps: e.g: make_pipeline(Xdawn(), Vectorizer(), LogisticRegression())</p>
</div>
<div class="section" id="psdestimator">
<h3><a class="toc-backref" href="#id6">PSDEstimator</a><a class="headerlink" href="#psdestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator computes the power spectral density (PSD) using the multitaper method. It takes a 3D array as input, it into 2D and computes the PSD.</p>
</div>
<div class="section" id="filterestimator">
<h3><a class="toc-backref" href="#id7">FilterEstimator</a><a class="headerlink" href="#filterestimator" title="Permalink to this headline">¶</a></h3>
<p>This estimator filters the 3D epochs data.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This is meant for use in conjunction with <code class="docutils literal"><span class="pre">RtEpochs</span></code>. It is not recommended in a normal processing pipeline as it may result in edge artifacts.</p>
</div>
</div>
</div>
<div class="section" id="spatial-filters">
<h2><a class="toc-backref" href="#id8">Spatial filters</a><a class="headerlink" href="#spatial-filters" title="Permalink to this headline">¶</a></h2>
<p>Just like temporal filters, spatial filters provide weights to modify the data along the sensor dimension. They are popular in the BCI community because of their simplicity and ability to distinguish spatially-separated neural activity.</p>
<div class="section" id="common-spatial-pattern">
<h3><a class="toc-backref" href="#id9">Common Spatial Pattern</a><a class="headerlink" href="#common-spatial-pattern" title="Permalink to this headline">¶</a></h3>
<p>This is a technique to analyze multichannel data based on recordings from two classes. Let <span class="math">\(X \in R^{C\times T}\)</span> be a segment of data with <span class="math">\(C\)</span> channels and <span class="math">\(T\)</span> time points. The data at a single time point is denoted by <span class="math">\(x(t)\)</span> such that <span class="math">\(X=[x(t), x(t+1), ..., x(t+T-1)]\)</span>. Common Spatial Pattern (CSP) finds a decomposition that projects the signal in the original sensor space to CSP space using the following transformation:</p>
<div class="math" id="equation-csp">
<span class="eqno">(1)<a class="headerlink" href="#equation-csp" title="Permalink to this equation">¶</a></span>\[x_{CSP}(t) = W^{T}x(t)\]</div>
<p>where each column of <span class="math">\(W \in R^{C\times C}\)</span> is a spatial filter and each row of <span class="math">\(x_{CSP}\)</span> is a CSP component. The matrix <span class="math">\(W\)</span> is also called the de-mixing matrix in other contexts. Let <span class="math">\(\Sigma^{+} \in R^{C\times C}\)</span> and <span class="math">\(\Sigma^{-} \in R^{C\times C}\)</span> be the estimates of the covariance matrices of the two conditions.
CSP analysis is given by the simultaneous diagonalization of the two covariance matrices</p>
<div class="math" id="equation-diagonalize_p">
<span class="eqno">(2)<a class="headerlink" href="#equation-diagonalize_p" title="Permalink to this equation">¶</a></span>\[W^{T}\Sigma^{+}W = \lambda^{+}\]</div>
<div class="math" id="equation-diagonalize_n">
<span class="eqno">(3)<a class="headerlink" href="#equation-diagonalize_n" title="Permalink to this equation">¶</a></span>\[W^{T}\Sigma^{-}W = \lambda^{-}\]</div>
<p>where <span class="math">\(\lambda^{C}\)</span> is a diagonal matrix whose entries are the eigenvalues of the following generalized eigenvalue problem</p>
<div class="math" id="equation-eigen_problem">
<span class="eqno">(4)<a class="headerlink" href="#equation-eigen_problem" title="Permalink to this equation">¶</a></span>\[\Sigma^{+}w = \lambda \Sigma^{-}w\]</div>
<p>Large entries in the diagonal matrix corresponds to a spatial filter which gives high variance in one class but low variance in the other. Thus, the filter facilitates discrimination between the two classes.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-eeg-py"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_space.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-space-py"><span class="std std-ref">Decoding in sensor space data using the Common Spatial Pattern (CSP)</span></a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">Spotlight:</p>
<p>The winning entry of the Grasp-and-lift EEG competition in Kaggle uses the CSP implementation in MNE. It was featured as a <a class="reference external" href="http://blog.kaggle.com/2015/08/12/july-2015-scripts-of-the-week/">script of the week</a>.</p>
</div>
</div>
<div class="section" id="xdawn">
<h3><a class="toc-backref" href="#id10">xDAWN</a><a class="headerlink" href="#xdawn" title="Permalink to this headline">¶</a></h3>
<p>Xdawn is a spatial filtering method designed to improve the signal to signal + noise ratio (SSNR) of the ERP responses. Xdawn was originally  designed for P300 evoked potential by enhancing the target response with respect to the non-target response. The implementation in MNE-Python is a generalization to any type of ERP.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/preprocessing/plot_xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-plot-xdawn-denoising-py"><span class="std std-ref">XDAWN Denoising</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-xdawn-eeg-py"><span class="std std-ref">XDAWN Decoding From EEG data</span></a></li>
</ul>
</div>
</div>
<div class="section" id="effect-matched-spatial-filtering">
<h3><a class="toc-backref" href="#id11">Effect-matched spatial filtering</a><a class="headerlink" href="#effect-matched-spatial-filtering" title="Permalink to this headline">¶</a></h3>
<p>The result is a spatial filter at each time point and a corresponding time course. Intuitively, the result gives the similarity between the filter at each time point and the data vector (sensors) at that time point.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></li>
</ul>
</div>
</div>
<div class="section" id="patterns-vs-filters">
<h3><a class="toc-backref" href="#id12">Patterns vs. filters</a><a class="headerlink" href="#patterns-vs-filters" title="Permalink to this headline">¶</a></h3>
<p>When interpreting the components of the CSP, it is often more intuitive to think about how <span class="math">\(x(t)\)</span> is composed of the different CSP components <span class="math">\(x_{CSP}(t)\)</span>. In other words, we can rewrite Equation <a class="reference internal" href="#equation-csp">(1)</a> as follows:</p>
<div class="math" id="equation-patterns">
<span class="eqno">(5)<a class="headerlink" href="#equation-patterns" title="Permalink to this equation">¶</a></span>\[x(t) = (W^{-1})^{T}x_{CSP}(t)\]</div>
<p>The columns of the matrix <span class="math">\((W^{-1})^T\)</span> are called spatial patterns. This is also called the mixing matrix. The example <a class="reference internal" href="../auto_examples/decoding/plot_linear_model_patterns.html#sphx-glr-auto-examples-decoding-plot-linear-model-patterns-py"><span class="std std-ref">Linear classifier on sensor data with plot patterns and filters</span></a> demonstrates the difference between patterns and filters.</p>
<p>Plotting a pattern is as simple as doing:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">info</span> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">info</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_patterns</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>  <span class="c1"># model is an instantiation of an estimator described in this section</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_001.png" style="height: 100px;" /></a>
<p>To plot the corresponding filter, you can do:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png"><img alt="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" class="align-center" src="manual/../../_images/sphx_glr_plot_linear_model_patterns_002.png" style="height: 100px;" /></a>
</div>
</div>
<div class="section" id="sensor-space-decoding">
<h2><a class="toc-backref" href="#id13">Sensor-space decoding</a><a class="headerlink" href="#sensor-space-decoding" title="Permalink to this headline">¶</a></h2>
<div class="section" id="generalization-across-time">
<h3><a class="toc-backref" href="#id14">Generalization Across Time</a><a class="headerlink" href="#generalization-across-time" title="Permalink to this headline">¶</a></h3>
<p>Generalization Across Time (GAT) is a modern strategy to infer neuroscientific conclusions from decoding analysis of sensor-space data. An accuracy matrix is constructed where each point represents the performance of the model trained on one time window and tested on another.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_time_generalization_001.png" style="width: 400px;" /></a>
<p>To use this functionality, simply do:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span> <span class="o">=</span> <span class="n">GeneralizationAcrossTime</span><span class="p">(</span><span class="n">predict_mode</span><span class="o">=</span><span class="s1">&#39;cross-validation&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Generalization Across Time (faces vs. scrambled)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_time_generalization_conditions.html#sphx-glr-auto-examples-decoding-plot-decoding-time-generalization-conditions-py"><span class="std std-ref">Decoding sensor space data with generalization across time and conditions</span></a></li>
</ul>
</div>
</div>
<div class="section" id="time-decoding">
<h3><a class="toc-backref" href="#id15">Time Decoding</a><a class="headerlink" href="#time-decoding" title="Permalink to this headline">¶</a></h3>
<p>In this strategy, a model trained on one time window is tested on the same time window. A moving time window will thus yield an accuracy curve similar to an ERP, but is considered more sensitive to effects in some situations. It is related to searchlight-based approaches in fMRI. This is also the diagonal of the GAT matrix.</p>
<a class="reference internal image-reference" href="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png"><img alt="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" class="align-center" src="manual/../../_images/sphx_glr_plot_decoding_sensors_001.png" style="width: 400px;" /></a>
<p>To generate this plot, you need to initialize a GAT object and then use the method <code class="docutils literal"><span class="pre">plot_diagonal</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gat</span><span class="o">.</span><span class="n">plot_diagonal</span><span class="p">()</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_tutorials/plot_sensors_decoding.html#sphx-glr-auto-tutorials-plot-sensors-decoding-py"><span class="std std-ref">Decoding sensor space data</span></a></li>
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_time_generalization_conditions.html#sphx-glr-auto-examples-decoding-plot-decoding-time-generalization-conditions-py"><span class="std std-ref">Decoding sensor space data with generalization across time and conditions</span></a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="source-space-decoding">
<h2><a class="toc-backref" href="#id16">Source-space decoding</a><a class="headerlink" href="#source-space-decoding" title="Permalink to this headline">¶</a></h2>
<p>Source space decoding is also possible, but because the number of features can be much larger than in the sensor space, univariate feature selection using ANOVA f-test (or some other metric) can be done to reduce the feature dimension. Interpreting decoding results might be easier in source space as compared to sensor space.</p>
<div class="topic">
<p class="topic-title first">Examples:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_spatio_temporal_source.html#sphx-glr-auto-examples-decoding-plot-decoding-spatio-temporal-source-py"><span class="std std-ref">Decoding source space data</span></a></li>
</ul>
</div>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012-2017, MNE Developers. Last updated on 2017-03-02.<br/>
    </p>
  </div>
</footer>
  </body>
</html>