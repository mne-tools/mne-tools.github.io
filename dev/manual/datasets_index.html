<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Datasets &#8212; MNE 0.15.dev0 documentation</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/flatly/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../_static/flag-icon.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.15.dev0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>


  </head>
  <body role="document">

<div class="row devbar alert alert-danger">
This documentation is for the <strong>development version 0.15.dev0</strong> - <a href="http://martinos.org/mne/stable">switch to Stable</a>
</div>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.15.dev0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../getting_started.html">Install</a></li>
                <li><a href="../documentation.html">Documentation</a></li>
                <li><a href="../python_reference.html">API</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Datasets</a><ul>
<li><a class="reference internal" href="#sample">Sample</a></li>
<li><a class="reference internal" href="#brainstorm">Brainstorm</a><ul>
<li><a class="reference internal" href="#auditory">Auditory</a></li>
<li><a class="reference internal" href="#resting-state">Resting state</a></li>
<li><a class="reference internal" href="#median-nerve">Median nerve</a></li>
</ul>
</li>
<li><a class="reference internal" href="#megsim">MEGSIM</a></li>
<li><a class="reference internal" href="#spm-faces">SPM faces</a></li>
<li><a class="reference internal" href="#eegbci-motor-imagery">EEGBCI motor imagery</a></li>
<li><a class="reference internal" href="#somatosensory">Somatosensory</a></li>
<li><a class="reference internal" href="#multimodal">Multimodal</a></li>
<li><a class="reference internal" href="#visual-92-object-categories">Visual 92 object categories</a></li>
<li><a class="reference internal" href="#mtrf-dataset">mTRF Dataset</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-12 content">
      
  <div class="section" id="datasets">
<span id="id1"></span><h1>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#sample" id="id12">Sample</a></li>
<li><a class="reference internal" href="#brainstorm" id="id13">Brainstorm</a><ul>
<li><a class="reference internal" href="#auditory" id="id14">Auditory</a></li>
<li><a class="reference internal" href="#resting-state" id="id15">Resting state</a></li>
<li><a class="reference internal" href="#median-nerve" id="id16">Median nerve</a></li>
</ul>
</li>
<li><a class="reference internal" href="#megsim" id="id17">MEGSIM</a></li>
<li><a class="reference internal" href="#spm-faces" id="id18">SPM faces</a></li>
<li><a class="reference internal" href="#eegbci-motor-imagery" id="id19">EEGBCI motor imagery</a></li>
<li><a class="reference internal" href="#somatosensory" id="id20">Somatosensory</a></li>
<li><a class="reference internal" href="#multimodal" id="id21">Multimodal</a></li>
<li><a class="reference internal" href="#visual-92-object-categories" id="id22">Visual 92 object categories</a></li>
<li><a class="reference internal" href="#mtrf-dataset" id="id23">mTRF Dataset</a></li>
<li><a class="reference internal" href="#references" id="id24">References</a></li>
</ul>
</div>
<p>All the dataset fetchers are available in <a class="reference internal" href="../python_reference.html#module-mne.datasets" title="mne.datasets"><code class="xref py py-mod docutils literal"><span class="pre">mne.datasets</span></code></a>. To download any of the datasets,
use the <code class="docutils literal"><span class="pre">data_path</span></code> (fetches full dataset) or the <code class="docutils literal"><span class="pre">load_data</span></code> (fetches dataset partially) functions.</p>
<div class="section" id="sample">
<h2><a class="toc-backref" href="#id12">Sample</a><a class="headerlink" href="#sample" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.sample.data_path()</span></code></a></p>
<p><a class="reference internal" href="sample_dataset.html#ch-sample-data"><span class="std std-ref">The sample data set</span></a> is recorded using a 306-channel Neuromag vectorview system.</p>
<p>In this experiment, checkerboard patterns were presented to the subject
into the left and right visual field, interspersed by tones to the
left or right ear. The interval between the stimuli was 750 ms. Occasionally
a smiley face was presented at the center of the visual field.
The subject was asked to press a key with the right index finger
as soon as possible after the appearance of the face.</p>
<p>Once the <code class="docutils literal"><span class="pre">data_path</span></code> is known, its contents can be examined using <a class="reference internal" href="io.html#ch-convert"><span class="std std-ref">IO functions</span></a>.</p>
</div>
<div class="section" id="brainstorm">
<h2><a class="toc-backref" href="#id13">Brainstorm</a><a class="headerlink" href="#brainstorm" title="Permalink to this headline">¶</a></h2>
<p>Dataset fetchers for three Brainstorm tutorials are available. Users must agree to the
license terms of these datasets before downloading them. These files are recorded in a CTF 275 system.
The data is converted to <cite>fif</cite> format before being made available to MNE users. However, MNE-Python now supports
IO for the <cite>ctf</cite> format as well in addition to the C converter utilities. Please consult the <a class="reference internal" href="io.html#ch-convert"><span class="std std-ref">IO section</span></a> for details.</p>
<div class="section" id="auditory">
<h3><a class="toc-backref" href="#id14">Auditory</a><a class="headerlink" href="#auditory" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a>.</p>
<p>Details about the data can be found at the Brainstorm <a class="reference external" href="http://neuroimage.usc.edu/brainstorm/DatasetAuditory">auditory dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/datasets/plot_brainstorm_data.html#sphx-glr-auto-examples-datasets-plot-brainstorm-data-py"><span class="std std-ref">Brainstorm auditory dataset tutorial</span></a>: Partially replicates the original Brainstorm tutorial.</li>
</ul>
</div>
</div>
<div class="section" id="resting-state">
<h3><a class="toc-backref" href="#id15">Resting state</a><a class="headerlink" href="#resting-state" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_resting.data_path.html#mne.datasets.brainstorm.bst_resting.data_path" title="mne.datasets.brainstorm.bst_resting.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.brainstorm.bst_resting.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="http://neuroimage.usc.edu/brainstorm/DatasetResting">resting state dataset tutorial</a>.</p>
</div>
<div class="section" id="median-nerve">
<h3><a class="toc-backref" href="#id16">Median nerve</a><a class="headerlink" href="#median-nerve" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="http://neuroimage.usc.edu/brainstorm/DatasetMedianNerveCtf">median nerve dataset tutorial</a>.</p>
</div>
</div>
<div class="section" id="megsim">
<h2><a class="toc-backref" href="#id17">MEGSIM</a><a class="headerlink" href="#megsim" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.megsim.load_data.html#mne.datasets.megsim.load_data" title="mne.datasets.megsim.load_data"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.megsim.load_data()</span></code></a></p>
<p>This dataset contains experimental and simulated MEG data. To load data from this dataset, do:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mne.io</span> <span class="k">import</span> <span class="n">Raw</span>
<span class="kn">from</span> <span class="nn">mne.datasets.megsim</span> <span class="k">import</span> <span class="n">load_data</span>
<span class="n">raw_fnames</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">condition</span><span class="o">=</span><span class="s1">&#39;visual&#39;</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;raw&#39;</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;experimental&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">Raw</span><span class="p">(</span><span class="n">raw_fnames</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>Detailed description of the dataset can be found in the related publication <a class="footnote-reference" href="#id7" id="id2">[1]</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/datasets/plot_megsim_data.html#sphx-glr-auto-examples-datasets-plot-megsim-data-py"><span class="std std-ref">MEGSIM experimental and simulation datasets</span></a></li>
</ul>
</div>
</div>
<div class="section" id="spm-faces">
<h2><a class="toc-backref" href="#id18">SPM faces</a><a class="headerlink" href="#spm-faces" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.spm_face.data_path.html#mne.datasets.spm_face.data_path" title="mne.datasets.spm_face.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.spm_face.data_path()</span></code></a></p>
<p>The <a class="reference external" href="http://www.fil.ion.ucl.ac.uk/spm/data/mmfaces/">SPM faces dataset</a> contains EEG, MEG and fMRI recordings on face perception.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/datasets/plot_spm_faces_dataset.html#sphx-glr-auto-examples-datasets-plot-spm-faces-dataset-py"><span class="std std-ref">From raw data to dSPM on SPM Faces dataset</span></a> Full pipeline including artifact removal, epochs averaging, forward model computation and source reconstruction using dSPM on the contrast: &#8220;faces - scrambled&#8221;.</li>
</ul>
</div>
</div>
<div class="section" id="eegbci-motor-imagery">
<h2><a class="toc-backref" href="#id19">EEGBCI motor imagery</a><a class="headerlink" href="#eegbci-motor-imagery" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.eegbci.load_data.html#mne.datasets.eegbci.load_data" title="mne.datasets.eegbci.load_data"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.eegbci.load_data()</span></code></a></p>
<p>The EEGBCI dataset is documented in <a class="footnote-reference" href="#id8" id="id3">[2]</a>. The data set is available at PhysioNet <a class="footnote-reference" href="#id9" id="id4">[3]</a>.
The dataset contains 64-channel EEG recordings from 109 subjects and 14 runs on each subject in EDF+ format.
The recordings were made using the BCI2000 system. To load a subject, do:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mne.io</span> <span class="k">import</span> <span class="n">concatenate_raws</span><span class="p">,</span> <span class="n">read_raw_edf</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="k">import</span> <span class="n">eegbci</span>
<span class="n">raw_fnames</span> <span class="o">=</span> <span class="n">eegbci</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">runs</span><span class="p">)</span>
<span class="n">raws</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_raw_edf</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">raw_fnames</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">concatenate_raws</span><span class="p">(</span><span class="n">raws</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-eeg-py"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></li>
</ul>
</div>
<p>Do not hesitate to contact MNE-Python developers on the
<a class="reference external" href="http://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">MNE mailing list</a>
to discuss the possibility to add more publicly available datasets.</p>
</div>
<div class="section" id="somatosensory">
<h2><a class="toc-backref" href="#id20">Somatosensory</a><a class="headerlink" href="#somatosensory" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.somato.data_path.html#mne.datasets.somato.data_path" title="mne.datasets.somato.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.somato.data_path()</span></code></a></p>
<p>This dataset contains somatosensory data with event-related synchronizations
(ERS) and desynchronizations (ERD).</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_tutorials/plot_sensors_time_frequency.html#sphx-glr-auto-tutorials-plot-sensors-time-frequency-py"><span class="std std-ref">Frequency and time-frequency sensors analysis</span></a></li>
</ul>
</div>
</div>
<div class="section" id="multimodal">
<h2><a class="toc-backref" href="#id21">Multimodal</a><a class="headerlink" href="#multimodal" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.multimodal.data_path.html#mne.datasets.multimodal.data_path" title="mne.datasets.multimodal.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.multimodal.data_path()</span></code></a></p>
<p>This dataset contains a single subject recorded at Otaniemi (Aalto University)
with auditory, visual, and somatosensory stimuli.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/io/plot_elekta_epochs.html#sphx-glr-auto-examples-io-plot-elekta-epochs-py"><span class="std std-ref">Getting averaging info from .fif files</span></a></li>
</ul>
</div>
</div>
<div class="section" id="visual-92-object-categories">
<h2><a class="toc-backref" href="#id22">Visual 92 object categories</a><a class="headerlink" href="#visual-92-object-categories" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.visual_92_categories.data_path.html#mne.datasets.visual_92_categories.data_path" title="mne.datasets.visual_92_categories.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.visual_92_categories.data_path()</span></code></a>.</p>
<p>This dataset is recorded using a 306-channel Neuromag vectorview system.</p>
<p>Experiment consisted in the visual presentation of 92 images of human, animal
and inanimate objects either natural or artificial <a class="footnote-reference" href="#id10" id="id5">[4]</a>. Given the high number
of conditions this dataset is well adapted to an approach based on
Representational Similarity Analysis (RSA).</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/decoding_rsa.html#sphx-glr-auto-examples-decoding-decoding-rsa-py"><span class="std std-ref">Representational Similarity Analysis (RSA)</span></a>: Partially replicates the results from Cichy et al. (2014).</li>
</ul>
</div>
</div>
<div class="section" id="mtrf-dataset">
<h2><a class="toc-backref" href="#id23">mTRF Dataset</a><a class="headerlink" href="#mtrf-dataset" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.mtrf.data_path.html#mne.datasets.mtrf.data_path" title="mne.datasets.mtrf.data_path"><code class="xref py py-func docutils literal"><span class="pre">mne.datasets.mtrf.data_path()</span></code></a>.</p>
<p>This dataset contains 128 channel EEG as well as natural speech stimulus features,
which is also available <a class="reference external" href="https://sourceforge.net/projects/aespa/files/">here</a>.</p>
<p>The experiment consisted of subjects listening to natural speech.
The dataset contains several feature representations of the speech stimulus,
suitable for using to fit continuous regression models of neural activity.
More details and a description of the package can be found in <a class="footnote-reference" href="#id11" id="id6">[5]</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/decoding/plot_receptive_field.html#sphx-glr-auto-examples-decoding-plot-receptive-field-py"><span class="std std-ref">Receptive Field Estimation and Prediction</span></a>: Partially replicates the results from Crosse et al. (2016).</li>
</ul>
</div>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id24">References</a><a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[1]</a></td><td>Aine CJ, Sanfratello L, Ranken D, Best E, MacArthur JA, Wallace T, Gilliam K, Donahue CH, Montano R, Bryant JE, Scott A, Stephen JM (2012) MEG-SIM: A Web Portal for Testing MEG Analysis Methods using Realistic Simulated and Empirical Data. Neuroinform 10:141-158</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[2]</a></td><td>Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id9" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[3]</a></td><td>Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[4]</a></td><td>Cichy, R. M., Pantazis, D., &amp; Oliva, A. &#8220;Resolving human object recognition in space and time.&#8221; Nature neuroscience (2014): 17(3), 455-462</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[5]</a></td><td>Crosse, M. J., Di Liberto, G. M., Bednar, A., &amp; Lalor, E. C. The Multivariate Temporal Response Function (mTRF) Toolbox: A MATLAB Toolbox for Relating Neural Signals to Continuous Stimuli. Frontiers in Human Neuroscience (2016): 10.</td></tr>
</tbody>
</table>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container"><img src="_static/institutions.png" alt="Institutions"></div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2017, MNE Developers. Last updated on 2017-06-10.</p>
  </div>
</footer>
  </body>
</html>