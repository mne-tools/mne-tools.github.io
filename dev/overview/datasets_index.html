
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Datasets Overview &#8212; MNE 0.23.dev0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.951c8c8e3af89de180a2f03968e0e7cb.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
    <!-- add `style` or `link` tags with your CSS `@font-face` declarations here -->
    <!-- ... and a `style` tag with setting `font-family` in `body` and `.header-style` -->
    <!-- ... and optionally preload the `woff2` for snappier page loads -->
    <!-- or add a `style` tag with a font fallback chain with good cross-platform coverage -->
    <style>
        body,.header-style {font-family: 'Source Sans Pro', sans-serif;}
        code,kbd,pre,samp {font-family: 'Source Code Pro', monospace;}
    </style>

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/font-source-sans-pro.css" />
    <link rel="stylesheet" type="text/css" href="../_static/font-source-code-pro.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.014cad6f3a039303089e.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/bootstrap_divs.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Command line tools using Python" href="../generated/commands.html" />
    <link rel="prev" title="Design philosophy" href="design_philosophy.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <script type="text/javascript" src="../_static/scrollfix.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
  
    <div class="container-fluid alert-danger devbar">
      <div class="row no-gutters">
        <div class="col-12 text-center">
          This is documentation for the <em>unstable development version</em> of MNE-Python. <a class="alert-link" href="https://mne.tools/stable">Click here</a> to switch to the stable version.
        </div>
      </div>
    </div>
  

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">
    <a class="navbar-brand" href="../index.html">
        
        <img src="../_static/mne_logo_small.svg" class="logo" alt="logo" />
        
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-auto col-lg-9 collapse navbar-collapse">
        <ul id="navbar-main-elements" class="navbar-nav mr-auto">
            
            
            <li class="nav-item ">
                <a class="nav-link" href="../install/index.html">Install</a>
            </li>
            
            <li class="nav-item active">
                <a class="nav-link" href="index.html">Documentation</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="../python_reference.html">API Reference</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="get_help.html">Get help</a>
            </li>
            
            <li class="nav-item ">
                <a class="nav-link" href="development.html">Development</a>
            </li>
            
            
        </ul>

        

        <ul class="navbar-nav">
            <!-- version dropdown -->
            <li class="mr-2 dropdown">
                <button type="button" class="btn btn-danger btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown">
                    v0.23.dev0
                    <span class="caret"></span>
                </button>
                <ul class="dropdown-menu" aria-labelledby="dLabelMore">
                    <li><a href="https://mne-tools.github.io/dev/index.html">v0.23 (devel)</a></li>
                    <li><a href="https://mne-tools.github.io/stable/index.html">v0.22 (stable)</a></li>
                    <li><a href="https://mne-tools.github.io/0.21/index.html">v0.21</a></li>
                    <li><a href="https://mne-tools.github.io/0.20/index.html">v0.20</a></li>
                    <li><a href="https://mne-tools.github.io/0.19/index.html">v0.19</a></li>
                    <li><a href="https://mne-tools.github.io/0.18/index.html">v0.18</a></li>
                    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
                    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
                    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
                    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
                    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
                    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
                    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
                </ul>
            </li>
            
            <li class="nav-item">
                <a class="nav-link" href="https://github.com/mne-tools/mne-python" target="_blank" rel="noopener">
                    <span><i class="fab fa-github-square"></i></span>
                </a>
            </li>
            
            
            <li class="nav-item">
                <a class="nav-link" href="https://twitter.com/mne_python" target="_blank" rel="noopener">
                    <span><i class="fab fa-twitter-square"></i></span>
                </a>
            </li>
            
            <!-- discourse forum link -->
            <li class="nav-item">
                <a class="nav-link" href="https://mne.discourse.group" target="_blank" rel="noopener">
                    <span><i class="fab fa-discourse"></i></span>
                </a>
            </li>
        </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
      <li class="toctree-l2">
 <a class="reference internal" href="../auto_tutorials/index.html">
  Tutorials
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../auto_examples/index.html">
  Examples
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../glossary.html">
  Glossary
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="implementation.html">
  Implementation details
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="design_philosophy.html">
  Design philosophy
 </a>
</li>

<li class="toctree-l2 current active">
 <a class="current reference internal" href="#">
  Example datasets
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../generated/commands.html">
  Command-line tools
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="migrating.html">
  Migrating from other analysis software
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="cookbook.html">
  The typical M/EEG workflow
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="cite.html">
  How to cite MNE-Python
 </a>
</li>

<li class="toctree-l2">
 <a class="reference internal" href="../cited.html">
  Papers citing MNE-Python
 </a>
</li>

    </ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>



<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample">
   Sample
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contents-of-the-data-set">
     Contents of the data set
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#brainstorm">
   Brainstorm
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auditory">
     Auditory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resting-state">
     Resting state
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#median-nerve">
     Median nerve
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spm-faces">
   SPM faces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eegbci-motor-imagery">
   EEGBCI motor imagery
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#somatosensory">
   Somatosensory
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multimodal">
   Multimodal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fnirs-motor">
   fNIRS motor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#high-frequency-sef">
   High frequency SEF
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visual-92-object-categories">
   Visual 92 object categories
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mtrf-dataset">
   mTRF Dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kiloword-dataset">
   Kiloword dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-neuroimaging-bti-dataset">
   4D Neuroimaging / BTi dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#opm">
   OPM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sleep-polysomnographic-database">
   The Sleep PolySomnoGraphic Database
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference-channel-noise-meg-data-set">
   Reference channel noise MEG data set
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#miscellaneous-datasets">
   Miscellaneous Datasets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fsaverage">
     fsaverage
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#infant-template-mris">
     Infant template MRIs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ecog-dataset">
     ECoG Dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#limo-dataset">
     LIMO Dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
<div>
  
  <div class="section" id="datasets-overview">
<span id="datasets"></span><h1>Datasets Overview<a class="headerlink" href="#datasets-overview" title="Permalink to this headline">¶</a></h1>
<div class="sidebar">
<p class="sidebar-title">Contributing datasets to MNE-Python</p>
<p>Do not hesitate to contact MNE-Python developers on the
<a class="reference external" href="https://mne.discourse.group">MNE Forum</a> to discuss the possibility of
adding more publicly available datasets.</p>
</div>
<p>All the dataset fetchers are available in <a class="reference internal" href="../datasets.html#module-mne.datasets" title="mne.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.datasets</span></code></a>. To download any of the datasets,
use the <code class="docutils literal notranslate"><span class="pre">data_path</span></code> (fetches full dataset) or the <code class="docutils literal notranslate"><span class="pre">load_data</span></code> (fetches dataset partially) functions.</p>
<p>All fetchers will check the default download location first to see if the dataset
is already on your computer, and only download it if necessary. The default
download location is also configurable; see the documentation of any of the
<code class="docutils literal notranslate"><span class="pre">data_path</span></code> functions for more information.</p>
<div class="section" id="sample">
<span id="sample-dataset"></span><h2>Sample<a class="headerlink" href="#sample" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sample.data_path()</span></code></a></p>
<p>These data were acquired with the Neuromag
Vectorview system at MGH/HMS/MIT Athinoula A. Martinos Center Biomedical
Imaging. EEG data from a 60-channel electrode cap was acquired simultaneously with
the MEG. The original MRI data set was acquired with a Siemens 1.5 T
Sonata scanner using an MPRAGE sequence.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These data are provided solely for the purpose of getting familiar
with the MNE software. The data should not be used to evaluate the
performance of the MEG or MRI system employed.</p>
</div>
<p>In this experiment, checkerboard patterns were presented to the subject
into the left and right visual field, interspersed by tones to the
left or right ear. The interval between the stimuli was 750 ms. Occasionally
a smiley face was presented at the center of the visual field.
The subject was asked to press a key with the right index finger
as soon as possible after the appearance of the face.</p>
<table class="table" id="id15">
<caption><span class="caption-text">Trigger codes for the sample data set.</span><a class="headerlink" href="#id15" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 16%" />
<col style="width: 9%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"></th>
<th class="head"><p>Contents</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>LA</p></td>
<td><p>1</p></td>
<td><p>Response to left-ear auditory stimulus</p></td>
</tr>
<tr class="row-odd"><td><p>RA</p></td>
<td><p>2</p></td>
<td><p>Response to right-ear auditory stimulus</p></td>
</tr>
<tr class="row-even"><td><p>LV</p></td>
<td><p>3</p></td>
<td><p>Response to left visual field stimulus</p></td>
</tr>
<tr class="row-odd"><td><p>RV</p></td>
<td><p>4</p></td>
<td><p>Response to right visual field stimulus</p></td>
</tr>
<tr class="row-even"><td><p>smiley</p></td>
<td><p>5</p></td>
<td><p>Response to the smiley face</p></td>
</tr>
<tr class="row-odd"><td><p>button</p></td>
<td><p>32</p></td>
<td><p>Response triggered by the button press</p></td>
</tr>
</tbody>
</table>
<div class="section" id="contents-of-the-data-set">
<h3>Contents of the data set<a class="headerlink" href="#contents-of-the-data-set" title="Permalink to this headline">¶</a></h3>
<p>The sample data set contains two main directories: <code class="docutils literal notranslate"><span class="pre">MEG/sample</span></code> (the MEG/EEG
data) and <code class="docutils literal notranslate"><span class="pre">subjects/sample</span></code> (the MRI reconstructions).
In addition to subject <code class="docutils literal notranslate"><span class="pre">sample</span></code>, the MRI surface reconstructions from another
subject, morph, are provided to demonstrate morphing capabilities.</p>
<table class="table" id="id16">
<caption><span class="caption-text">Contents of the MEG/sample directory.</span><a class="headerlink" href="#id16" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 26%" />
<col style="width: 74%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>File</p></th>
<th class="head"><p>Contents</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>sample/audvis_raw.fif</p></td>
<td><p>The raw MEG/EEG data</p></td>
</tr>
<tr class="row-odd"><td><p>audvis.ave</p></td>
<td><p>A template script for off-line averaging</p></td>
</tr>
<tr class="row-even"><td><p>auvis.cov</p></td>
<td><p>A template script for the computation of a noise-covariance matrix</p></td>
</tr>
</tbody>
</table>
<table class="table" id="id17">
<caption><span class="caption-text">Overview of the contents of the subjects/sample directory.</span><a class="headerlink" href="#id17" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>File / directory</p></th>
<th class="head"><p>Contents</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>bem</p></td>
<td><p>Directory for the forward modelling data</p></td>
</tr>
<tr class="row-odd"><td><p>bem/watershed</p></td>
<td><p>BEM surface segmentation data computed with the watershed algorithm</p></td>
</tr>
<tr class="row-even"><td><p>bem/inner_skull.surf</p></td>
<td><p>Inner skull surface for BEM</p></td>
</tr>
<tr class="row-odd"><td><p>bem/outer_skull.surf</p></td>
<td><p>Outer skull surface for BEM</p></td>
</tr>
<tr class="row-even"><td><p>bem/outer_skin.surf</p></td>
<td><p>Skin surface for BEM</p></td>
</tr>
<tr class="row-odd"><td><p>sample-head.fif</p></td>
<td><p>Skin surface in fif format for mne_analyze visualizations</p></td>
</tr>
<tr class="row-even"><td><p>surf</p></td>
<td><p>Surface reconstructions</p></td>
</tr>
<tr class="row-odd"><td><p>mri/T1</p></td>
<td><p>The T1-weighted MRI data employed in visualizations</p></td>
</tr>
</tbody>
</table>
<p>The following preprocessing steps have been already accomplished
in the sample data set:</p>
<ul class="simple">
<li><p>The MRI surface reconstructions have
been computed using the FreeSurfer software.</p></li>
<li><p>The BEM surfaces have been created with the watershed algorithm,
see <a class="reference internal" href="implementation.html#bem-watershed-algorithm"><span class="std std-ref">Using the watershed algorithm</span></a>.</p></li>
</ul>
<p>The <strong>sample</strong> dataset is distributed with <a class="reference internal" href="#fsaverage"><span class="std std-ref">fsaverage</span></a> for convenience.</p>
</div>
</div>
<div class="section" id="brainstorm">
<h2>Brainstorm<a class="headerlink" href="#brainstorm" title="Permalink to this headline">¶</a></h2>
<p>Dataset fetchers for three Brainstorm tutorials are available. Users must agree to the
license terms of these datasets before downloading them. These files are recorded in a CTF 275 system
and are provided in native CTF format (.ds files).</p>
<div class="section" id="auditory">
<h3>Auditory<a class="headerlink" href="#auditory" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a>.</p>
<p>Details about the data can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetAuditory">auditory dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/sample-datasets/plot_brainstorm_auditory.html#tut-brainstorm-auditory"><span class="std std-ref">Brainstorm auditory tutorial dataset</span></a>: Partially replicates the original Brainstorm tutorial.</p></li>
</ul>
</div>
</div>
<div class="section" id="resting-state">
<h3>Resting state<a class="headerlink" href="#resting-state" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_resting.data_path.html#mne.datasets.brainstorm.bst_resting.data_path" title="mne.datasets.brainstorm.bst_resting.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_resting.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetResting">resting state dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/connectivity/plot_mne_inverse_envelope_correlation.html#ex-envelope-correlation"><span class="std std-ref">Compute envelope correlations in source space</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="median-nerve">
<h3>Median nerve<a class="headerlink" href="#median-nerve" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetMedianNerveCtf">median nerve dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_brainstorm_data.html#ex-brainstorm-raw"><span class="std std-ref">Brainstorm raw (median nerve) dataset</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="spm-faces">
<h2>SPM faces<a class="headerlink" href="#spm-faces" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.spm_face.data_path.html#mne.datasets.spm_face.data_path" title="mne.datasets.spm_face.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.spm_face.data_path()</span></code></a></p>
<p>The <a class="reference external" href="https://www.fil.ion.ucl.ac.uk/spm/data/mmfaces/">SPM faces dataset</a> contains EEG, MEG and fMRI recordings on face perception.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/spm_faces_dataset.html#ex-spm-faces"><span class="std std-ref">From raw data to dSPM on SPM Faces dataset</span></a> Full pipeline including artifact removal, epochs averaging, forward model computation and source reconstruction using dSPM on the contrast: “faces - scrambled”.</p></li>
</ul>
</div>
</div>
<div class="section" id="eegbci-motor-imagery">
<h2>EEGBCI motor imagery<a class="headerlink" href="#eegbci-motor-imagery" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.eegbci.load_data.html#mne.datasets.eegbci.load_data" title="mne.datasets.eegbci.load_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.eegbci.load_data()</span></code></a></p>
<p>The EEGBCI dataset is documented in <a class="footnote-reference brackets" href="#schalketal2004" id="id1">1</a>. The data set is
available at PhysioNet <a class="footnote-reference brackets" href="#goldbergeretal2000" id="id2">2</a>. The dataset contains
64-channel EEG recordings from 109 subjects and 14 runs on each subject in EDF+
format. The recordings were made using the BCI2000 system. To load a subject,
do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mne.io</span> <span class="kn">import</span> <span class="n">concatenate_raws</span><span class="p">,</span> <span class="n">read_raw_edf</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">eegbci</span>
<span class="n">raw_fnames</span> <span class="o">=</span> <span class="n">eegbci</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">runs</span><span class="p">)</span>
<span class="n">raws</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_raw_edf</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">raw_fnames</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">concatenate_raws</span><span class="p">(</span><span class="n">raws</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#ex-decoding-csp-eeg"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="somatosensory">
<span id="somato-dataset"></span><h2>Somatosensory<a class="headerlink" href="#somatosensory" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.somato.data_path.html#mne.datasets.somato.data_path" title="mne.datasets.somato.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.somato.data_path()</span></code></a></p>
<p>This dataset contains somatosensory data with event-related synchronizations
(ERS) and desynchronizations (ERD).</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/time-freq/plot_sensors_time_frequency.html#tut-sensors-time-freq"><span class="std std-ref">Frequency and time-frequency sensor analysis</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/inverse/plot_dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/time_frequency/plot_time_frequency_global_field_power.html#ex-time-freq-global-field-power"><span class="std std-ref">Explore event-related dynamics for specific frequency bands</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="multimodal">
<h2>Multimodal<a class="headerlink" href="#multimodal" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.multimodal.data_path.html#mne.datasets.multimodal.data_path" title="mne.datasets.multimodal.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.multimodal.data_path()</span></code></a></p>
<p>This dataset contains a single subject recorded at Otaniemi (Aalto University)
with auditory, visual, and somatosensory stimuli.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/io/plot_elekta_epochs.html#ex-io-ave-fiff"><span class="std std-ref">Getting averaging info from .fif files</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="fnirs-motor">
<span id="fnirs-motor-dataset"></span><h2>fNIRS motor<a class="headerlink" href="#fnirs-motor" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.fnirs_motor.data_path.html#mne.datasets.fnirs_motor.data_path" title="mne.datasets.fnirs_motor.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.fnirs_motor.data_path()</span></code></a></p>
<p>This dataset contains a single subject recorded at Macquarie University.
It has optodes placed over the motor cortex. There are three conditions:</p>
<ul class="simple">
<li><p>tapping the left thumb to fingers</p></li>
<li><p>tapping the right thumb to fingers</p></li>
<li><p>a control where nothing happens</p></li>
</ul>
<p>The tapping lasts 5 seconds, and there are 30 trials of each condition.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/preprocessing/plot_70_fnirs_processing.html#tut-fnirs-processing"><span class="std std-ref">Preprocessing functional near-infrared spectroscopy (fNIRS) data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="high-frequency-sef">
<h2>High frequency SEF<a class="headerlink" href="#high-frequency-sef" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.hf_sef.data_path.html#mne.datasets.hf_sef.data_path" title="mne.datasets.hf_sef.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.hf_sef.data_path()</span></code></a></p>
<p>This dataset contains somatosensory evoked fields (median nerve stimulation)
with thousands of epochs. It was recorded with an Elekta TRIUX MEG device at
a sampling frequency of 3 kHz. The dataset is suitable for investigating
high-frequency somatosensory responses. Data from two subjects are included
with MRI images in DICOM format and FreeSurfer reconstructions.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_hf_sef_data.html#ex-hf-sef-data"><span class="std std-ref">high-frequency SEF responses</span></a>.</p></li>
</ul>
</div>
</div>
<div class="section" id="visual-92-object-categories">
<h2>Visual 92 object categories<a class="headerlink" href="#visual-92-object-categories" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.visual_92_categories.data_path.html#mne.datasets.visual_92_categories.data_path" title="mne.datasets.visual_92_categories.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.visual_92_categories.data_path()</span></code></a>.</p>
<p>This dataset is recorded using a 306-channel Neuromag vectorview system.</p>
<p>Experiment consisted in the visual presentation of 92 images of human, animal
and inanimate objects either natural or artificial <a class="footnote-reference brackets" href="#cichyetal2014" id="id3">3</a>.
Given the high number of conditions this dataset is well adapted to an approach
based on Representational Similarity Analysis (RSA).</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/decoding_rsa.html#ex-rsa-noplot"><span class="std std-ref">Representational Similarity Analysis (RSA)</span></a>: Partially replicates the results from <a class="footnote-reference brackets" href="#cichyetal2014" id="id4">3</a>.</p></li>
</ul>
</div>
</div>
<div class="section" id="mtrf-dataset">
<h2>mTRF Dataset<a class="headerlink" href="#mtrf-dataset" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.mtrf.data_path.html#mne.datasets.mtrf.data_path" title="mne.datasets.mtrf.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.mtrf.data_path()</span></code></a>.</p>
<p>This dataset contains 128 channel EEG as well as natural speech stimulus features,
which is also available <a class="reference external" href="https://sourceforge.net/projects/aespa/files/">here</a>.</p>
<p>The experiment consisted of subjects listening to natural speech.
The dataset contains several feature representations of the speech stimulus,
suitable for using to fit continuous regression models of neural activity.
More details and a description of the package can be found in
<a class="footnote-reference brackets" href="#crosseetal2016" id="id5">4</a>.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/plot_receptive_field_mtrf.html#ex-receptive-field-mtrf"><span class="std std-ref">Receptive Field Estimation and Prediction</span></a>: Partially replicates the results from <a class="footnote-reference brackets" href="#crosseetal2016" id="id6">4</a>.</p></li>
</ul>
</div>
</div>
<div class="section" id="kiloword-dataset">
<span id="id7"></span><h2>Kiloword dataset<a class="headerlink" href="#kiloword-dataset" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.kiloword.data_path.html#mne.datasets.kiloword.data_path" title="mne.datasets.kiloword.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.kiloword.data_path()</span></code></a>.</p>
<p>This dataset consists of averaged EEG data from 75 subjects performing a
lexical decision task on 960 English words <a class="footnote-reference brackets" href="#dufauetal2015" id="id8">5</a>. The words
are richly annotated, and can be used for e.g. multiple regression estimation
of EEG correlates of printed word processing.</p>
</div>
<div class="section" id="d-neuroimaging-bti-dataset">
<h2>4D Neuroimaging / BTi dataset<a class="headerlink" href="#d-neuroimaging-bti-dataset" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.phantom_4dbti.data_path.html#mne.datasets.phantom_4dbti.data_path" title="mne.datasets.phantom_4dbti.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.phantom_4dbti.data_path()</span></code></a>.</p>
<p>This dataset was obtained with a phantom on a 4D Neuroimaging / BTi system at
the MEG center in La Timone hospital in Marseille.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/sample-datasets/plot_phantom_4DBTi.html#tut-phantom-4dbti"><span class="std std-ref">4D Neuroimaging/BTi phantom dataset tutorial</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="opm">
<h2>OPM<a class="headerlink" href="#opm" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.opm.data_path.html#mne.datasets.opm.data_path" title="mne.datasets.opm.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.opm.data_path()</span></code></a></p>
<p>OPM data acquired using an Elekta DACQ, simply piping the data into Elekta
magnetometer channels. The FIF files thus appear to come from a TRIUX system
that is only acquiring a small number of magnetometer channels instead of the
whole array.</p>
<p>The OPM <code class="docutils literal notranslate"><span class="pre">coil_type</span></code> is custom, requiring a custom <code class="docutils literal notranslate"><span class="pre">coil_def.dat</span></code>.
The new <code class="docutils literal notranslate"><span class="pre">coil_type</span></code> is 9999.</p>
<p>OPM co-registration differs a bit from the typical SQUID-MEG workflow.
No <code class="docutils literal notranslate"><span class="pre">-trans.fif</span></code> file is needed for the OPMs, the FIF files include proper
sensor locations in MRI coordinates and no digitization of RPA/LPA/Nasion.
Thus the MEG&lt;-&gt;Head coordinate transform is taken to be an identity matrix
(i.e., everything is in MRI coordinates), even though this mis-identifies
the head coordinate frame (which is defined by the relationship of the
LPA, RPA, and Nasion).</p>
<p>Triggers include:</p>
<ul class="simple">
<li><p>Median nerve stimulation: trigger value 257.</p></li>
<li><p>Magnetic trigger (in OPM measurement only): trigger value 260.
1 second before the median nerve stimulation, a magnetic trigger is piped into the MSR.
This was to be able to check the synchronization between OPMs retrospectively, as each
sensor runs on an independent clock. Synchronization turned out to be satisfactory.</p></li>
</ul>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_opm_data.html#ex-opm-somatosensory"><span class="std std-ref">Optically pumped magnetometer (OPM) data</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/time_frequency/plot_source_power_spectrum_opm.html#ex-opm-resting-state"><span class="std std-ref">Compute source power spectral density (PSD) of VectorView and OPM data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="the-sleep-polysomnographic-database">
<h2>The Sleep PolySomnoGraphic Database<a class="headerlink" href="#the-sleep-polysomnographic-database" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.sleep_physionet.age.fetch_data.html#mne.datasets.sleep_physionet.age.fetch_data" title="mne.datasets.sleep_physionet.age.fetch_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sleep_physionet.age.fetch_data()</span></code></a>
<a class="reference internal" href="../generated/mne.datasets.sleep_physionet.temazepam.fetch_data.html#mne.datasets.sleep_physionet.temazepam.fetch_data" title="mne.datasets.sleep_physionet.temazepam.fetch_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sleep_physionet.temazepam.fetch_data()</span></code></a></p>
<p>The sleep PhysioNet database contains 197 whole-night PolySomnoGraphic sleep
recordings, containing EEG, EOG, chin EMG, and event markers. Some records also
contain respiration and body temperature. Corresponding hypnograms (sleep
patterns) were manually scored by well-trained technicians according to the
Rechtschaffen and Kales manual, and are also available. If you use these
data please cite <a class="footnote-reference brackets" href="#kempetal2000" id="id9">6</a> and <a class="footnote-reference brackets" href="#goldbergeretal2000" id="id10">2</a>.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/sample-datasets/plot_sleep.html#tut-sleep-stage-classif"><span class="std std-ref">Sleep stage classification from polysomnography (PSG) data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="reference-channel-noise-meg-data-set">
<h2>Reference channel noise MEG data set<a class="headerlink" href="#reference-channel-noise-meg-data-set" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.refmeg_noise.data_path.html#mne.datasets.refmeg_noise.data_path" title="mne.datasets.refmeg_noise.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.refmeg_noise.data_path()</span></code></a>.</p>
<p>This dataset was obtained with a 4D Neuroimaging / BTi system at
the University Clinic - Erlangen, Germany. There are powerful bursts of
external magnetic noise throughout the recording, which make it a good
example for automatic noise removal techniques.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/preprocessing/plot_find_ref_artifacts.html#ex-megnoise-processing"><span class="std std-ref">Find MEG reference channel artifacts</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="miscellaneous-datasets">
<h2>Miscellaneous Datasets<a class="headerlink" href="#miscellaneous-datasets" title="Permalink to this headline">¶</a></h2>
<p>These datasets are used for specific purposes in the documentation and in
general are not useful for separate analyses.</p>
<div class="section" id="fsaverage">
<span id="id11"></span><h3>fsaverage<a class="headerlink" href="#fsaverage" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.fetch_fsaverage()</span></code></a></p>
<p>For convenience, we provide a function to separately download and extract the
(or update an existing) fsaverage subject.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<p><a class="reference internal" href="../auto_tutorials/source-modeling/plot_eeg_no_mri.html#tut-eeg-fsaverage-source-modeling"><span class="std std-ref">EEG forward operator with a template MRI</span></a></p>
</div>
</div>
<div class="section" id="infant-template-mris">
<h3>Infant template MRIs<a class="headerlink" href="#infant-template-mris" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.fetch_infant_template.html#mne.datasets.fetch_infant_template" title="mne.datasets.fetch_infant_template"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.fetch_infant_template()</span></code></a></p>
<p>This function will download an infant template MRI from
<a class="footnote-reference brackets" href="#oreillyetal2021" id="id12">7</a> along with MNE-specific files.</p>
</div>
<div class="section" id="ecog-dataset">
<h3>ECoG Dataset<a class="headerlink" href="#ecog-dataset" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.misc.data_path.html#mne.datasets.misc.data_path" title="mne.datasets.misc.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.misc.data_path()</span></code></a>. Data exists at <code class="docutils literal notranslate"><span class="pre">/ecog/sample_ecog.mat</span></code>.</p>
<p>This dataset contains a sample Electrocorticography (ECoG) dataset. It includes
a single grid of electrodes placed over the temporal lobe during an auditory
listening task. This dataset is primarily used to demonstrate visualization
functions in MNE and does not contain useful metadata for analysis.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/visualization/plot_3d_to_2d.html#ex-electrode-pos-2d"><span class="std std-ref">How to convert 3D electrode positions to a 2D image.</span></a>: Demonstrates
how to project a 3D electrode location onto a 2D image, a common procedure
in electrocorticography.</p></li>
</ul>
</div>
</div>
<div class="section" id="limo-dataset">
<span id="id13"></span><h3>LIMO Dataset<a class="headerlink" href="#limo-dataset" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.limo.load_data.html#mne.datasets.limo.load_data" title="mne.datasets.limo.load_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.limo.load_data()</span></code></a>.</p>
<p>In the original LIMO experiment (see <a class="footnote-reference brackets" href="#rousseletetal2010" id="id14">8</a>), participants
performed a
two-alternative forced choice task, discriminating between two face stimuli.
Subjects discriminated the same two faces during the whole experiment.
The critical manipulation consisted of the level of noise added to the
face-stimuli during the task, making the faces more or less discernible to the
observer.</p>
<p>The presented faces varied across a noise-signal (or phase-coherence) continuum
spanning from 0 to 100% in increasing steps of 10%. In other words, faces with
high phase-coherence (e.g., 90%) were easy to identify, while faces with low
phase-coherence (e.g., 10%) were hard to identify and by extension hard to
discriminate.</p>
<div class="topic">
<p class="topic-title">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_limo_data.html#ex-limo-data"><span class="std std-ref">Single trial linear regression analysis with the LIMO dataset</span></a>: Explores data from a single subject of the LIMO dataset
and demonstrates how to fit a single trial linear regression using the
information contained in the metadata of the individual datasets.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="schalketal2004"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Gerwin Schalk, Dennis J. McFarland, Thilo Hinterberger, Niels Birbaumer, and Jonathan R. Wolpaw. BCI2000: a general-purpose brain-computer interface (BCI) system. <em>IEEE Transactions on Biomedical Engineering</em>, 51(6):1034–1043, 2004. <a class="reference external" href="https://doi.org/10.1109/TBME.2004.827072">doi:10.1109/TBME.2004.827072</a>.</p>
</dd>
<dt class="label" id="goldbergeretal2000"><span class="brackets">2</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id10">2</a>)</span></dt>
<dd><p>Ary L. Goldberger, Luis A. N. Amaral, Leon Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov, Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and H. Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. <em>Circulation</em>, 2000. <a class="reference external" href="https://doi.org/10.1161/01.CIR.101.23.e215">doi:10.1161/01.CIR.101.23.e215</a>.</p>
</dd>
<dt class="label" id="cichyetal2014"><span class="brackets">3</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Radoslaw Martin Cichy, Dimitrios Pantazis, and Aude Oliva. Resolving human object recognition in space and time. <em>Nature Neuroscience</em>, 17(3):455–462, 2014. <a class="reference external" href="https://doi.org/10.1038/nn.3635">doi:10.1038/nn.3635</a>.</p>
</dd>
<dt class="label" id="crosseetal2016"><span class="brackets">4</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id6">2</a>)</span></dt>
<dd><p>Michael J. Crosse, Giovanni M. Di Liberto, Adam Bednar, and Edmund C. Lalor. The multivariate temporal response function (mTRF) toolbox: a MATLAB toolbox for relating neural signals to continuous stimuli. <em>Frontiers in Human Neuroscience</em>, 2016. <a class="reference external" href="https://doi.org/10.3389/fnhum.2016.00604">doi:10.3389/fnhum.2016.00604</a>.</p>
</dd>
<dt class="label" id="dufauetal2015"><span class="brackets"><a class="fn-backref" href="#id8">5</a></span></dt>
<dd><p>Stéphane Dufau, Jonathan Grainger, Katherine J. Midgley, and Phillip J. Holcomb. A thousand words are worth a picture: snapshots of printed-word processing in an event-related potential megastudy. <em>Psychological Science</em>, 26(12):1887–1897, 2015. <a class="reference external" href="https://doi.org/10.1177/0956797615603934">doi:10.1177/0956797615603934</a>.</p>
</dd>
<dt class="label" id="kempetal2000"><span class="brackets"><a class="fn-backref" href="#id9">6</a></span></dt>
<dd><p>B. Kemp, A. H. Zwinderman, B. Tuk, H. A. C. Kamphuisen, and J. J. L. Oberyé. Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG. <em>IEEE Transactions on Biomedical Engineering</em>, 47(9):1185–1194, 2000. <a class="reference external" href="https://doi.org/10.1109/10.867928">doi:10.1109/10.867928</a>.</p>
</dd>
<dt class="label" id="oreillyetal2021"><span class="brackets"><a class="fn-backref" href="#id12">7</a></span></dt>
<dd><p>Christian O’Reilly, Eric Larson, John E. Richards, and Mayada Elsabbagh. Structural templates for imaging EEG cortical sources in infants. <em>NeuroImage</em>, 227:117682, February 2021. URL: <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1053811920311678">http://www.sciencedirect.com/science/article/pii/S1053811920311678</a> (visited on 2021-01-12), <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2020.117682">doi:10.1016/j.neuroimage.2020.117682</a>.</p>
</dd>
<dt class="label" id="rousseletetal2010"><span class="brackets"><a class="fn-backref" href="#id14">8</a></span></dt>
<dd><p>Guillaume A. Rousselet, Carl M. Gaspar, Cyril R. Pernet, Jesse S. Husk, Patrick J. Bennett, and Allison B. Sekuler. Healthy aging delays scalp EEG sensitivity to noise in a face discrimination task. <em>Frontiers in Psychology</em>, 1(19):1–14, 2010. <a class="reference external" href="https://doi.org/10.3389/fpsyg.2010.00019">doi:10.3389/fpsyg.2010.00019</a>.</p>
</dd>
</dl>
</p>
</div>
</div>


  
</div>

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="design_philosophy.html" title="previous page">Design philosophy</a>
    <a class='right-next' id="next-link" href="../generated/commands.html" title="next page">Command line tools using Python</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.014cad6f3a039303089e.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-37225609-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
<footer class="footer mt-5 mt-md-0">
  <div class="container institutions">
    <div class="d-flex flex-wrap flex-row justify-content-center">
      <div class="m-2">
          <a href="https://www.massgeneral.org/">
            <img class="institution" src="../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://martinos.org/">
            <img class="institution" src="../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://hms.harvard.edu/">
            <img class="institution" src="../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://web.mit.edu/">
            <img class="institution" src="../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.nyu.edu/">
            <img class="institution" src="../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="http://www.cea.fr/">
            <img class="institution" src="../_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://sci.aalto.fi/">
            <img class="institution" src="../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.telecom-paris.fr/">
            <img class="institution" src="../_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.washington.edu/">
            <img class="institution" src="../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://icm-institute.org/">
            <img class="institution" src="../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.bu.edu/">
            <img class="institution" src="../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inserm.fr/">
            <img class="institution" src="../_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.fz-juelich.de/">
            <img class="institution" src="../_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.tu-ilmenau.de/">
            <img class="institution" src="../_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://bids.berkeley.edu/">
            <img class="institution" src="../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.inria.fr/">
            <img class="institution" src="../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.au.dk/">
            <img class="institution" src="../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/>
          </a>
        </div>
      <div class="m-2">
          <a href="https://www.uni-graz.at/">
            <img class="institution" src="../_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/>
          </a>
        </div>
      
    </div>
  </div>
  <p class="text-center text-muted small">&copy; Copyright 2012–2021, MNE Developers. Last updated <time datetime="2021-02-20T17:26:11.514275+00:00" class="localized">2021-02-20 17:26 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
</footer>
  <script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>