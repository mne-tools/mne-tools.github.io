{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Visualizing epoched data\n\nThis tutorial shows how to plot epoched data as time series, how to plot the\nspectral density of epoched data, how to plot epochs as an imagemap, and how to\nplot the sensor locations and projectors stored in `~mne.Epochs` objects.\n\nWe'll start by importing the modules we need, loading the continuous (raw)\nsample data, and cropping it to save memory:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne\n\nsample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_file = (sample_data_folder / 'MEG' / 'sample' /\n                        'sample_audvis_raw.fif')\nraw = mne.io.read_raw_fif(sample_data_raw_file, verbose=False).crop(tmax=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create the `~mne.Epochs` data structure, we'll extract the event\nIDs stored in the :term:`stim channel`, map those integer event IDs to more\ndescriptive condition labels using an event dictionary, and pass those to the\n`~mne.Epochs` constructor, along with the `~mne.io.Raw` data and the\ndesired temporal limits of our epochs, ``tmin`` and ``tmax`` (for a\ndetailed explanation of these steps, see `tut-epochs-class`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "events = mne.find_events(raw, stim_channel='STI 014')\nevent_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n              'visual/right': 4, 'face': 5, 'button': 32}\nepochs = mne.Epochs(raw, events, tmin=-0.2, tmax=0.5, event_id=event_dict,\n                    preload=True)\ndel raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting ``Epochs`` as time series\n\n.. admonition:: Interactivity in pipelines and scripts\n    :class: sidebar hint\n\n    To use the interactive features of the `~mne.Epochs.plot` method\n    when running your code non-interactively, pass the ``block=True``\n    parameter, which halts the Python interpreter until the figure window is\n    closed. That way, any channels or epochs that you mark as \"bad\" will be\n    taken into account in subsequent processing steps.\n\nTo visualize epoched data as time series (one time series per channel), the\n`mne.Epochs.plot` method is available. It creates an interactive window\nwhere you can scroll through epochs and channels, enable/disable any\nunapplied :term:`SSP projectors <projector>` to see how they affect the\nsignal, and even manually mark bad channels (by clicking the channel name) or\nbad epochs (by clicking the data) for later dropping. Channels marked \"bad\"\nwill be shown in light grey color and will be added to\n``epochs.info['bads']``; epochs marked as bad will be indicated as ``'USER'``\nin ``epochs.drop_log``.\n\nHere we'll plot only the \"catch\" trials from the `sample dataset\n<sample-dataset>`, and pass in our events array so that the button press\nresponses also get marked (we'll plot them in red, and plot the \"face\" events\ndefining time zero for each epoch in blue). We also need to pass in\nour ``event_dict`` so that the `~mne.Epochs.plot` method will know what\nwe mean by \"button\" \u2014 this is because subsetting the conditions by\ncalling ``epochs['face']`` automatically purges the dropped entries from\n``epochs.event_id``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "catch_trials_and_buttonpresses = mne.pick_events(events, include=[5, 32])\nepochs['face'].plot(events=catch_trials_and_buttonpresses, event_id=event_dict,\n                    event_color=dict(button='red', face='blue'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see all sensors at once, we can use butterfly mode and group by selection:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs['face'].plot(events=catch_trials_and_buttonpresses, event_id=event_dict,\n                    event_color=dict(button='red', face='blue'),\n                    group_by='selection', butterfly=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting projectors from an ``Epochs`` object\n\nIn the plot above we can see heartbeat artifacts in the magnetometer\nchannels, so before we continue let's load ECG projectors from disk and apply\nthem to the data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ecg_proj_file = (sample_data_folder / 'MEG' / 'sample' /\n                 'sample_audvis_ecg-proj.fif')\necg_projs = mne.read_proj(ecg_proj_file)\nepochs.add_proj(ecg_projs)\nepochs.apply_proj()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as we saw in the `tut-section-raw-plot-proj` section, we can plot\nthe projectors present in an `~mne.Epochs` object using the same\n`~mne.Epochs.plot_projs_topomap` method. Since the original three\nempty-room magnetometer projectors were inherited from the\n`~mne.io.Raw` file, and we added two ECG projectors for each sensor\ntype, we should see nine projector topomaps:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs.plot_projs_topomap(vlim='joint')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that these field maps illustrate aspects of the signal that *have\nalready been removed* (because projectors in `~mne.io.Raw` data are\napplied by default when epoching, and because we called\n`~mne.Epochs.apply_proj` after adding additional ECG projectors from\nfile). You can check this by examining the ``'active'`` field of the\nprojectors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(all(proj['active'] for proj in epochs.info['projs']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting sensor locations\n\nJust like `~mne.io.Raw` objects, `~mne.Epochs` objects\nkeep track of sensor locations, which can be visualized with the\n`~mne.Epochs.plot_sensors` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs.plot_sensors(kind='3d', ch_type='all')\nepochs.plot_sensors(kind='topomap', ch_type='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the power spectrum of ``Epochs``\n\nAgain, just like `~mne.io.Raw` objects, :class:`~mne.Epochs` objects\ncan be converted to `spectral density`_ via\n:meth:`~mne.Epochs.compute_psd`, which can then be plotted using the\n:class:`~mne.time_frequency.EpochsSpectrum`'s\n:meth:`~mne.time_frequency.EpochsSpectrum.plot` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs['auditory'].compute_psd().plot(picks='eeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to plot spectral power estimates across sensors as a\nscalp topography, using the :class:`~mne.time_frequency.EpochsSpectrum`'s\n:meth:`~mne.time_frequency.EpochsSpectrum.plot_topomap` method. The default\nparameters will plot five frequency bands (\u03b4, \u03b8, \u03b1, \u03b2, \u03b3), will compute power\nbased on magnetometer channels (if present), and will plot the power\nestimates on a dB-like log-scale:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectrum = epochs['visual/right'].compute_psd()\nspectrum.plot_topomap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Prior to the addition of the :class:`~mne.time_frequency.EpochsSpectrum`\n   class, the above plots were possible via::\n\n       epochs['auditory'].plot_psd(picks='eeg')\n       epochs['visual/right'].plot_psd_topomap()\n\n   The :meth:`~mne.Epochs.plot_psd` and `~mne.Epochs.plot_psd_topomap`\n   methods of :class:`~mne.Epochs` objects are still provided to support\n   legacy analysis scripts, but new code should instead use the\n   :class:`~mne.time_frequency.EpochsSpectrum` object API.</p></div>\n\nJust like `~mne.Epochs.plot_projs_topomap`,\n`EpochsSpectrum.plot_topomap()<mne.time_frequency.EpochsSpectrum.plot_topomap>`\nhas a ``vlim='joint'`` option for fixing the colorbar limits jointly across\nall subplots, to give a better sense of the relative magnitude in each\nfrequency band. You can change which channel type is used via the\n``ch_type`` parameter, and if you want to view different frequency bands than\nthe defaults, the ``bands`` parameter takes a :class:`dict`, with keys\nproviding a subplot title and values providing either single frequency bins\nto plot, or lower/upper frequency band edges:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bands = {'10 Hz': 10, '15 Hz': 15, '20 Hz': 20, '10-20 Hz': (10, 20)}\nspectrum.plot_topomap(bands=bands, vlim='joint', ch_type='grad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you prefer untransformed power estimates, you can pass ``dB=False``. It is\nalso possible to normalize the power estimates by dividing by the total power\nacross all frequencies, by passing ``normalize=True``. See the docstring of\n`~mne.time_frequency.EpochsSpectrum.plot_topomap` for details.\n\n\n## Plotting ``Epochs`` as an image map\n\nA convenient way to visualize many epochs simultaneously is to plot them as\nan image map, with each row of pixels in the image representing a single\nepoch, the horizontal axis representing time, and each pixel's color\nrepresenting the signal value at that time sample for that epoch. Of course,\nthis requires either a separate image map for each channel, or some way of\ncombining information across channels. The latter is possible using the\n`~mne.Epochs.plot_image` method; the former can be achieved with the\n`~mne.Epochs.plot_image` method (one channel at a time) or with the\n`~mne.Epochs.plot_topo_image` method (all sensors at once).\n\nBy default, the image map generated by `~mne.Epochs.plot_image` will be\naccompanied by a scalebar indicating the range of the colormap, and a time\nseries showing the average signal across epochs and a bootstrapped 95%\nconfidence band around the mean. `~mne.Epochs.plot_image` is a highly\ncustomizable method with many parameters, including customization of the\nauxiliary colorbar and averaged time series subplots. See the docstrings of\n`~mne.Epochs.plot_image` and `mne.viz.plot_compare_evokeds` (which is\nused to plot the average time series) for full details. Here we'll show the\nmean across magnetometers for all epochs with an auditory stimulus:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs['auditory'].plot_image(picks='mag', combine='mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To plot image maps for individual sensors or a small group of sensors, use\nthe ``picks`` parameter. Passing ``combine=None`` (the default) will yield\nseparate plots for each sensor in ``picks``; passing ``combine='gfp'`` will\nplot the global field power (useful for combining sensors that respond with\nopposite polarity).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs['auditory'].plot_image(picks=['MEG 0242', 'MEG 0243'])\nepochs['auditory'].plot_image(picks=['MEG 0242', 'MEG 0243'], combine='gfp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To plot an image map for *all* sensors, use\n`~mne.Epochs.plot_topo_image`, which is optimized for plotting a large\nnumber of image maps simultaneously, and (in interactive sessions) allows you\nto click on each small image map to pop open a separate figure with the\nfull-sized image plot (as if you had called `~mne.Epochs.plot_image` on\njust that sensor). At the small scale shown in this tutorial it's hard to see\nmuch useful detail in these plots; it's often best when plotting\ninteractively to maximize the topo image plots to fullscreen. The default is\na figure with black background, so here we specify a white background and\nblack foreground text. By default `~mne.Epochs.plot_topo_image` will\nshow magnetometers and gradiometers on the same plot (and hence not show a\ncolorbar, since the sensors are on different scales) so we'll also pass a\n`~mne.channels.Layout` restricting each plot to one channel type.\nFirst, however, we'll also drop any epochs that have unusually high signal\nlevels, because they can cause the colormap limits to be too extreme and\ntherefore mask smaller signal fluctuations of interest.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reject_criteria = dict(mag=3000e-15,     # 3000 fT\n                       grad=3000e-13,    # 3000 fT/cm\n                       eeg=150e-6)       # 150 \u00b5V\nepochs.drop_bad(reject=reject_criteria)\n\nfor ch_type, title in dict(mag='Magnetometers', grad='Gradiometers').items():\n    layout = mne.channels.find_layout(epochs.info, ch_type=ch_type)\n    epochs['auditory/left'].plot_topo_image(layout=layout, fig_facecolor='w',\n                                            font_color='k', title=title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To plot image maps for all EEG sensors, pass an EEG layout as the ``layout``\nparameter of `~mne.Epochs.plot_topo_image`. Note also here the use of\nthe ``sigma`` parameter, which smooths each image map along the vertical\ndimension (across epochs) which can make it easier to see patterns across the\nsmall image maps (by smearing noisy epochs onto their neighbors, while\nreinforcing parts of the image where adjacent epochs are similar). However,\n``sigma`` can also disguise epochs that have persistent extreme values and\nmaybe should have been excluded, so it should be used with caution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layout = mne.channels.find_layout(epochs.info, ch_type='eeg')\nepochs['auditory/left'].plot_topo_image(layout=layout, fig_facecolor='w',\n                                        font_color='k', sigma=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. LINKS\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}