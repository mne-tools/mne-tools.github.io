{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Plotting with ``mne.viz.Brain``\n\nIn this example, we'll show how to use :class:`mne.viz.Brain`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Alex Rockhill <aprockhill@mailbox.org>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\nIn this example we use the ``sample`` data which is data from a subject\nbeing presented auditory and visual stimuli to display the functionality\nof :class:`mne.viz.Brain` for plotting data on a brain.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom matplotlib.cm import ScalarMappable\nfrom matplotlib.colors import Normalize\n\nimport mne\nfrom mne.datasets import sample\n\nprint(__doc__)\n\ndata_path = sample.data_path()\nsubjects_dir = data_path / \"subjects\"\nsample_dir = data_path / \"MEG\" / \"sample\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add source information\n\nPlot source information.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain_kwargs = dict(alpha=0.1, background=\"white\", cortex=\"low_contrast\")\nbrain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\n\nstc = mne.read_source_estimate(sample_dir / \"sample_audvis-meg\")\nstc.crop(0.09, 0.1)\n\nkwargs = dict(\n    fmin=stc.data.min(),\n    fmax=stc.data.max(),\n    alpha=0.25,\n    smoothing_steps=\"nearest\",\n    time=stc.times,\n)\nbrain.add_data(stc.lh_data, hemi=\"lh\", vertices=stc.lh_vertno, **kwargs)\nbrain.add_data(stc.rh_data, hemi=\"rh\", vertices=stc.rh_vertno, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modify the view of the brain\n\nYou can adjust the view of the brain using ``show_view`` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\nbrain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Highlight a region on the brain\n\nIt can be useful to highlight a region of the brain for analyses.\nTo highlight a region on the brain you can use the ``add_label`` method.\nLabels are stored in the Freesurfer label directory from the ``recon-all``\nfor that subject. Labels can also be made following the\n[Freesurfer instructions](https://surfer.nmr.mgh.harvard.edu/fswiki/mri_vol2label)\nHere we will show Brodmann Area 44.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The MNE sample dataset contains only a subselection of the\n          Freesurfer labels created during the ``recon-all``.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\nbrain.add_label(\"BA44\", hemi=\"lh\", color=\"green\", borders=True)\nbrain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Include the head in the image\n\nAdd a head image using the ``add_head`` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\nbrain.add_head(alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add sensors positions\n\nTo put into context the data that generated the source time course,\nthe sensor positions can be displayed as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\nevoked = mne.read_evokeds(sample_dir / \"sample_audvis-ave.fif\")[0]\ntrans = mne.read_trans(sample_dir / \"sample_audvis_raw-trans.fif\")\nbrain.add_sensors(evoked.info, trans)\nbrain.show_view(distance=500)  # move back to show sensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add current dipoles\n\nDipole modeling as in `tut-dipole-orientations` can be plotted on the\nbrain as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\ndip = mne.read_dipole(sample_dir / \"sample_audvis_set1.dip\")\ncmap = plt.colormaps[\"YlOrRd\"]\ncolors = [cmap(gof / dip.gof.max()) for gof in dip.gof]\nbrain.add_dipole(dip, trans, colors=colors, scales=list(dip.amplitude * 1e8))\nbrain.show_view(azimuth=-20, elevation=60, distance=300)\nimg = brain.screenshot()  # for next section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a screenshot for exporting the brain image\nAlso, we can a static image of the brain using ``screenshot`` (above),\nwhich will allow us to add a colorbar. This is useful for figures in\npublications.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.imshow(img)\nax.axis(\"off\")\ncax = fig.add_axes([0.9, 0.1, 0.05, 0.8])\nnorm = Normalize(vmin=0, vmax=dip.gof.max())\nfig.colorbar(ScalarMappable(norm=norm, cmap=cmap), cax=cax)\nfig.suptitle(\"Dipole Fits Scaled by Amplitude and Colored by GOF\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}