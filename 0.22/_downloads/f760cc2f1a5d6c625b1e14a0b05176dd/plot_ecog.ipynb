{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with ECoG data\n\nMNE supports working with more than just MEG and EEG data. Here we show some\nof the functions that can be used to facilitate working with\nelectrocorticography (ECoG) data.\n\nThis example shows how to use:\n\n- ECoG data\n- channel locations in subject's MRI space\n- projection onto a surface\n\nFor an example that involves sEEG data, channel locations in\nMNI space, or projection into a volume, see `tut_working_with_seeg`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Eric Larson <larson.eric.d@gmail.com>\n#          Chris Holdgraf <choldgraf@gmail.com>\n#          Adam Li <adam2392@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nimport mne\nfrom mne.viz import plot_alignment, snapshot_brain_montage\n\nprint(__doc__)\n\n# paths to mne datasets - sample ECoG and FreeSurfer subject\nmisc_path = mne.datasets.misc.data_path()\nsample_path = mne.datasets.sample.data_path()\nsubject = 'sample'\nsubjects_dir = sample_path + '/subjects'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load some ECoG electrode locations and names, and turn them into\na :class:`mne.channels.DigMontage` class. First, use pandas to read in the\n``.tsv`` file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# In this tutorial, the electrode coordinates are assumed to be in meters\nelec_df = pd.read_csv(misc_path + '/ecog/sample_ecog_electrodes.tsv',\n                      sep='\\t', header=0, index_col=None)\nch_names = elec_df['name'].tolist()\nch_coords = elec_df[['x', 'y', 'z']].to_numpy(dtype=float)\nch_pos = dict(zip(ch_names, ch_coords))\n# Ideally the nasion/LPA/RPA will also be present from the digitization, here\n# we use fiducials estimated from the subject's FreeSurfer MNI transformation:\nlpa, nasion, rpa = mne.coreg.get_mni_fiducials(\n    subject, subjects_dir=subjects_dir)\nlpa, nasion, rpa = lpa['r'], nasion['r'], rpa['r']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we make a :class:`mne.channels.DigMontage` stating that the ECoG\ncontacts are in the FreeSurfer surface RAS (i.e., MRI) coordinate system.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = mne.channels.make_dig_montage(\n    ch_pos, coord_frame='mri', nasion=nasion, lpa=lpa, rpa=rpa)\nprint('Created %s channel positions' % len(ch_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we get the :term:`trans` that transforms from our MRI coordinate system\nto the head coordinate frame. This transform will be applied to the\ndata when applying the montage so that standard plotting functions like\n:func:`mne.viz.plot_evoked_topomap` will be aligned properly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trans = mne.channels.compute_native_head_t(montage)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our montage, we can load in our corresponding\ntime-series data and set the montage to the raw data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# first we'll load in the sample dataset\nraw = mne.io.read_raw_edf(misc_path + '/ecog/sample_ecog.edf')\n\n# drop bad channels\nraw.info['bads'].extend([ch for ch in raw.ch_names if ch not in ch_names])\nraw.load_data()\nraw.drop_channels(raw.info['bads'])\nraw.crop(0, 2)  # just process 2 sec of data for speed\n\n# attach montage\nraw.set_montage(montage)\n\n# set channel types to ECoG (instead of EEG)\nraw.set_channel_types({ch_name: 'ecog' for ch_name in raw.ch_names})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then plot the locations of our electrodes on our subject's brain.\nWe'll use :func:`~mne.viz.snapshot_brain_montage` to save the plot as image\ndata (along with xy positions of each electrode in the image), so that later\nwe can plot frequency band power on top of it.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>These are not real electrodes for this subject, so they\n          do not align to the cortical surface perfectly.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_alignment(raw.info, subject=subject, subjects_dir=subjects_dir,\n                     surfaces=['pial'], trans=trans, coord_frame='mri')\nmne.viz.set_3d_view(fig, 200, 70, focalpoint=[0, -0.005, 0.03])\n\nxy, im = snapshot_brain_montage(fig, montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll compute the signal power in the gamma (30-90 Hz) and alpha\n(8-12 Hz) bands.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gamma_power_t = raw.copy().filter(30, 90).apply_hilbert(\n    envelope=True).get_data()\nalpha_power_t = raw.copy().filter(8, 12).apply_hilbert(\n    envelope=True).get_data()\ngamma_power = gamma_power_t.mean(axis=-1)\nalpha_power = alpha_power_t.mean(axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's use matplotlib to overplot frequency band power onto the electrodes\nwhich can be plotted on top of the brain from\n:func:`~mne.viz.snapshot_brain_montage`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Convert from a dictionary to array to plot\nxy_pts = np.vstack([xy[ch] for ch in raw.info['ch_names']])\n\n# colormap to view spectral power\ncmap = 'viridis'\n\n# Create a 1x2 figure showing the average power in gamma and alpha bands.\nfig, axs = plt.subplots(1, 2, figsize=(20, 10))\n# choose a colormap range wide enough for both frequency bands\n_gamma_alpha_power = np.concatenate((gamma_power, alpha_power)).flatten()\nvmin, vmax = np.percentile(_gamma_alpha_power, [10, 90])\nfor ax, band_power, band in zip(axs,\n                                [gamma_power, alpha_power],\n                                ['Gamma', 'Alpha']):\n    ax.imshow(im)\n    ax.set_axis_off()\n    sc = ax.scatter(*xy_pts.T, c=band_power, s=200,\n                    cmap=cmap, vmin=vmin, vmax=vmax)\n    ax.set_title(f'{band} band power', size='x-large')\nfig.colorbar(sc, ax=axs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Say we want to visualize the evolution of the power in the gamma band,\ninstead of just plotting the average. We can use\n`matplotlib.animation.FuncAnimation` to create an animation and apply this\nto the brain figure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create an initialization and animation function\n# to pass to FuncAnimation\ndef init():\n    \"\"\"Create an empty frame.\"\"\"\n    return paths,\n\n\ndef animate(i, activity):\n    \"\"\"Animate the plot.\"\"\"\n    paths.set_array(activity[:, i])\n    return paths,\n\n\n# create the figure and apply the animation of the\n# gamma frequency band activity\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(im)\nax.set_axis_off()\npaths = ax.scatter(*xy_pts.T, c=np.zeros(len(xy_pts)), s=200,\n                   cmap=cmap, vmin=vmin, vmax=vmax)\nfig.colorbar(paths, ax=ax)\nax.set_title('Gamma frequency over time (Hilbert transform)',\n             size='large')\n\n# avoid edge artifacts and decimate, showing just a short chunk\nsl = slice(100, 150)\nshow_power = gamma_power_t[:, sl]\nanim = animation.FuncAnimation(fig, animate, init_func=init,\n                               fargs=(show_power,),\n                               frames=show_power.shape[1],\n                               interval=100, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, we can project the sensor data to the nearest locations on\nthe pial surface and visualize that:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evoked = mne.EvokedArray(\n    gamma_power_t[:, sl], raw.info, tmin=raw.times[sl][0])\nstc = mne.stc_near_sensors(evoked, trans, subject, subjects_dir=subjects_dir)\nclim = dict(kind='value', lims=[vmin * 0.9, vmin, vmax])\nbrain = stc.plot(surface='pial', hemi='both', initial_time=0.68,\n                 colormap='viridis', clim=clim, views='parietal',\n                 subjects_dir=subjects_dir, size=(500, 500))\n\n# You can save a movie like the one on our documentation website with:\n# brain.save_movie(time_dilation=50, interpolation='linear', framerate=10,\n#                  time_viewer=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}