.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_time_frequency_plot_time_frequency_erds.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_time_frequency_plot_time_frequency_erds.py:


===============================
Compute and visualize ERDS maps
===============================

This example calculates and displays ERDS maps of event-related EEG data. ERDS
(sometimes also written as ERD/ERS) is short for event-related
desynchronization (ERD) and event-related synchronization (ERS) [1]_.
Conceptually, ERD corresponds to a decrease in power in a specific frequency
band relative to a baseline. Similarly, ERS corresponds to an increase in
power. An ERDS map is a time/frequency representation of ERD/ERS over a range
of frequencies [2]_. ERDS maps are also known as ERSP (event-related spectral
perturbation) [3]_.

We use a public EEG BCI data set containing two different motor imagery tasks
available at PhysioNet. The two tasks are imagined hand and feet movement. Our
goal is to generate ERDS maps for each of the two tasks.

First, we load the data and create epochs of 5s length. The data sets contain
multiple channels, but we will only consider the three channels C3, Cz, and C4.
We compute maps containing frequencies ranging from 2 to 35Hz. We map ERD to
red color and ERS to blue color, which is the convention in many ERDS
publications. Finally, we perform cluster-based permutation tests to estimate
significant ERDS values (corrected for multiple comparisons within channels).

References
----------

.. [1] G. Pfurtscheller, F. H. Lopes da Silva. Event-related EEG/MEG
       synchronization and desynchronization: basic principles. Clinical
       Neurophysiology 110(11), 1842-1857, 1999.
.. [2] B. Graimann, J. E. Huggins, S. P. Levine, G. Pfurtscheller.
       Visualization of significant ERD/ERS patterns in multichannel EEG and
       ECoG data. Clinical Neurophysiology 113(1), 43-47, 2002.
.. [3] S. Makeig. Auditory event-related dynamics of the EEG spectrum and
       effects of exposure to tones. Electroencephalography and Clinical
       Neurophysiology 86(4), 283-293, 1993.




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/time_frequency/images/sphx_glr_plot_time_frequency_erds_001.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/time_frequency/images/sphx_glr_plot_time_frequency_erds_002.png
            :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out::

    Extracting EDF parameters from /home/circleci/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S001/S001R06.edf...
    EDF file detected
    EDF annotations detected (consider using raw.find_edf_events() to extract them)
    Setting channel info structure...
    Creating raw.info structure...
    Reading 0 ... 19999  =      0.000 ...   124.994 secs...
    Extracting EDF parameters from /home/circleci/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S001/S001R10.edf...
    EDF file detected
    EDF annotations detected (consider using raw.find_edf_events() to extract them)
    Setting channel info structure...
    Creating raw.info structure...
    Reading 0 ... 19999  =      0.000 ...   124.994 secs...
    Extracting EDF parameters from /home/circleci/mne_data/MNE-eegbci-data/physiobank/database/eegmmidb/S001/S001R14.edf...
    EDF file detected
    EDF annotations detected (consider using raw.find_edf_events() to extract them)
    Setting channel info structure...
    Creating raw.info structure...
    Reading 0 ... 19999  =      0.000 ...   124.994 secs...
    Trigger channel has a non-zero initial value of 1 (consider using initial_event=True to detect this event)
    Removing orphaned offset at the beginning of the file.
    89 events found
    Event IDs: [1 2 3]
    45 matching events found
    No baseline correction applied
    Not setting metadata
    0 projection items activated
    Loading data for 45 events and 961 original time points ...
    0 bad epochs dropped
    Applying baseline correction (mode: percent)
    Using a threshold of 1.724718
    stat_fun(H1): min=-8.523637 max=3.197747
    Running initial clustering
    Found 78 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.724718
    stat_fun(H1): min=-8.523637 max=3.197747
    Running initial clustering
    Found 65 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied
    Using a threshold of 1.724718
    stat_fun(H1): min=-4.573067 max=3.687727
    Running initial clustering
    Found 85 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.724718
    stat_fun(H1): min=-4.573067 max=3.687727
    Running initial clustering
    Found 57 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied
    Using a threshold of 1.724718
    stat_fun(H1): min=-6.599131 max=3.329547
    Running initial clustering
    Found 64 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.724718
    stat_fun(H1): min=-6.599131 max=3.329547
    Running initial clustering
    Found 64 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied
    Applying baseline correction (mode: percent)
    Using a threshold of 1.713872
    stat_fun(H1): min=-3.687815 max=3.369164
    Running initial clustering
    Found 66 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.713872
    stat_fun(H1): min=-3.687815 max=3.369164
    Running initial clustering
    Found 75 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied
    Using a threshold of 1.713872
    stat_fun(H1): min=-5.046259 max=5.406477
    Running initial clustering
    Found 98 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.713872
    stat_fun(H1): min=-5.046259 max=5.406477
    Running initial clustering
    Found 66 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied
    Using a threshold of 1.713872
    stat_fun(H1): min=-5.964817 max=4.078953
    Running initial clustering
    Found 92 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations
    Done.
    Using a threshold of -1.713872
    stat_fun(H1): min=-5.964817 max=4.078953
    Running initial clustering
    Found 52 clusters
    Permuting 99 times...
    Computing cluster p-values
    Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations
    Done.
    No baseline correction applied




|


.. code-block:: python

    # Authors: Clemens Brunner <clemens.brunner@gmail.com>
    #
    # License: BSD (3-clause)


    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib.colors import LinearSegmentedColormap
    import mne
    from mne.datasets import eegbci
    from mne.io import concatenate_raws, read_raw_edf
    from mne.time_frequency import tfr_multitaper
    from mne.stats import permutation_cluster_1samp_test as pcluster_test


    def center_cmap(cmap, vmin, vmax):
        """Center given colormap (ranging from vmin to vmax) at value 0.

        Note that eventually this could also be achieved by re-normalizing a given
        colormap by subclassing matplotlib.colors.Normalize as described here:
        https://matplotlib.org/users/colormapnorms.html#custom-normalization-two-linear-ranges
        """  # noqa: E501
        vzero = abs(vmin) / (vmax - vmin)
        index_old = np.linspace(0, 1, cmap.N)
        index_new = np.hstack([np.linspace(0, vzero, cmap.N // 2, endpoint=False),
                               np.linspace(vzero, 1, cmap.N // 2)])
        cdict = {"red": [], "green": [], "blue": [], "alpha": []}
        for old, new in zip(index_old, index_new):
            r, g, b, a = cmap(old)
            cdict["red"].append((new, r, r))
            cdict["green"].append((new, g, g))
            cdict["blue"].append((new, b, b))
            cdict["alpha"].append((new, a, a))
        return LinearSegmentedColormap("erds", cdict)


    # load and preprocess data ####################################################
    subject = 1  # use data from subject 1
    runs = [6, 10, 14]  # use only hand and feet motor imagery runs

    fnames = eegbci.load_data(subject, runs)
    raws = [read_raw_edf(f, preload=True, stim_channel='auto') for f in fnames]
    raw = concatenate_raws(raws)

    raw.rename_channels(lambda x: x.strip('.'))  # remove dots from channel names

    events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')

    picks = mne.pick_channels(raw.info["ch_names"], ["C3", "Cz", "C4"])

    # epoch data ##################################################################
    tmin, tmax = -1, 4  # define epochs around events (in s)
    event_ids = dict(hands=2, feet=3)  # map event IDs to tasks

    epochs = mne.Epochs(raw, events, event_ids, tmin - 0.5, tmax + 0.5,
                        picks=picks, baseline=None, preload=True)

    # compute ERDS maps ###########################################################
    freqs = np.arange(2, 36, 1)  # frequencies from 2-35Hz
    n_cycles = freqs  # use constant t/f resolution
    vmin, vmax = -1, 1.5  # set min and max ERDS values in plot
    baseline = [-1, 0]  # baseline interval (in s)
    cmap = center_cmap(plt.cm.RdBu, vmin, vmax)  # zero maps to white
    kwargs = dict(n_permutations=100, step_down_p=0.05, seed=1,
                  buffer_size=None)  # for cluster test

    for event in event_ids:
        tfr = tfr_multitaper(epochs[event], freqs=freqs, n_cycles=n_cycles,
                             use_fft=True, return_itc=False, average=False,
                             decim=2)
        tfr.crop(tmin, tmax)
        tfr.apply_baseline(baseline, mode="percent")

        fig, axes = plt.subplots(1, 4, figsize=(12, 4),
                                 gridspec_kw={"width_ratios": [10, 10, 10, 1]})
        for ch, ax in enumerate(axes[:-1]):  # for each channel
            # positive clusters
            _, c1, p1, _ = pcluster_test(tfr.data[:, ch, ...], tail=1, **kwargs)
            # negative clusters
            _, c2, p2, _ = pcluster_test(tfr.data[:, ch, ...], tail=-1, **kwargs)

            # note that we keep clusters with p <= 0.05 from the combined clusters
            # of two independent tests; in this example, we do not correct for
            # these two comparisons
            c = np.stack(c1 + c2, axis=2)  # combined clusters
            p = np.concatenate((p1, p2))  # combined p-values
            mask = c[..., p <= 0.05].any(axis=-1)

            # plot TFR (ERDS map with masking)
            tfr.average().plot([ch], vmin=vmin, vmax=vmax, cmap=(cmap, False),
                               axes=ax, colorbar=False, show=False, mask=mask)

            ax.set_title(epochs.ch_names[ch], fontsize=10)
            ax.axvline(0, linewidth=1, color="black", linestyle=":")  # event
            if not ax.is_first_col():
                ax.set_ylabel("")
                ax.set_yticklabels("")
        fig.colorbar(axes[0].collections[1], cax=axes[-1])
        fig.suptitle("ERDS ({})".format(event))
        fig.show()

**Total running time of the script:** ( 0 minutes  11.403 seconds)


.. _sphx_glr_download_auto_examples_time_frequency_plot_time_frequency_erds.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_time_frequency_erds.py <plot_time_frequency_erds.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_time_frequency_erds.ipynb <plot_time_frequency_erds.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
