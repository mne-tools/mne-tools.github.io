{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Working with sEEG data\n\nMNE supports working with more than just MEG and EEG data. Here we show some\nof the functions that can be used to facilitate working with\nstereoelectroencephalography (sEEG) data.\n\nThis example shows how to use:\n\n- sEEG data\n- channel locations in MNI space\n- projection into a volume\n\nNote that our sample sEEG electrodes are already assumed to be in MNI\nspace. If you want to map positions from your subject MRI space to MNI\nfsaverage space, you must apply the FreeSurfer's talairach.xfm transform\nfor your dataset. You can take a look at `tut-freesurfer-mne` for\nmore information.\n\nFor an example that involves ECoG data, channel locations in a\nsubject-specific MRI, or projection into a surface, see\n`tut_working_with_ecog`. In the ECoG example, we show\nhow to visualize surface grid channels on the brain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Eric Larson <larson.eric.d@gmail.com>\n#          Adam Li <adam2392@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport os.path as op\n\nimport numpy as np\nimport pandas as pd\n\nimport mne\nfrom mne.datasets import fetch_fsaverage\n\nprint(__doc__)\n\n# paths to mne datasets - sample sEEG and FreeSurfer's fsaverage subject\n# which is in MNI space\nmisc_path = mne.datasets.misc.data_path()\nsample_path = mne.datasets.sample.data_path()\nsubject = 'fsaverage'\nsubjects_dir = sample_path + '/subjects'\n\n# use mne-python's fsaverage data\nfetch_fsaverage(subjects_dir=subjects_dir, verbose=True)  # downloads if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load some sEEG electrode locations and names, and turn them into\na :class:`mne.channels.DigMontage` class. First, use pandas to read in the\n``.tsv`` file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# In mne-python, the electrode coordinates are required to be in meters\nelec_df = pd.read_csv(misc_path + '/seeg/sample_seeg_electrodes.tsv',\n                      sep='\\t', header=0, index_col=None)\nch_names = elec_df['name'].tolist()\nch_coords = elec_df[['x', 'y', 'z']].to_numpy(dtype=float)\n\n# the test channel coordinates were in mm, so we convert them to meters\nch_coords = ch_coords / 1000.\n\n# create dictionary of channels and their xyz coordinates (now in MNI space)\nch_pos = dict(zip(ch_names, ch_coords))\n\n# Ideally the nasion/LPA/RPA will also be present from the digitization, here\n# we use fiducials estimated from the subject's FreeSurfer MNI transformation:\nlpa, nasion, rpa = mne.coreg.get_mni_fiducials(\n    subject, subjects_dir=subjects_dir)\nlpa, nasion, rpa = lpa['r'], nasion['r'], rpa['r']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we make a :class:`mne.channels.DigMontage` stating that the sEEG\ncontacts are in the FreeSurfer surface RAS (i.e., MRI) coordinate system\nfor the given subject. Keep in mind that ``fsaverage`` is special in that\nit is already in MNI space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "montage = mne.channels.make_dig_montage(\n    ch_pos, coord_frame='mri', nasion=nasion, lpa=lpa, rpa=rpa)\nprint('Created %s channel positions' % len(ch_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we get the :term:`trans` that transforms from our MRI coordinate system\nto the head coordinate frame. This transform will be applied to the\ndata when applying the montage so that standard plotting functions like\n:func:`mne.viz.plot_evoked_topomap` will be aligned properly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trans = mne.channels.compute_native_head_t(montage)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our montage, we can load in our corresponding\ntime-series data and set the montage to the raw data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# first we'll load in the sample dataset\nraw = mne.io.read_raw_edf(misc_path + '/seeg/sample_seeg.edf')\n\n# drop bad channels\nraw.info['bads'].extend([ch for ch in raw.ch_names if ch not in ch_names])\nraw.load_data()\nraw.drop_channels(raw.info['bads'])\nraw.crop(0, 2)  # just process 2 sec of data for speed\n\n# attach montage\nraw.set_montage(montage)\n\n# set channel types to sEEG (instead of EEG) that have actual positions\nraw.set_channel_types(\n    {ch_name: 'seeg' if np.isfinite(ch_pos[ch_name]).all() else 'misc'\n     for ch_name in raw.ch_names})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check to make sure everything is aligned.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_alignment(raw.info, trans, 'fsaverage',\n                             subjects_dir=subjects_dir, show_axes=True,\n                             surfaces=[\"pial\", \"head\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll get the raw data and plot its amplitude over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize this raw data on the ``fsaverage`` brain (in MNI space) as\na heatmap. This works by first creating an ``Evoked`` data structure\nfrom the data of interest (in this example, it is just the raw LFP).\nThen one should generate a ``stc`` data structure, which will be able\nto visualize source activity on the brain in various different formats.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get standard fsaverage volume (5mm grid) source space\nfname_src = op.join(subjects_dir, 'fsaverage', 'bem',\n                    'fsaverage-vol-5-src.fif')\nvol_src = mne.read_source_spaces(fname_src)\n\nevoked = mne.EvokedArray(raw.get_data(), raw.info).crop(0, 1)  # shorter\nstc = mne.stc_near_sensors(\n    evoked, trans, subject, subjects_dir=subjects_dir, src=vol_src,\n    verbose='error')  # ignore missing electrode warnings\nstc = abs(stc)  # just look at magnitude\nclim = dict(kind='value', lims=np.percentile(abs(evoked.data), [10, 50, 75]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot 3D source (brain region) visualization:\n\nBy default, `stc.plot_3d() <mne.VolSourceEstimate.plot_3d>` will show a time\ncourse of the source with the largest absolute value across any time point.\nIn this example, it is simply the source with the largest raw signal value.\nIts location is marked on the brain by a small blue sphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "brain = stc.plot_3d(\n    src=vol_src, subjects_dir=subjects_dir,\n    view_layout='horizontal', views=['axial', 'coronal', 'sagittal'],\n    size=(800, 300), show_traces=0.4, clim=clim,\n    add_data_kwargs=dict(colorbar_kwargs=dict(label_font_size=8)))\n\n# You can save a movie like the one on our documentation website with:\n# brain.save_movie(time_dilation=3, interpolation='linear', framerate=10,\n#                  time_viewer=True, filename='./mne-test-seeg.m4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we used a BEM surface for the ``fsaverage`` subject from\nFreeSurfer.\n\nFor additional common analyses of interest, see the following:\n\n- For volumetric plotting options, including limiting to a specific area of\n  the volume specified by say an atlas, or plotting different types of\n  source visualizations see:\n  `tut-viz-stcs`.\n- For extracting activation within a specific FreeSurfer volume and using\n  different FreeSurfer volumes, see: `tut-freesurfer-mne`.\n- For working with BEM surfaces and using FreeSurfer, or mne to generate\n  them, see: `tut-forward`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}