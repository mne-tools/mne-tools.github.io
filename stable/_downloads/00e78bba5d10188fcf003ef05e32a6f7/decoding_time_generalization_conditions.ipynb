{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Decoding sensor space data with generalization across time and conditions\n\nThis example runs the analysis described in :footcite:`KingDehaene2014`. It\nillustrates how one can\nfit a linear classifier to identify a discriminatory topography at a given time\ninstant and subsequently assess whether this linear model can accurately\npredict all of the time samples of a second set of conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Jean-Remi King <jeanremi.king@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n#          Denis Engemann <denis.engemann@gmail.com>\n#\n# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.decoding import GeneralizingEstimator\n\nprint(__doc__)\n\n# Preprocess data\ndata_path = sample.data_path()\n# Load and filter data, set up epochs\nmeg_path = data_path / 'MEG' / 'sample'\nraw_fname = meg_path / 'sample_audvis_filt-0-40_raw.fif'\nevents_fname = meg_path / 'sample_audvis_filt-0-40_raw-eve.fif'\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\npicks = mne.pick_types(raw.info, meg=True, exclude='bads')  # Pick MEG channels\nraw.filter(1., 30., fir_design='firwin')  # Band pass filtering signals\nevents = mne.read_events(events_fname)\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2,\n            'Visual/Left': 3, 'Visual/Right': 4}\ntmin = -0.050\ntmax = 0.400\n# decimate to make the example faster to run, but then use verbose='error' in\n# the Epochs constructor to suppress warning about decimation causing aliasing\ndecim = 2\nepochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n                    proj=True, picks=picks, baseline=None, preload=True,\n                    reject=dict(mag=5e-12), decim=decim, verbose='error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will train the classifier on all left visual vs auditory trials\nand test on all right visual vs auditory trials.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = make_pipeline(\n    StandardScaler(),\n    LogisticRegression(solver='liblinear')  # liblinear is faster than lbfgs\n)\ntime_gen = GeneralizingEstimator(clf, scoring='roc_auc', n_jobs=None,\n                                 verbose=True)\n\n# Fit classifiers on the epochs where the stimulus was presented to the left.\n# Note that the experimental condition y indicates auditory or visual\ntime_gen.fit(X=epochs['Left'].get_data(),\n             y=epochs['Left'].events[:, 2] > 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score on the epochs where the stimulus was presented to the right.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = time_gen.score(X=epochs['Right'].get_data(),\n                        y=epochs['Right'].events[:, 2] > 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1)\nim = ax.matshow(scores, vmin=0, vmax=1., cmap='RdBu_r', origin='lower',\n                extent=epochs.times[[0, -1, 0, -1]])\nax.axhline(0., color='k')\nax.axvline(0., color='k')\nax.xaxis.set_ticks_position('bottom')\nax.set_xlabel('Testing Time (s)')\nax.set_ylabel('Training Time (s)')\nax.set_title('Generalization across time and condition')\nplt.colorbar(im, ax=ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}