{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Visualising statistical significance thresholds on EEG data\n\nMNE-Python provides a range of tools for statistical hypothesis testing\nand the visualisation of the results. Here, we show a few options for\nexploratory and confirmatory tests - e.g., targeted t-tests, cluster-based\npermutation approaches (here with Threshold-Free Cluster Enhancement);\nand how to visualise the results.\n\nThe underlying data comes from :footcite:`DufauEtAl2015`; we contrast long vs.\nshort words. TFCE is described in :footcite:`SmithNichols2009`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import ttest_ind\n\nimport mne\nfrom mne.channels import find_ch_adjacency, make_1020_channel_selections\nfrom mne.stats import spatio_temporal_cluster_test\n\nnp.random.seed(0)\n\n# Load the data\npath = mne.datasets.kiloword.data_path() / 'kword_metadata-epo.fif'\nepochs = mne.read_epochs(path)\n# These data are quite smooth, so to speed up processing we'll (unsafely!) just\n# decimate them\nepochs.decimate(4, verbose='error')\nname = \"NumberOfLetters\"\n\n# Split up the data by the median length in letters via the attached metadata\nmedian_value = str(epochs.metadata[name].median())\nlong_words = epochs[name + \" > \" + median_value]\nshort_words = epochs[name + \" < \" + median_value]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we have a specific point in space and time we wish to test, it can be\nconvenient to convert the data into Pandas Dataframe format. In this case,\nthe :class:`mne.Epochs` object has a convenient\n:meth:`mne.Epochs.to_data_frame` method, which returns a dataframe.\nThis dataframe can then be queried for specific time windows and sensors.\nThe extracted data can be submitted to standard statistical tests. Here,\nwe conduct t-tests on the difference between long and short words.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_windows = ((.2, .25), (.35, .45))\nelecs = [\"Fz\", \"Cz\", \"Pz\"]\nindex = ['condition', 'epoch', 'time']\n\n# display the EEG data in Pandas format (first 5 rows)\nprint(epochs.to_data_frame(index=index)[elecs].head())\n\nreport = \"{elec}, time: {tmin}-{tmax} s; t({df})={t_val:.3f}, p={p:.3f}\"\nprint(\"\\nTargeted statistical test results:\")\nfor (tmin, tmax) in time_windows:\n    long_df = long_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n    short_df = short_words.copy().crop(tmin, tmax).to_data_frame(index=index)\n    for elec in elecs:\n        # extract data\n        A = long_df[elec].groupby(\"condition\").mean()\n        B = short_df[elec].groupby(\"condition\").mean()\n\n        # conduct t test\n        t, p = ttest_ind(A, B)\n\n        # display results\n        format_dict = dict(elec=elec, tmin=tmin, tmax=tmax,\n                           df=len(epochs.events) - 2, t_val=t, p=p)\n        print(report.format(**format_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Absent specific hypotheses, we can also conduct an exploratory\nmass-univariate analysis at all sensors and time points. This requires\ncorrecting for multiple tests.\nMNE offers various methods for this; amongst them, cluster-based permutation\nmethods allow deriving power from the spatio-temoral correlation structure\nof the data. Here, we use TFCE.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Calculate adjacency matrix between sensors from their locations\nadjacency, _ = find_ch_adjacency(epochs.info, \"eeg\")\n\n# Extract data: transpose because the cluster test requires channels to be last\n# In this case, inference is done over items. In the same manner, we could\n# also conduct the test over, e.g., subjects.\nX = [long_words.get_data().transpose(0, 2, 1),\n     short_words.get_data().transpose(0, 2, 1)]\ntfce = dict(start=.4, step=.4)  # ideally start and step would be smaller\n\n# Calculate statistical thresholds\nt_obs, clusters, cluster_pv, h0 = spatio_temporal_cluster_test(\n    X, tfce, adjacency=adjacency,\n    n_permutations=100)  # a more standard number would be 1000+\nsignificant_points = cluster_pv.reshape(t_obs.shape).T < .05\nprint(str(significant_points.sum()) + \" points selected by TFCE ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results of these mass univariate analyses can be visualised by plotting\n:class:`mne.Evoked` objects as images (via :class:`mne.Evoked.plot_image`)\nand masking points for significance.\nHere, we group channels by Regions of Interest to facilitate localising\neffects on the head.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We need an evoked object to plot the image to be masked\nevoked = mne.combine_evoked([long_words.average(), short_words.average()],\n                            weights=[1, -1])  # calculate difference wave\ntime_unit = dict(time_unit=\"s\")\nevoked.plot_joint(title=\"Long vs. short words\", ts_args=time_unit,\n                  topomap_args=time_unit)  # show difference wave\n\n# Create ROIs by checking channel labels\nselections = make_1020_channel_selections(evoked.info, midline=\"12z\")\n\n# Visualize the results\nfig, axes = plt.subplots(nrows=3, figsize=(8, 8))\naxes = {sel: ax for sel, ax in zip(selections, axes.ravel())}\nevoked.plot_image(axes=axes, group_by=selections, colorbar=False, show=False,\n                  mask=significant_points, show_names=\"all\", titles=None,\n                  **time_unit)\nplt.colorbar(axes[\"Left\"].images[-1], ax=list(axes.values()), shrink=.3,\n             label=\"\u00b5V\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}