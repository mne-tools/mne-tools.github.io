{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute source power spectral density (PSD) of VectorView and OPM data\n\nHere we compute the resting state from raw for data recorded using\na Neuromag VectorView system and a custom OPM system.\nThe pipeline is meant to mostly follow the Brainstorm [1]_\n`OMEGA resting tutorial pipeline <bst_omega_>`_.\nThe steps we use are:\n\n1. Filtering: downsample heavily.\n2. Artifact detection: use SSP for EOG and ECG.\n3. Source localization: dSPM, depth weighting, cortically constrained.\n4. Frequency: power spectral density (Welch), 4 sec window, 50% overlap.\n5. Standardize: normalize by relative power for each source.\n   :depth: 1\n\n\n## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Denis Engemann <denis.engemann@gmail.com>\n#          Luke Bloy <luke.bloy@gmail.com>\n#          Eric Larson <larson.eric.d@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport os.path as op\n\nfrom mne.filter import next_fast_len\n\nimport mne\n\n\nprint(__doc__)\n\ndata_path = mne.datasets.opm.data_path()\nsubject = 'OPM_sample'\n\nsubjects_dir = op.join(data_path, 'subjects')\nbem_dir = op.join(subjects_dir, subject, 'bem')\nbem_fname = op.join(subjects_dir, subject, 'bem',\n                    subject + '-5120-5120-5120-bem-sol.fif')\nsrc_fname = op.join(bem_dir, '%s-oct6-src.fif' % subject)\nvv_fname = data_path + '/MEG/SQUID/SQUID_resting_state.fif'\nvv_erm_fname = data_path + '/MEG/SQUID/SQUID_empty_room.fif'\nvv_trans_fname = data_path + '/MEG/SQUID/SQUID-trans.fif'\nopm_fname = data_path + '/MEG/OPM/OPM_resting_state_raw.fif'\nopm_erm_fname = data_path + '/MEG/OPM/OPM_empty_room_raw.fif'\nopm_trans_fname = None\nopm_coil_def_fname = op.join(data_path, 'MEG', 'OPM', 'coil_def.dat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data, resample. We will store the raw objects in dicts with entries\n\"vv\" and \"opm\" to simplify housekeeping and simplify looping later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raws = dict()\nraw_erms = dict()\nnew_sfreq = 90.  # Nyquist frequency (45 Hz) < line noise freq (50 Hz)\nraws['vv'] = mne.io.read_raw_fif(vv_fname, verbose='error')  # ignore naming\nraws['vv'].load_data().resample(new_sfreq)\nraws['vv'].info['bads'] = ['MEG2233', 'MEG1842']\nraw_erms['vv'] = mne.io.read_raw_fif(vv_erm_fname, verbose='error')\nraw_erms['vv'].load_data().resample(new_sfreq)\nraw_erms['vv'].info['bads'] = ['MEG2233', 'MEG1842']\n\nraws['opm'] = mne.io.read_raw_fif(opm_fname)\nraws['opm'].load_data().resample(new_sfreq)\nraw_erms['opm'] = mne.io.read_raw_fif(opm_erm_fname)\nraw_erms['opm'].load_data().resample(new_sfreq)\n# Make sure our assumptions later hold\nassert raws['opm'].info['sfreq'] == raws['vv'].info['sfreq']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do some minimal artifact rejection just for VectorView data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "titles = dict(vv='VectorView', opm='OPM')\nssp_ecg, _ = mne.preprocessing.compute_proj_ecg(\n    raws['vv'], tmin=-0.1, tmax=0.1, n_grad=1, n_mag=1)\nraws['vv'].add_proj(ssp_ecg, remove_existing=True)\n# due to how compute_proj_eog works, it keeps the old projectors, so\n# the output contains both projector types (and also the original empty-room\n# projectors)\nssp_ecg_eog, _ = mne.preprocessing.compute_proj_eog(\n    raws['vv'], n_grad=1, n_mag=1, ch_name='MEG0112')\nraws['vv'].add_proj(ssp_ecg_eog, remove_existing=True)\nraw_erms['vv'].add_proj(ssp_ecg_eog)\nfig = mne.viz.plot_projs_topomap(raws['vv'].info['projs'][-4:],\n                                 info=raws['vv'].info)\nfig.suptitle(titles['vv'])\nfig.subplots_adjust(0.05, 0.05, 0.95, 0.85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kinds = ('vv', 'opm')\nn_fft = next_fast_len(int(round(4 * new_sfreq)))\nprint('Using n_fft=%d (%0.1f sec)' % (n_fft, n_fft / raws['vv'].info['sfreq']))\nfor kind in kinds:\n    fig = raws[kind].plot_psd(n_fft=n_fft, proj=True)\n    fig.suptitle(titles[kind])\n    fig.subplots_adjust(0.1, 0.1, 0.95, 0.85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alignment and forward\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we use a reduced size source space (oct5) just for speed\nsrc = mne.setup_source_space(\n    subject, 'oct5', add_dist=False, subjects_dir=subjects_dir)\n# This line removes source-to-source distances that we will not need.\n# We only do it here to save a bit of memory, in general this is not required.\ndel src[0]['dist'], src[1]['dist']\nbem = mne.read_bem_solution(bem_fname)\nfwd = dict()\n\n# check alignment and generate forward for VectorView\nkwargs = dict(azimuth=0, elevation=90, distance=0.6, focalpoint=(0., 0., 0.))\nfig = mne.viz.plot_alignment(\n    raws['vv'].info, trans=vv_trans_fname, subject=subject,\n    subjects_dir=subjects_dir, dig=True, coord_frame='mri',\n    surfaces=('head', 'white'))\nmne.viz.set_3d_view(figure=fig, **kwargs)\nfwd['vv'] = mne.make_forward_solution(\n    raws['vv'].info, vv_trans_fname, src, bem, eeg=False, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And for OPM:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with mne.use_coil_def(opm_coil_def_fname):\n    fig = mne.viz.plot_alignment(\n        raws['opm'].info, trans=opm_trans_fname, subject=subject,\n        subjects_dir=subjects_dir, dig=False, coord_frame='mri',\n        surfaces=('head', 'white'))\n    mne.viz.set_3d_view(figure=fig, **kwargs)\n    fwd['opm'] = mne.make_forward_solution(\n        raws['opm'].info, opm_trans_fname, src, bem, eeg=False, verbose=True)\n\ndel src, bem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute and apply inverse to PSD estimated using multitaper + Welch.\nGroup into frequency bands, then normalize each source point and sensor\nindependently. This makes the value of each sensor point and source location\nin each frequency band the percentage of the PSD accounted for by that band.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freq_bands = dict(\n    delta=(2, 4), theta=(5, 7), alpha=(8, 12), beta=(15, 29), gamma=(30, 45))\ntopos = dict(vv=dict(), opm=dict())\nstcs = dict(vv=dict(), opm=dict())\n\nsnr = 3.\nlambda2 = 1. / snr ** 2\nfor kind in kinds:\n    noise_cov = mne.compute_raw_covariance(raw_erms[kind])\n    inverse_operator = mne.minimum_norm.make_inverse_operator(\n        raws[kind].info, forward=fwd[kind], noise_cov=noise_cov, verbose=True)\n    stc_psd, sensor_psd = mne.minimum_norm.compute_source_psd(\n        raws[kind], inverse_operator, lambda2=lambda2,\n        n_fft=n_fft, dB=False, return_sensor=True, verbose=True)\n    topo_norm = sensor_psd.data.sum(axis=1, keepdims=True)\n    stc_norm = stc_psd.sum()  # same operation on MNE object, sum across freqs\n    # Normalize each source point by the total power across freqs\n    for band, limits in freq_bands.items():\n        data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n        topos[kind][band] = mne.EvokedArray(\n            100 * data / topo_norm, sensor_psd.info)\n        stcs[kind][band] = \\\n            100 * stc_psd.copy().crop(*limits).sum() / stc_norm.data\n    del inverse_operator\ndel fwd, raws, raw_erms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can make some plots of each frequency band. Note that the OPM head\ncoverage is only over right motor cortex, so only localization\nof beta is likely to be worthwhile.\n\n## Theta\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_band(kind, band):\n    \"\"\"Plot activity within a frequency band on the subject's brain.\"\"\"\n    title = \"%s %s\\n(%d-%d Hz)\" % ((titles[kind], band,) + freq_bands[band])\n    topos[kind][band].plot_topomap(\n        times=0., scalings=1., cbar_fmt='%0.1f', vmin=0, cmap='inferno',\n        time_format=title)\n    brain = stcs[kind][band].plot(\n        subject=subject, subjects_dir=subjects_dir, views='cau', hemi='both',\n        time_label=title, title=title, colormap='inferno',\n        time_viewer=False, show_traces=False,\n        clim=dict(kind='percent', lims=(70, 85, 99)), smoothing_steps=10)\n    brain.show_view(dict(azimuth=0, elevation=0), roll=0)\n    return fig, brain\n\n\nfig_theta, brain_theta = plot_band('vv', 'theta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alpha\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_alpha, brain_alpha = plot_band('vv', 'alpha')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Beta\nHere we also show OPM data, which shows a profile similar to the VectorView\ndata beneath the sensors. VectorView first:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_beta, brain_beta = plot_band('vv', 'beta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then OPM:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_beta_opm, brain_beta_opm = plot_band('opm', 'beta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gamma\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_gamma, brain_gamma = plot_band('vv', 'gamma')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. [1] Tadel F, Baillet S, Mosher JC, Pantazis D, Leahy RM.\n       Brainstorm: A User-Friendly Application for MEG/EEG Analysis.\n       Computational Intelligence and Neuroscience, vol. 2011, Article ID\n       879716, 13 pages, 2011. doi:10.1155/2011/879716\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}