{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Repairing artifacts with SSP\n\nThis tutorial covers the basics of signal-space projection (SSP) and shows\nhow SSP can be used for artifact repair; extended examples illustrate use\nof SSP for environmental noise reduction, and for repair of ocular and\nheartbeat artifacts.\n\nWe begin as always by importing the necessary Python modules. To save ourselves\nfrom repeatedly typing ``mne.preprocessing`` we'll directly import a handful of\nfunctions from that submodule:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport mne\nfrom mne.preprocessing import (create_eog_epochs, create_ecg_epochs,\n                               compute_proj_ecg, compute_proj_eog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Before applying SSP (or any artifact repair strategy), be sure to observe\n    the artifacts in your data to make sure you choose the right repair tool.\n    Sometimes the right tool is no tool at all \u2014 if the artifacts are small\n    enough you may not even need to repair them to get good analysis results.\n    See `tut-artifact-overview` for guidance on detecting and\n    visualizing various types of artifact.</p></div>\n\n## What is SSP?\n\nSignal-space projection (SSP) :footcite:`UusitaloIlmoniemi1997` is a\ntechnique for removing noise from EEG\nand MEG signals by :term:`projecting <projector>` the signal onto a\nlower-dimensional subspace. The subspace is chosen by calculating the average\npattern across sensors when the noise is present, treating that pattern as\na \"direction\" in the sensor space, and constructing the subspace to be\northogonal to the noise direction (for a detailed walk-through of projection\nsee `tut-projectors-background`).\n\nThe most common use of SSP is to remove noise from MEG signals when the noise\ncomes from environmental sources (sources outside the subject's body and the\nMEG system, such as the electromagnetic fields from nearby electrical\nequipment) and when that noise is *stationary* (doesn't change much over the\nduration of the recording). However, SSP can also be used to remove\nbiological artifacts such as heartbeat (ECG) and eye movement (EOG)\nartifacts. Examples of each of these are given below.\n\n\n## Example: Environmental noise reduction from empty-room recordings\n\nThe `example data <sample-dataset>` was recorded on a Neuromag system,\nwhich stores SSP projectors for environmental noise removal in the system\nconfiguration (so that reasonably clean raw data can be viewed in real-time\nduring acquisition). For this reason, all the `~mne.io.Raw` data in\nthe example dataset already includes SSP projectors, which are noted in the\noutput when loading the data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_data_folder = mne.datasets.sample.data_path()\nsample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n                                    'sample_audvis_raw.fif')\n# here we crop and resample just for speed\nraw = mne.io.read_raw_fif(sample_data_raw_file).crop(0, 60)\nraw.load_data().resample(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `example data <sample-dataset>` also includes an \"empty room\"\nrecording taken the same day as the recording of the subject. This will\nprovide a more accurate estimate of environmental noise than the projectors\nstored with the system (which are typically generated during annual\nmaintenance and tuning). Since we have this subject-specific empty-room\nrecording, we'll create our own projectors from it and discard the\nsystem-provided SSP projectors (saving them first, for later comparison with\nthe custom ones):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "system_projs = raw.info['projs']\nraw.del_proj()\nempty_room_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n                               'ernoise_raw.fif')\n# cropped to 60 sec just for speed\nempty_room_raw = mne.io.read_raw_fif(empty_room_file).crop(0, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the empty room recording itself has the system-provided SSP\nprojectors in it \u2014 we'll remove those from the empty room file too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "empty_room_raw.del_proj()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the empty-room noise\n\nLet's take a look at the spectrum of the empty room noise. We can view an\nindividual spectrum for each sensor, or an average (with confidence band)\nacross sensors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for average in (False, True):\n    empty_room_raw.plot_psd(average=average, dB=False, xscale='log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the empty-room projectors\n\nWe create the SSP vectors using `~mne.compute_proj_raw`, and control\nthe number of projectors with parameters ``n_grad`` and ``n_mag``. Once\ncreated, the field pattern of the projectors can be easily visualized with\n`~mne.viz.plot_projs_topomap`. We include the parameter\n``vlim='joint'`` so that the colormap is computed jointly for all projectors\nof a given channel type; this makes it easier to compare their relative\nsmoothness. Note that for the function to know the types of channels in a\nprojector, you must also provide the corresponding `~mne.Info` object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "empty_room_projs = mne.compute_proj_raw(empty_room_raw, n_grad=3, n_mag=3)\nmne.viz.plot_projs_topomap(empty_room_projs, colorbar=True, vlim='joint',\n                           info=empty_room_raw.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the gradiometer-based projectors seem to reflect problems with\nindividual sensor units rather than a global noise source (indeed, planar\ngradiometers are much less sensitive to distant sources). This is the reason\nthat the system-provided noise projectors are computed only for\nmagnetometers. Comparing the system-provided projectors to the\nsubject-specific ones, we can see they are reasonably similar (though in a\ndifferent order) and the left-right component seems to have changed\npolarity.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 3)\nfor idx, _projs in enumerate([system_projs, empty_room_projs[3:]]):\n    mne.viz.plot_projs_topomap(_projs, axes=axs[idx], colorbar=True,\n                               vlim='joint', info=empty_room_raw.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing how projectors affect the signal\n\nWe could visualize the different effects these have on the data by applying\neach set of projectors to different copies of the `~mne.io.Raw` object\nusing `~mne.io.Raw.apply_proj`. However, the `~mne.io.Raw.plot`\nmethod has a ``proj`` parameter that allows us to *temporarily* apply\nprojectors while plotting, so we can use this to visualize the difference\nwithout needing to copy the data. Because the projectors are so similar, we\nneed to zoom in pretty close on the data to see any differences:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mags = mne.pick_types(raw.info, meg='mag')\nfor title, projs in [('system', system_projs),\n                     ('subject-specific', empty_room_projs[3:])]:\n    raw.add_proj(projs, remove_existing=True)\n    with mne.viz.use_browser_backend('matplotlib'):\n        fig = raw.plot(proj=True, order=mags, duration=1, n_channels=2)\n    fig.subplots_adjust(top=0.9)  # make room for title\n    fig.suptitle('{} projectors'.format(title), size='xx-large', weight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The effect is sometimes easier to see on averaged data. Here we use an\ninteractive feature of `mne.Evoked.plot_topomap` to turn projectors on\nand off to see the effect on the data. Of course, the interactivity won't\nwork on the tutorial website, but you can download the tutorial and try it\nlocally:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "events = mne.find_events(raw, stim_channel='STI 014')\nevent_id = {'auditory/left': 1}\n\n# NOTE: appropriate rejection criteria are highly data-dependent\nreject = dict(mag=4000e-15,     # 4000 fT\n              grad=4000e-13,    # 4000 fT/cm\n              eeg=150e-6,       # 150 \u00b5V\n              eog=250e-6)       # 250 \u00b5V\n\n# time range where we expect to see the auditory N100: 50-150 ms post-stimulus\ntimes = np.linspace(0.05, 0.15, 5)\n\nepochs = mne.Epochs(raw, events, event_id, proj='delayed', reject=reject)\nfig = epochs.average().plot_topomap(times, proj='interactive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the ERP/F using ``evoked.plot()`` or ``evoked.plot_joint()`` with\nand without projectors applied can also be informative, as can plotting with\n``proj='reconstruct'``, which can reduce the signal bias introduced by\nprojections (see `tut-artifact-ssp-reconstruction` below).\n\n## Example: EOG and ECG artifact repair\n\n### Visualizing the artifacts\n\nAs mentioned in `the ICA tutorial <tut-artifact-ica>`, an important\nfirst step is visualizing the artifacts you want to repair. Here they are in\nthe raw data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# pick some channels that clearly show heartbeats and blinks\nregexp = r'(MEG [12][45][123]1|EEG 00.)'\nartifact_picks = mne.pick_channels_regexp(raw.ch_names, regexp=regexp)\nraw.plot(order=artifact_picks, n_channels=len(artifact_picks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repairing ECG artifacts with SSP\n\nMNE-Python provides several functions for detecting and removing heartbeats\nfrom EEG and MEG data. As we saw in `tut-artifact-overview`,\n`~mne.preprocessing.create_ecg_epochs` can be used to both detect and\nextract heartbeat artifacts into an `~mne.Epochs` object, which can\nbe used to visualize how the heartbeat artifacts manifest across the sensors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ecg_evoked = create_ecg_epochs(raw).average()\necg_evoked.plot_joint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looks like the EEG channels are pretty spread out; let's baseline-correct and\nplot again:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ecg_evoked.apply_baseline((None, None))\necg_evoked.plot_joint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compute SSP projectors for the heartbeat artifact, you can use\n`~mne.preprocessing.compute_proj_ecg`, which takes a\n`~mne.io.Raw` object as input and returns the requested number of\nprojectors for magnetometers, gradiometers, and EEG channels (default is two\nprojectors for each channel type).\n`~mne.preprocessing.compute_proj_ecg` also returns an :term:`events`\narray containing the sample numbers corresponding to the peak of the\n[R wave](https://en.wikipedia.org/wiki/QRS_complex)_ of each detected\nheartbeat.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "projs, events = compute_proj_ecg(raw, n_grad=1, n_mag=1, n_eeg=1, reject=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first line of output tells us that\n`~mne.preprocessing.compute_proj_ecg` found three existing projectors\nalready in the `~mne.io.Raw` object, and will include those in the\nlist of projectors that it returns (appending the new ECG projectors to the\nend of the list). If you don't want that, you can change that behavior with\nthe boolean ``no_proj`` parameter. Since we've already run the computation,\nwe can just as easily separate out the ECG projectors by indexing the list of\nprojectors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ecg_projs = projs[3:]\nprint(ecg_projs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like with the empty-room projectors, we can visualize the scalp\ndistribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_projs_topomap(ecg_projs, info=raw.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Moreover, because these projectors were created using epochs chosen\nspecifically because they contain time-locked artifacts, we can do a\njoint plot of the projectors and their effect on the time-averaged epochs.\nThis figure has three columns:\n\n1. The left shows the data traces before (black) and after (green)\n   projection. We can see that the ECG artifact is well suppressed by one\n   projector per channel type.\n2. The center shows the topomaps associated with the projectors, in this case\n   just a single topography for our one projector per channel type.\n3. The right again shows the data traces (black), but this time with those\n   traces also projected onto the first projector for each channel type (red)\n   plus one surrogate ground truth for an ECG channel (MEG 0111).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ideally here we would just do `picks_trace='ecg'`, but this dataset did not\n# have a dedicated ECG channel recorded, so we just pick a channel that was\n# very sensitive to the artifact\nfig = mne.viz.plot_projs_joint(ecg_projs, ecg_evoked, picks_trace='MEG 0111')\nfig.suptitle('ECG projectors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since no dedicated ECG sensor channel was detected in the\n`~mne.io.Raw` object, by default\n`~mne.preprocessing.compute_proj_ecg` used the magnetometers to\nestimate the ECG signal (as stated on the third line of output, above). You\ncan also supply the ``ch_name`` parameter to restrict which channel to use\nfor ECG artifact detection; this is most useful when you had an ECG sensor\nbut it is not labeled as such in the `~mne.io.Raw` file.\n\nThe next few lines of the output describe the filter used to isolate ECG\nevents. The default settings are usually adequate, but the filter can be\ncustomized via the parameters ``ecg_l_freq``, ``ecg_h_freq``, and\n``filter_length`` (see the documentation of\n`~mne.preprocessing.compute_proj_ecg` for details).\n\n.. TODO what are the cases where you might need to customize the ECG filter?\n   infants? Heart murmur?\n\nOnce the ECG events have been identified,\n`~mne.preprocessing.compute_proj_ecg` will also filter the data\nchannels before extracting epochs around each heartbeat, using the parameter\nvalues given in ``l_freq``, ``h_freq``, ``filter_length``, ``filter_method``,\nand ``iir_params``. Here again, the default parameter values are usually\nadequate.\n\n.. TODO should advice for filtering here be the same as advice for filtering\n   raw data generally? (e.g., keep high-pass very low to avoid peak shifts?\n   what if your raw data is already filtered?)\n\nBy default, the filtered epochs will be averaged together\nbefore the projection is computed; this can be controlled with the boolean\n``average`` parameter. In general this improves the signal-to-noise (where\n\"signal\" here is our artifact!) ratio because the artifact temporal waveform\nis fairly similar across epochs and well time locked to the detected events.\n\nTo get a sense of how the heartbeat affects the signal at each sensor, you\ncan plot the data with and without the ECG projectors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.del_proj()\nfor title, proj in [('Without', empty_room_projs), ('With', ecg_projs)]:\n    raw.add_proj(proj, remove_existing=False)\n    with mne.viz.use_browser_backend('matplotlib'):\n        fig = raw.plot(order=artifact_picks, n_channels=len(artifact_picks))\n    fig.subplots_adjust(top=0.9)  # make room for title\n    fig.suptitle('{} ECG projectors'.format(title), size='xx-large',\n                 weight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, note that above we passed ``reject=None`` to the\n`~mne.preprocessing.compute_proj_ecg` function, meaning that all\ndetected ECG epochs would be used when computing the projectors (regardless\nof signal quality in the data sensors during those epochs). The default\nbehavior is to reject epochs based on signal amplitude: epochs with\npeak-to-peak amplitudes exceeding 50 \u00b5V in EEG channels, 250 \u00b5V in EOG\nchannels, 2000 fT/cm in gradiometer channels, or 3000 fT in magnetometer\nchannels. You can change these thresholds by passing a dictionary with keys\n``eeg``, ``eog``, ``mag``, and ``grad`` (though be sure to pass the threshold\nvalues in volts, teslas, or teslas/meter). Generally, it is a good idea to\nreject such epochs when computing the ECG projectors (since presumably the\nhigh-amplitude fluctuations in the channels are noise, not reflective of\nbrain activity); passing ``reject=None`` above was done simply to avoid the\ndozens of extra lines of output (enumerating which sensor(s) were responsible\nfor each rejected epoch) from cluttering up the tutorial.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>`~mne.preprocessing.compute_proj_ecg` has a similar parameter\n    ``flat`` for specifying the *minimum* acceptable peak-to-peak amplitude\n    for each channel type.</p></div>\n\nWhile `~mne.preprocessing.compute_proj_ecg` conveniently combines\nseveral operations into a single function, MNE-Python also provides functions\nfor performing each part of the process. Specifically:\n\n- `mne.preprocessing.find_ecg_events` for detecting heartbeats in a\n  `~mne.io.Raw` object and returning a corresponding :term:`events`\n  array\n\n- `mne.preprocessing.create_ecg_epochs` for detecting heartbeats in a\n  `~mne.io.Raw` object and returning an `~mne.Epochs` object\n\n- `mne.compute_proj_epochs` for creating projector(s) from any\n  `~mne.Epochs` object\n\nSee the documentation of each function for further details.\n\n\n### Repairing EOG artifacts with SSP\n\nOnce again let's visualize our artifact before trying to repair it. We've\nseen above the large deflections in frontal EEG channels in the raw data;\nhere is how the ocular artifacts manifests across all the sensors:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eog_evoked = create_eog_epochs(raw).average(picks='all')\neog_evoked.apply_baseline((None, None))\neog_evoked.plot_joint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like we did with the heartbeat artifact, we can compute SSP projectors\nfor the ocular artifact using `~mne.preprocessing.compute_proj_eog`,\nwhich again takes a `~mne.io.Raw` object as input and returns the\nrequested number of projectors for magnetometers, gradiometers, and EEG\nchannels (default is two projectors for each channel type). This time, we'll\npass ``no_proj`` parameter (so we get back only the new EOG projectors, not\nalso the existing projectors in the `~mne.io.Raw` object), and we'll\nignore the events array by assigning it to ``_`` (the conventional way of\nhandling unwanted return elements in Python).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eog_projs, _ = compute_proj_eog(raw, n_grad=1, n_mag=1, n_eeg=1, reject=None,\n                                no_proj=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like with the empty-room and ECG projectors, we can visualize the scalp\ndistribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_projs_topomap(eog_projs, info=raw.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can do a joint image:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = mne.viz.plot_projs_joint(eog_projs, eog_evoked, 'eog')\nfig.suptitle('EOG projectors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, we can make a joint visualization with our EOG evoked. We will\nalso make a bad choice here and select *two* EOG projectors for EEG and\nmagnetometers, and we will see them show up as noise in the plot. Even though\nthe projected time course (left column) looks perhaps okay, problems show\nup in the center (topomaps) and right plots (projection of channel data\nonto the projection vector):\n\n1. The second magnetometer topomap has a bilateral auditory field pattern.\n2. The uniformly-scaled projected temporal time course (solid lines) show\n   that, while the first projector trace (red) has a large EOG-like\n   amplitude, the second projector trace (blue-green) is much smaller.\n3. The re-normalized projected temporal time courses show that the\n   second PCA trace is very noisy relative to the EOG channel data (yellow).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eog_projs_bad, _ = compute_proj_eog(\n    raw, n_grad=1, n_mag=2, n_eeg=2, reject=None,\n    no_proj=True)\nfig = mne.viz.plot_projs_joint(eog_projs_bad, eog_evoked, picks_trace='eog')\nfig.suptitle('Too many EOG projectors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we repeat the plot from above (with empty room and ECG projectors) and\ncompare it to a plot with empty room, ECG, and EOG projectors, to see how\nwell the ocular artifacts have been repaired:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for title in ('Without', 'With'):\n    if title == 'With':\n        raw.add_proj(eog_projs)\n    with mne.viz.use_browser_backend('matplotlib'):\n        fig = raw.plot(order=artifact_picks, n_channels=len(artifact_picks))\n    fig.subplots_adjust(top=0.9)  # make room for title\n    fig.suptitle('{} EOG projectors'.format(title), size='xx-large',\n                 weight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the small peaks in the first to magnetometer channels (``MEG\n1411`` and ``MEG 1421``) that occur at the same time as the large EEG\ndeflections have also been removed.\n\n\n## Choosing the number of projectors\n\nIn the examples above, we used 3 projectors (all magnetometer) to capture\nempty room noise, and saw how projectors computed for the gradiometers failed\nto capture *global* patterns (and thus we discarded the gradiometer\nprojectors). Then we computed 3 projectors (1 for each channel type) to\ncapture the heartbeat artifact, and 3 more to capture the ocular artifact.\nHow did we choose these numbers? The short answer is \"based on experience\" \u2014\nknowing how heartbeat artifacts typically manifest across the sensor array\nallows us to recognize them when we see them, and recognize when additional\nprojectors are capturing something else other than a heartbeat artifact (and\nthus may be removing brain signal and should be discarded).\n\n\n## Visualizing SSP sensor-space bias via signal reconstruction\n.. admonition:: SSP reconstruction\n    :class: sidebar note\n\n    Internally, the reconstruction is performed by effectively using a\n    minimum-norm source localization to a spherical source space with the\n    projections accounted for, and then projecting the source-space data\n    back out to sensor space.\n\nBecause SSP performs an orthogonal projection, any spatial component in the\ndata that is not perfectly orthogonal to the SSP spatial direction(s) will\nhave its overall amplitude reduced by the projection operation. In other\nwords, SSP typically introduces some amount of amplitude reduction bias in\nthe sensor space data.\n\nWhen performing source localization of M/EEG data, these projections are\nproperly taken into account by being applied not just to the M/EEG data\nbut also to the forward solution, and hence SSP should not bias the estimated\nsource amplitudes. However, for sensor space analyses, it can be useful to\nvisualize the extent to which SSP projection has biased the data. This can be\nexplored by using ``proj='reconstruct'`` in evoked plotting functions, for\nexample via `evoked.plot() <mne.Evoked.plot>`, here restricted to just\nEEG channels for speed:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evoked_eeg = epochs.average().pick('eeg')\nevoked_eeg.del_proj().add_proj(ecg_projs).add_proj(eog_projs)\nfig, axes = plt.subplots(1, 3, figsize=(8, 3), sharex=True, sharey=True)\nfor pi, proj in enumerate((False, True, 'reconstruct')):\n    ax = axes[pi]\n    evoked_eeg.plot(proj=proj, axes=ax, spatial_colors=True)\n    parts = ax.get_title().split('(')\n    ylabel = (f'{parts[0]} ({ax.get_ylabel()})\\n{parts[1].replace(\")\", \"\")}'\n              if pi == 0 else '')\n    ax.set(ylabel=ylabel, title=f'proj={proj}')\n    ax.yaxis.set_tick_params(labelbottom=True)\n    for text in list(ax.texts):\n        text.remove()\nmne.viz.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that here the bias in the EEG and magnetometer channels is reduced by\nthe reconstruction. This suggests that the application of SSP has slightly\nreduced the amplitude of our signals in sensor space, but that it should not\nbias the amplitudes in source space.\n\n## References\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}