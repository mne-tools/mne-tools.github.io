{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Single trial linear regression analysis with the LIMO dataset\n\nHere we explore the structure of the data contained in the\n`LIMO dataset`_.\nThis example replicates and extends some of the main analysis\nand tools integrated in `LIMO MEEG`_, a MATLAB toolbox originally designed\nto interface with EEGLAB_.\n\nIn summary, the example:\n\n- Fetches epoched data files for a single subject of the LIMO dataset\n  :footcite:`Rousselet2016`. If the LIMO files are not found on disk, the\n  fetcher `mne.datasets.limo.load_data()` will automatically download\n  the files from a remote repository.\n\n- During import, information about the data (i.e., sampling rate, number of\n  epochs per condition, number and name of EEG channels per subject, etc.) is\n  extracted from the LIMO :file:`.mat` files stored on disk and added to the\n  epochs structure as metadata.\n\n- Fits linear models on the single subject's data and visualizes inferential\n  measures to evaluate the significance of the estimated effects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Jose C. Garcia Alanis <alanis.jcg@gmail.com>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom mne import combine_evoked\nfrom mne.datasets.limo import load_data\nfrom mne.stats import linear_regression\nfrom mne.viz import plot_compare_evokeds, plot_events\n\nprint(__doc__)\n\n# subject to use\nsubj = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About the data\n\nIn the original LIMO experiment (see :footcite:`RousseletEtAl2010`),\nparticipants performed a\ntwo-alternative forced choice task, discriminating between two face stimuli.\nThe same two faces were used during the whole experiment,\nwith varying levels of noise added, making the faces more or less\ndiscernible to the observer (see `Fig 1`_ in :footcite:`RousseletEtAl2008`\nfor a similar approach).\n\nThe presented faces varied across a noise-signal (or phase-coherence)\ncontinuum spanning from 0 to 85% in increasing steps of 5%.\nIn other words, faces with high phase-coherence (e.g., 85%) were easy to\nidentify, while faces with low phase-coherence (e.g., 5%) were hard to\nidentify and by extension very hard to discriminate.\n\n\n## Load the data\n\nWe'll begin by loading the data from subject 1 of the LIMO dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This step can take a little while if you're loading the data for the\n# first time.\nlimo_epochs = load_data(subject=subj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the result of the loading process is an\n:class:`mne.EpochsArray` containing the data ready to interface\nwith MNE-Python.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(limo_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize events\n\nWe can visualise the distribution of the face events contained in the\n``limo_epochs`` structure. Events should appear clearly grouped, as the\nepochs are ordered by condition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plot_events(limo_epochs.events, event_id=limo_epochs.event_id)\nfig.suptitle(\"Distribution of events in LIMO epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As it can be seen above, conditions are coded as ``Face/A`` and ``Face/B``.\nInformation about the phase-coherence of the presented faces is stored in the\nepochs metadata. These information can be easily accessed by calling\n``limo_epochs.metadata``. As shown below, the epochs metadata also contains\ninformation about the presented faces for convenience.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(limo_epochs.metadata.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's take a closer look at the information in the epochs\nmetadata.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We want include all columns in the summary table\nepochs_summary = limo_epochs.metadata.describe(include=\"all\").round(3)\nprint(epochs_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first column of the summary table above provides more or less the same\ninformation as the ``print(limo_epochs)`` command we ran before. There are\n1055 faces (i.e., epochs), subdivided in 2 conditions (i.e., Face A and\nFace B) and, for this particular subject, there are more epochs for the\ncondition Face B.\n\nIn addition, we can see in the second column that the values for the\nphase-coherence variable range from -1.619 to 1.642. This is because the\nphase-coherence values are provided as a z-scored variable in the LIMO\ndataset. Note that they have a mean of zero and a standard deviation of 1.\n\n\n## Visualize condition ERPs\n\nLet's plot the ERPs evoked by Face A and Face B, to see how similar they are.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# only show -250 to 500 ms\nts_args = dict(xlim=(-0.25, 0.5))\n\n# plot evoked response for face A\nlimo_epochs[\"Face/A\"].average().plot_joint(\n    times=[0.15], title=\"Evoked response: Face A\", ts_args=ts_args\n)\n# and face B\nlimo_epochs[\"Face/B\"].average().plot_joint(\n    times=[0.15], title=\"Evoked response: Face B\", ts_args=ts_args\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also compute the difference wave contrasting Face A and Face B.\nAlthough, looking at the evoked responses above, we shouldn't expect great\ndifferences among these face-stimuli.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Face A minus Face B\ndifference_wave = combine_evoked(\n    [limo_epochs[\"Face/A\"].average(), limo_epochs[\"Face/B\"].average()], weights=[1, -1]\n)\n\n# plot difference wave\ndifference_wave.plot_joint(times=[0.15], title=\"Difference Face A - Face B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, no clear pattern appears when contrasting\nFace A and Face B. However, we could narrow our search a little bit more.\nSince this is a \"visual paradigm\" it might be best to look at electrodes\nlocated over the occipital lobe, as differences between stimuli (if any)\nmight easier to spot over visual areas.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a dictionary containing the evoked responses\nconditions = [\"Face/A\", \"Face/B\"]\nevokeds = {condition: limo_epochs[condition].average() for condition in conditions}\n\n# concentrate analysis an occipital electrodes (e.g. B11)\npick = evokeds[\"Face/A\"].ch_names.index(\"B11\")\n\n# compare evoked responses\nplot_compare_evokeds(evokeds, picks=pick, ylim=dict(eeg=(-15, 7.5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do see a difference between Face A and B, but it is pretty small.\n\n\n## Visualize effect of stimulus phase-coherence\n\nSince phase-coherence\ndetermined whether a face stimulus could be easily identified,\none could expect that faces with high phase-coherence should evoke stronger\nactivation patterns along occipital electrodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "phase_coh = limo_epochs.metadata[\"phase-coherence\"]\n# get levels of phase coherence\nlevels = sorted(phase_coh.unique())\n# create labels for levels of phase coherence (i.e., 0 - 85%)\nlabels = [\"{0:.2f}\".format(i) for i in np.arange(0.0, 0.90, 0.05)]\n\n# create dict of evokeds for each level of phase-coherence\nevokeds = {\n    label: limo_epochs[phase_coh == level].average()\n    for level, label in zip(levels, labels)\n}\n\n# pick channel to plot\nelectrodes = [\"C22\", \"B11\"]\n# create figures\nfor electrode in electrodes:\n    fig, ax = plt.subplots(figsize=(8, 4))\n    plot_compare_evokeds(\n        evokeds,\n        axes=ax,\n        ylim=dict(eeg=(-20, 15)),\n        picks=electrode,\n        cmap=(\"Phase coherence\", \"magma\"),\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above, there are some considerable differences between the\nactivation patterns evoked by stimuli with low vs. high phase-coherence at\nthe chosen electrodes.\n\n\n## Prepare data for linear regression analysis\n\nBefore we test the significance of these differences using linear\nregression, we'll interpolate missing channels that were\ndropped during preprocessing of the data.\nFurthermore, we'll drop the EOG channels (marked by the \"EXG\" prefix)\npresent in the data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "limo_epochs.interpolate_bads(reset_bads=True)\nlimo_epochs.drop_channels([\"EXG1\", \"EXG2\", \"EXG3\", \"EXG4\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define predictor variables and design matrix\n\nTo run the regression analysis,\nwe need to create a design matrix containing information about the\nvariables (i.e., predictors) we want to use for prediction of brain\nactivity patterns. For this purpose, we'll use the information we have in\n``limo_epochs.metadata``: phase-coherence and Face A vs. Face B.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# name of predictors + intercept\npredictor_vars = [\"face a - face b\", \"phase-coherence\", \"intercept\"]\n\n# create design matrix\ndesign = limo_epochs.metadata[[\"phase-coherence\", \"face\"]].copy()\ndesign[\"face a - face b\"] = np.where(design[\"face\"] == \"A\", 1, -1)\ndesign[\"intercept\"] = 1\ndesign = design[predictor_vars]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can set up the linear model to be used in the analysis using\nMNE-Python's func:`~mne.stats.linear_regression` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = linear_regression(limo_epochs, design_matrix=design, names=predictor_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract regression coefficients\n\nThe results are stored within the object ``reg``,\nwhich is a dictionary of evoked objects containing\nmultiple inferential measures for each predictor in the design matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"predictors are:\", list(reg))\nprint(\"fields are:\", [field for field in getattr(reg[\"intercept\"], \"_fields\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot model results\n\nNow we can access and plot the results of the linear regression analysis by\ncalling :samp:`reg['{<name of predictor>}'].{<measure of interest>}` and\nusing the\n:meth:`~mne.Evoked.plot_joint` method just as we would do with any other\nevoked object.\nBelow we can see a clear effect of phase-coherence, with higher\nphase-coherence (i.e., better \"face visibility\") having a negative effect on\nthe activity measured at occipital electrodes around 200 to 250 ms following\nstimulus onset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg[\"phase-coherence\"].beta.plot_joint(\n    ts_args=ts_args, title=\"Effect of Phase-coherence\", times=[0.23]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the corresponding T values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# use unit=False and scale=1 to keep values at their original\n# scale (i.e., avoid conversion to micro-volt).\nts_args = dict(xlim=(-0.25, 0.5), unit=False)\ntopomap_args = dict(scalings=dict(eeg=1), average=0.05)\n\nfig = reg[\"phase-coherence\"].t_val.plot_joint(\n    ts_args=ts_args, topomap_args=topomap_args, times=[0.23]\n)\nfig.axes[0].set_ylabel(\"T-value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conversely, there appears to be no (or very small) systematic effects when\ncomparing Face A and Face B stimuli. This is largely consistent with the\ndifference wave approach presented above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts_args = dict(xlim=(-0.25, 0.5))\n\nreg[\"face a - face b\"].beta.plot_joint(\n    ts_args=ts_args, title=\"Effect of Face A vs. Face B\", times=[0.23]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}