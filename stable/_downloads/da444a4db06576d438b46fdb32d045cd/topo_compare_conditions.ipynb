{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compare evoked responses for different conditions\n\nIn this example, an Epochs object for visual and auditory responses is created.\nBoth conditions are then accessed by their respective names to create a sensor\nlayout plot of the related evoked responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Denis Engemann <denis.engemann@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n\n# License: BSD (3-clause)\n\n\nimport matplotlib.pyplot as plt\nimport mne\n\nfrom mne.viz import plot_evoked_topo\nfrom mne.datasets import sample\n\nprint(__doc__)\n\ndata_path = sample.data_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\ntmin = -0.2\ntmax = 0.5\n\n#   Setup for reading the raw data\nraw = mne.io.read_raw_fif(raw_fname)\nevents = mne.read_events(event_fname)\n\n#   Set up amplitude-peak rejection values for MEG channels\nreject = dict(grad=4000e-13, mag=4e-12)\n\n# Create epochs including different events\nevent_id = {'audio/left': 1, 'audio/right': 2,\n            'visual/left': 3, 'visual/right': 4}\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n                    picks='meg', baseline=(None, 0), reject=reject)\n\n# Generate list of evoked objects from conditions names\nevokeds = [epochs[name].average() for name in ('left', 'right')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show topography for two different conditions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = 'blue', 'red'\ntitle = 'MNE sample data\\nleft vs right (A/V combined)'\n\nplot_evoked_topo(evokeds, color=colors, title=title, background_color='w')\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}