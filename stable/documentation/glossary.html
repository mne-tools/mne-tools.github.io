
<!DOCTYPE html>


<html lang="en" data-theme="auto">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Glossary &#8212; MNE 1.6.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=4af67c33" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script src="../_static/documentation_options.js?v=ab756d2f"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-5TBCPCRB6X"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-5TBCPCRB6X');
            </script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'documentation/glossary';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://mne.tools/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6';
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Algorithms and other implementation details" href="implementation.html" />
    <link rel="prev" title="From raw data to dSPM on SPM Faces dataset" href="../auto_examples/datasets/spm_faces_dataset_sgskip.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="auto">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/mne_logo_small.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/mne_logo_small.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../install/index.html">
                        Install
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        Documentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/python_reference.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../help/index.html">
                        Get help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../development/index.html">
                        Development
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown">
      1.6  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-mastodon"></i></span>
            <label class="sr-only">Mastodon</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discourse"></i></span>
            <label class="sr-only">Forum</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../install/index.html">
                        Install
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        Documentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api/python_reference.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../help/index.html">
                        Get help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../development/index.html">
                        Development
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown">
      1.6  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="External Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-mastodon"></i></span>
            <label class="sr-only">Mastodon</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Forum" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discourse"></i></span>
            <label class="sr-only">Forum</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/intro/index.html">Introductory tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/10_overview.html">Overview of MEG/EEG analysis with MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/15_inplace.html">Modifying data in-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/20_events_from_raw.html">Parsing events from raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/30_info.html">The Info data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/40_sensor_locations.html">Working with sensor locations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/50_configure_mne.html">Configuring MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/intro/70_report.html">Getting started with mne.Report</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/io/index.html">Reading data for different recording systems</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/10_reading_meg_data.html">Importing data from MEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/20_reading_eeg_data.html">Importing data from EEG devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/30_reading_fnirs_data.html">Importing data from fNIRS devices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/60_ctf_bst_auditory.html">Working with CTF data: the Brainstorm auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/io/70_reading_eyetracking_data.html">Importing Data from Eyetracking devices</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/raw/index.html">Working with continuous data</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/10_raw_overview.html">The Raw data structure: continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/20_event_arrays.html">Working with events</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/30_annotate_raw.html">Annotating continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/raw/40_visualize_raw.html">Built-in plotting methods for Raw objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/preprocessing/index.html">Preprocessing</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/10_preprocessing_overview.html">Overview of artifact detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/15_handling_bad_channels.html">Handling bad channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/20_rejecting_bad_data.html">Rejecting bad data spans and breaks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/25_background_filtering.html">Background information on filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/30_filtering_resampling.html">Filtering and resampling data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/35_artifact_correction_regression.html">Repairing artifacts with regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/40_artifact_correction_ica.html">Repairing artifacts with ICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/45_projectors_background.html">Background on projectors and projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">Repairing artifacts with SSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/55_setting_eeg_reference.html">Setting the EEG reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/59_head_positions.html">Extracting and visualizing subject head movement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">Signal-space separation (SSS) and Maxwell filtering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/70_fnirs_processing.html">Preprocessing functional near-infrared spectroscopy (fNIRS) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/80_opm_processing.html">Preprocessing optically pumped magnetometer (OPM) MEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/preprocessing/90_eyetracking_data.html">Working with eye tracker data in MNE-Python</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/epochs/index.html">Segmenting continuous data into epochs</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/10_epochs_overview.html">The Epochs data structure: discontinuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/15_baseline_regression.html">Regression-based baseline correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/20_visualize_epochs.html">Visualizing epoched data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/30_epochs_metadata.html">Working with Epoch metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/40_autogenerate_metadata.html">Auto-generating Epochs metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/50_epochs_to_data_frame.html">Exporting Epochs to Pandas DataFrames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/epochs/60_make_fixed_length_epochs.html">Divide continuous data into equally-spaced epochs</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/evoked/index.html">Estimating evoked responses</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/10_evoked_overview.html">The Evoked data structure: evoked/averaged data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/20_visualize_evoked.html">Visualizing Evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/30_eeg_erp.html">EEG analysis - Event-Related Potentials (ERPs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/evoked/40_whitened.html">Plotting whitened data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/time-freq/index.html">Time-frequency analysis</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/10_spectrum_class.html">The Spectrum and EpochsSpectrum classes: frequency-domain data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/20_sensors_time_frequency.html">Frequency and time-frequency sensor analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/time-freq/50_ssvep.html">Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/forward/index.html">Forward models and source spaces</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/10_background_freesurfer.html">FreeSurfer MRI reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/20_source_alignment.html">Source alignment and coordinate frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/25_automated_coreg.html">Using an automated approach to coregistration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/30_forward.html">Head model and forward computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/35_eeg_no_mri.html">EEG forward operator with a template MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/50_background_freesurfer_mne.html">How MNE uses FreeSurferâ€™s outputs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/80_fix_bem_in_blender.html">Fixing BEM and head surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/forward/90_compute_covariance.html">Computing a covariance matrix</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/inverse/index.html">Source localization and inverses</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/10_stc_class.html">The SourceEstimate data structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/20_dipole_fit.html">Source localization with equivalent current dipole (ECD) fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/30_mne_dspm_loreta.html">Source localization with MNE, dSPM, sLORETA, and eLORETA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/35_dipole_orientations.html">The role of dipole orientations in distributed source localization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/40_mne_fixed_free.html">Computing various MNE solutions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/50_beamformer_lcmv.html">Source reconstruction using an LCMV beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/60_visualize_stc.html">Visualize source time courses (stcs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/70_eeg_mri_coords.html">EEG source localization given electrode locations on an MRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">Brainstorm Elekta phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">Brainstorm CTF phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/90_phantom_4DBTi.html">4D Neuroimaging/BTi phantom dataset tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/inverse/95_phantom_KIT.html">KIT phantom dataset tutorial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/index.html">Statistical analysis of sensor data</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/10_background_stats.html">Statistical inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/20_erp_stats.html">Visualising statistical significance thresholds on EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">Non-parametric 1 sample cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">Non-parametric between conditions cluster statistic on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/70_cluster_rmANOVA_time_freq.html">Mass-univariate twoway repeated measures ANOVA on single trial power</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">Spatiotemporal permutation F-test on full sensor data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/stats-source-space/index.html">Statistical analysis of source estimates</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">Permutation t-test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">2 samples permutation test on source data with spatio-temporal clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">Repeated measures ANOVA on source data with spatio-temporal clustering</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/machine-learning/index.html">Machine learning models of neural activity</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/machine-learning/30_strf.html">Spectro-temporal receptive field (STRF) estimation on continuous data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/machine-learning/50_decoding.html">Decoding (MVPA)</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/clinical/index.html">Clinical applications</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/20_seeg.html">Working with sEEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/30_ecog.html">Working with ECoG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/clinical/60_sleep.html">Sleep stage classification from polysomnography (PSG) data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/simulation/index.html">Simulation</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/10_array_objs.html">Creating MNE-Python data structures from scratch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/70_point_spread.html">Corrupt known signal with point spread</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/simulation/80_dics.html">DICS for power mapping</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_tutorials/visualization/index.html">Visualization tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/visualization/10_publication_figure.html">Make figures more publication ready</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_tutorials/visualization/20_ui_events.html">Using the event system to link figures</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/io/index.html">Input/Output</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/elekta_epochs.html">Getting averaging info from .fif files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_neo_format.html">How to use data in neural ensemble (NEO) format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_noise_covariance_matrix.html">Reading/Writing a noise covariance matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/io/read_xdf.html">Reading XDF EEG data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/simulation/index.html">Data Simulation</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/plot_stc_metrics.html">Compare simulated and estimated source activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulate_evoked_data.html">Generate simulated evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulate_raw_data.html">Generate simulated raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/simulated_raw_data_using_subject_anatomy.html">Simulate raw data using subject anatomy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/simulation/source_simulator.html">Generate simulated source data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/preprocessing/index.html">Preprocessing</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/contralateral_referencing.html">Using contralateral referencing for EEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/css.html">Cortical Signal Suppression (CSS) for removal of cortical signals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/define_target_events.html">Define target events based on time lag, plot evoked response</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eeg_bridging.html">Identify EEG Electrodes Bridged by too much Gel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eeg_csd.html">Transform EEG data using current source density (CSD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eog_artifact_histogram.html">Show EOG artifact timing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/eog_regression.html">Reduce EOG artifacts through regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/find_ref_artifacts.html">Find MEG reference channel artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/fnirs_artifact_removal.html">Visualise NIRS artifact correction methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/ica_comparison.html">Compare the different ICA algorithms in MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/interpolate_bad_channels.html">Interpolate bad channels for MEG/EEG channels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/movement_compensation.html">Maxwell filter data with movement compensation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/movement_detection.html">Annotate movement artifacts and reestimate dev_head_t</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/muscle_detection.html">Annotate muscle artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/muscle_ica.html">Removing muscle ICA components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/otp.html">Plot sensor denoising using oversampled temporal projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/shift_evoked.html">Shifting time-scale in evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/virtual_evoked.html">Remap MEG channel types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/preprocessing/xdawn_denoising.html">XDAWN Denoising</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/visualization/index.html">Visualization</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/3d_to_2d.html">How to convert 3D electrode positions to a 2D image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/brain.html">Plotting with <code class="docutils literal notranslate"><span class="pre">mne.viz.Brain</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/channel_epochs_image.html">Visualize channel over epochs as an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/eeg_on_scalp.html">Plotting EEG sensors on the scalp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_arrowmap.html">Plotting topographic arrowmaps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_topomap.html">Plotting topographic maps of evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/evoked_whitening.html">Whitening evoked data with a noise covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/eyetracking_plot_heatmap.html">Plotting eye-tracking heatmaps in MNE-Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/meg_sensors.html">Plotting sensor layouts of MEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/mne_helmet.html">Plot the MNE brain and helmet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/montage_sgskip.html">Plotting sensor layouts of EEG systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/parcellation.html">Plot a cortical parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/roi_erpimage_by_rt.html">Plot single trial activity, grouped by ROI and sorted by RT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/ssp_projs_sensitivity_map.html">Sensitivity map of SSP projections</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/topo_compare_conditions.html">Compare evoked responses for different conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/topo_customized.html">Plot custom topographies for MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/visualization/xhemi.html">Cross-hemisphere comparison</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/time_frequency/index.html">Time-Frequency Examples</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/compute_csd.html">Compute a cross-spectral density (CSD) matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/compute_source_psd_epochs.html">Compute Power Spectral Density of inverse solution from single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_label_time_frequency.html">Compute power and phase lock in label of the source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_power_spectrum.html">Compute source power spectral density (PSD) in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_power_spectrum_opm.html">Compute source power spectral density (PSD) of VectorView and OPM data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/source_space_time_frequency.html">Compute induced power in the source space with dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/temporal_whitening.html">Temporal whitening with AR model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_erds.html">Compute and visualize ERDS maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_global_field_power.html">Explore event-related dynamics for specific frequency bands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/time_frequency/time_frequency_simulated.html">Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/stats/index.html">Statistics Examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/cluster_stats_evoked.html">Permutation F-test on sensor data with 1D cluster level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/fdr_stats_evoked.html">FDR correction on T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/linear_regression_raw.html">Regression on continuous data (rER[P/F])</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/sensor_permutation_test.html">Permutation T-test on sensor data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/stats/sensor_regression.html">Analysing continuous features with binning and regression in sensor space</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/decoding/index.html">Machine Learning (Decoding, Encoding, and MVPA)</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_csp_eeg.html">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_csp_timefreq.html">Decoding in time-frequency space using Common Spatial Patterns (CSP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_rsa_sgskip.html">Representational Similarity Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_spatio_temporal_source.html">Decoding source space data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_spoc_CMC.html">Continuous Target Decoding with SPoC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_time_generalization_conditions.html">Decoding sensor space data with generalization across time and conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_unsupervised_spatial_filter.html">Analysis of evoked response using ICA and PCA reduction techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/decoding_xdawn_eeg.html">XDAWN Decoding From EEG data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/ems_filtering.html">Compute effect-matched-spatial filtering (EMS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/linear_model_patterns.html">Linear classifier on sensor data with plot patterns and filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/receptive_field_mtrf.html">Receptive Field Estimation and Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/decoding/ssd_spatial_filters.html">Compute Spectro-Spatial Decomposition (SSD) spatial filters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../auto_examples/connectivity/index.html">Connectivity Analysis Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/forward/index.html">Forward modeling</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/forward_sensitivity_maps.html">Display sensitivity maps for EEG and MEG sensors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/left_cerebellum_volume_source.html">Generate a left cerebellum volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/forward/source_space_morphing.html">Use source space morphing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/inverse/index.html">Inverse problem and source analysis</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_epochs_in_label.html">Compute MNE-dSPM inverse solution on single epochs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_raw_in_label.html">Compute sLORETA inverse solution on raw data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_volume.html">Compute MNE-dSPM inverse solution on evoked data in volume source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/custom_inverse_solver.html">Source localization with a custom inverse solver</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/dics_epochs.html">Compute source level time-frequency timecourses using a DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/dics_source_power.html">Compute source power using DICS beamformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/evoked_ers_source_power.html">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/gamma_map_inverse.html">Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_activation_from_stc.html">Extracting time course from source_estimate object</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_from_stc.html">Generate a functional label from source estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/label_source_activations.html">Extracting the time series of activations in a label</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mixed_norm_inverse.html">Compute sparse inverse solution with mixed norm: MxNE and irMxNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mixed_source_space_inverse.html">Compute MNE inverse solution on evoked data with a mixed source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/mne_cov_power.html">Compute source power estimate by projecting the covariance with MNE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/morph_surface_stc.html">Morph surface source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/morph_volume_stc.html">Morph volumetric source estimate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/multi_dipole_model.html">Computing source timecourses with an XFit-like multi-dipole model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/multidict_reweighted_tfmxne.html">Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_label_leakage.html">Visualize source leakage among labels using a circular graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_vertices.html">Plot point-spread functions (PSFs) and cross-talk functions (CTFs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_ctf_vertices_lcmv.html">Compute cross-talk functions for LCMV beamformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/psf_volume.html">Plot point-spread functions (PSFs) for a volume</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/rap_music.html">Compute Rap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/read_inverse.html">Reading an inverse operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/read_stc.html">Reading an STC file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/resolution_metrics.html">Compute spatial resolution metrics in source space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/resolution_metrics_eegmeg.html">Compute spatial resolution metrics to compare MEG with EEG+MEG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/snr_estimate.html">Estimate data SNR using an inverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/source_space_snr.html">Computing source space SNR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/time_frequency_mixed_norm_inverse.html">Compute MxNE with time-frequency sparse prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/trap_music.html">Compute Trap-Music on evoked data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/inverse/vector_mne_solution.html">Plotting the full vector-valued MNE solution</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/datasets/index.html">Examples on open datasets</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/brainstorm_data.html">Brainstorm raw (median nerve) dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/hf_sef_data.html">HF-SEF dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/kernel_phantom.html">Kernel OPM phantom data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/limo_data.html">Single trial linear regression analysis with the LIMO dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/opm_data.html">Optically pumped magnetometer (OPM) data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/datasets/spm_faces_dataset_sgskip.html">From raw data to dSPM on SPM Faces dataset</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="implementation.html">Implementation details</a></li>
<li class="toctree-l1"><a class="reference internal" href="design_philosophy.html">Design philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Example datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generated/commands.html">Command-line tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help/migrating.html">Migrating from other analysis software</a></li>
<li class="toctree-l1"><a class="reference internal" href="cookbook.html">The typical M/EEG workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="cite.html">How to cite MNE-Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="cited.html">Papers citing MNE-Python</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article"></div>
              
              
<div>
  
  <section id="glossary">
<h1>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h1>
<p>The Glossary provides short definitions of vocabulary specific to MNE-Python and
general neuroimaging concepts. If you think a term is missing, please consider
<a class="reference external" href="https://github.com/mne-tools/mne-python/issues/new?template=glossary.md">creating a new issue</a> or <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/new/main">opening a pull request</a> to add it.</p>
<dl class="glossary">
<dt id="term-annotations">annotations<a class="headerlink" href="#term-annotations" title="Link to this term">#</a></dt><dd><p>An annotation is defined by an onset, a duration, and a textual
description. It can contain information about the experiment, but
also details on signals marked by a human such as bad data segments,
sleep stages, sleep events (spindles, K-complex), and so on.
An <a class="reference internal" href="../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container for multiple annotations,
which is available as the <code class="docutils literal notranslate"><span class="pre">annotations</span></code> attribute of <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects. See <a class="reference internal" href="../generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> for the class definition and
<a class="reference internal" href="../auto_tutorials/intro/20_events_from_raw.html#tut-events-vs-annotations"><span class="std std-ref">Parsing events from raw data</span></a> for a short tutorial.
See also <a class="reference internal" href="#term-events"><span class="xref std std-term">events</span></a>.</p>
</dd>
<dt id="term-beamformer">beamformer<a class="headerlink" href="#term-beamformer" title="Link to this term">#</a></dt><dd><p>A beamformer is a popular source estimation approach that uses a set of
spatial filters (beamformer weights) to compute time courses of sources
at predefined locations. See <a class="reference internal" href="../generated/mne.beamformer.Beamformer.html#mne.beamformer.Beamformer" title="mne.beamformer.Beamformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">beamformer.Beamformer</span></code></a> for the class
definition. See also <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>.</p>
</dd>
<dt id="term-BEM">BEM<a class="headerlink" href="#term-BEM" title="Link to this term">#</a></dt><dt id="term-boundary-element-model">boundary element model<a class="headerlink" href="#term-boundary-element-model" title="Link to this term">#</a></dt><dt id="term-boundary-element-method">boundary element method<a class="headerlink" href="#term-boundary-element-method" title="Link to this term">#</a></dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the definion of the conductor model in the
forward model computation. The boundary element model consists of surfaces
such as the inner skull, outer skull, and outer skin (scalp) that define
compartments of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="../generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="../generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="../auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for a usage demo.</p>
</dd>
<dt id="term-channels">channels<a class="headerlink" href="#term-channels" title="Link to this term">#</a></dt><dd><p>Channels refer to MEG sensors, EEG electrodes or other sensors such as
EOG, ECG, sEEG, ECoG, etc. Channels usually have
a type (such as gradiometer), and a unit (such as T/m) used e.g. for
plotting. See also <a class="reference internal" href="#term-data-channels"><span class="xref std std-term">data channels</span></a>.</p>
</dd>
<dt id="term-data-channels">data channels<a class="headerlink" href="#term-data-channels" title="Link to this term">#</a></dt><dd><p>Many functions in MNE-Python operate on â€œdata channelsâ€ by default. These
are channels that contain electrophysiological data from the brain,
as opposed to other channel types such as EOG, ECG, stimulus/trigger,
or acquisition system status data. The set of channels considered
â€œdata channelsâ€ in MNE contains the following types (together with scale
factors for plotting):</p>
<div class="compound">
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'mag'</span></code>: <strong>Magnetometers</strong> (scaled by 1e+15 to plot in <em>fT</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'grad'</span></code>: <strong>Gradiometers</strong> (scaled by 1e+13 to plot in <em>fT/cm</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'eeg'</span></code>: <strong>EEG</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'csd'</span></code>: <strong>Current source density</strong> (scaled by 1000 to plot in <em>mV/mÂ²</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'seeg'</span></code>: <strong>sEEG</strong> (scaled by 1000 to plot in <em>mV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ecog'</span></code>: <strong>ECoG</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'dbs'</span></code>: <strong>DBS</strong> (scaled by 1e+06 to plot in <em>ÂµV</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbo'</span></code>: <strong>Oxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>ÂµM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'hbr'</span></code>: <strong>Deoxyhemoglobin</strong> (scaled by 1e+06 to plot in <em>ÂµM</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_cw_amplitude'</span></code>: <strong>fNIRS (CW amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_ac_amplitude'</span></code>: <strong>fNIRS (FD AC amplitude)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_fd_phase'</span></code>: <strong>fNIRS (FD phase)</strong> (scaled by 1 to plot in <em>rad</em>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fnirs_od'</span></code>: <strong>fNIRS (OD)</strong> (scaled by 1 to plot in <em>V</em>)</p></li>
</ul>
</div>
</dd>
<dt id="term-DC">DC<a class="headerlink" href="#term-DC" title="Link to this term">#</a></dt><dt id="term-direct-current">direct current<a class="headerlink" href="#term-direct-current" title="Link to this term">#</a></dt><dd><p>The part of a signal that stays constant over time. The â€œDC offsetâ€
of electrophysiological signals is often dealt with by high-pass
filtering or by subtracting some suitable baseline.</p>
</dd>
<dt id="term-DICS">DICS<a class="headerlink" href="#term-DICS" title="Link to this term">#</a></dt><dt id="term-dynamic-imaging-of-coherent-sources">dynamic imaging of coherent sources<a class="headerlink" href="#term-dynamic-imaging-of-coherent-sources" title="Link to this term">#</a></dt><dd><p>Dynamic Imaging of Coherent Sources is a method for computing source
power in different frequency bands. See <a class="reference internal" href="../auto_examples/inverse/dics_source_power.html#ex-inverse-source-power"><span class="std std-ref">Compute source power using DICS beamformer</span></a>
and <a class="reference internal" href="../generated/mne.beamformer.make_dics.html#mne.beamformer.make_dics" title="mne.beamformer.make_dics"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_dics()</span></code></a> for more details.</p>
</dd>
<dt id="term-digitization">digitization<a class="headerlink" href="#term-digitization" title="Link to this term">#</a></dt><dd><p>Digitization is a procedure of recording the head shape and locations of
fiducial coils (or <a class="reference internal" href="#term-HPI"><span class="xref std std-term">HPI</span></a>) and/or EEG electrodes on the head. They
are represented as a set of points in 3D space.
See <a class="reference internal" href="../auto_tutorials/intro/40_sensor_locations.html#reading-dig-montages"><span class="std std-ref">Reading sensor digitization files</span></a> and <a class="reference internal" href="implementation.html#dig-formats"><span class="std std-ref">Supported formats for digitized 3D locations</span></a>.</p>
</dd>
<dt id="term-dipole">dipole<a class="headerlink" href="#term-dipole" title="Link to this term">#</a></dt><dt id="term-ECD">ECD<a class="headerlink" href="#term-ECD" title="Link to this term">#</a></dt><dt id="term-equivalent-current-dipole">equivalent current dipole<a class="headerlink" href="#term-equivalent-current-dipole" title="Link to this term">#</a></dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small cortical region. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by these techniques
are well approximated by (i.e., equivalent to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-dSPM">dSPM<a class="headerlink" href="#term-dSPM" title="Link to this term">#</a></dt><dt id="term-dynamic-statistical-parametric-mapping">dynamic statistical parametric mapping<a class="headerlink" href="#term-dynamic-statistical-parametric-mapping" title="Link to this term">#</a></dt><dd><p>Dynamic statistical parametric mapping (dSPM) gives a noise-normalized
minimum-norm estimate at a given source location. It is calculated by
dividing the activity estimate at each source location by the baseline
standard deviation of the noise.</p>
</dd>
<dt id="term-eLORETA">eLORETA<a class="headerlink" href="#term-eLORETA" title="Link to this term">#</a></dt><dt id="term-sLORETA">sLORETA<a class="headerlink" href="#term-sLORETA" title="Link to this term">#</a></dt><dd><p>eLORETA and sLORETA (exact and standardized low resolution brain
electromagnetic tomography) are linear source estimation techniques
like <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a> and <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>. sLORETA outputs
standardized values (like dSPM), while eLORETA generates normalized
current estimates. See <a class="reference internal" href="../generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>,
<a class="reference internal" href="../auto_tutorials/inverse/30_mne_dspm_loreta.html#tut-inverse-methods"><span class="std std-ref">Source localization with MNE, dSPM, sLORETA, and eLORETA</span></a>, and <a class="reference internal" href="../auto_examples/inverse/compute_mne_inverse_raw_in_label.html#example-sloreta"><span class="std std-ref">Compute sLORETA inverse solution on raw data</span></a>.</p>
</dd>
<dt id="term-epochs">epochs<a class="headerlink" href="#term-epochs" title="Link to this term">#</a></dt><dd><p>Epochs (sometimes called â€œtrialsâ€ in other software packages) are
equal-length segments of data extracted from continuous data. Usually,
epochs are extracted around stimulus events or responses,
though sometimes sequential or overlapping epochs are used (e.g.,
for analysis of resting-state activity). See <a class="reference internal" href="../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the
class definition and <a class="reference internal" href="../auto_tutorials/epochs/10_epochs_overview.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: discontinuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-events">events<a class="headerlink" href="#term-events" title="Link to this term">#</a></dt><dd><p>Events correspond to specific time points in raw data, such as triggers,
experimental condition events, etc. MNE-Python represents events with
integers stored in NumPy arrays of shape <code class="docutils literal notranslate"><span class="pre">(n_events,</span> <span class="pre">3)</span></code>. The first
column contains the event onset (in samples) with <a class="reference internal" href="#term-first_samp"><span class="xref std std-term">first_samp</span></a>
included. The last column contains the event code. The second
column contains the signal value of the immediately preceding sample,
and reflects the fact that event arrays sometimes originate from
analog voltage channels (â€œtrigger channelsâ€ or â€œstim channelsâ€). In
most cases, the second column is all zeros and can be ignored.
Event arrays can be created with <a class="reference internal" href="../generated/mne.make_fixed_length_events.html#mne.make_fixed_length_events" title="mne.make_fixed_length_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.make_fixed_length_events()</span></code></a>,
<a class="reference internal" href="../generated/mne.read_events.html#mne.read_events" title="mne.read_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.read_events()</span></code></a>, and <a class="reference internal" href="../generated/mne.find_events.html#mne.find_events" title="mne.find_events"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.find_events()</span></code></a>.
See <a class="reference internal" href="../auto_tutorials/intro/20_events_from_raw.html#tut-events-vs-annotations"><span class="std std-ref">Parsing events from raw data</span></a> for a short tutorial.
See also <a class="reference internal" href="#term-annotations"><span class="xref std std-term">annotations</span></a>.</p>
</dd>
<dt id="term-evoked">evoked<a class="headerlink" href="#term-evoked" title="Link to this term">#</a></dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked objects over different subjects.
See <a class="reference internal" href="../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the class definition and
<a class="reference internal" href="../auto_tutorials/evoked/10_evoked_overview.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-fiducial">fiducial<a class="headerlink" href="#term-fiducial" title="Link to this term">#</a></dt><dt id="term-fiducial-point">fiducial point<a class="headerlink" href="#term-fiducial-point" title="Link to this term">#</a></dt><dt id="term-anatomical-landmark">anatomical landmark<a class="headerlink" href="#term-anatomical-landmark" title="Link to this term">#</a></dt><dd><p>Fiducials are objects placed in the field of view of an imaging system
to act as known spatial references that are easy to localize.
In neuroimaging, fiducials are often placed on anatomical landmarks
such as the nasion (NAS) or left/right preauricular points (LPA and
RPA).</p>
<p>These known reference locations are used to define a coordinate system
for localizing sensors (hence NAS, LPA and RPA are often
called â€œcardinal pointsâ€ because they define the cardinal directions of
the head coordinate system). The cardinal points are also useful when
co-registering measurements in different coordinate systems (such as
aligning EEG sensor locations to an MRI of the head).</p>
<p>Due to the common neuroimaging practice of placing fiducial objects on
anatomical landmarks, the terms â€œfiducialâ€, â€œanatomical landmarkâ€, and
â€œcardinal pointâ€ are often (erroneously) used interchangeably.</p>
</dd>
<dt id="term-first_samp">first_samp<a class="headerlink" href="#term-first_samp" title="Link to this term">#</a></dt><dd><p>The <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> attribute of <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the onset of the hardware acquisition system and the
time when data recording started. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. In other words,
<a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw.first_samp" title="mne.io.Raw.first_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">first_samp</span></code></a> will be <code class="docutils literal notranslate"><span class="pre">0</span></code> in <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects loaded from non-VectorView data files. See also
<a class="reference internal" href="#term-last_samp"><span class="xref std std-term">last_samp</span></a>.</p>
</dd>
<dt id="term-forward">forward<a class="headerlink" href="#term-forward" title="Link to this term">#</a></dt><dt id="term-forward-solution">forward solution<a class="headerlink" href="#term-forward-solution" title="Link to this term">#</a></dt><dd><p>The forward solution is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors
(the â€œlead field matrixâ€). Calculating a forward solution requires a
conductivity model of the head, which encapsulates the geometries and
electrical conductivities of the different tissue compartments (see
<a class="reference internal" href="#term-boundary-element-model"><span class="xref std std-term">boundary element model</span></a> and <a class="reference internal" href="../generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">bem.ConductorModel</span></code></a>).
For information about the Forward object and the data it stores, see
<a class="reference internal" href="../generated/mne.Forward.html#mne.Forward" title="mne.Forward"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Forward</span></code></a>.</p>
</dd>
<dt id="term-FreeSurfer-LUT">FreeSurfer LUT<a class="headerlink" href="#term-FreeSurfer-LUT" title="Link to this term">#</a></dt><dt id="term-LUT">LUT<a class="headerlink" href="#term-LUT" title="Link to this term">#</a></dt><dd><p>A FreeSurfer lookup table (LUT) provides a mapping between a given
volumetric atlas or surface label name, its integer value
(e.g., in <code class="docutils literal notranslate"><span class="pre">aparc+aseg.mgz</span></code>), and its standard color (see the
<a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT">FreeSurfer wiki</a>
for more information). Custom LUTs can be also be created from different
surface parcellations, see for example <a class="reference external" href="https://github.com/mne-tools/mne-python/pull/7639#issuecomment-625907891">this comment about HCPMMP</a>.</p>
</dd>
<dt id="term-GFP">GFP<a class="headerlink" href="#term-GFP" title="Link to this term">#</a></dt><dt id="term-global-field-power">global field power<a class="headerlink" href="#term-global-field-power" title="Link to this term">#</a></dt><dd><p>Global Field Power (GFP) is a measure of the (non-)uniformity
of the electromagnetic field at the sensors. It is typically calculated
as the standard deviation of the sensor values at each time point. Thus,
it is a one-dimensional time series capturing the spatial variability
of the signal across sensor locations.</p>
</dd>
<dt id="term-HED">HED<a class="headerlink" href="#term-HED" title="Link to this term">#</a></dt><dt id="term-hierarchical-event-descriptors">hierarchical event descriptors<a class="headerlink" href="#term-hierarchical-event-descriptors" title="Link to this term">#</a></dt><dd><p>Hierarchical event descriptors (HED) are tags that use
keywords separated by slashes (/) to describe different types of
experimental events (for example, <code class="docutils literal notranslate"><span class="pre">stimulus/circle/red/left</span></code> and
<code class="docutils literal notranslate"><span class="pre">stimulus/circle/blue/left</span></code>). These tags can be used to group
experimental events and select event types for analysis.</p>
</dd>
<dt id="term-HPI">HPI<a class="headerlink" href="#term-HPI" title="Link to this term">#</a></dt><dt id="term-cHPI">cHPI<a class="headerlink" href="#term-cHPI" title="Link to this term">#</a></dt><dt id="term-head-position-indicator">head position indicator<a class="headerlink" href="#term-head-position-indicator" title="Link to this term">#</a></dt><dd><p>Head position indicators (HPI, sometimes cHPI for
<em>continuous</em> head position indicators) are small coils attached to a
subjectâ€™s head during MEG acquisition. Each coil emits a sinusoidal
signal of a different frequency, which is picked up by the MEG sensors
and can be used to infer the head position. With cHPI, the sinusoidal
signals are typically set at frequencies above any neural signal of
interest, and thus can be removed after head position correction via
low-pass filtering. See <a class="reference internal" href="../auto_tutorials/preprocessing/59_head_positions.html#tut-head-pos"><span class="std std-ref">Extracting and visualizing subject head movement</span></a>.</p>
</dd>
<dt id="term-info">info<a class="headerlink" href="#term-info" title="Link to this term">#</a></dt><dt id="term-measurement-info">measurement info<a class="headerlink" href="#term-measurement-info" title="Link to this term">#</a></dt><dd><p>A â€œmeasurement infoâ€ (or short â€œinfoâ€) object is a collection of metadata
related to <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>, <a class="reference internal" href="../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a>, or <a class="reference internal" href="../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a>
objects. It contains channel locations and types, sampling frequency,
preprocessing history such as filters, etc.
See <a class="reference internal" href="../auto_tutorials/intro/30_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse">inverse<a class="headerlink" href="#term-inverse" title="Link to this term">#</a></dt><dt id="term-inverse-operator">inverse operator<a class="headerlink" href="#term-inverse-operator" title="Link to this term">#</a></dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods <a class="reference internal" href="#term-MNE"><span class="xref std std-term">MNE</span></a>, <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>, <a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, and
<a class="reference internal" href="#term-eLORETA"><span class="xref std std-term">eLORETA</span></a>. See <a class="reference internal" href="../generated/mne.minimum_norm.apply_inverse.html#mne.minimum_norm.apply_inverse" title="mne.minimum_norm.apply_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">minimum_norm.apply_inverse()</span></code></a>.</p>
</dd>
<dt id="term-label">label<a class="headerlink" href="#term-label" title="Link to this term">#</a></dt><dd><p>A <a class="reference internal" href="../generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a defined region in the cortex, often called
a region of interest (ROI) in the literature. Labels can be defined
anatomically (based on the physical structure of the cortex) or functionally
(based on cortical responses to specific stimuli). See also <a class="reference internal" href="#term-ROI"><span class="xref std std-term">ROI</span></a>.</p>
</dd>
<dt id="term-last_samp">last_samp<a class="headerlink" href="#term-last_samp" title="Link to this term">#</a></dt><dd><p>The <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw.last_samp" title="mne.io.Raw.last_samp"><code class="xref py py-attr docutils literal notranslate"><span class="pre">last_samp</span></code></a> attribute of <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a>
objects is an integer representing the number of time samples that
passed between the start and end of data recording. This approach to sample
numbering is a peculiarity of VectorView MEG systems, but for
consistency it is present in all <a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-class docutils literal notranslate"><span class="pre">Raw</span></code></a> objects
regardless of the source of the data. See also <a class="reference internal" href="#term-first_samp"><span class="xref std std-term">first_samp</span></a>.</p>
</dd>
<dt id="term-layout">layout<a class="headerlink" href="#term-layout" title="Link to this term">#</a></dt><dd><p>A <a class="reference internal" href="../generated/mne.channels.Layout.html#mne.channels.Layout" title="mne.channels.Layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layout</span></code></a> gives sensor positions in two
dimensions (defined by <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code>, and <code class="docutils literal notranslate"><span class="pre">height</span></code> values for
each sensor). It is primarily used for illustrative purposes (i.e., making
diagrams of approximate sensor positions in cartoons of the head,
so-called topographies or topomaps). See also <a class="reference internal" href="#term-montage"><span class="xref std std-term">montage</span></a>.</p>
</dd>
<dt id="term-LCMV">LCMV<a class="headerlink" href="#term-LCMV" title="Link to this term">#</a></dt><dt id="term-LCMV-beamformer">LCMV beamformer<a class="headerlink" href="#term-LCMV-beamformer" title="Link to this term">#</a></dt><dd><p>Linearly constrained minimum variance beamformer attempt to
estimate activity for a given source while suppressing cross-talk from
other regions (<a class="reference internal" href="../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">beamformer.make_lcmv()</span></code></a>). See also
<a class="reference internal" href="#term-beamformer"><span class="xref std std-term">beamformer</span></a>.</p>
</dd>
<dt id="term-maximum-intensity-projection">maximum intensity projection<a class="headerlink" href="#term-maximum-intensity-projection" title="Link to this term">#</a></dt><dd><p>A method to display pixel-wise activity within some volume by
finding the maximum value along a vector from the viewer to the pixel
(i.e., along the vector pependicular to the view plane).</p>
</dd>
<dt id="term-MNE">MNE<a class="headerlink" href="#term-MNE" title="Link to this term">#</a></dt><dt id="term-minimum-norm-estimate">minimum-norm estimate<a class="headerlink" href="#term-minimum-norm-estimate" title="Link to this term">#</a></dt><dt id="term-minimum-norm-estimation">minimum-norm estimation<a class="headerlink" href="#term-minimum-norm-estimation" title="Link to this term">#</a></dt><dd><p>Minimum-norm estimation (MNE) can be used to generate a distributed
map of activation on a <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a> (usually on a cortical surface).
MNE uses a linear <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> to project sensor measurements
into the source space. The <a class="reference internal" href="#term-inverse-operator"><span class="xref std std-term">inverse operator</span></a> is computed from the
<a class="reference internal" href="#term-forward-solution"><span class="xref std std-term">forward solution</span></a> for a subject and an estimate of the
<a class="reference internal" href="#term-noise-covariance"><span class="xref std std-term">noise covariance</span></a> of sensor measurements.</p>
</dd>
<dt id="term-montage">montage<a class="headerlink" href="#term-montage" title="Link to this term">#</a></dt><dd><p>EEG channel names and relative positions of sensors on the scalp.
While layouts are 2D locations, montages are 3D locations. A montage
can also contain locations for HPI points, fiducial points, or
extra head shape points.
See <a class="reference internal" href="../generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage"><code class="xref py py-class docutils literal notranslate"><span class="pre">DigMontage</span></code></a> for the class definition. See also
<a class="reference internal" href="#term-layout"><span class="xref std std-term">layout</span></a>.</p>
</dd>
<dt id="term-morphing">morphing<a class="headerlink" href="#term-morphing" title="Link to this term">#</a></dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is known as realignment in the fMRI
literature. This operation is necessary for group studies to get the
data into a common space for statistical analysis.
See <a class="reference internal" href="implementation.html#ch-morph"><span class="std std-ref">Morphing and averaging source estimates</span></a> for more details.</p>
</dd>
<dt id="term-noise-covariance">noise covariance<a class="headerlink" href="#term-noise-covariance" title="Link to this term">#</a></dt><dd><p>The noise covariance is a matrix that contains the covariance between data
channels. It is a square matrix with shape <code class="docutils literal notranslate"><span class="pre">n_channels</span></code> <span class="math notranslate nohighlight">\(\times\)</span>
<code class="docutils literal notranslate"><span class="pre">n_channels</span></code>. It is especially useful when working with multiple sensor
types (e.g. EEG and MEG). In practice, the matrix is estimated from baseline
periods or empty room measurements, and it also provides a noise model
that can be used for subsequent analysis (like source imaging).</p>
</dd>
<dt id="term-OPM">OPM<a class="headerlink" href="#term-OPM" title="Link to this term">#</a></dt><dt id="term-optically-pumped-magnetometer">optically pumped magnetometer<a class="headerlink" href="#term-optically-pumped-magnetometer" title="Link to this term">#</a></dt><dd><p>An optically pumped magnetometer (OPM) is a type of magnetometer
that uses a laser passing through a gas (e.g., rubidium) to sense
magnetic fluctuations. OPMs can operate near room temperature.</p>
</dd>
<dt id="term-path-like">path-like<a class="headerlink" href="#term-path-like" title="Link to this term">#</a></dt><dd><p>Something that acts like a path in a file system. This can be a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>
or a <a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pathlib.Path</span></code></a>.</p>
</dd>
<dt id="term-pick">pick<a class="headerlink" href="#term-pick" title="Link to this term">#</a></dt><dd><p>An integer that is the index of a channel in the <a class="reference internal" href="#term-measurement-info"><span class="xref std std-term">measurement info</span></a>.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector<a class="headerlink" href="#term-projector" title="Link to this term">#</a></dt><dt id="term-SSP">SSP<a class="headerlink" href="#term-SSP" title="Link to this term">#</a></dt><dd><p>A projector, also referred to as Signal Space
Projection (SSP), defines a linear operation applied spatially to EEG
or MEG data. A matrix multiplication of an SSP projector with the data
will reduce the rank of the data by projecting it to a
lower-dimensional subspace. Such projections are typically applied to
both the data and the forward operator when performing
source localization. Note that EEG average referencing can be done
using such a projection operator. Projectors are stored alongside data
in the <a class="reference internal" href="#term-measurement-info"><span class="xref std std-term">measurement info</span></a> in the field <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-RAS">RAS<a class="headerlink" href="#term-RAS" title="Link to this term">#</a></dt><dd><p>Right-Anterior-Superior, denoting the standard way to define coordinate
frames in MNE-Python:</p>
<dl class="simple">
<dt>R</dt><dd><p>+X is right, -X is left</p>
</dd>
<dt>A</dt><dd><p>+Y is anterior (front), -Y is posterior (rear)</p>
</dd>
<dt>S</dt><dd><p>+Z is superior (top), -Z is inferior (bottom)</p>
</dd>
</dl>
</dd>
<dt id="term-raw">raw<a class="headerlink" href="#term-raw" title="Link to this term">#</a></dt><dd><p><a class="reference internal" href="../generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Raw</span></code></a> objects hold continuous data (preprocessed or not), typically
obtained from reading recordings stored in a file.
See <a class="reference internal" href="../generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the class definition and <a class="reference internal" href="../auto_tutorials/raw/10_raw_overview.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a>
for a narrative overview.</p>
</dd>
<dt id="term-ROI">ROI<a class="headerlink" href="#term-ROI" title="Link to this term">#</a></dt><dt id="term-region-of-interest">region of interest<a class="headerlink" href="#term-region-of-interest" title="Link to this term">#</a></dt><dd><p>A spatial region where an experimental effect is expected to manifest.
This can be a collection of sensors or, when performing inverse imaging,
a set of vertices on the cortical surface or within the cortical volume.
See also <a class="reference internal" href="#term-label"><span class="xref std std-term">label</span></a>.</p>
</dd>
<dt id="term-selection">selection<a class="headerlink" href="#term-selection" title="Link to this term">#</a></dt><dd><p>A selection is a set of picked channels (for example, all sensors
falling within a <a class="reference internal" href="#term-region-of-interest"><span class="xref std std-term">region of interest</span></a>).</p>
</dd>
<dt id="term-source-space">source space<a class="headerlink" href="#term-source-space" title="Link to this term">#</a></dt><dd><p>A source space specifies where in the brain source amplitudes are
estimated. It corresponds to locations of a set of
candidate <a class="reference internal" href="#term-ECD"><span class="xref std std-term">equivalent current dipoles</span></a>. MNE-Python mostly
works with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See <a class="reference internal" href="../auto_tutorials/forward/30_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>
to read about how to compute a forward operator in a source space.
See <a class="reference internal" href="../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the class definition and information
about the data it contains.</p>
</dd>
<dt id="term-SQUID">SQUID<a class="headerlink" href="#term-SQUID" title="Link to this term">#</a></dt><dt id="term-superconducting-quantum-interference-device">superconducting quantum interference device<a class="headerlink" href="#term-superconducting-quantum-interference-device" title="Link to this term">#</a></dt><dd><p>A superconducting quantum interference device (SQUID) is a type of
magnetometer that uses superconducting materials to sense magnetic
fluctuations. Standard low-temperature SQUID sensors typically found
in MEG systems operate at temperatures within a few degrees of
absolute zero (e.g., below 4 K).</p>
</dd>
<dt id="term-STC">STC<a class="headerlink" href="#term-STC" title="Link to this term">#</a></dt><dt id="term-source-estimate">source estimate<a class="headerlink" href="#term-source-estimate" title="Link to this term">#</a></dt><dt id="term-source-time-course">source time course<a class="headerlink" href="#term-source-time-course" title="Link to this term">#</a></dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods such as <a class="reference internal" href="#term-dSPM"><span class="xref std std-term">dSPM</span></a>,
<a class="reference internal" href="#term-sLORETA"><span class="xref std std-term">sLORETA</span></a>, <a class="reference internal" href="#term-LCMV"><span class="xref std std-term">LCMV</span></a>, or MxNE.
STCs contain the amplitudes of the neural sources over time.
In MNE-Python, <a class="reference internal" href="../generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a> objects only store the
amplitudes of activation but not the locations of the sources. The
locations are stored separately in the <a class="reference internal" href="../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> object
that was used to compute the forward operator.
See <a class="reference internal" href="../generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>,
<a class="reference internal" href="../generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, and <a class="reference internal" href="../generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>.</p>
</dd>
<dt id="term-stim-channel">stim channel<a class="headerlink" href="#term-stim-channel" title="Link to this term">#</a></dt><dt id="term-trigger-channel">trigger channel<a class="headerlink" href="#term-trigger-channel" title="Link to this term">#</a></dt><dd><p>A stim channel or trigger channel is a channel that encodes
events during the recording. It is typically a channel that is always
zero and takes positive values when something happens (such as the
onset of a stimulus or a subject response). Stim channels are often
prefixed with <code class="docutils literal notranslate"><span class="pre">STI</span></code> to distinguish them from other channel types. See
<a class="reference internal" href="../auto_tutorials/intro/20_events_from_raw.html#stim-channel-defined"><span class="std std-ref">What is a STIM channel?</span></a> for more details.</p>
</dd>
<dt id="term-template-montage">template montage<a class="headerlink" href="#term-template-montage" title="Link to this term">#</a></dt><dd><p>An idealized EEG <a class="reference internal" href="#term-montage"><span class="xref std std-term">montage</span></a>, often provided by the manufacturer
of the EEG system or cap. The electrode positions were not actually
measured on the participantsâ€™ heads, but rather were calculated
assuming optimal theoretical placement on a sphere.</p>
</dd>
<dt id="term-tfr">tfr<a class="headerlink" href="#term-tfr" title="Link to this term">#</a></dt><dd><p>A time-frequency representation (TFR) is often a spectrogram (STFT) or
scaleogram (wavelet) showing the frequency content as a function of
time.</p>
</dd>
<dt id="term-trans">trans<a class="headerlink" href="#term-trans" title="Link to this term">#</a></dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
<dt id="term-whitening">whitening<a class="headerlink" href="#term-whitening" title="Link to this term">#</a></dt><dd><p>A linear operation that transforms data with a known covariance
structure into â€œwhitened dataâ€, which has a covariance structure equal to
the identity matrix. In other words, whitening creates virtual channels that
are uncorrelated and have unit variance. This is also known as a
sphering transformation.</p>
<p>The term â€œwhiteningâ€ comes from the fact that light with a flat
frequency spectrum in the visible range is white, whereas
non-uniform frequency spectra lead to perception of different colors
(e.g., â€œpink noiseâ€ has a <code class="docutils literal notranslate"><span class="pre">1/f</span></code> characteristic, which for visible
light would appear pink).</p>
</dd>
</dl>
</section>


  
</div>

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../auto_examples/datasets/spm_faces_dataset_sgskip.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">From raw data to dSPM on SPM Faces dataset</p>
      </div>
    </a>
    <a class="right-next"
       href="implementation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Algorithms and other implementation details</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  
  <div class="tocsection editthispage">
    <a href="https://github.com/mne-tools/mne-python/edit/main/doc/documentation/glossary.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

    <script src="https://mne.tools/versionwarning.js"></script>
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center text-muted small">&copy; Copyright 2012â€“2024, MNE Developers. Last updated <time datetime="2024-01-17T15:53:28.456158+00:00" class="localized">2024-01-17 15:53 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p></div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>