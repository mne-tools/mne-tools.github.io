<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Source reconstruction using an LCMV beamformer &#8212; MNE 0.22.1 documentation</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/bootstrap_divs.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    <script type="text/javascript" src="../../_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="../../_static/style.css " type="text/css" />
    <link rel="stylesheet" href="../../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/font-source-code-pro.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/font-source-sans-pro.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/flag-icon.css" type="text/css" />


    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>



  </head><body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/mne_logo_small.svg"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.22.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../install/index.html">Install</a></li>
                <li><a href="../../overview/index.html">Overview</a></li>
                <li><a href="../index.html">Tutorials</a></li>
                <li><a href="../../auto_examples/index.html">Examples</a></li>
                <li><a href="../../glossary.html">Glossary</a></li>
                <li><a href="../../python_reference.html">API</a></li>
            
            
            <li class="dropdown globaltoc-container">
              <a role="button" id="dLabelGlobalToc" data-toggle="dropdown" data-target="#" href="#">More<b class="caret"></b></a>
              <ul class="dropdown-menu globaltoc" role="menu" aria-labelledby="dLabelGlobalToc">
                <li><a href="https://github.com/mne-tools/mne-python"><i class="fa fa-github"></i> GitHub</a></li>
                <li><a href="../../overview/get_help.html"><i class="fa fa-question-circle"></i> Get help</a></li>
                <li><a href="../../install/contributing.html"><i class="fa fa-code-fork"></i> Contribute</a></li>
                <li><a href="../../overview/cite.html"><i class="fa fa-book"></i> Cite MNE</a></li>
              </ul>
            </li>

            <li class="dropdown">
              <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="dLabelMore" data-toggle="dropdown" style="margin-left: 10px">
              v0.22.1
              <span class="caret"></span>
            </button>
              <ul class="dropdown-menu" aria-labelledby="dLabelMore">
                <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
                <li><a href="https://mne-tools.github.io/stable/index.html">v0.22 (stable)</a></li>
                <li><a href="https://mne-tools.github.io/0.21/index.html">v0.21</a></li>
                <li><a href="https://mne-tools.github.io/0.20/index.html">v0.20</a></li>
                <li><a href="https://mne-tools.github.io/0.19/index.html">v0.19</a></li>
                <li><a href="https://mne-tools.github.io/0.18/index.html">v0.18</a></li>
                <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
                <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
                <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
                <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
                <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
                <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
                <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
              </ul>
            </li>

            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-source-modeling-plot-beamformer-lcmv-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="source-reconstruction-using-an-lcmv-beamformer">
<span id="sphx-glr-auto-tutorials-source-modeling-plot-beamformer-lcmv-py"></span><h1>Source reconstruction using an LCMV beamformer<a class="headerlink" href="#source-reconstruction-using-an-lcmv-beamformer" title="Permalink to this headline">Â¶</a></h1>
<p>This tutorial gives an overview of the beamformer method
and shows how to use an LCMV beamformer to reconstruct source activity.</p>
<div class="contents local topic" id="page-contents">
<p class="topic-title">Page contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction-to-beamformers" id="id5">Introduction to beamformers</a></p></li>
<li><p><a class="reference internal" href="#data-processing" id="id6">Data processing</a></p></li>
<li><p><a class="reference internal" href="#computing-the-covariance-matrices" id="id7">Computing the covariance matrices</a></p></li>
<li><p><a class="reference internal" href="#the-forward-model" id="id8">The forward model</a></p></li>
<li><p><a class="reference internal" href="#handling-depth-bias" id="id9">Handling depth bias</a></p></li>
<li><p><a class="reference internal" href="#compute-the-spatial-filter" id="id10">Compute the spatial filter</a></p></li>
<li><p><a class="reference internal" href="#apply-the-spatial-filter" id="id11">Apply the spatial filter</a></p></li>
<li><p><a class="reference internal" href="#visualize-the-reconstructed-source-activity" id="id12">Visualize the reconstructed source activity</a></p>
<ul>
<li><p><a class="reference internal" href="#on-mri-slices-orthoview-2d" id="id13">On MRI slices (orthoview; 2D)</a></p></li>
<li><p><a class="reference internal" href="#on-mni-glass-brain-orthoview-2d" id="id14">On MNI glass brain (orthoview; 2D)</a></p></li>
<li><p><a class="reference internal" href="#volumetric-rendering-3d-with-vectors" id="id15">Volumetric rendering (3D) with vectors</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#visualize-the-activity-of-the-maximum-voxel-with-all-three-components" id="id16">Visualize the activity of the maximum voxel with all three components</a></p></li>
<li><p><a class="reference internal" href="#morph-the-output-to-fsaverage" id="id17">Morph the output to fsaverage</a></p></li>
<li><p><a class="reference internal" href="#references" id="id18">References</a></p></li>
</ul>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Britta Westner &lt;britta.wstnr@gmail.com&gt;</span>
<span class="c1">#          Eric Larson &lt;larson.eric.d@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <span class="n">sample</span><span class="p">,</span> <a href="../../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a>
<span class="kn">from</span> <span class="nn">mne.beamformer</span> <span class="kn">import</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">,</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a>
</pre></div>
</div>
<section id="introduction-to-beamformers">
<h2><a class="toc-backref" href="#id5">Introduction to beamformers</a><a class="headerlink" href="#introduction-to-beamformers" title="Permalink to this headline">Â¶</a></h2>
<p>A beamformer is a spatial filter that reconstructs source activity by
scanning through a grid of pre-defined source points and estimating activity
at each of those source points independently. A set of weights is
constructed for each defined source location which defines the contribution
of each sensor to this source.
Beamformers are often used for their focal reconstructions and their ability
to reconstruct deeper sources. They can also suppress external noise sources.
The beamforming method applied in this tutorial is the linearly constrained
minimum variance (LCMV) beamformer <a class="footnote-reference brackets" href="#vanveenetal1997" id="id1">1</a> operates on
time series.
Frequency-resolved data can be reconstructed with the dynamic imaging of
coherent sources (DICS) beamforming method <a class="footnote-reference brackets" href="#grossetal2001" id="id2">2</a>.
As we will see in the following, the spatial filter is computed from two
ingredients: the forward model solution and the covariance matrix of the
data.</p>
</section>
<section id="data-processing">
<h2><a class="toc-backref" href="#id6">Data processing</a><a class="headerlink" href="#data-processing" title="Permalink to this headline">Â¶</a></h2>
<p>We will use the sample data set for this tutorial and reconstruct source
activity on the trials with left auditory stimulation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/subjects&#39;</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_filt-0-40_raw.fif&#39;</span>

<span class="c1"># Read the raw data</span>
<span class="n">raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="mne.io.read_raw_fif" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_fname</span></a><span class="p">)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;bads&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;MEG 2443&#39;</span><span class="p">]</span>  <span class="c1"># bad MEG channel</span>

<span class="c1"># Set up the epoching</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># those are the trials with left-ear auditory stimuli</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a> <span class="o">=</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span>
<a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="mne.find_events" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><span class="n">raw</span><span class="p">)</span>

<span class="c1"># pick relevant channels</span>
<span class="n">raw</span><span class="o">.</span><span class="n">pick</span><span class="p">([</span><span class="s1">&#39;meg&#39;</span><span class="p">,</span> <span class="s1">&#39;eog&#39;</span><span class="p">])</span>  <span class="c1"># pick channels of interest</span>

<span class="c1"># Create epochs</span>
<a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># already applied</span>
<span class="n">epochs</span> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">events</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">event_id</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="p">,</span>
                    <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">proj</span></a><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="mf">4000e-13</span><span class="p">,</span> <span class="n">mag</span><span class="o">=</span><span class="mf">4e-12</span><span class="p">,</span> <span class="n">eog</span><span class="o">=</span><span class="mf">150e-6</span><span class="p">))</span>

<span class="c1"># for speed purposes, cut to a window of interest</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">average</span><span class="p">()</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">)</span>

<span class="c1"># Visualize averaged sensor space data</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_joint" title="mne.EvokedArray.plot_joint" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">evoked</span><span class="o">.</span><span class="n">plot_joint</span></a><span class="p">()</span>

<span class="k">del</span> <span class="n">raw</span>  <span class="c1"># save memory</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="0.093 s" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_001.png" />
</li>
<li><img alt="0.093 s" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_002.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
        Average EEG reference (1 x 60)  idle
    Range : 6450 ... 48149 =     42.956 ...   320.665 secs
Ready.
319 events found
Event IDs: [ 1  2  3  4  5 32]
Removing projector &lt;Projection | Average EEG reference, active : False, n_channels : 60&gt;
Not setting metadata
Not setting metadata
72 matching events found
Setting baseline interval to [-0.19979521315838786, 0.0] sec
Applying baseline correction (mode: mean)
Created an SSP operator (subspace dimension = 3)
Loading data for 72 events and 106 original time points ...
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on MAG : [&#39;MEG 1711&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
17 bad epochs dropped
Created an SSP operator (subspace dimension = 3)
3 projection items activated
SSP projectors applied...
Removing projector &lt;Projection | PCA-v1, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v2, active : True, n_channels : 102&gt;
Removing projector &lt;Projection | PCA-v3, active : True, n_channels : 102&gt;
</pre></div>
</div>
</section>
<section id="computing-the-covariance-matrices">
<h2><a class="toc-backref" href="#id7">Computing the covariance matrices</a><a class="headerlink" href="#computing-the-covariance-matrices" title="Permalink to this headline">Â¶</a></h2>
<p>Spatial filters use the data covariance to estimate the filter
weights. The data covariance matrix will be <a class="reference external" href="https://en.wikipedia.org/wiki/Invertible_matrix">inverted</a> during the spatial
filter computation, so it is valuable to plot the covariance matrix and its
eigenvalues to gauge whether matrix inversion will be possible.
Also, because we want to combine different channel types (magnetometers and
gradiometers), we need to account for the different amplitude scales of these
channel types. To do this we will supply a noise covariance matrix to the
beamformer, which will be used for whitening.
The data covariance matrix should be estimated from a time window that
includes the brain signal of interest,
and incorporate enough samples for a stable estimate. A rule of thumb is to
use more samples than there are channels in the data set; see
<a class="footnote-reference brackets" href="#brookesetal2008" id="id3">3</a> for more detailed advice on covariance estimation
for beamformers. Here, we use a time
window incorporating the expected auditory response at around 100 ms post
stimulus and extend the period to account for a low number of trials (72) and
low sampling rate of 150 Hz.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span></a><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                                  <span class="n">method</span><span class="o">=</span><span class="s1">&#39;empirical&#39;</span><span class="p">)</span>
<a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_covariance</span></a><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                   <span class="n">method</span><span class="o">=</span><span class="s1">&#39;empirical&#39;</span><span class="p">)</span>
<a href="../../generated/mne.Covariance.html#mne.Covariance.plot" title="mne.Covariance.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">data_cov</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
<span class="k">del</span> <span class="n">epochs</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="Magnetometers covariance, Gradiometers covariance" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_003.png" />
</li>
<li><img alt="Magnetometers covariance, Gradiometers covariance" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_004.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from data with rank=None
    Using tolerance 4.1e-09 (2.2e-16 eps * 305 dim * 6.1e+04  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
    Created an SSP operator (subspace dimension = 3)
    Setting small MEG eigenvalues to zero (without PCA)
Reducing data rank from 305 -&gt; 302
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 2035
[done]
Computing rank from data with rank=None
    Using tolerance 2.8e-09 (2.2e-16 eps * 305 dim * 4.2e+04  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
    Created an SSP operator (subspace dimension = 3)
    Setting small MEG eigenvalues to zero (without PCA)
Reducing data rank from 305 -&gt; 302
Estimating covariance using EMPIRICAL
Done.
Number of samples used : 1705
[done]
Computing rank from covariance with rank=None
    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)
    Estimated rank (mag): 99
    MAG: rank 99 computed from 102 data channels with 0 projectors
Computing rank from covariance with rank=None
    Using tolerance 4.3e-13 (2.2e-16 eps * 203 dim * 9.4  max singular value)
    Estimated rank (grad): 203
    GRAD: rank 203 computed from 203 data channels with 0 projectors
</pre></div>
</div>
<p>When looking at the covariance matrix plots, we can see that our data is
slightly rank-deficient as the rank is not equal to the number of channels.
Thus, we will have to regularize the covariance matrix before inverting it
in the beamformer calculation. This can be achieved by setting the parameter
<code class="docutils literal notranslate"><span class="pre">reg=0.05</span></code> when calculating the spatial filter with
<a class="reference internal" href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_lcmv()</span></code></a>. This corresponds to loading the diagonal
of the covariance matrix with 5% of the sensor power.</p>
</section>
<section id="the-forward-model">
<h2><a class="toc-backref" href="#id8">The forward model</a><a class="headerlink" href="#the-forward-model" title="Permalink to this headline">Â¶</a></h2>
<p>The forward model is the other important ingredient for the computation of a
spatial filter. Here, we will load the forward model from disk; more
information on how to create a forward model can be found in this tutorial:
<a class="reference internal" href="plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a>.
Note that beamformers are usually computed in a <a class="reference internal" href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">volume</span> <span class="pre">source</span> <span class="pre">space</span></code></a>, because estimating only cortical surface
activation can misrepresent the data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read forward model</span>

<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fwd_fname</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_path</span></a> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis-meg-vol-7-fwd.fif&#39;</span>
<span class="n">forward</span> <span class="o">=</span> <a href="../../generated/mne.read_forward_solution.html#mne.read_forward_solution" title="mne.read_forward_solution" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_forward_solution</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fwd_fname</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading forward solution from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-vol-7-fwd.fif...
    Reading a source space...
    [done]
    1 source spaces read
    Desired named matrix (kind = 3523) not available
    Read MEG forward solution (3757 sources, 306 channels, free orientations)
    Source spaces transformed to the forward solution coordinate frame
</pre></div>
</div>
</section>
<section id="handling-depth-bias">
<h2><a class="toc-backref" href="#id9">Handling depth bias</a><a class="headerlink" href="#handling-depth-bias" title="Permalink to this headline">Â¶</a></h2>
<p>The forward model solution is inherently biased toward superficial sources.
When analyzing single conditions it is best to mitigate the depth bias
somehow. There are several ways to do this:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.beamformer.make_lcmv()</span></code></a> has a <code class="docutils literal notranslate"><span class="pre">depth</span></code> parameter that normalizes
the forward model prior to computing the spatial filters. See the docstring
for details.</p></li>
<li><p>Unit-noise gain beamformers handle depth bias by normalizing the
weights of the spatial filter. Choose this by setting
<code class="docutils literal notranslate"><span class="pre">weight_norm='unit-noise-gain'</span></code>.</p></li>
<li><p>When computing the Neural activity index, the depth bias is handled by
normalizing both the weights and the estimated noise (see
<a class="footnote-reference brackets" href="#vanveenetal1997" id="id4">1</a>). Choose this by setting <code class="docutils literal notranslate"><span class="pre">weight_norm='nai'</span></code>.</p></li>
</ul>
<p>Note that when comparing conditions, the depth bias will cancel out and it is
possible to set both parameters to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</section>
<section id="compute-the-spatial-filter">
<h2><a class="toc-backref" href="#id10">Compute the spatial filter</a><a class="headerlink" href="#compute-the-spatial-filter" title="Permalink to this headline">Â¶</a></h2>
<p>Now we can compute the spatial filter. Weâll use a unit-noise gain beamformer
to deal with depth bias, and will also optimize the orientation of the
sources such that output power is maximized.
This is achieved by setting <code class="docutils literal notranslate"><span class="pre">pick_ori='max-power'</span></code>.
This gives us one source estimate per source (i.e., voxel), which is known
as a scalar beamformer.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filters</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                    <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="o">=</span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="p">,</span> <span class="n">pick_ori</span><span class="o">=</span><span class="s1">&#39;max-power&#39;</span><span class="p">,</span>
                    <span class="n">weight_norm</span><span class="o">=</span><span class="s1">&#39;unit-noise-gain&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># You can save the filter for later use with:</span>
<span class="c1"># filters.save(&#39;filters-lcmv.h5&#39;)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from covariance with rank=None
    Using tolerance 7.1e-13 (2.2e-16 eps * 305 dim * 10  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Computing rank from covariance with rank=None
    Using tolerance 2.9e-13 (2.2e-16 eps * 305 dim * 4.3  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Making LCMV beamformer with rank {&#39;meg&#39;: 302}
Computing inverse operator with 305 channels.
    305 out of 306 channels remain after picking
Selected 305 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 3)
Computing rank from covariance with rank={&#39;meg&#39;: 302}
    Setting small MEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 3757 sources
Filter computation complete
</pre></div>
</div>
<p>It is also possible to compute a vector beamformer, which gives back three
estimates per voxel, corresponding to the three direction components of the
source. This can be achieved by setting
<code class="docutils literal notranslate"><span class="pre">pick_ori='vector'</span></code> and will yield a <a class="reference internal" href="../../generated/mne.VolVectorSourceEstimate.html#mne.VolVectorSourceEstimate" title="mne.VolVectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">volume</span> <span class="pre">vector</span> <span class="pre">source</span> <span class="pre">estimate</span></code></a>. So we will compute another set of filters
using the vector beamformer approach:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filters_vec</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.make_lcmv.html#mne.beamformer.make_lcmv" title="mne.beamformer.make_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">make_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">forward</span><span class="p">,</span> <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data_cov</span></a><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                        <a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="o">=</span><a href="../../generated/mne.Covariance.html#mne.Covariance" title="mne.Covariance" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">noise_cov</span></a><span class="p">,</span> <span class="n">pick_ori</span><span class="o">=</span><span class="s1">&#39;vector&#39;</span><span class="p">,</span>
                        <span class="n">weight_norm</span><span class="o">=</span><span class="s1">&#39;unit-noise-gain&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># save a bit of memory</span>
<a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a> <span class="o">=</span> <span class="n">forward</span><span class="p">[</span><span class="s1">&#39;src&#39;</span><span class="p">]</span>
<span class="k">del</span> <span class="n">forward</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing rank from covariance with rank=None
    Using tolerance 7.1e-13 (2.2e-16 eps * 305 dim * 10  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Computing rank from covariance with rank=None
    Using tolerance 2.9e-13 (2.2e-16 eps * 305 dim * 4.3  max singular value)
    Estimated rank (mag + grad): 302
    MEG: rank 302 computed from 305 data channels with 3 projectors
Making LCMV beamformer with rank {&#39;meg&#39;: 302}
Computing inverse operator with 305 channels.
    305 out of 306 channels remain after picking
Selected 305 channels
Whitening the forward solution.
    Created an SSP operator (subspace dimension = 3)
Computing rank from covariance with rank={&#39;meg&#39;: 302}
    Setting small MEG eigenvalues to zero (without PCA)
Creating the source covariance matrix
Adjusting source covariance matrix.
Computing beamformer filters for 3757 sources
Filter computation complete
</pre></div>
</div>
</section>
<section id="apply-the-spatial-filter">
<h2><a class="toc-backref" href="#id11">Apply the spatial filter</a><a class="headerlink" href="#apply-the-spatial-filter" title="Permalink to this headline">Â¶</a></h2>
<p>The spatial filter can be applied to different data types: raw, epochs,
evoked data or the data covariance matrix to gain a static image of power.
The function to apply the spatial filter to <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">Evoked</span></code></a> data is
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv()</span></code></a> which is
what we will use here. The other functions are
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_raw.html#mne.beamformer.apply_lcmv_raw" title="mne.beamformer.apply_lcmv_raw"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_raw()</span></code></a>,
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_epochs.html#mne.beamformer.apply_lcmv_epochs" title="mne.beamformer.apply_lcmv_epochs"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_epochs()</span></code></a>, and
<a class="reference internal" href="../../generated/mne.beamformer.apply_lcmv_cov.html#mne.beamformer.apply_lcmv_cov" title="mne.beamformer.apply_lcmv_cov"><code class="xref py py-func docutils literal notranslate"><span class="pre">apply_lcmv_cov()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">max_ori_out</span><span class="o">=</span><span class="s1">&#39;signed&#39;</span><span class="p">)</span>
<span class="n">stc_vec</span> <span class="o">=</span> <a href="../../generated/mne.beamformer.apply_lcmv.html#mne.beamformer.apply_lcmv" title="mne.beamformer.apply_lcmv" class="sphx-glr-backref-module-mne-beamformer sphx-glr-backref-type-py-function"><span class="n">apply_lcmv</span></a><span class="p">(</span><a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evoked</span></a><span class="p">,</span> <span class="n">filters_vec</span><span class="p">,</span> <span class="n">max_ori_out</span><span class="o">=</span><span class="s1">&#39;signed&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">filters</span><span class="p">,</span> <span class="n">filters_vec</span>
</pre></div>
</div>
</section>
<section id="visualize-the-reconstructed-source-activity">
<h2><a class="toc-backref" href="#id12">Visualize the reconstructed source activity</a><a class="headerlink" href="#visualize-the-reconstructed-source-activity" title="Permalink to this headline">Â¶</a></h2>
<p>We can visualize the source estimate in different ways, e.g. as a volume
rendering, an overlay onto the MRI, or as an overlay onto a glass brain.</p>
<p>The plots for the scalar beamformer show brain activity in the right temporal
lobe around 100 ms post stimulus. This is expected given the left-ear
auditory stimulation of the experiment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="p">,</span> <span class="n">subject</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
              <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.087</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<section id="on-mri-slices-orthoview-2d">
<h3><a class="toc-backref" href="#id13">On MRI slices (orthoview; 2D)</a><a class="headerlink" href="#on-mri-slices-orthoview-2d" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;stat_map&#39;</span><span class="p">,</span> <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">pos_lims</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="plot beamformer lcmv" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_005.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Fixing initial time: 0.087 sec
Showing: t = 0.087 s, (50.7, 2.0, -13.3) mm, [18, 12, 9] vox, 5184 vertex
</pre></div>
</div>
</section>
<section id="on-mni-glass-brain-orthoview-2d">
<h3><a class="toc-backref" href="#id14">On MNI glass brain (orthoview; 2D)</a><a class="headerlink" href="#on-mni-glass-brain-orthoview-2d" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;glass_brain&#39;</span><span class="p">,</span> <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="plot beamformer lcmv" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_006.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Transforming subject RAS (non-zero origin) -&gt; MNI Talairach
     1.022485 -0.008449 -0.036217       5.60 mm
     0.071071  0.914866  0.406098     -19.82 mm
     0.008756 -0.433700  1.028119      -1.55 mm
     0.000000  0.000000  0.000000       1.00

Fixing initial time: 0.087 sec
Showing: t = 0.087 s, (57.9, -19.7, -15.6) mm, [18, 12, 9] vox, 5184 vertex
</pre></div>
</div>
</section>
<section id="volumetric-rendering-3d-with-vectors">
<h3><a class="toc-backref" href="#id15">Volumetric rendering (3D) with vectors</a><a class="headerlink" href="#volumetric-rendering-3d-with-vectors" title="Permalink to this headline">Â¶</a></h3>
<p>These plots can also be shown using a volumetric rendering via
<a class="reference internal" href="../../generated/mne.VolVectorSourceEstimate.html#mne.VolVectorSourceEstimate.plot_3d" title="mne.VolVectorSourceEstimate.plot_3d"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_3d()</span></code></a>. Letâs try visualizing the
vector beamformer case. Here we get three source time courses out per voxel
(one for each component of the dipole moment: x, y, and z), which appear
as small vectors in the visualization (in the 2D plotters, only the
magnitude can be shown):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <span class="n">stc_vec</span><span class="o">.</span><span class="n">plot_3d</span><span class="p">(</span>
    <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span>
    <span class="n">views</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;coronal&#39;</span><span class="p">,</span> <span class="s1">&#39;sagittal&#39;</span><span class="p">,</span> <span class="s1">&#39;axial&#39;</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>
    <span class="n">view_layout</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span> <span class="n">show_traces</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img alt="plot beamformer lcmv" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_007.png" />
</section>
</section>
<section id="visualize-the-activity-of-the-maximum-voxel-with-all-three-components">
<h2><a class="toc-backref" href="#id16">Visualize the activity of the maximum voxel with all three components</a><a class="headerlink" href="#visualize-the-activity-of-the-maximum-voxel-with-all-three-components" title="Permalink to this headline">Â¶</a></h2>
<p>We can also visualize all three components in the peak voxel. For this, we
will first find the peak voxel and then plot the time courses of this voxel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">peak_vox</span></a><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">_</span></a> <span class="o">=</span> <span class="n">stc_vec</span><span class="o">.</span><span class="n">get_peak</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmin</span></a><span class="o">=</span><span class="mf">0.08</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tmax</span></a><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">vert_as_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori_labels</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">]</span>
<a href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">stc_vec</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">peak_vox</span></a><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori_labels</span></a><span class="p">):</span>
    <a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot" title="matplotlib.axes.Axes.plot" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">stc_vec</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ori</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> component&#39;</span> <span class="o">%</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">label</span></a><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.legend.html#matplotlib.axes.Axes.legend" title="matplotlib.axes.Axes.legend" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">legend</span></a><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.artist.Artist.set.html#matplotlib.artist.Artist.set" title="matplotlib.artist.Artist.set" class="sphx-glr-backref-module-matplotlib-artist sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set</span></a><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Activity per orientation in the peak voxel&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Time (s)&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Amplitude (a. u.)&#39;</span><span class="p">)</span>
<span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plt_show</span><span class="p">()</span>
<span class="k">del</span> <span class="n">stc_vec</span>
</pre></div>
</div>
<img alt="Activity per orientation in the peak voxel" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_008.png" />
</section>
<section id="morph-the-output-to-fsaverage">
<h2><a class="toc-backref" href="#id17">Morph the output to fsaverage</a><a class="headerlink" href="#morph-the-output-to-fsaverage" title="Permalink to this headline">Â¶</a></h2>
<p>We can also use volumetric morphing to get the data to fsaverage space. This
is for example necessary when comparing activity across subjects. Here, we
will use the scalar beamformer example.
We pass a <a class="reference internal" href="../../generated/mne.SourceMorph.html#mne.SourceMorph" title="mne.SourceMorph"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.SourceMorph</span></code></a> as the <code class="docutils literal notranslate"><span class="pre">src</span></code> argument to
<a class="reference internal" href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate.plot" title="mne.VolSourceEstimate.plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.VolSourceEstimate.plot</span></code></a>. To save some computational load when applying
the morph, we will crop the <code class="docutils literal notranslate"><span class="pre">stc</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">)</span>  <span class="c1"># ensure fsaverage src exists</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_fs_src</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">+</span> <span class="s1">&#39;/fsaverage/bem/fsaverage-vol-5-src.fif&#39;</span>

<a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a> <span class="o">=</span> <a href="../../generated/mne.read_source_spaces.html#mne.read_source_spaces" title="mne.read_source_spaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">read_source_spaces</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fname_fs_src</span></a><span class="p">)</span>
<a href="../../generated/mne.SourceMorph.html#mne.SourceMorph" title="mne.SourceMorph" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">morph</span></a> <span class="o">=</span> <a href="../../generated/mne.compute_source_morph.html#mne.compute_source_morph" title="mne.compute_source_morph" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">compute_source_morph</span></a><span class="p">(</span>
    <a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="p">,</span> <span class="n">subject_from</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span><span class="p">,</span> <span class="n">src_to</span><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
    <span class="n">niter_sdr</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">niter_affine</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>  <span class="c1"># just for speed</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stc_fs</span></a> <span class="o">=</span> <a href="../../generated/mne.SourceMorph.html#mne.SourceMorph.apply" title="mne.SourceMorph.apply" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">morph</span><span class="o">.</span><span class="n">apply</span></a><span class="p">(</span><span class="n">stc</span><span class="p">)</span>
<span class="k">del</span> <span class="n">stc</span>

<a href="../../generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate.plot" title="mne.VolSourceEstimate.plot" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">stc_fs</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span>
    <a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src</span></a><span class="o">=</span><a href="../../generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">src_fs</span></a><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;stat_map&#39;</span><span class="p">,</span> <span class="n">initial_time</span><span class="o">=</span><span class="mf">0.085</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span>
    <span class="n">clim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">pos_lims</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lims</span></a><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot beamformer lcmv" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_beamformer_lcmv_009.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>12 files missing from /home/circleci/project/mne/datasets/_fsaverage/root.txt in /home/circleci/mne_data/MNE-sample-data/subjects
Downloading missing files remotely
Downloading https://files.osf.io/v1/resources/rxvq7/providers/osfstorage/5cbdba4ef2be3c0019091890?revision=2&amp;action=download&amp;direct&amp;version=2 (186.7 MB)

  0%|          | Downloading : 0.00/187M [00:00&lt;?,        ?B/s]
  0%|          | Downloading : 248k/187M [00:00&lt;00:13,    15.0MB/s]
  1%|          | Downloading : 0.99M/187M [00:00&lt;00:06,    27.9MB/s]
  1%|1         | Downloading : 2.49M/187M [00:00&lt;00:03,    49.8MB/s]
  2%|2         | Downloading : 4.49M/187M [00:00&lt;00:07,    24.8MB/s]
  3%|2         | Downloading : 5.49M/187M [00:00&lt;00:09,    19.8MB/s]
  3%|3         | Downloading : 6.49M/187M [00:00&lt;00:10,    18.3MB/s]
  4%|4         | Downloading : 7.49M/187M [00:00&lt;00:09,    19.6MB/s]
  5%|5         | Downloading : 9.49M/187M [00:00&lt;00:07,    24.1MB/s]
  6%|6         | Downloading : 11.5M/187M [00:00&lt;00:06,    28.2MB/s]
  8%|7         | Downloading : 14.5M/187M [00:00&lt;00:06,    27.9MB/s]
  8%|8         | Downloading : 15.5M/187M [00:00&lt;00:07,    24.9MB/s]
  9%|8         | Downloading : 16.5M/187M [00:00&lt;00:07,    23.3MB/s]
  9%|9         | Downloading : 17.5M/187M [00:00&lt;00:08,    21.7MB/s]
 10%|9         | Downloading : 18.5M/187M [00:00&lt;00:07,    22.5MB/s]
 11%|#         | Downloading : 20.5M/187M [00:00&lt;00:06,    25.0MB/s]
 12%|#1        | Downloading : 21.5M/187M [00:00&lt;00:06,    25.9MB/s]
 13%|#2        | Downloading : 23.5M/187M [00:00&lt;00:06,    28.5MB/s]
 14%|#3        | Downloading : 25.5M/187M [00:00&lt;00:05,    31.0MB/s]
 16%|#5        | Downloading : 29.5M/187M [00:00&lt;00:04,    36.5MB/s]
 18%|#7        | Downloading : 33.5M/187M [00:00&lt;00:03,    41.8MB/s]
 19%|#9        | Downloading : 35.5M/187M [00:01&lt;00:03,    44.1MB/s]
 20%|##        | Downloading : 37.5M/187M [00:01&lt;00:03,    46.5MB/s]
 22%|##2       | Downloading : 41.5M/187M [00:01&lt;00:02,    51.3MB/s]
 24%|##4       | Downloading : 45.5M/187M [00:01&lt;00:02,    55.7MB/s]
 25%|##5       | Downloading : 47.5M/187M [00:01&lt;00:02,    57.4MB/s]
 28%|##7       | Downloading : 51.5M/187M [00:01&lt;00:02,    53.9MB/s]
 29%|##8       | Downloading : 53.5M/187M [00:01&lt;00:02,    49.1MB/s]
 30%|###       | Downloading : 56.5M/187M [00:01&lt;00:02,    51.9MB/s]
 32%|###2      | Downloading : 60.5M/187M [00:01&lt;00:02,    55.5MB/s]
 35%|###4      | Downloading : 64.5M/187M [00:01&lt;00:02,    59.0MB/s]
 36%|###5      | Downloading : 66.5M/187M [00:01&lt;00:02,    55.2MB/s]
 37%|###6      | Downloading : 68.5M/187M [00:01&lt;00:02,    53.7MB/s]
 38%|###7      | Downloading : 70.5M/187M [00:01&lt;00:02,    55.3MB/s]
 40%|###9      | Downloading : 74.5M/187M [00:01&lt;00:02,    58.7MB/s]
 42%|####2     | Downloading : 78.5M/187M [00:01&lt;00:01,    62.2MB/s]
 44%|####4     | Downloading : 82.5M/187M [00:01&lt;00:01,    65.2MB/s]
 46%|####6     | Downloading : 86.5M/187M [00:01&lt;00:01,    68.2MB/s]
 48%|####8     | Downloading : 90.5M/187M [00:01&lt;00:01,    71.2MB/s]
 51%|#####     | Downloading : 94.5M/187M [00:01&lt;00:01,    74.0MB/s]
 53%|#####2    | Downloading : 98.5M/187M [00:01&lt;00:01,    76.7MB/s]
 55%|#####4    | Downloading : 102M/187M [00:01&lt;00:01,    79.7MB/s]
 57%|#####7    | Downloading : 106M/187M [00:01&lt;00:01,    83.3MB/s]
 59%|#####9    | Downloading : 110M/187M [00:01&lt;00:00,    86.6MB/s]
 61%|######1   | Downloading : 114M/187M [00:01&lt;00:00,    89.0MB/s]
 63%|######3   | Downloading : 118M/187M [00:01&lt;00:00,    91.0MB/s]
 66%|######5   | Downloading : 122M/187M [00:01&lt;00:00,    92.1MB/s]
 68%|######7   | Downloading : 126M/187M [00:02&lt;00:00,    73.7MB/s]
 69%|######8   | Downloading : 128M/187M [00:02&lt;00:00,    74.8MB/s]
 71%|#######   | Downloading : 132M/187M [00:02&lt;00:00,    77.3MB/s]
 72%|#######2  | Downloading : 134M/187M [00:02&lt;00:00,    78.4MB/s]
 73%|#######3  | Downloading : 136M/187M [00:02&lt;00:00,    79.4MB/s]
 75%|#######5  | Downloading : 140M/187M [00:02&lt;00:00,    81.6MB/s]
 76%|#######6  | Downloading : 142M/187M [00:02&lt;00:00,    82.6MB/s]
 77%|#######7  | Downloading : 144M/187M [00:02&lt;00:00,    83.7MB/s]
 78%|#######8  | Downloading : 146M/187M [00:02&lt;00:00,    84.5MB/s]
 80%|#######9  | Downloading : 148M/187M [00:02&lt;00:00,    85.3MB/s]
 81%|########  | Downloading : 150M/187M [00:02&lt;00:00,    86.1MB/s]
 83%|########2 | Downloading : 154M/187M [00:02&lt;00:00,    88.3MB/s]
 85%|########4 | Downloading : 158M/187M [00:02&lt;00:00,    91.0MB/s]
 86%|########5 | Downloading : 160M/187M [00:02&lt;00:00,    91.6MB/s]
 87%|########7 | Downloading : 162M/187M [00:02&lt;00:00,    92.4MB/s]
 89%|########9 | Downloading : 166M/187M [00:02&lt;00:00,    94.6MB/s]
 90%|######### | Downloading : 168M/187M [00:02&lt;00:00,    95.3MB/s]
 91%|#########1| Downloading : 170M/187M [00:02&lt;00:00,    96.2MB/s]
 93%|#########3| Downloading : 174M/187M [00:02&lt;00:00,    98.4MB/s]
 96%|#########5| Downloading : 178M/187M [00:02&lt;00:00,     101MB/s]
 98%|#########7| Downloading : 182M/187M [00:02&lt;00:00,     104MB/s]
100%|#########9| Downloading : 186M/187M [00:02&lt;00:00,     107MB/s]
100%|##########| Downloading : 187M/187M [00:02&lt;00:00,    74.2MB/s]
Verifying hash 5133fe92b7b8f03ae19219d5f46e4177.
File saved as /tmp/tmpxwlwzj2o/temp.zip.

Extracting missing files
Successfully extracted 12 files
10 files missing from /home/circleci/project/mne/datasets/_fsaverage/bem.txt in /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage
Downloading missing files remotely
Downloading https://files.osf.io/v1/resources/rxvq7/providers/osfstorage/5cbdb9f5353c58001aa02025?revision=4&amp;action=download&amp;direct&amp;version=4 (227.8 MB)

  0%|          | Downloading : 0.00/228M [00:00&lt;?,        ?B/s]
  0%|          | Downloading : 120k/228M [00:00&lt;00:31,    7.62MB/s]
  0%|          | Downloading : 568k/228M [00:00&lt;00:16,    14.8MB/s]
  1%|          | Downloading : 1.30M/228M [00:00&lt;00:10,    23.6MB/s]
  1%|1         | Downloading : 2.80M/228M [00:00&lt;00:06,    37.0MB/s]
  2%|2         | Downloading : 4.80M/228M [00:00&lt;00:06,    34.5MB/s]
  3%|2         | Downloading : 5.80M/228M [00:00&lt;00:06,    34.1MB/s]
  3%|2         | Downloading : 6.80M/228M [00:00&lt;00:06,    33.7MB/s]
  3%|3         | Downloading : 7.80M/228M [00:00&lt;00:06,    35.6MB/s]
  4%|3         | Downloading : 8.80M/228M [00:00&lt;00:06,    37.2MB/s]
  5%|4         | Downloading : 10.8M/228M [00:00&lt;00:05,    41.3MB/s]
  6%|6         | Downloading : 13.8M/228M [00:00&lt;00:04,    45.5MB/s]
  7%|6         | Downloading : 15.8M/228M [00:00&lt;00:04,    48.9MB/s]
  9%|8         | Downloading : 19.8M/228M [00:00&lt;00:03,    56.6MB/s]
 10%|9         | Downloading : 21.8M/228M [00:00&lt;00:03,    59.6MB/s]
 10%|#         | Downloading : 23.8M/228M [00:00&lt;00:03,    62.6MB/s]
 11%|#1        | Downloading : 25.8M/228M [00:00&lt;00:03,    64.2MB/s]
 12%|#2        | Downloading : 27.8M/228M [00:00&lt;00:03,    66.6MB/s]
 13%|#3        | Downloading : 29.8M/228M [00:00&lt;00:03,    68.8MB/s]
 14%|#3        | Downloading : 31.8M/228M [00:00&lt;00:02,    71.6MB/s]
 15%|#4        | Downloading : 33.8M/228M [00:00&lt;00:02,    73.5MB/s]
 16%|#5        | Downloading : 35.8M/228M [00:00&lt;00:02,    74.9MB/s]
 17%|#6        | Downloading : 37.8M/228M [00:00&lt;00:02,    77.5MB/s]
 17%|#7        | Downloading : 39.8M/228M [00:00&lt;00:02,    78.7MB/s]
 18%|#8        | Downloading : 41.8M/228M [00:00&lt;00:02,    80.6MB/s]
 19%|#9        | Downloading : 43.8M/228M [00:00&lt;00:02,    81.5MB/s]
 20%|##        | Downloading : 45.8M/228M [00:00&lt;00:02,    79.3MB/s]
 21%|##        | Downloading : 47.8M/228M [00:00&lt;00:02,    79.6MB/s]
 22%|##1       | Downloading : 49.8M/228M [00:00&lt;00:02,    80.4MB/s]
 23%|##2       | Downloading : 51.8M/228M [00:00&lt;00:02,    81.5MB/s]
 25%|##4       | Downloading : 55.8M/228M [00:00&lt;00:02,    86.2MB/s]
 27%|##7       | Downloading : 61.8M/228M [00:00&lt;00:01,    94.5MB/s]
 29%|##8       | Downloading : 65.8M/228M [00:00&lt;00:01,    98.4MB/s]
 31%|###       | Downloading : 69.8M/228M [00:00&lt;00:01,     102MB/s]
 32%|###2      | Downloading : 73.8M/228M [00:00&lt;00:01,     104MB/s]
 34%|###4      | Downloading : 77.8M/228M [00:00&lt;00:01,     108MB/s]
 36%|###5      | Downloading : 81.8M/228M [00:00&lt;00:01,     109MB/s]
 38%|###7      | Downloading : 85.8M/228M [00:00&lt;00:01,     109MB/s]
 39%|###9      | Downloading : 89.8M/228M [00:01&lt;00:01,     110MB/s]
 41%|####1     | Downloading : 93.8M/228M [00:01&lt;00:01,     111MB/s]
 43%|####2     | Downloading : 97.8M/228M [00:01&lt;00:01,     112MB/s]
 45%|####4     | Downloading : 102M/228M [00:01&lt;00:01,     111MB/s]
 46%|####6     | Downloading : 106M/228M [00:01&lt;00:01,     109MB/s]
 48%|####8     | Downloading : 110M/228M [00:01&lt;00:01,     109MB/s]
 50%|####9     | Downloading : 114M/228M [00:01&lt;00:01,     109MB/s]
 52%|#####1    | Downloading : 118M/228M [00:01&lt;00:01,     109MB/s]
 53%|#####3    | Downloading : 122M/228M [00:01&lt;00:01,     110MB/s]
 55%|#####5    | Downloading : 126M/228M [00:01&lt;00:00,     110MB/s]
 57%|#####6    | Downloading : 130M/228M [00:01&lt;00:00,     112MB/s]
 59%|#####8    | Downloading : 134M/228M [00:01&lt;00:00,     114MB/s]
 61%|######    | Downloading : 138M/228M [00:01&lt;00:00,     115MB/s]
 62%|######2   | Downloading : 142M/228M [00:01&lt;00:00,     114MB/s]
 64%|######4   | Downloading : 146M/228M [00:01&lt;00:00,     113MB/s]
 66%|######5   | Downloading : 150M/228M [00:01&lt;00:00,     113MB/s]
 68%|######7   | Downloading : 154M/228M [00:01&lt;00:00,     113MB/s]
 69%|######9   | Downloading : 158M/228M [00:01&lt;00:00,     113MB/s]
 71%|#######1  | Downloading : 162M/228M [00:01&lt;00:00,     115MB/s]
 73%|#######2  | Downloading : 166M/228M [00:01&lt;00:00,     117MB/s]
 75%|#######4  | Downloading : 170M/228M [00:01&lt;00:00,     119MB/s]
 76%|#######6  | Downloading : 174M/228M [00:01&lt;00:00,     122MB/s]
 78%|#######8  | Downloading : 178M/228M [00:01&lt;00:00,     122MB/s]
 80%|#######9  | Downloading : 182M/228M [00:01&lt;00:00,     121MB/s]
 82%|########1 | Downloading : 186M/228M [00:01&lt;00:00,     120MB/s]
 83%|########3 | Downloading : 190M/228M [00:01&lt;00:00,     119MB/s]
 85%|########5 | Downloading : 194M/228M [00:01&lt;00:00,     118MB/s]
 87%|########6 | Downloading : 198M/228M [00:01&lt;00:00,     118MB/s]
 89%|########8 | Downloading : 202M/228M [00:02&lt;00:00,     119MB/s]
 90%|######### | Downloading : 206M/228M [00:02&lt;00:00,     118MB/s]
 92%|#########2| Downloading : 210M/228M [00:02&lt;00:00,     119MB/s]
 94%|#########3| Downloading : 214M/228M [00:02&lt;00:00,     118MB/s]
 96%|#########5| Downloading : 218M/228M [00:02&lt;00:00,     117MB/s]
 97%|#########7| Downloading : 222M/228M [00:02&lt;00:00,     116MB/s]
 99%|#########9| Downloading : 226M/228M [00:02&lt;00:00,     115MB/s]
100%|##########| Downloading : 228M/228M [00:02&lt;00:00,     115MB/s]
100%|##########| Downloading : 228M/228M [00:02&lt;00:00,     106MB/s]
Verifying hash b31509cdcf7908af6a83dc5ee8f49fb1.
File saved as /tmp/tmpcrdnwp0q/temp.zip.

Extracting missing files
Successfully extracted 10 files
    Reading a source space...
    [done]
    1 source spaces read
Volume source space(s) present...
    Loading /home/circleci/mne_data/MNE-sample-data/subjects/sample/mri/brain.mgz as &quot;from&quot; volume
    Loading /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage/mri/brain.mgz as &quot;to&quot; volume
Computing nonlinear Symmetric Diffeomorphic Registration...
Optimizing translation:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
Optimizing rigid-body:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
    Translation:   22.7 mm
    Rotation:      20.7Â°
    RÂ²:            96.5%
Optimizing full affine:
    Optimizing level 2 [max iter: 10]
    Optimizing level 1 [max iter: 10]
    Optimizing level 0 [max iter: 5]
    RÂ²:            96.9%
Optimizing SDR:
    RÂ²:            99.0%
[done]

  0%|          | Time : 0/16 [00:00&lt;?,       ?it/s]
  6%|6         | Time : 1/16 [00:00&lt;00:01,    8.37it/s]
 12%|#2        | Time : 2/16 [00:00&lt;00:01,    9.08it/s]
 19%|#8        | Time : 3/16 [00:00&lt;00:01,    9.39it/s]
 25%|##5       | Time : 4/16 [00:00&lt;00:01,    9.54it/s]
 31%|###1      | Time : 5/16 [00:00&lt;00:01,    9.63it/s]
 38%|###7      | Time : 6/16 [00:00&lt;00:01,    9.70it/s]
 44%|####3     | Time : 7/16 [00:00&lt;00:00,    9.74it/s]
 50%|#####     | Time : 8/16 [00:00&lt;00:00,    9.78it/s]
 56%|#####6    | Time : 9/16 [00:00&lt;00:00,    9.81it/s]
 62%|######2   | Time : 10/16 [00:01&lt;00:00,    9.83it/s]
 69%|######8   | Time : 11/16 [00:01&lt;00:00,    9.84it/s]
 75%|#######5  | Time : 12/16 [00:01&lt;00:00,    9.86it/s]
 81%|########1 | Time : 13/16 [00:01&lt;00:00,    9.87it/s]
 88%|########7 | Time : 14/16 [00:01&lt;00:00,    9.87it/s]
 94%|#########3| Time : 15/16 [00:01&lt;00:00,    9.89it/s]
100%|##########| Time : 16/16 [00:01&lt;00:00,    9.90it/s]
100%|##########| Time : 16/16 [00:01&lt;00:00,    9.85it/s]
Fixing initial time: 0.085 sec
Showing: t = 0.087 s, (50.0, -20.0, -15.0) mm, [26, 19, 12] vox, 16097 vertex
</pre></div>
</div>
</section>
<section id="references">
<h2><a class="toc-backref" href="#id18">References</a><a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="vanveenetal1997"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>BarryÂ D. VanÂ Veen, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki. Localization of brain electrical activity via linearly constrained minimum variance spatial filtering. <em>IEEE Transactions on Biomedical Engineering</em>, 44(9):867â880, 1997. <a class="reference external" href="https://doi.org/10.1109/10.623056">doi:10.1109/10.623056</a>.</p>
</dd>
<dt class="label" id="grossetal2001"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Joachim GroÃ, Jan Kujala, MattiÂ S. HÃ¤mÃ¤lÃ¤inen, Lars Timmermann, Alfons Schnitzler, and Riitta Salmelin. Dynamic imaging of coherent sources: studying neural interactions in the human brain. <em>Proceedings of the National Academy of Sciences</em>, 98(2):694â699, 2001. <a class="reference external" href="https://doi.org/10.1073/pnas.98.2.694">doi:10.1073/pnas.98.2.694</a>.</p>
</dd>
<dt class="label" id="brookesetal2008"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>MatthewÂ J. Brookes, Jiri Vrba, StephenÂ E. Robinson, ClaireÂ M. Stevenson, AndrewÂ M. Peters, GarethÂ R. Barnes, Arjan Hillebrand, and PeterÂ G. Morris. Optimising experimental design for MEG beamformer imaging. <em>NeuroImage</em>, 39(4):1788â1802, 2008. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2007.09.050">doi:10.1016/j.neuroimage.2007.09.050</a>.</p>
</dd>
</dl>
</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  23.636 seconds)</p>
<p><strong>Estimated memory usage:</strong>  867 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-source-modeling-plot-beamformer-lcmv-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5eb07454cc61e69bb753495d09354a86/plot_beamformer_lcmv.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_beamformer_lcmv.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/34fd5b71616977c61ebac55c010819c1/plot_beamformer_lcmv.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_beamformer_lcmv.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container"><div class="row">
    <div class="container col-md-12 institutions">
      <ul class="list-unstyled">
        <li><a href="https://www.massgeneral.org/"><img class="institution" src="../../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a></li>
        <li><a href="https://martinos.org/"><img class="institution" src="../../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a></li>
        <li><a href="https://hms.harvard.edu/"><img class="institution" src="../../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a></li>
        <li><a href="https://web.mit.edu/"><img class="institution" src="../../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a></li>
        <li><a href="https://www.nyu.edu/"><img class="institution" src="../../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a></li>
        <li><a href="http://www.cea.fr/"><img class="institution" src="../../_static/institution_logos/CEA.png" title="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives" alt="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives"/></a></li>
        <li><a href="https://sci.aalto.fi/"><img class="institution" src="../../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a></li>
        <li><a href="https://www.telecom-paris.fr/"><img class="institution" src="../../_static/institution_logos/Telecom_Paris_Tech.png" title="TÃ©lÃ©com ParisTech" alt="TÃ©lÃ©com ParisTech"/></a></li>
        <li><a href="https://www.washington.edu/"><img class="institution" src="../../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a></li>
        <li><a href="https://icm-institute.org/"><img class="institution" src="../../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle Ã©piniÃ¨re" alt="Institut du Cerveau et de la Moelle Ã©piniÃ¨re"/></a></li>
        <li><a href="https://www.bu.edu/"><img class="institution" src="../../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a></li>
        <li><a href="https://www.inserm.fr/"><img class="institution" src="../../_static/institution_logos/Inserm.svg" title="Institut national de la santÃ© et de la recherche mÃ©dicale" alt="Institut national de la santÃ© et de la recherche mÃ©dicale"/></a></li>
        <li><a href="https://www.fz-juelich.de/"><img class="institution" src="../../_static/institution_logos/Julich.svg" title="Forschungszentrum JÃ¼lich" alt="Forschungszentrum JÃ¼lich"/></a></li>
        <li><a href="https://www.tu-ilmenau.de/"><img class="institution" src="../../_static/institution_logos/Ilmenau.gif" title="Technische UniversitÃ¤t Ilmenau" alt="Technische UniversitÃ¤t Ilmenau"/></a></li>
        <li><a href="https://bids.berkeley.edu/"><img class="institution" src="../../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a></li>
        <li><a href="https://www.inria.fr/"><img class="institution" src="../../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a></li>
        <li><a href="https://www.au.dk/"><img class="institution" src="../../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a></li>
        <li><a href="https://www.uni-graz.at/"><img class="institution" src="../../_static/institution_logos/Graz.jpg" title="Karl-Franzens-UniversitÃ¤t Graz" alt="Karl-Franzens-UniversitÃ¤t Graz"/></a></li>
      </ul>
      <p class="text-center text-muted small">&copy; Copyright 2012-2021, MNE Developers. Last updated <time datetime="2021-04-02T17:37:54.428702+00:00" class="localized">2021-04-02 17:37 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
    </div></div></div>
  </footer>
  <script src="https://mne.tools/versionwarning.js"></script>
  </body>
</html>