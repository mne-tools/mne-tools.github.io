
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Single trial linear regression analysis with the LIMO dataset &#8212; MNE 1.1.1 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=19ec7dda39a41ce4efdb" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=19ec7dda39a41ce4efdb" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=19ec7dda39a41ce4efdb">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.google-analytics.com/analytics.js"></script>
    <script>
                    window.ga = window.ga || function () {
                        (ga.q = ga.q || []).push(arguments) };
                    ga.l = +new Date;
                    ga('create', 'UA-37225609-1', 'auto');
                    ga('set', 'anonymizeIp', true);
                    ga('send', 'pageview');
                </script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Optically pumped magnetometer (OPM) data" href="opm_data.html" />
    <link rel="prev" title="HF-SEF dataset" href="hf_sef_data.html" />
    <link rel="canonical" href="https://mne.tools/stable/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">

  <!-- checkbox to toggle primary sidebar -->
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  <!-- Checkboxes to toggle the secondary sidebar -->
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  <!-- A search field pop-up that will only show when the search button is clicked -->

  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  

  
  <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/mne_logo_small.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../install/index.html">
  Install
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../overview/index.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../python_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/get_help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../overview/development.html">
  Development
 </a>
</li>

</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search">
  <i class="fas fa-search"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        1.1  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables auto_examples/datasets/limo_data and {'json_url': 'https://mne.tools/dev/_static/versions.json', 'version_match': '1.1'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "auto_examples/datasets/limo_data.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://mne.tools/dev/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "auto_examples/datasets/limo_data.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const span = document.createElement("span");
            span.textContent = `${entry.name}`;

            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            node.appendChild(span);

            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's 1.1 variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "1.1") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-python" title="GitHub" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Discourse" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-discourse"></i></span>
            <label class="sr-only">Discourse</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank"><span><i class="fab fa-discord"></i></span>
            <label class="sr-only">Discord</label></a>
        </li>
      </ul>
      </div>
      
    </div>

  </div>

</div>

<script>
// Adds the `shown` class to the parent so that we can trigger overflow
// behavior that depends on whether we're expanded
$('#navbar-collapsible').on('show.bs.collapse', function () {
  $(".bd-header").addClass("shown");
});
$('#navbar-collapsible').on('hide.bs.collapse', function () {
  $(".bd-header").removeClass("shown");
});
</script>
  </nav>
  

  <div class="bd-container container-xl">
    <div class="bd-container__inner row">
      



<div class="bd-sidebar-primary bd-sidebar">
  <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../auto_tutorials/index.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/intro/index.html">
     Introductory tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/10_overview.html">
       Overview of MEG/EEG analysis with MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/15_inplace.html">
       Modifying data in-place
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/20_events_from_raw.html">
       Parsing events from raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/30_info.html">
       The Info data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/40_sensor_locations.html">
       Working with sensor locations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/50_configure_mne.html">
       Configuring MNE-Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/intro/70_report.html">
       Getting started with mne.Report
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/io/index.html">
     Reading data for different recording systems
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/io/10_reading_meg_data.html">
       Importing data from MEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/io/20_reading_eeg_data.html">
       Importing data from EEG devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/io/30_reading_fnirs_data.html">
       Importing data from fNIRS devices
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/io/60_ctf_bst_auditory.html">
       Working with CTF data: the Brainstorm auditory dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/raw/index.html">
     Working with continuous data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/raw/10_raw_overview.html">
       The Raw data structure: continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/raw/20_event_arrays.html">
       Working with events
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/raw/30_annotate_raw.html">
       Annotating continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/raw/40_visualize_raw.html">
       Built-in plotting methods for Raw objects
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/preprocessing/index.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/10_preprocessing_overview.html">
       Overview of artifact detection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/15_handling_bad_channels.html">
       Handling bad channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/20_rejecting_bad_data.html">
       Rejecting bad data spans and breaks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/25_background_filtering.html">
       Background information on filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/30_filtering_resampling.html">
       Filtering and resampling data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/35_artifact_correction_regression.html">
       Repairing artifacts with regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/40_artifact_correction_ica.html">
       Repairing artifacts with ICA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/45_projectors_background.html">
       Background on projectors and projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/50_artifact_correction_ssp.html">
       Repairing artifacts with SSP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/55_setting_eeg_reference.html">
       Setting the EEG reference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/59_head_positions.html">
       Extracting and visualizing subject head movement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/60_maxwell_filtering_sss.html">
       Signal-space separation (SSS) and Maxwell filtering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/preprocessing/70_fnirs_processing.html">
       Preprocessing functional near-infrared spectroscopy (fNIRS) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/epochs/index.html">
     Segmenting continuous data into epochs
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/10_epochs_overview.html">
       The Epochs data structure: discontinuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/15_baseline_regression.html">
       Regression-based baseline correction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/20_visualize_epochs.html">
       Visualizing epoched data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/30_epochs_metadata.html">
       Working with Epoch metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/40_autogenerate_metadata.html">
       Auto-generating Epochs metadata
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/50_epochs_to_data_frame.html">
       Exporting Epochs to Pandas DataFrames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/epochs/60_make_fixed_length_epochs.html">
       Divide continuous data into equally-spaced epochs
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/evoked/index.html">
     Estimating evoked responses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/evoked/10_evoked_overview.html">
       The Evoked data structure: evoked/averaged data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/evoked/20_visualize_evoked.html">
       Visualizing Evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/evoked/30_eeg_erp.html">
       EEG analysis - Event-Related Potentials (ERPs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/evoked/40_whitened.html">
       Plotting whitened data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/time-freq/index.html">
     Time-frequency analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/time-freq/20_sensors_time_frequency.html">
       Frequency and time-frequency sensor analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/time-freq/50_ssvep.html">
       Frequency-tagging: Basic analysis of an SSVEP/vSSR dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/forward/index.html">
     Forward models and source spaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/10_background_freesurfer.html">
       FreeSurfer MRI reconstruction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/20_source_alignment.html">
       Source alignment and coordinate frames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/25_automated_coreg.html">
       Using an automated approach to coregistration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/30_forward.html">
       Head model and forward computation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/35_eeg_no_mri.html">
       EEG forward operator with a template MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/50_background_freesurfer_mne.html">
       How MNE uses FreeSurfer’s outputs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/80_fix_bem_in_blender.html">
       Fixing BEM and head surfaces
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/forward/90_compute_covariance.html">
       Computing a covariance matrix
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/inverse/index.html">
     Source localization and inverses
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/10_stc_class.html">
       The SourceEstimate data structure
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/20_dipole_fit.html">
       Source localization with equivalent current dipole (ECD) fit
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/30_mne_dspm_loreta.html">
       Source localization with MNE, dSPM, sLORETA, and eLORETA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/35_dipole_orientations.html">
       The role of dipole orientations in distributed source localization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/40_mne_fixed_free.html">
       Computing various MNE solutions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/50_beamformer_lcmv.html">
       Source reconstruction using an LCMV beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/60_visualize_stc.html">
       Visualize source time courses (stcs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/70_eeg_mri_coords.html">
       EEG source localization given electrode locations on an MRI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/80_brainstorm_phantom_elekta.html">
       Brainstorm Elekta phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/85_brainstorm_phantom_ctf.html">
       Brainstorm CTF phantom dataset tutorial
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/inverse/90_phantom_4DBTi.html">
       4D Neuroimaging/BTi phantom dataset tutorial
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/index.html">
     Statistical analysis of sensor data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/10_background_stats.html">
       Statistical inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/20_erp_stats.html">
       Visualising statistical significance thresholds on EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/40_cluster_1samp_time_freq.html">
       Non-parametric 1 sample cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/50_cluster_between_time_freq.html">
       Non-parametric between conditions cluster statistic on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/70_cluster_rmANOVA_time_freq.html">
       Mass-univariate twoway repeated measures ANOVA on single trial power
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html">
       Spatiotemporal permutation F-test on full sensor data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/stats-source-space/index.html">
     Statistical analysis of source estimates
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-source-space/20_cluster_1samp_spatiotemporal.html">
       Permutation t-test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-source-space/30_cluster_ftest_spatiotemporal.html">
       2 samples permutation test on source data with spatio-temporal clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/stats-source-space/60_cluster_rmANOVA_spatiotemporal.html">
       Repeated measures ANOVA on source data with spatio-temporal clustering
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/machine-learning/index.html">
     Machine learning models of neural activity
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/machine-learning/30_strf.html">
       Spectro-temporal receptive field (STRF) estimation on continuous data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/machine-learning/50_decoding.html">
       Decoding (MVPA)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/clinical/index.html">
     Clinical applications
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/clinical/10_ieeg_localize.html">
       Locating intracranial electrode contacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/clinical/20_seeg.html">
       Working with sEEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/clinical/30_ecog.html">
       Working with ECoG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/clinical/60_sleep.html">
       Sleep stage classification from polysomnography (PSG) data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../auto_tutorials/simulation/index.html">
     Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/simulation/10_array_objs.html">
       Creating MNE-Python data structures from scratch
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/simulation/70_point_spread.html">
       Corrupt known signal with point spread
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../auto_tutorials/simulation/80_dics.html">
       DICS for power mapping
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../io/index.html">
     Input/Output
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/elekta_epochs.html">
       Getting averaging info from .fif files
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/read_neo_format.html">
       How to use data in neural ensemble (NEO) format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/read_noise_covariance_matrix.html">
       Reading/Writing a noise covariance matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../io/read_xdf.html">
       Reading XDF EEG data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../simulation/index.html">
     Data Simulation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/simulate_evoked_data.html">
       Generate simulated evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/simulate_raw_data.html">
       Generate simulated raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/simulated_raw_data_using_subject_anatomy.html">
       Simulate raw data using subject anatomy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../simulation/source_simulator.html">
       Generate simulated source data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../preprocessing/index.html">
     Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/css.html">
       Cortical Signal Suppression (CSS) for removal of cortical signals
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/define_target_events.html">
       Define target events based on time lag, plot evoked response
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/eeg_bridging.html">
       Identify EEG Electrodes Bridged by too much Gel
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/eeg_csd.html">
       Transform EEG data using current source density (CSD)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/eog_artifact_histogram.html">
       Show EOG artifact timing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/find_ref_artifacts.html">
       Find MEG reference channel artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/fnirs_artifact_removal.html">
       Visualise NIRS artifact correction methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/ica_comparison.html">
       Compare the different ICA algorithms in MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/interpolate_bad_channels.html">
       Interpolate bad channels for MEG/EEG channels
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/movement_compensation.html">
       Maxwell filter data with movement compensation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/movement_detection.html">
       Annotate movement artifacts and reestimate dev_head_t
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/muscle_detection.html">
       Annotate muscle artifacts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/muscle_ica.html">
       Removing muscle ICA components
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/otp.html">
       Plot sensor denoising using oversampled temporal projection
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/shift_evoked.html">
       Shifting time-scale in evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/virtual_evoked.html">
       Remap MEG channel types
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../preprocessing/xdawn_denoising.html">
       XDAWN Denoising
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../visualization/index.html">
     Visualization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/3d_to_2d.html">
       How to convert 3D electrode positions to a 2D image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/brain.html">
       Plotting with
       <code class="docutils literal notranslate">
        <span class="pre">
         mne.viz.Brain
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/channel_epochs_image.html">
       Visualize channel over epochs as an image
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/eeg_on_scalp.html">
       Plotting EEG sensors on the scalp
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/evoked_arrowmap.html">
       Plotting topographic arrowmaps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/evoked_topomap.html">
       Plotting topographic maps of evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/evoked_whitening.html">
       Whitening evoked data with a noise covariance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/meg_sensors.html">
       Plotting sensor layouts of MEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/mne_helmet.html">
       Plot the MNE brain and helmet
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/montage_sgskip.html">
       Plotting sensor layouts of EEG systems
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/parcellation.html">
       Plot a cortical parcellation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/publication_figure.html">
       Make figures more publication ready
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/roi_erpimage_by_rt.html">
       Plot single trial activity, grouped by ROI and sorted by RT
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/sensor_noise_level.html">
       Show noise levels from empty room data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/ssp_projs_sensitivity_map.html">
       Sensitivity map of SSP projections
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/topo_compare_conditions.html">
       Compare evoked responses for different conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/topo_customized.html">
       Plot custom topographies for MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../visualization/xhemi.html">
       Cross-hemisphere comparison
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../time_frequency/index.html">
     Time-Frequency Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/compute_csd.html">
       Compute a cross-spectral density (CSD) matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/compute_source_psd_epochs.html">
       Compute Power Spectral Density of inverse solution from single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/source_label_time_frequency.html">
       Compute power and phase lock in label of the source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/source_power_spectrum.html">
       Compute source power spectral density (PSD) in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/source_power_spectrum_opm.html">
       Compute source power spectral density (PSD) of VectorView and OPM data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/source_space_time_frequency.html">
       Compute induced power in the source space with dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/temporal_whitening.html">
       Temporal whitening with AR model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/time_frequency_erds.html">
       Compute and visualize ERDS maps
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/time_frequency_global_field_power.html">
       Explore event-related dynamics for specific frequency bands
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../time_frequency/time_frequency_simulated.html">
       Time-frequency on simulated data (Multitaper vs. Morlet vs. Stockwell)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../stats/index.html">
     Statistics Examples
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats/cluster_stats_evoked.html">
       Permutation F-test on sensor data with 1D cluster level
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats/fdr_stats_evoked.html">
       FDR correction on T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats/linear_regression_raw.html">
       Regression on continuous data (rER[P/F])
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats/sensor_permutation_test.html">
       Permutation T-test on sensor data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../stats/sensor_regression.html">
       Analysing continuous features with binning and regression in sensor space
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../decoding/index.html">
     Machine Learning (Decoding, Encoding, and MVPA)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_csp_eeg.html">
       Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_csp_timefreq.html">
       Decoding in time-frequency space using Common Spatial Patterns (CSP)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_rsa_sgskip.html">
       Representational Similarity Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_spatio_temporal_source.html">
       Decoding source space data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_spoc_CMC.html">
       Continuous Target Decoding with SPoC
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_time_generalization_conditions.html">
       Decoding sensor space data with generalization across time and conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_unsupervised_spatial_filter.html">
       Analysis of evoked response using ICA and PCA reduction techniques
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/decoding_xdawn_eeg.html">
       XDAWN Decoding From EEG data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/ems_filtering.html">
       Compute effect-matched-spatial filtering (EMS)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/linear_model_patterns.html">
       Linear classifier on sensor data with plot patterns and filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/receptive_field_mtrf.html">
       Receptive Field Estimation and Prediction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../decoding/ssd_spatial_filters.html">
       Compute Spectro-Spatial Decomposition (SSD) spatial filters
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../connectivity/index.html">
     Connectivity Analysis Examples
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../forward/index.html">
     Forward modeling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/forward_sensitivity_maps.html">
       Display sensitivity maps for EEG and MEG sensors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/left_cerebellum_volume_source.html">
       Generate a left cerebellum volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../forward/source_space_morphing.html">
       Use source space morphing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../inverse/index.html">
     Inverse problem and source analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/compute_mne_inverse_epochs_in_label.html">
       Compute MNE-dSPM inverse solution on single epochs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/compute_mne_inverse_raw_in_label.html">
       Compute sLORETA inverse solution on raw data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/compute_mne_inverse_volume.html">
       Compute MNE-dSPM inverse solution on evoked data in volume source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/custom_inverse_solver.html">
       Source localization with a custom inverse solver
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/dics_source_power.html">
       Compute source power using DICS beamformer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/evoked_ers_source_power.html">
       Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/gamma_map_inverse.html">
       Compute a sparse inverse solution using the Gamma-MAP empirical Bayesian method
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/label_activation_from_stc.html">
       Extracting time course from source_estimate object
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/label_from_stc.html">
       Generate a functional label from source estimates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/label_source_activations.html">
       Extracting the time series of activations in a label
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/mixed_norm_inverse.html">
       Compute sparse inverse solution with mixed norm: MxNE and irMxNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/mixed_source_space_inverse.html">
       Compute MNE inverse solution on evoked data with a mixed source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/mne_cov_power.html">
       Compute source power estimate by projecting the covariance with MNE
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/morph_surface_stc.html">
       Morph surface source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/morph_volume_stc.html">
       Morph volumetric source estimate
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/multi_dipole_model.html">
       Computing source timecourses with an XFit-like multi-dipole model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/multidict_reweighted_tfmxne.html">
       Compute iterative reweighted TF-MxNE with multiscale time-frequency dictionary
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/psf_ctf_label_leakage.html">
       Visualize source leakage among labels using a circular graph
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/psf_ctf_vertices.html">
       Plot point-spread functions (PSFs) and cross-talk functions (CTFs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/psf_ctf_vertices_lcmv.html">
       Compute cross-talk functions for LCMV beamformers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/rap_music.html">
       Compute Rap-Music on evoked data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/read_inverse.html">
       Reading an inverse operator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/read_stc.html">
       Reading an STC file
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/resolution_metrics.html">
       Compute spatial resolution metrics in source space
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/resolution_metrics_eegmeg.html">
       Compute spatial resolution metrics to compare MEG with EEG+MEG
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/snr_estimate.html">
       Estimate data SNR using an inverse
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/source_space_snr.html">
       Computing source space SNR
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/time_frequency_mixed_norm_inverse.html">
       Compute MxNE with time-frequency sparse prior
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../inverse/vector_mne_solution.html">
       Plotting the full vector-valued MNE solution
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     Examples on open datasets
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
    <label for="toctree-checkbox-26">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="brainstorm_data.html">
       Brainstorm raw (median nerve) dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hf_sef_data.html">
       HF-SEF dataset
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Single trial linear regression analysis with the LIMO dataset
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="opm_data.html">
       Optically pumped magnetometer (OPM) data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="spm_faces_dataset_sgskip.html">
       From raw data to dSPM on SPM Faces dataset
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/implementation.html">
   Implementation details
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/design_philosophy.html">
   Design philosophy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/datasets_index.html">
   Example datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../generated/commands.html">
   Command-line tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/migrating.html">
   Migrating from other analysis software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cookbook.html">
   The typical M/EEG workflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview/cite.html">
   How to cite MNE-Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cited.html">
   Papers citing MNE-Python
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


      <!-- ↓↓↓↓↓ this chunk is customized ↓↓↓↓↓ -->
      
        

<div class="bd-sidebar-secondary bd-toc">
    
    <div class="toc-item">
      
<div class="tocsection onthispage">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#about-the-data">
   About the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-data">
   Load the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-events">
   Visualize events
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-condition-erps">
   Visualize condition ERPs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-effect-of-stimulus-phase-coherence">
   Visualize effect of stimulus phase-coherence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prepare-data-for-linear-regression-analysis">
   Prepare data for linear regression analysis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-predictor-variables-and-design-matrix">
   Define predictor variables and design matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extract-regression-coefficients">
   Extract regression coefficients
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-model-results">
   Plot model results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
    <div class="toc-item">
      
    </div>
    
</div>


      
      <!-- ↑↑↑ this chunk is customized ↑↑↑ -->

      
      <div class="bd-content col">

        <div class="bd-header-article">
            <div class="bd-header-article__inner">
    <div class="bd-header-article__start">
        
        <label class="sidebar-toggle primary-toggle" for="__primary">
            <span class="fas fa-outdent"></span>
        </label>
        
    </div>

    <div class="bd-header-article__end">
        
        <label class="sidebar-toggle secondary-toggle" for="__secondary">
            <span class="fas fa-outdent"></span>
        </label>
        
    </div>
</div>
        </div>

        <!-- ↓↓↓↓↓ this chunk is customized ↓↓↓↓↓ -->
        
          <div>
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-datasets-limo-data-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="single-trial-linear-regression-analysis-with-the-limo-dataset">
<span id="ex-limo-data"></span><span id="sphx-glr-auto-examples-datasets-limo-data-py"></span><h1>Single trial linear regression analysis with the LIMO dataset<a class="headerlink" href="#single-trial-linear-regression-analysis-with-the-limo-dataset" title="Permalink to this heading">#</a></h1>
<p>Here we explore the structure of the data contained in the
<a class="reference external" href="https://datashare.is.ed.ac.uk/handle/10283/2189?show=full">LIMO dataset</a>.
This example replicates and extends some of the main analysis
and tools integrated in <a class="reference external" href="https://github.com/LIMO-EEG-Toolbox">LIMO MEEG</a>, a MATLAB toolbox originally designed
to interface with <a class="reference external" href="https://sccn.ucsd.edu/eeglab/index.php">EEGLAB</a>.</p>
<p>In summary, the example:</p>
<ul class="simple">
<li><p>Fetches epoched data files for a single subject of the LIMO dataset
<a class="footnote-reference brackets" href="#footcite-rousselet2016" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. If the LIMO files are not found on disk, the
fetcher <a class="reference internal" href="../../generated/mne.datasets.limo.load_data.html#mne.datasets.limo.load_data" title="mne.datasets.limo.load_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mne.datasets.limo.load_data()</span></code></a> will automatically download
the files from a remote repository.</p></li>
<li><p>During import, information about the data (i.e., sampling rate, number of
epochs per condition, number and name of EEG channels per subject, etc.) is
extracted from the LIMO <code class="file docutils literal notranslate"><span class="pre">.mat</span></code> files stored on disk and added to the
epochs structure as metadata.</p></li>
<li><p>Fits linear models on the single subject’s data and visualizes inferential
measures to evaluate the significance of the estimated effects.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Jose C. Garcia Alanis &lt;alanis.jcg@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">mne.datasets.limo</span> <span class="kn">import</span> <a href="../../generated/mne.datasets.limo.load_data.html#mne.datasets.limo.load_data" title="mne.datasets.limo.load_data" class="sphx-glr-backref-module-mne-datasets-limo sphx-glr-backref-type-py-function"><span class="n">load_data</span></a>
<span class="kn">from</span> <span class="nn">mne.stats</span> <span class="kn">import</span> <a href="../../generated/mne.stats.linear_regression.html#mne.stats.linear_regression" title="mne.stats.linear_regression" class="sphx-glr-backref-module-mne-stats sphx-glr-backref-type-py-function"><span class="n">linear_regression</span></a>
<span class="kn">from</span> <span class="nn">mne.viz</span> <span class="kn">import</span> <a href="../../generated/mne.viz.plot_events.html#mne.viz.plot_events" title="mne.viz.plot_events" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">plot_events</span></a><span class="p">,</span> <a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">plot_compare_evokeds</span></a>
<span class="kn">from</span> <span class="nn">mne</span> <span class="kn">import</span> <a href="../../generated/mne.combine_evoked.html#mne.combine_evoked" title="mne.combine_evoked" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">combine_evoked</span></a>


<span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># subject to use</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj</span></a> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<section id="about-the-data">
<h2>About the data<a class="headerlink" href="#about-the-data" title="Permalink to this heading">#</a></h2>
<p>In the original LIMO experiment (see <a class="footnote-reference brackets" href="#footcite-rousseletetal2010" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>),
participants performed a
two-alternative forced choice task, discriminating between two face stimuli.
The same two faces were used during the whole experiment,
with varying levels of noise added, making the faces more or less
discernible to the observer (see <a class="reference external" href="https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-9-98/figures/1">Fig 1</a> in <a class="footnote-reference brackets" href="#footcite-rousseletetal2008" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>
for a similar approach).</p>
<p>The presented faces varied across a noise-signal (or phase-coherence)
continuum spanning from 0 to 85% in increasing steps of 5%.
In other words, faces with high phase-coherence (e.g., 85%) were easy to
identify, while faces with low phase-coherence (e.g., 5%) were hard to
identify and by extension very hard to discriminate.</p>
</section>
<section id="load-the-data">
<h2>Load the data<a class="headerlink" href="#load-the-data" title="Permalink to this heading">#</a></h2>
<p>We’ll begin by loading the data from subject 1 of the LIMO dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># This step can take a little while if you&#39;re loading the data for the</span>
<span class="c1"># first time.</span>
<a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a> <span class="o">=</span> <a href="../../generated/mne.datasets.limo.load_data.html#mne.datasets.limo.load_data" title="mne.datasets.limo.load_data" class="sphx-glr-backref-module-mne-datasets-limo sphx-glr-backref-type-py-function"><span class="n">load_data</span></a><span class="p">(</span><span class="n">subject</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Adding metadata with 2 columns
1055 matching events found
No baseline correction applied
0 projection items activated
</pre></div>
</div>
<p>Note that the result of the loading process is an
<a class="reference internal" href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.EpochsArray</span></code></a> containing the data ready to interface
with MNE-Python.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;EpochsArray |  1055 events (all good), -0.299944 - 0.499907 sec, baseline off, ~213.7 MB, data loaded, with metadata,
 &#39;Face/A&#39;: 524
 &#39;Face/B&#39;: 531&gt;
</pre></div>
</div>
</section>
<section id="visualize-events">
<h2>Visualize events<a class="headerlink" href="#visualize-events" title="Permalink to this heading">#</a></h2>
<p>We can visualise the distribution of the face events contained in the
<code class="docutils literal notranslate"><span class="pre">limo_epochs</span></code> structure. Events should appear clearly grouped, as the
epochs are ordered by condition.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="../../generated/mne.viz.plot_events.html#mne.viz.plot_events" title="mne.viz.plot_events" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">plot_events</span></a><span class="p">(</span><a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">events</span></a><span class="p">,</span> <span class="n">event_id</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">event_id</span></a><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.suptitle" title="matplotlib.figure.Figure.suptitle" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span></a><span class="p">(</span><span class="s2">&quot;Distribution of events in LIMO epochs&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_001.png" srcset="../../_images/sphx_glr_limo_data_001.png" alt="Distribution of events in LIMO epochs" class = "sphx-glr-single-img"/><p>As it can be seen above, conditions are coded as <code class="docutils literal notranslate"><span class="pre">Face/A</span></code> and <code class="docutils literal notranslate"><span class="pre">Face/B</span></code>.
Information about the phase-coherence of the presented faces is stored in the
epochs metadata. These information can be easily accessed by calling
<code class="docutils literal notranslate"><span class="pre">limo_epochs.metadata</span></code>. As shown below, the epochs metadata also contains
information about the presented faces for convenience.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.metadata" title="mne.EpochsArray.metadata" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">head</span></a><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  face  phase-coherence
0    A         0.491210
1    A        -1.235572
2    A        -1.043707
3    A         1.642398
4    A        -0.659978
</pre></div>
</div>
<p>Now let’s take a closer look at the information in the epochs
metadata.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We want include all columns in the summary table</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs_summary</span></a> <span class="o">=</span> <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.metadata" title="mne.EpochsArray.metadata" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">describe</span></a><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs_summary</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>        face  phase-coherence
count   1055         1055.000
unique     2              NaN
top        B              NaN
freq     531              NaN
mean     NaN           -0.000
std      NaN            1.000
min      NaN           -1.619
25%      NaN           -0.852
50%      NaN           -0.084
75%      NaN            0.875
max      NaN            1.642
</pre></div>
</div>
<p>The first column of the summary table above provides more or less the same
information as the <code class="docutils literal notranslate"><span class="pre">print(limo_epochs)</span></code> command we ran before. There are
1055 faces (i.e., epochs), subdivided in 2 conditions (i.e., Face A and
Face B) and, for this particular subject, there are more epochs for the
condition Face B.</p>
<p>In addition, we can see in the second column that the values for the
phase-coherence variable range from -1.619 to 1.642. This is because the
phase-coherence values are provided as a z-scored variable in the LIMO
dataset. Note that they have a mean of zero and a standard deviation of 1.</p>
</section>
<section id="visualize-condition-erps">
<h2>Visualize condition ERPs<a class="headerlink" href="#visualize-condition-erps" title="Permalink to this heading">#</a></h2>
<p>Let’s plot the ERPs evoked by Face A and Face B, to see how similar they are.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># only show -250 to 500 ms</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>

<span class="c1"># plot evoked response for face A</span>
<a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><span class="s1">&#39;Face/A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Evoked response: Face A&#39;</span><span class="p">,</span>
                                           <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="p">)</span>
<span class="c1"># and face B</span>
<a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><span class="s1">&#39;Face/B&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                                           <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Evoked response: Face B&#39;</span><span class="p">,</span>
                                           <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_limo_data_002.png" srcset="../../_images/sphx_glr_limo_data_002.png" alt="0.150 s" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_limo_data_003.png" srcset="../../_images/sphx_glr_limo_data_003.png" alt="0.150 s" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No projector specified for this dataset. Please consider the method self.add_proj.
No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
<p>We can also compute the difference wave contrasting Face A and Face B.
Although, looking at the evoked responses above, we shouldn’t expect great
differences among these face-stimuli.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Face A minus Face B</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">difference_wave</span></a> <span class="o">=</span> <a href="../../generated/mne.combine_evoked.html#mne.combine_evoked" title="mne.combine_evoked" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">combine_evoked</span></a><span class="p">([</span><a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><span class="s1">&#39;Face/A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">(),</span>
                                  <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><span class="s1">&#39;Face/B&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">()],</span>
                                 <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># plot difference wave</span>
<a href="../../generated/mne.EvokedArray.html#mne.EvokedArray.plot_joint" title="mne.EvokedArray.plot_joint" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">difference_wave</span><span class="o">.</span><span class="n">plot_joint</span></a><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.15</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Difference Face A - Face B&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_004.png" srcset="../../_images/sphx_glr_limo_data_004.png" alt="0.150 s" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
<p>As expected, no clear pattern appears when contrasting
Face A and Face B. However, we could narrow our search a little bit more.
Since this is a “visual paradigm” it might be best to look at electrodes
located over the occipital lobe, as differences between stimuli (if any)
might easier to spot over visual areas.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a dictionary containing the evoked responses</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conditions</span></a> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Face/A&quot;</span><span class="p">,</span> <span class="s2">&quot;Face/B&quot;</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evokeds</span></a> <span class="o">=</span> <span class="p">{</span><span class="n">condition</span><span class="p">:</span> <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><span class="n">condition</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>
           <span class="k">for</span> <span class="n">condition</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conditions</span></a><span class="p">}</span>

<span class="c1"># concentrate analysis an occipital electrodes (e.g. B11)</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pick</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evokeds</span></a><span class="p">[</span><span class="s2">&quot;Face/A&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">ch_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;B11&#39;</span><span class="p">)</span>

<span class="c1"># compare evoked responses</span>
<a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">plot_compare_evokeds</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evokeds</span></a><span class="p">,</span> <span class="n">picks</span><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pick</span></a><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">eeg</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">)))</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_005.png" srcset="../../_images/sphx_glr_limo_data_005.png" alt="B11" class = "sphx-glr-single-img"/><p>We do see a difference between Face A and B, but it is pretty small.</p>
</section>
<section id="visualize-effect-of-stimulus-phase-coherence">
<h2>Visualize effect of stimulus phase-coherence<a class="headerlink" href="#visualize-effect-of-stimulus-phase-coherence" title="Permalink to this heading">#</a></h2>
<p>Since phase-coherence
determined whether a face stimulus could be easily identified,
one could expect that faces with high phase-coherence should evoke stronger
activation patterns along occipital electrodes.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">phase_coh</span></a> <span class="o">=</span> <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.metadata" title="mne.EpochsArray.metadata" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">metadata</span></a><span class="p">[</span><span class="s1">&#39;phase-coherence&#39;</span><span class="p">]</span>
<span class="c1"># get levels of phase coherence</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">levels</span></a> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html#pandas.Series.unique" title="pandas.Series.unique" class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-method"><span class="n">phase_coh</span><span class="o">.</span><span class="n">unique</span></a><span class="p">())</span>
<span class="c1"># create labels for levels of phase coherence (i.e., 0 - 85%)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels</span></a> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)]</span>

<span class="c1"># create dict of evokeds for each level of phase-coherence</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evokeds</span></a> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">[</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">phase_coh</span></a> <span class="o">==</span> <span class="n">level</span><span class="p">]</span><span class="o">.</span><span class="n">average</span><span class="p">()</span>
           <span class="k">for</span> <span class="n">level</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">levels</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">labels</span></a><span class="p">)}</span>

<span class="c1"># pick channel to plot</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">electrodes</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span> <span class="s1">&#39;B11&#39;</span><span class="p">]</span>
<span class="c1"># create figures</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">electrode</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">electrodes</span></a><span class="p">:</span>
    <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">plot_compare_evokeds</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">evokeds</span></a><span class="p">,</span>
                         <span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                         <span class="n">ylim</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">eeg</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">)),</span>
                         <span class="n">picks</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">electrode</span></a><span class="p">,</span>
                         <span class="n">cmap</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Phase coherence&quot;</span><span class="p">,</span> <span class="s2">&quot;magma&quot;</span><span class="p">))</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_limo_data_006.png" srcset="../../_images/sphx_glr_limo_data_006.png" alt="C22" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_limo_data_007.png" srcset="../../_images/sphx_glr_limo_data_007.png" alt="B11" class = "sphx-glr-multi-img"/></li>
</ul>
<p>As shown above, there are some considerable differences between the
activation patterns evoked by stimuli with low vs. high phase-coherence at
the chosen electrodes.</p>
</section>
<section id="prepare-data-for-linear-regression-analysis">
<h2>Prepare data for linear regression analysis<a class="headerlink" href="#prepare-data-for-linear-regression-analysis" title="Permalink to this heading">#</a></h2>
<p>Before we test the significance of these differences using linear
regression, we’ll interpolate missing channels that were
dropped during preprocessing of the data.
Furthermore, we’ll drop the EOG channels (marked by the “EXG” prefix)
present in the data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.interpolate_bads" title="mne.EpochsArray.interpolate_bads" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">interpolate_bads</span></a><span class="p">(</span><span class="n">reset_bads</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.drop_channels" title="mne.EpochsArray.drop_channels" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-method"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">drop_channels</span></a><span class="p">([</span><span class="s1">&#39;EXG1&#39;</span><span class="p">,</span> <span class="s1">&#39;EXG2&#39;</span><span class="p">,</span> <span class="s1">&#39;EXG3&#39;</span><span class="p">,</span> <span class="s1">&#39;EXG4&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Interpolating bad channels
    Automatic origin fit: head of radius 95.0 mm
Computing interpolation matrix from 113 sensor positions
Interpolating 15 sensors
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<table class="table table-hover table-striped table-sm table-responsive small">
    <tr>
        <th>Number of events</th>
        <td>1055</td>
    </tr>
    <tr>
        <th>Events</th>

        <td>Face/A: 524<br/>Face/B: 531</td>

    </tr>
    <tr>
        <th>Time range</th>
        <td>-0.300 – 0.500 sec</td>
    </tr>
    <tr>
        <th>Baseline</th>
        <td>off</td>
    </tr>
</table>
</div>
<br />
<br /></section>
<section id="define-predictor-variables-and-design-matrix">
<h2>Define predictor variables and design matrix<a class="headerlink" href="#define-predictor-variables-and-design-matrix" title="Permalink to this heading">#</a></h2>
<p>To run the regression analysis,
we need to create a design matrix containing information about the
variables (i.e., predictors) we want to use for prediction of brain
activity patterns. For this purpose, we’ll use the information we have in
<code class="docutils literal notranslate"><span class="pre">limo_epochs.metadata</span></code>: phase-coherence and Face A vs. Face B.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># name of predictors + intercept</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">predictor_vars</span></a> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;face a - face b&#39;</span><span class="p">,</span> <span class="s1">&#39;phase-coherence&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">]</span>

<span class="c1"># create design matrix</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a> <span class="o">=</span> <a href="../../generated/mne.EpochsArray.html#mne.EpochsArray.metadata" title="mne.EpochsArray.metadata" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-property"><span class="n">limo_epochs</span><span class="o">.</span><span class="n">metadata</span></a><span class="p">[[</span><span class="s1">&#39;phase-coherence&#39;</span><span class="p">,</span> <span class="s1">&#39;face&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a><span class="p">[</span><span class="s1">&#39;face a - face b&#39;</span><span class="p">]</span> <span class="o">=</span> <a href="https://numpy.org/devdocs/reference/generated/numpy.where.html#numpy.where" title="numpy.where" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a><span class="p">[</span><span class="s1">&#39;face&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a><span class="p">[</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">predictor_vars</span></a><span class="p">]</span>
</pre></div>
</div>
<p>Now we can set up the linear model to be used in the analysis using
MNE-Python’s func:<a class="reference internal" href="../../generated/mne.stats.linear_regression.html#mne.stats.linear_regression" title="mne.stats.linear_regression"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_regression</span></code></a> function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a> <span class="o">=</span> <a href="../../generated/mne.stats.linear_regression.html#mne.stats.linear_regression" title="mne.stats.linear_regression" class="sphx-glr-backref-module-mne-stats sphx-glr-backref-type-py-function"><span class="n">linear_regression</span></a><span class="p">(</span><a href="../../generated/mne.EpochsArray.html#mne.EpochsArray" title="mne.EpochsArray" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">limo_epochs</span></a><span class="p">,</span>
                        <span class="n">design_matrix</span><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design</span></a><span class="p">,</span>
                        <span class="n">names</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">predictor_vars</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Fitting linear model to epochs, (25728 targets, 3 regressors)
Done
</pre></div>
</div>
</section>
<section id="extract-regression-coefficients">
<h2>Extract regression coefficients<a class="headerlink" href="#extract-regression-coefficients" title="Permalink to this heading">#</a></h2>
<p>The results are stored within the object <code class="docutils literal notranslate"><span class="pre">reg</span></code>,
which is a dictionary of evoked objects containing
multiple inferential measures for each predictor in the design matrix.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predictors are:&#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;fields are:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">field</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">],</span> <span class="s1">&#39;_fields&#39;</span><span class="p">)])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>predictors are: [&#39;face a - face b&#39;, &#39;phase-coherence&#39;, &#39;intercept&#39;]
fields are: [&#39;beta&#39;, &#39;stderr&#39;, &#39;t_val&#39;, &#39;p_val&#39;, &#39;mlog10_p_val&#39;]
</pre></div>
</div>
</section>
<section id="plot-model-results">
<h2>Plot model results<a class="headerlink" href="#plot-model-results" title="Permalink to this heading">#</a></h2>
<p>Now we can access and plot the results of the linear regression analysis by
calling <code class="samp docutils literal notranslate"><span class="pre">reg['</span><em><span class="pre">&lt;name</span> <span class="pre">of</span> <span class="pre">predictor&gt;</span></em><span class="pre">'].</span><em><span class="pre">&lt;measure</span> <span class="pre">of</span> <span class="pre">interest&gt;</span></em></code> and
using the
<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_joint" title="mne.Evoked.plot_joint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">plot_joint()</span></code></a> method just as we would do with any other
evoked object.
Below we can see a clear effect of phase-coherence, with higher
phase-coherence (i.e., better “face visibility”) having a negative effect on
the activity measured at occipital electrodes around 200 to 250 ms following
stimulus onset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a><span class="p">[</span><span class="s1">&#39;phase-coherence&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="p">,</span>
                                       <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Effect of Phase-coherence&#39;</span><span class="p">,</span>
                                       <span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.23</span><span class="p">])</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_008.png" srcset="../../_images/sphx_glr_limo_data_008.png" alt="0.230 s" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
<p>We can also plot the corresponding T values.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># use unit=False and scale=1 to keep values at their original</span>
<span class="c1"># scale (i.e., avoid conversion to micro-volt).</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
               <span class="n">unit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">topomap_args</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">scalings</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">eeg</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">average</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a><span class="p">[</span><span class="s1">&#39;phase-coherence&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">t_val</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="p">,</span>
                                              <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">topomap_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">topomap_args</span></a><span class="p">,</span>
                                              <span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.23</span><span class="p">])</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.axes" title="matplotlib.figure.Figure.axes" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-property"><span class="n">fig</span><span class="o">.</span><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;T-value&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_009.png" srcset="../../_images/sphx_glr_limo_data_009.png" alt="0.208 – 0.256 s" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
<p>Conversely, there appears to be no (or very small) systematic effects when
comparing Face A and Face B stimuli. This is largely consistent with the
difference wave approach presented above.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>

<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg</span></a><span class="p">[</span><span class="s1">&#39;face a - face b&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ts_args</span></a><span class="p">,</span>
                                       <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Effect of Face A vs. Face B&#39;</span><span class="p">,</span>
                                       <span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="mf">0.23</span><span class="p">])</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_limo_data_010.png" srcset="../../_images/sphx_glr_limo_data_010.png" alt="0.230 s" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>No projector specified for this dataset. Please consider the method self.add_proj.
</pre></div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id4">
<aside class="footnote brackets" id="footcite-rousselet2016" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Guillaume A. Rousselet. LIMO EEG dataset. 2016. <a class="reference external" href="https://doi.org/10.7488/ds/1556">doi:10.7488/ds/1556</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-rousseletetal2010" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Guillaume A. Rousselet, Carl M. Gaspar, Cyril R. Pernet, Jesse S. Husk, Patrick J. Bennett, and Allison B. Sekuler. Healthy aging delays scalp EEG sensitivity to noise in a face discrimination task. <em>Frontiers in Psychology</em>, 1(19):1–14, 2010. <a class="reference external" href="https://doi.org/10.3389/fpsyg.2010.00019">doi:10.3389/fpsyg.2010.00019</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-rousseletetal2008" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Guillaume A. Rousselet, Cyril R. Pernet, Patrick J. Bennett, and Allison B. Sekuler. Parametric study of EEG sensitivity to phase noise during face processing. <em>BMC Neuroscience</em>, 9(1):98, 2008. <a class="reference external" href="https://doi.org/10.1186/1471-2202-9-98">doi:10.1186/1471-2202-9-98</a>.</p>
</aside>
</aside>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  48.300 seconds)</p>
<p><strong>Estimated memory usage:</strong>  631 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-datasets-limo-data-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/d5f0a6e7a68993492a3fdb5d5af2bf74/limo_data.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">limo_data.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f47934a488455dcef7b3567776837d1a/limo_data.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">limo_data.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


            
          </div>
        
        <!-- ↑↑↑ this chunk is customized ↑↑↑ -->

        
        <footer class="bd-footer-article">
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="hf_sef_data.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">HF-SEF dataset</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="opm_data.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Optically pumped magnetometer (OPM) data</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
        </footer>
        
      </div>
      
    </div>
  </div>

  
  <!-- ↓↓↓↓↓ this chunk is customized ↓↓↓↓↓ -->
    <script src="https://mne.tools/versionwarning.js"></script>
    
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=19ec7dda39a41ce4efdb"></script>

  <!-- ↑↑↑ this chunk is customized ↑↑↑ -->
  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="text-center text-muted small">&copy; Copyright 2012–2022, MNE Developers. Last updated <time datetime="2022-08-24T23:14:16.977835+00:00" class="localized">2022-08-24 23:14 UTC</time>
<script type="text/javascript">$(function () { $("time.localized").each(function () { var el = $(this); el.text(new Date(el.attr("datetime")).toLocaleString([], {dateStyle: "medium", timeStyle: "long"})); }); } )</script></p>
  </div>
  
</div>
  </footer>
  </body>
</html>