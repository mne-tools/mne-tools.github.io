
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Locating intracranial electrode contacts &#8212; MNE-GUI-Addons 0.2.0.dev11+g39c3e29 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script src="../_static/documentation_options.js?v=f7abae66"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/ieeg_locate';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM" href="evoked_ers_source_power.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">MNE-GUI-Addons 0.2.0.dev11+g39c3e29 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api.html">
                        Python API Reference
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        Examples
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-gui-addons" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-mastodon fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Discourse" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../api.html">
                        Python API Reference
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        Examples
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/mne-tools/mne-gui-addons" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://fosstodon.org/@mne" title="Mastodon" class="nav-link" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-mastodon fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Mastodon</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/mne_python" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://mne.discourse.group/" title="Discourse" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discord.gg/rKfvxTuATa" title="Discord" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="locate_ieeg_micro.html">Locating micro-scale intracranial electrode contacts</a></li>
<li class="toctree-l1"><a class="reference internal" href="volume_stc_group_study.html">Volume Source Time Course Estimate for a Group Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="evoked_ers_source_power.html">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Locating intracranial electrode contacts</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Locating...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-ieeg-locate-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="locating-intracranial-electrode-contacts">
<span id="tut-ieeg-localize"></span><span id="sphx-glr-auto-examples-ieeg-locate-py"></span><h1>Locating intracranial electrode contacts<a class="headerlink" href="#locating-intracranial-electrode-contacts" title="Link to this heading">#</a></h1>
<p>Analysis of intracranial electrophysiology recordings typically involves
finding the position of each contact relative to brain structures. In a
typical setup, the brain and the electrode locations will be in two places
and will have to be aligned; the brain is best visualized by a
pre-implantation magnetic resonance (MR) image whereas the electrode contact
locations are best visualized in a post-implantation computed tomography (CT)
image. The CT image has greater intensity than the background at each of the
electrode contacts and for the skull. Using the skull, the CT can be aligned
to MR-space. This accomplishes our goal of obtaining contact locations in
MR-space (which is where the brain structures are best determined using the
<a class="reference external" href="https://mne.tools/stable/auto_tutorials/forward/10_background_freesurfer.html#tut-freesurfer-reconstruction" title="(in MNE v1.5)"><span>FreeSurfer MRI reconstruction</span></a>). Contact locations in MR-space can also
be warped to a template space such as <code class="docutils literal notranslate"><span class="pre">fsaverage</span></code> for group comparisons.
Please note that this tutorial requires <code class="docutils literal notranslate"><span class="pre">nibabel</span></code>, <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> and <code class="docutils literal notranslate"><span class="pre">dipy</span></code>
which can be installed using <code class="docutils literal notranslate"><span class="pre">pip</span></code> as well as 3D plotting
(see <a class="reference external" href="https://mne.tools/stable/install/manual_install.html#manual-install" title="(in MNE v1.5)"><span>Install via pip or conda</span></a>).</p>
<p>Support for intracranial electrophysiology analysis in MNE was added after
the original publication, so please cite <a class="footnote-reference brackets" href="#footcite-rockhilletal2022" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> if you
use this module in your analysis to support the addition of new projects to
MNE.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Alex Rockhill &lt;aprockhill@mailbox.org&gt;</span>
<span class="c1">#          Eric Larson &lt;larson.eric.d@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD-3-Clause</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">nibabel</span> <span class="k">as</span> <span class="nn">nib</span>
<span class="kn">import</span> <span class="nn">nilearn.plotting</span>
<span class="kn">from</span> <span class="nn">dipy.align</span> <span class="kn">import</span> <span class="n">resample</span>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">import</span> <span class="nn">mne_gui_addons</span> <span class="k">as</span> <span class="nn">mne_gui</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="kn">import</span> <a href="https://mne.tools/stable/generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a>

<span class="c1"># paths to mne datasets: sample sEEG and FreeSurfer&#39;s fsaverage subject,</span>
<span class="c1"># which is in MNI space</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.datasets.misc.data_path.html#mne.datasets.misc.data_path" title="mne.datasets.misc.data_path" class="sphx-glr-backref-module-mne-datasets-misc sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">misc</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_path</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path" class="sphx-glr-backref-module-mne-datasets-sample sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sample_path</span></a> <span class="o">/</span> <span class="s2">&quot;subjects&quot;</span>

<span class="c1"># use mne-python&#39;s fsaverage data</span>
<a href="https://mne.tools/stable/generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage" class="sphx-glr-backref-module-mne-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_fsaverage</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># downloads if needed</span>

<span class="c1"># GUI requires pyvista backend</span>
<a href="https://mne.tools/stable/generated/mne.viz.set_3d_backend.html#mne.viz.set_3d_backend" title="mne.viz.set_3d_backend" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">set_3d_backend</span></a><span class="p">(</span><span class="s2">&quot;pyvistaqt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using default location ~/mne_data for sample...

  0%|                                              | 0.00/1.65G [00:00&lt;?, ?B/s]
  0%|▏                                    | 6.31M/1.65G [00:00&lt;00:26, 63.1MB/s]
  1%|▎                                    | 12.6M/1.65G [00:00&lt;00:27, 60.5MB/s]
  1%|▍                                    | 20.6M/1.65G [00:00&lt;00:23, 69.0MB/s]
  2%|▋                                    | 28.3M/1.65G [00:00&lt;00:22, 72.4MB/s]
  2%|▊                                    | 36.5M/1.65G [00:00&lt;00:21, 75.6MB/s]
  3%|▉                                    | 44.5M/1.65G [00:00&lt;00:20, 77.0MB/s]
  3%|█▏                                   | 52.5M/1.65G [00:00&lt;00:20, 78.1MB/s]
  4%|█▎                                   | 61.2M/1.65G [00:00&lt;00:19, 81.0MB/s]
  4%|█▌                                   | 69.7M/1.65G [00:00&lt;00:19, 82.2MB/s]
  5%|█▊                                   | 78.4M/1.65G [00:01&lt;00:18, 83.6MB/s]
  5%|█▉                                   | 86.7M/1.65G [00:01&lt;00:18, 83.2MB/s]
  6%|██▏                                  | 95.1M/1.65G [00:01&lt;00:18, 83.5MB/s]
  6%|██▍                                   | 104M/1.65G [00:01&lt;00:18, 83.5MB/s]
  7%|██▌                                   | 112M/1.65G [00:01&lt;00:20, 76.9MB/s]
  7%|██▊                                   | 121M/1.65G [00:01&lt;00:19, 79.8MB/s]
  8%|██▉                                   | 129M/1.65G [00:01&lt;00:18, 82.5MB/s]
  8%|███▏                                  | 138M/1.65G [00:01&lt;00:18, 83.8MB/s]
  9%|███▍                                  | 147M/1.65G [00:01&lt;00:17, 85.3MB/s]
  9%|███▌                                  | 156M/1.65G [00:01&lt;00:17, 85.9MB/s]
 10%|███▊                                  | 164M/1.65G [00:02&lt;00:17, 83.1MB/s]
 10%|███▉                                  | 173M/1.65G [00:02&lt;00:17, 84.7MB/s]
 11%|████▏                                 | 182M/1.65G [00:02&lt;00:17, 84.7MB/s]
 12%|████▍                                 | 190M/1.65G [00:02&lt;00:17, 85.4MB/s]
 12%|████▌                                 | 199M/1.65G [00:02&lt;00:16, 86.3MB/s]
 13%|████▊                                 | 208M/1.65G [00:02&lt;00:16, 86.6MB/s]
 13%|████▉                                 | 217M/1.65G [00:02&lt;00:16, 87.1MB/s]
 14%|█████▏                                | 226M/1.65G [00:02&lt;00:16, 87.2MB/s]
 14%|█████▍                                | 234M/1.65G [00:02&lt;00:16, 86.7MB/s]
 15%|█████▌                                | 243M/1.65G [00:02&lt;00:16, 86.7MB/s]
 15%|█████▊                                | 252M/1.65G [00:03&lt;00:16, 85.0MB/s]
 16%|█████▉                                | 260M/1.65G [00:03&lt;00:17, 81.7MB/s]
 16%|██████▏                               | 268M/1.65G [00:03&lt;00:17, 81.3MB/s]
 17%|██████▎                               | 277M/1.65G [00:03&lt;00:16, 81.8MB/s]
 17%|██████▌                               | 285M/1.65G [00:03&lt;00:16, 83.0MB/s]
 18%|██████▊                               | 294M/1.65G [00:03&lt;00:16, 84.2MB/s]
 18%|██████▉                               | 303M/1.65G [00:03&lt;00:15, 85.7MB/s]
 19%|███████▏                              | 312M/1.65G [00:03&lt;00:15, 86.3MB/s]
 19%|███████▎                              | 320M/1.65G [00:03&lt;00:15, 86.2MB/s]
 20%|███████▌                              | 329M/1.65G [00:03&lt;00:15, 86.3MB/s]
 20%|███████▊                              | 338M/1.65G [00:04&lt;00:15, 84.7MB/s]
 21%|███████▉                              | 346M/1.65G [00:04&lt;00:15, 85.0MB/s]
 21%|████████▏                             | 355M/1.65G [00:04&lt;00:15, 81.7MB/s]
 22%|████████▎                             | 363M/1.65G [00:04&lt;00:15, 81.3MB/s]
 22%|████████▌                             | 371M/1.65G [00:04&lt;00:15, 82.6MB/s]
 23%|████████▋                             | 380M/1.65G [00:04&lt;00:15, 81.9MB/s]
 23%|████████▉                             | 388M/1.65G [00:04&lt;00:16, 78.5MB/s]
 24%|█████████                             | 396M/1.65G [00:04&lt;00:16, 77.4MB/s]
 24%|█████████▎                            | 404M/1.65G [00:04&lt;00:15, 78.6MB/s]
 25%|█████████▍                            | 412M/1.65G [00:05&lt;00:15, 78.1MB/s]
 25%|█████████▋                            | 420M/1.65G [00:05&lt;00:15, 78.4MB/s]
 26%|█████████▊                            | 428M/1.65G [00:05&lt;00:15, 77.9MB/s]
 26%|██████████                            | 436M/1.65G [00:05&lt;00:15, 78.4MB/s]
 27%|██████████▏                           | 443M/1.65G [00:05&lt;00:15, 78.3MB/s]
 27%|██████████▍                           | 451M/1.65G [00:05&lt;00:15, 78.0MB/s]
 28%|██████████▌                           | 460M/1.65G [00:05&lt;00:14, 79.8MB/s]
 28%|██████████▊                           | 468M/1.65G [00:05&lt;00:14, 81.8MB/s]
 29%|██████████▉                           | 477M/1.65G [00:05&lt;00:14, 82.8MB/s]
 29%|███████████▏                          | 486M/1.65G [00:05&lt;00:13, 84.0MB/s]
 30%|███████████▎                          | 494M/1.65G [00:06&lt;00:13, 84.4MB/s]
 30%|███████████▌                          | 503M/1.65G [00:06&lt;00:13, 85.0MB/s]
 31%|███████████▊                          | 511M/1.65G [00:06&lt;00:13, 85.1MB/s]
 31%|███████████▉                          | 520M/1.65G [00:06&lt;00:13, 85.4MB/s]
 32%|████████████▏                         | 528M/1.65G [00:06&lt;00:13, 85.4MB/s]
 32%|████████████▎                         | 537M/1.65G [00:06&lt;00:13, 85.5MB/s]
 33%|████████████▌                         | 546M/1.65G [00:06&lt;00:12, 85.4MB/s]
 34%|████████████▋                         | 554M/1.65G [00:06&lt;00:12, 85.6MB/s]
 34%|████████████▉                         | 563M/1.65G [00:06&lt;00:12, 86.1MB/s]
 35%|█████████████▏                        | 571M/1.65G [00:06&lt;00:12, 85.8MB/s]
 35%|█████████████▎                        | 580M/1.65G [00:07&lt;00:12, 86.3MB/s]
 36%|█████████████▌                        | 589M/1.65G [00:07&lt;00:12, 86.2MB/s]
 36%|█████████████▋                        | 597M/1.65G [00:07&lt;00:12, 86.1MB/s]
 37%|█████████████▉                        | 606M/1.65G [00:07&lt;00:12, 86.4MB/s]
 37%|██████████████▏                       | 615M/1.65G [00:07&lt;00:12, 86.1MB/s]
 38%|██████████████▎                       | 624M/1.65G [00:07&lt;00:11, 86.3MB/s]
 38%|██████████████▌                       | 632M/1.65G [00:07&lt;00:11, 86.1MB/s]
 39%|██████████████▋                       | 641M/1.65G [00:07&lt;00:11, 86.2MB/s]
 39%|██████████████▉                       | 649M/1.65G [00:07&lt;00:11, 85.2MB/s]
 40%|███████████████▏                      | 658M/1.65G [00:07&lt;00:11, 86.0MB/s]
 40%|███████████████▎                      | 667M/1.65G [00:08&lt;00:11, 86.1MB/s]
 41%|███████████████▌                      | 675M/1.65G [00:08&lt;00:11, 86.0MB/s]
 41%|███████████████▋                      | 684M/1.65G [00:08&lt;00:11, 86.4MB/s]
 42%|███████████████▉                      | 693M/1.65G [00:08&lt;00:11, 86.3MB/s]
 42%|████████████████▏                     | 701M/1.65G [00:08&lt;00:11, 86.3MB/s]
 43%|████████████████▎                     | 710M/1.65G [00:08&lt;00:10, 86.3MB/s]
 43%|████████████████▌                     | 719M/1.65G [00:08&lt;00:10, 86.6MB/s]
 44%|████████████████▋                     | 728M/1.65G [00:08&lt;00:10, 84.2MB/s]
 45%|████████████████▉                     | 737M/1.65G [00:08&lt;00:10, 86.0MB/s]
 45%|█████████████████▏                    | 745M/1.65G [00:08&lt;00:10, 86.9MB/s]
 46%|█████████████████▎                    | 754M/1.65G [00:09&lt;00:10, 88.0MB/s]
 46%|█████████████████▌                    | 763M/1.65G [00:09&lt;00:10, 88.2MB/s]
 47%|█████████████████▊                    | 772M/1.65G [00:09&lt;00:09, 89.0MB/s]
 47%|█████████████████▉                    | 781M/1.65G [00:09&lt;00:09, 87.7MB/s]
 48%|██████████████████▏                   | 790M/1.65G [00:09&lt;00:10, 84.5MB/s]
 48%|██████████████████▎                   | 799M/1.65G [00:09&lt;00:10, 83.7MB/s]
 49%|██████████████████▌                   | 807M/1.65G [00:09&lt;00:11, 73.9MB/s]
 49%|██████████████████▋                   | 815M/1.65G [00:09&lt;00:11, 76.0MB/s]
 50%|██████████████████▉                   | 823M/1.65G [00:09&lt;00:10, 77.8MB/s]
 50%|███████████████████                   | 831M/1.65G [00:10&lt;00:10, 78.4MB/s]
 51%|███████████████████▎                  | 840M/1.65G [00:10&lt;00:10, 80.4MB/s]
 51%|███████████████████▌                  | 848M/1.65G [00:10&lt;00:09, 81.2MB/s]
 52%|███████████████████▋                  | 857M/1.65G [00:10&lt;00:09, 82.7MB/s]
 52%|███████████████████▉                  | 865M/1.65G [00:10&lt;00:09, 82.9MB/s]
 53%|████████████████████                  | 874M/1.65G [00:10&lt;00:09, 84.1MB/s]
 53%|████████████████████▎                 | 882M/1.65G [00:10&lt;00:09, 83.9MB/s]
 54%|████████████████████▍                 | 891M/1.65G [00:10&lt;00:11, 65.4MB/s]
 54%|████████████████████▋                 | 898M/1.65G [00:10&lt;00:12, 59.0MB/s]
 55%|████████████████████▊                 | 904M/1.65G [00:11&lt;00:12, 58.8MB/s]
 55%|████████████████████▉                 | 912M/1.65G [00:11&lt;00:11, 62.5MB/s]
 56%|█████████████████████▏                | 919M/1.65G [00:11&lt;00:11, 65.1MB/s]
 56%|█████████████████████▎                | 926M/1.65G [00:11&lt;00:10, 67.4MB/s]
 57%|█████████████████████▍                | 934M/1.65G [00:11&lt;00:10, 70.6MB/s]
 57%|█████████████████████▋                | 942M/1.65G [00:11&lt;00:09, 72.3MB/s]
 58%|█████████████████████▊                | 951M/1.65G [00:11&lt;00:09, 75.4MB/s]
 58%|██████████████████████                | 959M/1.65G [00:11&lt;00:08, 79.0MB/s]
 59%|██████████████████████▎               | 968M/1.65G [00:11&lt;00:08, 82.2MB/s]
 59%|██████████████████████▍               | 977M/1.65G [00:11&lt;00:08, 83.8MB/s]
 60%|██████████████████████▋               | 986M/1.65G [00:12&lt;00:07, 85.0MB/s]
 60%|██████████████████████▊               | 995M/1.65G [00:12&lt;00:07, 84.3MB/s]
 61%|██████████████████████▍              | 1.00G/1.65G [00:12&lt;00:09, 67.7MB/s]
 61%|██████████████████████▋              | 1.01G/1.65G [00:12&lt;00:09, 70.3MB/s]
 62%|██████████████████████▊              | 1.02G/1.65G [00:12&lt;00:08, 72.8MB/s]
 62%|██████████████████████▉              | 1.03G/1.65G [00:12&lt;00:08, 73.9MB/s]
 63%|███████████████████████▏             | 1.03G/1.65G [00:12&lt;00:08, 74.8MB/s]
 63%|███████████████████████▎             | 1.04G/1.65G [00:12&lt;00:08, 75.6MB/s]
 64%|███████████████████████▌             | 1.05G/1.65G [00:12&lt;00:07, 76.5MB/s]
 64%|███████████████████████▋             | 1.06G/1.65G [00:13&lt;00:07, 76.9MB/s]
 64%|███████████████████████▊             | 1.07G/1.65G [00:13&lt;00:07, 77.7MB/s]
 65%|████████████████████████             | 1.07G/1.65G [00:13&lt;00:07, 78.0MB/s]
 65%|████████████████████████▏            | 1.08G/1.65G [00:13&lt;00:07, 79.0MB/s]
 66%|████████████████████████▍            | 1.09G/1.65G [00:13&lt;00:07, 79.7MB/s]
 66%|████████████████████████▌            | 1.10G/1.65G [00:13&lt;00:06, 80.1MB/s]
 67%|████████████████████████▊            | 1.11G/1.65G [00:13&lt;00:06, 80.5MB/s]
 67%|████████████████████████▉            | 1.11G/1.65G [00:13&lt;00:06, 80.5MB/s]
 68%|█████████████████████████            | 1.12G/1.65G [00:13&lt;00:06, 80.6MB/s]
 68%|█████████████████████████▎           | 1.13G/1.65G [00:13&lt;00:06, 80.8MB/s]
 69%|█████████████████████████▍           | 1.14G/1.65G [00:14&lt;00:06, 79.8MB/s]
 69%|█████████████████████████▋           | 1.15G/1.65G [00:14&lt;00:06, 78.4MB/s]
 70%|█████████████████████████▊           | 1.15G/1.65G [00:14&lt;00:07, 70.6MB/s]
 70%|█████████████████████████▉           | 1.16G/1.65G [00:14&lt;00:07, 67.0MB/s]
 71%|██████████████████████████▏          | 1.17G/1.65G [00:14&lt;00:07, 65.8MB/s]
 71%|██████████████████████████▎          | 1.17G/1.65G [00:14&lt;00:07, 65.8MB/s]
 72%|██████████████████████████▍          | 1.18G/1.65G [00:14&lt;00:06, 68.4MB/s]
 72%|██████████████████████████▋          | 1.19G/1.65G [00:14&lt;00:06, 71.0MB/s]
 72%|██████████████████████████▊          | 1.20G/1.65G [00:14&lt;00:06, 73.5MB/s]
 73%|███████████████████████████          | 1.21G/1.65G [00:15&lt;00:05, 75.8MB/s]
 73%|███████████████████████████▏         | 1.21G/1.65G [00:15&lt;00:05, 77.6MB/s]
 74%|███████████████████████████▎         | 1.22G/1.65G [00:15&lt;00:05, 79.0MB/s]
 74%|███████████████████████████▌         | 1.23G/1.65G [00:15&lt;00:05, 79.4MB/s]
 75%|███████████████████████████▋         | 1.24G/1.65G [00:15&lt;00:05, 80.5MB/s]
 75%|███████████████████████████▉         | 1.25G/1.65G [00:15&lt;00:04, 82.9MB/s]
 76%|████████████████████████████▏        | 1.26G/1.65G [00:15&lt;00:04, 84.5MB/s]
 77%|████████████████████████████▎        | 1.27G/1.65G [00:15&lt;00:04, 77.7MB/s]
 77%|████████████████████████████▌        | 1.27G/1.65G [00:15&lt;00:04, 78.7MB/s]
 78%|████████████████████████████▋        | 1.28G/1.65G [00:15&lt;00:04, 79.7MB/s]
 78%|████████████████████████████▊        | 1.29G/1.65G [00:16&lt;00:04, 80.8MB/s]
 79%|█████████████████████████████        | 1.30G/1.65G [00:16&lt;00:04, 81.4MB/s]
 79%|█████████████████████████████▏       | 1.31G/1.65G [00:16&lt;00:04, 82.4MB/s]
 80%|█████████████████████████████▍       | 1.32G/1.65G [00:16&lt;00:04, 83.9MB/s]
 80%|█████████████████████████████▋       | 1.32G/1.65G [00:16&lt;00:03, 84.1MB/s]
 81%|█████████████████████████████▊       | 1.33G/1.65G [00:16&lt;00:03, 84.1MB/s]
 81%|██████████████████████████████       | 1.34G/1.65G [00:16&lt;00:03, 81.2MB/s]
 82%|██████████████████████████████▏      | 1.35G/1.65G [00:16&lt;00:03, 82.7MB/s]
 82%|██████████████████████████████▍      | 1.36G/1.65G [00:16&lt;00:03, 84.1MB/s]
 83%|██████████████████████████████▌      | 1.37G/1.65G [00:16&lt;00:03, 85.0MB/s]
 83%|██████████████████████████████▊      | 1.38G/1.65G [00:17&lt;00:03, 85.0MB/s]
 84%|██████████████████████████████▉      | 1.38G/1.65G [00:17&lt;00:04, 54.8MB/s]
 84%|███████████████████████████████▏     | 1.39G/1.65G [00:17&lt;00:04, 57.8MB/s]
 85%|███████████████████████████████▎     | 1.40G/1.65G [00:17&lt;00:04, 54.6MB/s]
 85%|███████████████████████████████▍     | 1.40G/1.65G [00:17&lt;00:04, 56.6MB/s]
 85%|███████████████████████████████▌     | 1.41G/1.65G [00:17&lt;00:03, 64.1MB/s]
 86%|███████████████████████████████▊     | 1.42G/1.65G [00:17&lt;00:03, 64.9MB/s]
 86%|███████████████████████████████▉     | 1.43G/1.65G [00:18&lt;00:03, 69.0MB/s]
 87%|████████████████████████████████▏    | 1.44G/1.65G [00:18&lt;00:03, 72.0MB/s]
 87%|████████████████████████████████▎    | 1.44G/1.65G [00:18&lt;00:02, 73.6MB/s]
 88%|████████████████████████████████▍    | 1.45G/1.65G [00:18&lt;00:02, 75.0MB/s]
 88%|████████████████████████████████▋    | 1.46G/1.65G [00:18&lt;00:02, 75.9MB/s]
 89%|████████████████████████████████▊    | 1.47G/1.65G [00:18&lt;00:02, 76.2MB/s]
 89%|█████████████████████████████████    | 1.47G/1.65G [00:18&lt;00:03, 57.4MB/s]
 90%|█████████████████████████████████▏   | 1.48G/1.65G [00:18&lt;00:02, 62.3MB/s]
 90%|█████████████████████████████████▎   | 1.49G/1.65G [00:18&lt;00:02, 66.8MB/s]
 91%|█████████████████████████████████▌   | 1.50G/1.65G [00:19&lt;00:02, 70.8MB/s]
 91%|█████████████████████████████████▋   | 1.51G/1.65G [00:19&lt;00:01, 74.3MB/s]
 92%|█████████████████████████████████▉   | 1.51G/1.65G [00:19&lt;00:01, 77.4MB/s]
 92%|██████████████████████████████████   | 1.52G/1.65G [00:19&lt;00:01, 79.7MB/s]
 93%|██████████████████████████████████▎  | 1.53G/1.65G [00:19&lt;00:01, 81.3MB/s]
 93%|██████████████████████████████████▍  | 1.54G/1.65G [00:19&lt;00:01, 81.0MB/s]
 94%|██████████████████████████████████▋  | 1.55G/1.65G [00:19&lt;00:01, 74.1MB/s]
 94%|██████████████████████████████████▊  | 1.56G/1.65G [00:19&lt;00:01, 75.0MB/s]
 95%|███████████████████████████████████  | 1.56G/1.65G [00:19&lt;00:01, 73.2MB/s]
 95%|███████████████████████████████████▏ | 1.57G/1.65G [00:19&lt;00:01, 77.0MB/s]
 96%|███████████████████████████████████▍ | 1.58G/1.65G [00:20&lt;00:00, 80.0MB/s]
 96%|███████████████████████████████████▌ | 1.59G/1.65G [00:20&lt;00:00, 81.9MB/s]
 97%|███████████████████████████████████▊ | 1.60G/1.65G [00:20&lt;00:00, 71.5MB/s]
 97%|███████████████████████████████████▉ | 1.61G/1.65G [00:20&lt;00:00, 71.7MB/s]
 98%|████████████████████████████████████ | 1.61G/1.65G [00:20&lt;00:00, 72.9MB/s]
 98%|████████████████████████████████████▎| 1.62G/1.65G [00:20&lt;00:00, 74.6MB/s]
 99%|████████████████████████████████████▍| 1.63G/1.65G [00:20&lt;00:00, 77.8MB/s]
 99%|████████████████████████████████████▋| 1.64G/1.65G [00:20&lt;00:00, 80.7MB/s]
100%|████████████████████████████████████▊| 1.65G/1.65G [00:20&lt;00:00, 82.1MB/s]
  0%|                                              | 0.00/1.65G [00:00&lt;?, ?B/s]
100%|█████████████████████████████████████| 1.65G/1.65G [00:00&lt;00:00, 5.62TB/s]
Download complete in 40s (1576.2 MB)
16 files missing from root.txt in /home/circleci/mne_data/MNE-sample-data/subjects
Downloading missing files remotely

  0%|                                               | 0.00/196M [00:00&lt;?, ?B/s]
  3%|▉                                     | 4.97M/196M [00:00&lt;00:03, 49.7MB/s]
  7%|██▌                                   | 13.4M/196M [00:00&lt;00:02, 70.3MB/s]
 11%|████▎                                 | 22.5M/196M [00:00&lt;00:02, 79.4MB/s]
 16%|██████                                | 31.2M/196M [00:00&lt;00:01, 82.6MB/s]
 20%|███████▋                              | 39.6M/196M [00:00&lt;00:01, 83.2MB/s]
 25%|█████████▎                            | 48.2M/196M [00:00&lt;00:01, 84.1MB/s]
 29%|███████████                           | 57.0M/196M [00:00&lt;00:01, 85.4MB/s]
 34%|████████████▊                         | 65.8M/196M [00:00&lt;00:01, 86.2MB/s]
 38%|██████████████▍                       | 74.5M/196M [00:00&lt;00:01, 86.3MB/s]
 42%|████████████████▏                     | 83.2M/196M [00:01&lt;00:01, 86.6MB/s]
 47%|█████████████████▊                    | 91.8M/196M [00:01&lt;00:01, 80.2MB/s]
 51%|████████████████████                   | 101M/196M [00:01&lt;00:01, 82.0MB/s]
 56%|█████████████████████▊                 | 109M/196M [00:01&lt;00:01, 83.6MB/s]
 60%|███████████████████████▍               | 118M/196M [00:01&lt;00:00, 84.0MB/s]
 64%|█████████████████████████▏             | 126M/196M [00:01&lt;00:00, 84.1MB/s]
 69%|██████████████████████████▊            | 135M/196M [00:01&lt;00:00, 84.7MB/s]
 73%|████████████████████████████▌          | 144M/196M [00:01&lt;00:00, 85.5MB/s]
 78%|██████████████████████████████▎        | 152M/196M [00:01&lt;00:00, 85.5MB/s]
 82%|████████████████████████████████       | 161M/196M [00:01&lt;00:00, 85.7MB/s]
 86%|█████████████████████████████████▋     | 169M/196M [00:02&lt;00:00, 84.9MB/s]
 91%|███████████████████████████████████▍   | 178M/196M [00:02&lt;00:00, 85.4MB/s]
 95%|█████████████████████████████████████▏ | 186M/196M [00:02&lt;00:00, 84.1MB/s]
100%|██████████████████████████████████████▊| 195M/196M [00:02&lt;00:00, 83.5MB/s]
  0%|                                               | 0.00/196M [00:00&lt;?, ?B/s]
100%|████████████████████████████████████████| 196M/196M [00:00&lt;00:00, 596GB/s]
Extracting missing files
Successfully extracted 16 files
10 files missing from bem.txt in /home/circleci/mne_data/MNE-sample-data/subjects/fsaverage
Downloading missing files remotely

  0%|                                               | 0.00/239M [00:00&lt;?, ?B/s]
  1%|▌                                     | 3.28M/239M [00:00&lt;00:07, 32.8MB/s]
  5%|█▊                                    | 11.7M/239M [00:00&lt;00:03, 63.1MB/s]
  8%|███▏                                  | 19.9M/239M [00:00&lt;00:03, 71.8MB/s]
 12%|████▌                                 | 28.3M/239M [00:00&lt;00:02, 76.6MB/s]
 15%|█████▊                                | 36.8M/239M [00:00&lt;00:02, 79.6MB/s]
 19%|███████▏                              | 45.5M/239M [00:00&lt;00:02, 82.1MB/s]
 23%|████████▌                             | 53.9M/239M [00:00&lt;00:02, 82.5MB/s]
 26%|█████████▉                            | 62.3M/239M [00:00&lt;00:02, 83.2MB/s]
 30%|███████████▏                          | 70.6M/239M [00:00&lt;00:02, 82.2MB/s]
 33%|████████████▋                         | 79.5M/239M [00:01&lt;00:01, 84.2MB/s]
 37%|█████████████▉                        | 87.9M/239M [00:01&lt;00:01, 81.6MB/s]
 40%|███████████████▎                      | 96.5M/239M [00:01&lt;00:01, 82.9MB/s]
 44%|█████████████████                      | 105M/239M [00:01&lt;00:01, 81.8MB/s]
 47%|██████████████████▌                    | 113M/239M [00:01&lt;00:01, 82.9MB/s]
 51%|███████████████████▉                   | 122M/239M [00:01&lt;00:01, 83.7MB/s]
 55%|█████████████████████▎                 | 130M/239M [00:01&lt;00:01, 83.0MB/s]
 58%|██████████████████████▋                | 139M/239M [00:01&lt;00:01, 84.8MB/s]
 62%|████████████████████████▏              | 148M/239M [00:01&lt;00:01, 85.0MB/s]
 65%|█████████████████████████▌             | 156M/239M [00:01&lt;00:00, 85.1MB/s]
 69%|██████████████████████████▉            | 165M/239M [00:02&lt;00:00, 86.3MB/s]
 73%|████████████████████████████▍          | 174M/239M [00:02&lt;00:00, 87.1MB/s]
 77%|█████████████████████████████▉         | 183M/239M [00:02&lt;00:00, 87.8MB/s]
 80%|███████████████████████████████▎       | 192M/239M [00:02&lt;00:00, 88.3MB/s]
 84%|████████████████████████████████▊      | 201M/239M [00:02&lt;00:00, 88.4MB/s]
 88%|██████████████████████████████████▎    | 210M/239M [00:02&lt;00:00, 88.5MB/s]
 92%|███████████████████████████████████▋   | 219M/239M [00:02&lt;00:00, 88.8MB/s]
 95%|█████████████████████████████████████▏ | 228M/239M [00:02&lt;00:00, 88.9MB/s]
 99%|██████████████████████████████████████▋| 237M/239M [00:02&lt;00:00, 89.0MB/s]
  0%|                                               | 0.00/239M [00:00&lt;?, ?B/s]
100%|████████████████████████████████████████| 239M/239M [00:00&lt;00:00, 865GB/s]
Extracting missing files
Successfully extracted 10 files
</pre></div>
</div>
<section id="aligning-the-t1-to-acpc">
<h2>Aligning the T1 to ACPC<a class="headerlink" href="#aligning-the-t1-to-acpc" title="Link to this heading">#</a></h2>
<p>For intracranial electrophysiology recordings, the Brain Imaging Data
Structure (BIDS) standard requires that coordinates be aligned to the
anterior commissure and posterior commissure (ACPC-aligned). Therefore, it is
recommended that you do this alignment before finding the positions of the
channels in your recording. Doing this will make the “mri” (aka surface RAS)
coordinate frame an ACPC coordinate frame. This can be done using
Freesurfer’s freeview:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>freeview<span class="w"> </span><span class="nv">$MISC_PATH</span>/seeg/sample_seeg_T1.mgz
</pre></div>
</div>
<p>And then interact with the graphical user interface:</p>
<p>First, it is recommended to change the cursor style to long, this can be done
through the menu options like so:</p>
<blockquote>
<div><p><span class="menuselection">Freeview ‣ Preferences ‣ General ‣ Cursor style
‣ Long</span></p>
</div></blockquote>
<p>Then, the image needs to be aligned to ACPC to look like the image below.
This can be done by pulling up the transform popup from the menu like so:</p>
<blockquote>
<div><p><span class="menuselection">Tools ‣ Transform Volume</span></p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Be sure to set the text entry box labeled RAS (not TkReg RAS) to
<code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">0</span> <span class="pre">0</span></code> before beginning the transform.</p>
</div>
<p>Then translate the image until the crosshairs meet on the AC and
run through the PC as shown in the plot. The eyes should be in
the ACPC plane and the image should be rotated until they are symmetrical,
and the crosshairs should transect the midline of the brain.
Be sure to use both the rotate and the translate menus and save the volume
after you’re finished using <code class="docutils literal notranslate"><span class="pre">Save</span> <span class="pre">Volume</span> <span class="pre">As</span></code> in the transform popup
<a class="footnote-reference brackets" href="#footcite-hamiltonetal2017" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T1</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;mri&quot;</span> <span class="o">/</span> <span class="s2">&quot;T1.mgz&quot;</span><span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.viewers.html#nibabel.viewers.OrthoSlicer3D" title="nibabel.viewers.OrthoSlicer3D" class="sphx-glr-backref-module-nibabel-viewers sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">viewer</span></a> <span class="o">=</span> <span class="n">T1</span><span class="o">.</span><span class="n">orthoview</span><span class="p">()</span>
<a href="https://nipy.org/nibabel/reference/nibabel.viewers.html#nibabel.viewers.OrthoSlicer3D.set_position" title="nibabel.viewers.OrthoSlicer3D.set_position" class="sphx-glr-backref-module-nibabel-viewers sphx-glr-backref-type-py-method"><span class="n">viewer</span><span class="o">.</span><span class="n">set_position</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.viewers.html#nibabel.viewers.OrthoSlicer3D.figs" title="nibabel.viewers.OrthoSlicer3D.figs" class="sphx-glr-backref-module-nibabel-viewers sphx-glr-backref-type-py-property"><span class="n">viewer</span><span class="o">.</span><span class="n">figs</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;PC&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">107</span><span class="p">,</span> <span class="mi">108</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">headwidth</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.viewers.html#nibabel.viewers.OrthoSlicer3D.figs" title="nibabel.viewers.OrthoSlicer3D.figs" class="sphx-glr-backref-module-nibabel-viewers sphx-glr-backref-type-py-property"><span class="n">viewer</span><span class="o">.</span><span class="n">figs</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="s2">&quot;AC&quot;</span><span class="p">,</span>
    <span class="p">(</span><span class="mi">137</span><span class="p">,</span> <span class="mi">108</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">246</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">headwidth</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_001.png" srcset="../_images/sphx_glr_ieeg_locate_001.png" alt="ieeg locate" class = "sphx-glr-single-img"/></section>
<section id="freesurfer-recon-all">
<h2>Freesurfer recon-all<a class="headerlink" href="#freesurfer-recon-all" title="Link to this heading">#</a></h2>
<p>The first step is the most time consuming; the freesurfer reconstruction.
This process segments out the brain from the rest of the MR image and
determines which voxels correspond to each brain area based on a template
deformation. This process takes approximately 8 hours so plan accordingly.
The example dataset contains the data from completed reconstruction so
we will proceed using that.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">SUBJECT</span><span class="o">=</span>sample_seeg
<span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">SUBJECTS_DIR</span><span class="o">=</span><span class="nv">$MY_DATA_DIRECTORY</span>
<span class="gp">$ </span>recon-all<span class="w"> </span>-subjid<span class="w"> </span><span class="nv">$SUBJECT</span><span class="w"> </span>-sd<span class="w"> </span><span class="nv">$SUBJECTS_DIR</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-i<span class="w"> </span><span class="nv">$MISC_PATH</span>/seeg/sample_seeg_T1.mgz<span class="w"> </span>-all<span class="w"> </span>-deface
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may need to include an additional <code class="docutils literal notranslate"><span class="pre">-cw256</span></code> flag which can be added
to the end of the recon-all command if your MR scan is not
<code class="docutils literal notranslate"><span class="pre">256</span> <span class="pre">×</span> <span class="pre">256</span> <span class="pre">×</span> <span class="pre">256</span></code> voxels.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using the <code class="docutils literal notranslate"><span class="pre">-deface</span></code> flag will create a defaced, anonymized T1 image
located at <code class="docutils literal notranslate"><span class="pre">$MY_DATA_DIRECTORY/$SUBJECT/mri/orig_defaced.mgz</span></code>,
which is helpful for when you publish your data. You can also use
<a class="reference external" href="https://mne.tools/mne-bids/stable/generated/mne_bids.write_anat.html#mne_bids.write_anat" title="(in MNE-BIDS v0.14)"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne_bids.write_anat()</span></code></a> and pass <code class="docutils literal notranslate"><span class="pre">deface=True</span></code>.</p>
</div>
</section>
<section id="aligning-the-ct-to-the-mr">
<h2>Aligning the CT to the MR<a class="headerlink" href="#aligning-the-ct-to-the-mr" title="Link to this heading">#</a></h2>
<p>Let’s load our T1 and CT images and visualize them. You can hardly
see the CT, it’s so misaligned that all you can see is part of the
stereotactic frame that is anteriolateral to the skull in the middle plot.
Clearly, we need to align the CT to the T1 image.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_overlay</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">compare</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define a helper function for comparing plots.&quot;&quot;&quot;</span>
    <span class="n">image</span> <span class="o">=</span> <a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.apply_orientation" title="nibabel.orientations.apply_orientation" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">apply_orientation</span></a><span class="p">(</span>
        <a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">dataobj</span><span class="p">),</span>
        <a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.axcodes2ornt" title="nibabel.orientations.axcodes2ornt" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">axcodes2ornt</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.aff2axcodes" title="nibabel.orientations.aff2axcodes" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">aff2axcodes</span></a><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">affine</span><span class="p">)),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
    <span class="n">compare</span> <span class="o">=</span> <a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.apply_orientation" title="nibabel.orientations.apply_orientation" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">apply_orientation</span></a><span class="p">(</span>
        <a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">dataobj</span><span class="p">),</span>
        <a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.axcodes2ornt" title="nibabel.orientations.axcodes2ornt" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">axcodes2ornt</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.orientations.html#nibabel.orientations.aff2axcodes" title="nibabel.orientations.aff2axcodes" class="sphx-glr-backref-module-nibabel-orientations sphx-glr-backref-type-py-function"><span class="n">nib</span><span class="o">.</span><span class="n">orientations</span><span class="o">.</span><span class="n">aff2axcodes</span></a><span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">affine</span><span class="p">)),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
    <span class="k">if</span> <span class="n">thresh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">compare</span><span class="p">[</span><span class="n">compare</span> <span class="o">&lt;</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.quantile.html#numpy.quantile" title="numpy.quantile" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">quantile</span></a><span class="p">(</span><span class="n">compare</span><span class="p">,</span> <span class="n">thresh</span><span class="p">)]</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">nan</span></a>
    <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.suptitle" title="matplotlib.figure.Figure.suptitle" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span></a><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">):</span>
        <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow" title="matplotlib.axes.Axes.imshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span></a><span class="p">(</span>
            <a href="https://numpy.org/doc/stable/reference/generated/numpy.take.html#numpy.take" title="numpy.take" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">take</span></a><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span>
        <span class="p">)</span>
        <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow" title="matplotlib.axes.Axes.imshow" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span></a><span class="p">(</span>
            <a href="https://numpy.org/doc/stable/reference/generated/numpy.take.html#numpy.take" title="numpy.take" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">take</span></a><span class="p">(</span><span class="n">compare</span><span class="p">,</span> <span class="p">[</span><span class="n">compare</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gist_heat&quot;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="p">)</span>
        <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis" title="matplotlib.axes.Axes.invert_yaxis" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span></a><span class="p">()</span>
        <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.axis.html#matplotlib.axes.Axes.axis" title="matplotlib.axes.Axes.axis" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axis</span></a><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.tight_layout" title="matplotlib.figure.Figure.tight_layout" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>


<span class="n">CT_orig</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_seeg_CT.mgz&quot;</span><span class="p">)</span>

<span class="c1"># resample to T1&#39;s definition of world coordinates</span>
<span class="n">CT_resampled</span> <span class="o">=</span> <span class="n">resample</span><span class="p">(</span>
    <span class="n">moving</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">CT_orig</span><span class="o">.</span><span class="n">dataobj</span><span class="p">),</span>
    <span class="n">static</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">T1</span><span class="o">.</span><span class="n">dataobj</span><span class="p">),</span>
    <span class="n">moving_affine</span><span class="o">=</span><span class="n">CT_orig</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
    <span class="n">static_affine</span><span class="o">=</span><span class="n">T1</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_overlay</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">CT_resampled</span><span class="p">,</span> <span class="s2">&quot;Unaligned CT Overlaid on T1&quot;</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="k">del</span> <span class="n">CT_resampled</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_002.png" srcset="../_images/sphx_glr_ieeg_locate_002.png" alt="Unaligned CT Overlaid on T1" class = "sphx-glr-single-img"/><p>Now we need to align our CT image to the T1 image.</p>
<p>We want this to be a rigid transformation (just rotation + translation),
so we don’t do a full affine registration (that includes shear) here.
This takes a while (~10 minutes) to execute so we skip actually running it
here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.compute_volume_registration.html#mne.transforms.compute_volume_registration" title="mne.transforms.compute_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">compute_volume_registration</span></a><span class="p">(</span>
     <span class="n">CT_orig</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">pipeline</span><span class="o">=</span><span class="s1">&#39;rigids&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Instead we just hard-code the resulting 4x4 matrix:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.99270756</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03243313</span><span class="p">,</span> <span class="mf">0.11610254</span><span class="p">,</span> <span class="o">-</span><span class="mf">133.094156</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.04374389</span><span class="p">,</span> <span class="mf">0.99439665</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09623816</span><span class="p">,</span> <span class="o">-</span><span class="mf">97.58320673</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.11233068</span><span class="p">,</span> <span class="mf">0.10061512</span><span class="p">,</span> <span class="mf">0.98856381</span><span class="p">,</span> <span class="o">-</span><span class="mf">84.45551601</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># use a cval=&#39;1%&#39; here to make the values outside the domain of the CT</span>
<span class="c1"># the same as the background level during interpolation</span>
<span class="n">CT_aligned</span> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html#mne.transforms.apply_volume_registration" title="mne.transforms.apply_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">apply_volume_registration</span></a><span class="p">(</span>
    <span class="n">CT_orig</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <span class="n">cval</span><span class="o">=</span><span class="s2">&quot;1%&quot;</span>
<span class="p">)</span>
<span class="n">plot_overlay</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">CT_aligned</span><span class="p">,</span> <span class="s2">&quot;Aligned CT Overlaid on T1&quot;</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="k">del</span> <span class="n">CT_orig</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_003.png" srcset="../_images/sphx_glr_ieeg_locate_003.png" alt="Aligned CT Overlaid on T1" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Applying affine registration ...
Using a lower bound at the 1.0 percentile: -1024.0
[done]
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Alignment failures sometimes occur which requires manual pre-alignment.
Freesurfer’s <code class="docutils literal notranslate"><span class="pre">freeview</span></code> can be used to to align manually</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>freeview<span class="w"> </span><span class="nv">$MISC_PATH</span>/seeg/sample_seeg/mri/T1.mgz<span class="w"> </span><span class="se">\</span>
<span class="gp">   $</span>MISC_PATH/seeg/sample_seeg_CT.mgz:colormap<span class="o">=</span>heat:opacity<span class="o">=</span><span class="m">0</span>.6
</pre></div>
</div>
<ul class="simple">
<li><p>Navigate to the upper toolbar, go to
<span class="menuselection">Tools ‣ Transform Volume</span></p></li>
<li><p>Use the rotation and translation slide bars to align the CT
to the MR (be sure to have the CT selected in the upper left menu)</p></li>
<li><p>Save the linear transform array (lta) file using the <code class="docutils literal notranslate"><span class="pre">Save</span> <span class="pre">Reg...</span></code>
button</p></li>
</ul>
<p>Since we really require as much precision as possible for the
alignment, we should rerun the algorithm starting with the manual
alignment. This time, we just want to skip to the most exact rigid
alignment, without smoothing, since the manual alignment is already
very close.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load transform</span>
<span class="n">manual_reg_affine_vox</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">read_lta</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>  <span class="c1"># the path used above</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a><span class="p">,</span> <span class="s1">&#39;seeg&#39;</span><span class="p">,</span> <span class="s1">&#39;sample_seeg_CT_aligned_manual.mgz.lta&#39;</span><span class="p">))</span>
<span class="c1"># convert from vox-&gt;vox to ras-&gt;ras</span>
<span class="n">manual_reg_affine</span> <span class="o">=</span> \
    <span class="n">CT_orig</span><span class="o">.</span><span class="n">affine</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">manual_reg_affine_vox</span><span class="p">)</span> \
    <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">CT_orig</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.compute_volume_registration.html#mne.transforms.compute_volume_registration" title="mne.transforms.compute_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">compute_volume_registration</span></a><span class="p">(</span>
    <span class="n">CT_orig</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <span class="n">pipeline</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;rigid&#39;</span><span class="p">],</span>
    <span class="n">starting_affine</span><span class="o">=</span><span class="n">manual_reg_affine</span><span class="p">)</span>
<span class="n">CT_aligned</span> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html#mne.transforms.apply_volume_registration" title="mne.transforms.apply_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">apply_volume_registration</span></a><span class="p">(</span>
    <span class="n">CT_orig</span><span class="p">,</span> <span class="n">T1</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <span class="n">cval</span><span class="o">=</span><span class="s1">&#39;1%&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The rest of the tutorial can then be completed using <code class="docutils literal notranslate"><span class="pre">CT_aligned</span></code>
from this point on.</p>
</div>
<p>We can now see how the CT image looks properly aligned to the T1 image.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The hyperintense skull is actually aligned to the hypointensity between
the brain and the scalp. The brighter area surrounding the skull in the
MR is actually subcutaneous fat.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># make low intensity parts of the CT transparent for easier visualization</span>
<span class="n">CT_data</span> <span class="o">=</span> <span class="n">CT_aligned</span><span class="o">.</span><span class="n">get_fdata</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">CT_data</span><span class="p">[</span><span class="n">CT_data</span> <span class="o">&lt;</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.quantile.html#numpy.quantile" title="numpy.quantile" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">quantile</span></a><span class="p">(</span><span class="n">CT_data</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)]</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">nan</span></a>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">T1_data</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">T1</span><span class="o">.</span><span class="n">dataobj</span><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="ow">in</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">:</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.axis.html#matplotlib.axes.Axes.axis" title="matplotlib.axes.Axes.axis" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">axis</span></a><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">T1_data</span></a><span class="p">[</span><span class="n">T1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MR&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">(</span><span class="n">CT_aligned</span><span class="o">.</span><span class="n">dataobj</span><span class="p">)[</span><span class="n">CT_aligned</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CT&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">T1_data</span></a><span class="p">[</span><span class="n">T1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">CT_data</span><span class="p">[</span><span class="n">CT_aligned</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gist_heat&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="k">for</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="ow">in</span> <span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.annotate.html#matplotlib.axes.Axes.annotate" title="matplotlib.axes.Axes.annotate" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">annotate</span></a><span class="p">(</span>
        <span class="s2">&quot;Subcutaneous fat&quot;</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">110</span><span class="p">,</span> <span class="mi">52</span><span class="p">),</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span>
        <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
        <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">),</span>
    <span class="p">)</span>
<span class="k">for</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="ow">in</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">:</span>
    <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.annotate.html#matplotlib.axes.Axes.annotate" title="matplotlib.axes.Axes.annotate" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">annotate</span></a><span class="p">(</span>
        <span class="s2">&quot;Skull (dark in MR, bright in CT)&quot;</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">175</span><span class="p">),</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">246</span><span class="p">),</span>
        <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span>
        <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">),</span>
    <span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CT aligned to MR&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.tight_layout" title="matplotlib.figure.Figure.tight_layout" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span></a><span class="p">()</span>
<span class="k">del</span> <span class="n">CT_data</span><span class="p">,</span> <span class="n">T1</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_004.png" srcset="../_images/sphx_glr_ieeg_locate_004.png" alt="MR, CT, CT aligned to MR" class = "sphx-glr-single-img"/><p>Now we need to estimate the “head” coordinate transform.</p>
<p>MNE stores digitization montages in a coordinate frame called “head”
defined by fiducial points (origin is halfway between the LPA and RPA
see <a class="reference external" href="https://mne.tools/stable/auto_tutorials/forward/20_source_alignment.html#tut-source-alignment" title="(in MNE v1.5)"><span>Source alignment and coordinate frames</span></a>). For sEEG, it is convenient to get an
estimate of the location of the fiducial points for the subject
using the Talairach transform (see <a class="reference external" href="https://mne.tools/stable/generated/mne.coreg.get_mni_fiducials.html#mne.coreg.get_mni_fiducials" title="(in MNE v1.5)"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.coreg.get_mni_fiducials()</span></code></a>)
to use to define the coordinate frame so that we don’t have to manually
identify their location.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># estimate head-&gt;mri transform</span>
<a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.coreg.estimate_head_mri_t.html#mne.coreg.estimate_head_mri_t" title="mne.coreg.estimate_head_mri_t" class="sphx-glr-backref-module-mne-coreg sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">coreg</span><span class="o">.</span><span class="n">estimate_head_mri_t</span></a><span class="p">(</span><span class="s2">&quot;sample_seeg&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="marking-the-location-of-each-electrode-contact">
<h2>Marking the Location of Each Electrode Contact<a class="headerlink" href="#marking-the-location-of-each-electrode-contact" title="Link to this heading">#</a></h2>
<p>Now, the CT and the MR are in the same space, so when you are looking at a
point in CT space, it is the same point in MR space. So now everything is
ready to determine the location of each electrode contact in the
individual subject’s anatomical space (T1-space). To do this, we can use the
MNE intracranial electrode location graphical user interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The most useful coordinate frame for intracranial electrodes is
generally the <code class="docutils literal notranslate"><span class="pre">surface</span> <span class="pre">RAS</span></code> coordinate frame because that is
the coordinate frame that all the surface and image files that
Freesurfer outputs are in, see <a class="reference external" href="https://mne.tools/stable/auto_tutorials/forward/50_background_freesurfer_mne.html#tut-freesurfer-mne" title="(in MNE v1.5)"><span>How MNE uses FreeSurfer’s outputs</span></a>. These are
useful for finding the brain structures nearby each contact and
plotting the results.</p>
</div>
<p>See the following video on how to operate the GUI or follow the steps below:</p>
<div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://www.youtube.com/embed/8JWDJhXq0VY" style="border: 0; height: 345px; width: 560px">
</iframe></div><ul class="simple">
<li><p>Click in each image to navigate to each electrode contact</p></li>
<li><p>Select the contact name in the right panel</p></li>
<li><p>Press the “Mark” button or the “m” key to associate that
position with that contact</p></li>
<li><p>Repeat until each contact is marked, they will both appear as circles
in the plots and be colored in the sidebar when marked</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The channel locations are saved to the <code class="docutils literal notranslate"><span class="pre">raw</span></code> object every time
a location is marked or removed so there is no “Save” button.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using the scroll or +/- arrow keys you can zoom in and out,
and the up/down, left/right and page up/page down keys allow
you to move one slice in any direction. This information is
available in the help menu, accessible by pressing the “h” key.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If “Snap to Center” is on, this will use the radius so be
sure to set it properly.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load electrophysiology data to find channel locations for</span>
<span class="c1"># (the channels are already located in the example)</span>

<a href="https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.io.read_raw.html#mne.io.read_raw" title="mne.io.read_raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_seeg_ieeg.fif&quot;</span><span class="p">)</span>

<span class="c1"># you may want to add `block=True` to halt execution until you have interacted</span>
<span class="c1"># with the GUI to find the channel positions, that way the raw object can</span>
<span class="c1"># be used later in the script (e.g. saved with channel positions)</span>
<a href="../generated/mne_gui_addons.locate_ieeg.html#mne_gui_addons.locate_ieeg" title="mne_gui_addons.locate_ieeg" class="sphx-glr-backref-module-mne_gui_addons sphx-glr-backref-type-py-function"><span class="n">mne_gui</span><span class="o">.</span><span class="n">locate_ieeg</span></a><span class="p">(</span>
    <a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span>
    <a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans</span></a><span class="p">,</span>
    <span class="n">CT_aligned</span><span class="p">,</span>
    <span class="n">subject</span><span class="o">=</span><span class="s2">&quot;sample_seeg&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># The `raw` object is modified to contain the channel locations</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_005.png" srcset="../_images/sphx_glr_ieeg_locate_005.png" alt="GUI" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-misc-data/seeg/sample_seeg_ieeg.fif...
    Range : 1310640 ... 1370605 =   1311.411 ...  1371.411 secs
Ready.
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
</pre></div>
</div>
<p>Let’s do a quick sidebar and show what this looks like for ECoG as well.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://nipy.org/nibabel/reference/nibabel.freesurfer.html#nibabel.freesurfer.mghformat.MGHImage" title="nibabel.freesurfer.mghformat.MGHImage" class="sphx-glr-backref-module-nibabel-freesurfer-mghformat sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">T1_ecog</span></a> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_ecog&quot;</span> <span class="o">/</span> <span class="s2">&quot;mri&quot;</span> <span class="o">/</span> <span class="s2">&quot;T1.mgz&quot;</span><span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.freesurfer.html#nibabel.freesurfer.mghformat.MGHImage" title="nibabel.freesurfer.mghformat.MGHImage" class="sphx-glr-backref-module-nibabel-freesurfer-mghformat sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CT_orig_ecog</span></a> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_ecog_CT.mgz&quot;</span><span class="p">)</span>

<span class="c1"># pre-computed affine from `mne.transforms.compute_volume_registration`</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.99982382</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00414586</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01830679</span><span class="p">,</span> <span class="mf">0.15413965</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.00549597</span><span class="p">,</span> <span class="mf">0.99721885</span><span class="p">,</span> <span class="mf">0.07432601</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.54316131</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.01794773</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07441352</span><span class="p">,</span> <span class="mf">0.99706595</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.84162514</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="c1"># align CT</span>
<a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CT_aligned_ecog</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html#mne.transforms.apply_volume_registration" title="mne.transforms.apply_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">apply_volume_registration</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.freesurfer.html#nibabel.freesurfer.mghformat.MGHImage" title="nibabel.freesurfer.mghformat.MGHImage" class="sphx-glr-backref-module-nibabel-freesurfer-mghformat sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CT_orig_ecog</span></a><span class="p">,</span> <a href="https://nipy.org/nibabel/reference/nibabel.freesurfer.html#nibabel.freesurfer.mghformat.MGHImage" title="nibabel.freesurfer.mghformat.MGHImage" class="sphx-glr-backref-module-nibabel-freesurfer-mghformat sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">T1_ecog</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <span class="n">cval</span><span class="o">=</span><span class="s2">&quot;1%&quot;</span>
<span class="p">)</span>

<a href="https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw" title="mne.io.Raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.io.read_raw.html#mne.io.read_raw" title="mne.io.read_raw" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_ecog_ieeg.fif&quot;</span><span class="p">)</span>
<span class="c1"># use estimated `trans` which was used when the locations were found previously</span>
<a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans_ecog</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.coreg.estimate_head_mri_t.html#mne.coreg.estimate_head_mri_t" title="mne.coreg.estimate_head_mri_t" class="sphx-glr-backref-module-mne-coreg sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">coreg</span><span class="o">.</span><span class="n">estimate_head_mri_t</span></a><span class="p">(</span><span class="s2">&quot;sample_ecog&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span><span class="p">)</span>
<a href="../generated/mne_gui_addons.locate_ieeg.html#mne_gui_addons.locate_ieeg" title="mne_gui_addons.locate_ieeg" class="sphx-glr-backref-module-mne_gui_addons sphx-glr-backref-type-py-function"><span class="n">mne_gui</span><span class="o">.</span><span class="n">locate_ieeg</span></a><span class="p">(</span>
    <a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span>
    <a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans_ecog</span></a><span class="p">,</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CT_aligned_ecog</span></a><span class="p">,</span>
    <span class="n">subject</span><span class="o">=</span><span class="s2">&quot;sample_ecog&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_006.png" srcset="../_images/sphx_glr_ieeg_locate_006.png" alt="GUI" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Applying affine registration ...
Using a lower bound at the 1.0 percentile: -3024.0
[done]
Opening raw data file /home/circleci/mne_data/MNE-misc-data/ecog/sample_ecog_ieeg.fif...
    Range : 0 ... 112 =      0.000 ...     0.700 secs
Ready.
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
</pre></div>
</div>
<p>For ECoG, we typically want to account for “brain shift” or shrinking of the
brain away from the skull/dura due to changes in pressure during the
craniotomy
Note: this requires the BEM surfaces to have been computed e.g. using
<a class="reference external" href="https://mne.tools/stable/generated/commands.html#mne-watershed-bem" title="(in MNE v1.5)"><span class="xref std std-ref">mne watershed_bem</span></a> or <a class="reference external" href="https://mne.tools/stable/generated/commands.html#mne-flash-bem" title="(in MNE v1.5)"><span class="xref std std-ref">mne flash_bem</span></a>.
First, let’s plot the localized sensor positions without modification.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot projected sensors</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain_kwargs</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cortex</span><span class="o">=</span><span class="s2">&quot;low_contrast&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">background</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">Brain</span></a><span class="p">(</span>
    <span class="s2">&quot;sample_ecog&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Before Projection&quot;</span><span class="p">,</span>
    <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain_kwargs</span></a><span class="p">,</span>
<span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.add_sensors" title="mne.viz.Brain.add_sensors" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">add_sensors</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans_ecog</span></a><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">view_kwargs</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">azimuth</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">elevation</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="n">focalpoint</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">15</span><span class="p">))</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.show_view" title="mne.viz.Brain.show_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">show_view</span></a><span class="p">(</span><span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">view_kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_007.png" srcset="../_images/sphx_glr_ieeg_locate_007.png" alt="ieeg locate" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
Channel types:: ecog: 320, seeg: 74
</pre></div>
</div>
<p>Now, let’s project the sensors to the brain surface and re-plot them.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># project sensors to the brain surface</span>
<a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span><span class="o">.</span><span class="n">info</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.preprocessing.ieeg.project_sensors_onto_brain.html#mne.preprocessing.ieeg.project_sensors_onto_brain" title="mne.preprocessing.ieeg.project_sensors_onto_brain" class="sphx-glr-backref-module-mne-preprocessing-ieeg sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">ieeg</span><span class="o">.</span><span class="n">project_sensors_onto_brain</span></a><span class="p">(</span>
    <a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans_ecog</span></a><span class="p">,</span> <span class="s2">&quot;sample_ecog&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span>
<span class="p">)</span>

<span class="c1"># plot projected sensors</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">Brain</span></a><span class="p">(</span>
    <span class="s2">&quot;sample_ecog&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;ecog&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;After Projection&quot;</span><span class="p">,</span>
    <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain_kwargs</span></a><span class="p">,</span>
<span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.add_sensors" title="mne.viz.Brain.add_sensors" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">add_sensors</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw_ecog</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans_ecog</span></a><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.show_view" title="mne.viz.Brain.show_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">show_view</span></a><span class="p">(</span><span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">view_kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_008.png" srcset="../_images/sphx_glr_ieeg_locate_008.png" alt="ieeg locate" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
Channel types:: ecog: 320, seeg: 74
</pre></div>
</div>
<p>Let’s plot the electrode contact locations on the subject’s brain.</p>
<p>MNE stores digitization montages in a coordinate frame called “head”
defined by fiducial points (origin is halfway between the LPA and RPA
see <a class="reference external" href="https://mne.tools/stable/auto_tutorials/forward/20_source_alignment.html#tut-source-alignment" title="(in MNE v1.5)"><span>Source alignment and coordinate frames</span></a>). For sEEG, it is convenient to get an
estimate of the location of the fiducial points for the subject
using the Talairach transform (see <a class="reference external" href="https://mne.tools/stable/generated/mne.coreg.get_mni_fiducials.html#mne.coreg.get_mni_fiducials" title="(in MNE v1.5)"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.coreg.get_mni_fiducials()</span></code></a>)
to use to define the coordinate frame so that we don’t have to manually
identify their location. The estimated head-&gt;mri <code class="docutils literal notranslate"><span class="pre">trans</span></code> was used
when the electrode contacts were localized so we need to use it again here.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the alignment</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">Brain</span></a><span class="p">(</span><span class="s2">&quot;sample_seeg&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span><span class="p">,</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain_kwargs</span></a><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.add_sensors" title="mne.viz.Brain.add_sensors" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">add_sensors</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans</span></a><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.show_view" title="mne.viz.Brain.show_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">show_view</span></a><span class="p">(</span><span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">view_kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_009.png" srcset="../_images/sphx_glr_ieeg_locate_009.png" alt="ieeg locate" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
Channel types:: seeg: 119
</pre></div>
</div>
</section>
<section id="warping-to-a-common-atlas">
<h2>Warping to a Common Atlas<a class="headerlink" href="#warping-to-a-common-atlas" title="Link to this heading">#</a></h2>
<p>Electrode contact locations are often compared across subjects in a template
space such as <code class="docutils literal notranslate"><span class="pre">fsaverage</span></code> or <code class="docutils literal notranslate"><span class="pre">cvs_avg35_inMNI152</span></code>. To transform electrode
contact locations to that space, we need to determine a function that maps
from the subject’s brain to the template brain. We will use the symmetric
diffeomorphic registration (SDR) implemented by <code class="docutils literal notranslate"><span class="pre">Dipy</span></code> to do this.</p>
<p>Before we can make a function to account for individual differences in the
shape and size of brain areas, we need to fix the alignment of the brains.
The plot below shows that they are not yet aligned.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the subject&#39;s brain and the Freesurfer &quot;fsaverage&quot; template brain</span>
<span class="n">subject_brain</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">misc_path</span></a> <span class="o">/</span> <span class="s2">&quot;seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;sample_seeg&quot;</span> <span class="o">/</span> <span class="s2">&quot;mri&quot;</span> <span class="o">/</span> <span class="s2">&quot;brain.mgz&quot;</span><span class="p">)</span>
<span class="n">template_brain</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a> <span class="o">/</span> <span class="s2">&quot;fsaverage&quot;</span> <span class="o">/</span> <span class="s2">&quot;mri&quot;</span> <span class="o">/</span> <span class="s2">&quot;brain.mgz&quot;</span><span class="p">)</span>

<span class="n">plot_overlay</span><span class="p">(</span>
    <span class="n">template_brain</span><span class="p">,</span> <span class="n">subject_brain</span><span class="p">,</span> <span class="s2">&quot;Alignment with fsaverage before Affine Registration&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_010.png" srcset="../_images/sphx_glr_ieeg_locate_010.png" alt="Alignment with fsaverage before Affine Registration" class = "sphx-glr-single-img"/><p>Now, we’ll register the affine of the subject’s brain to the template brain.
This aligns the two brains, preparing the subject’s brain to be warped
to the template.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Here we use custom <code class="docutils literal notranslate"><span class="pre">zooms</span></code> just for speed (this downsamples
the image resolution), in general we recommend using
<code class="docutils literal notranslate"><span class="pre">zooms=None</span></code> (default) for highest accuracy!</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">zooms</span></a> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">translation</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">rigid</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">sdr</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <a href="https://dipy.org/documentation/latest/reference/dipy.align/#dipy.align.imwarp.DiffeomorphicMap" title="dipy.align.imwarp.DiffeomorphicMap" class="sphx-glr-backref-module-dipy-align-imwarp sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sdr_morph</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.compute_volume_registration.html#mne.transforms.compute_volume_registration" title="mne.transforms.compute_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">compute_volume_registration</span></a><span class="p">(</span>
    <span class="n">subject_brain</span><span class="p">,</span> <span class="n">template_brain</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">zooms</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">zooms</span></a><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subject_brain_sdr</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html#mne.transforms.apply_volume_registration" title="mne.transforms.apply_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">apply_volume_registration</span></a><span class="p">(</span>
    <span class="n">subject_brain</span><span class="p">,</span> <span class="n">template_brain</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <a href="https://dipy.org/documentation/latest/reference/dipy.align/#dipy.align.imwarp.DiffeomorphicMap" title="dipy.align.imwarp.DiffeomorphicMap" class="sphx-glr-backref-module-dipy-align-imwarp sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sdr_morph</span></a>
<span class="p">)</span>

<span class="c1"># apply the transform to the subject brain to plot it</span>
<span class="n">plot_overlay</span><span class="p">(</span>
    <span class="n">template_brain</span><span class="p">,</span> <a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subject_brain_sdr</span></a><span class="p">,</span> <span class="s2">&quot;Alignment with fsaverage after SDR Registration&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_011.png" srcset="../_images/sphx_glr_ieeg_locate_011.png" alt="Alignment with fsaverage after SDR Registration" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing registration...
Reslicing to zooms=(10.0, 10.0, 10.0) for translation ...
Optimizing translation:
    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
    Translation:    4.9 mm
    R²:            95.3%
Optimizing rigid:
    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
    Translation:    4.9 mm
    Rotation:       9.3°
    R²:            96.0%
Optimizing affine:
    Optimizing level 2 [max iter: 10000]
    Optimizing level 1 [max iter: 1000]
    Optimizing level 0 [max iter: 100]
    R²:            95.8%
Reslicing to zooms=(5.0, 5.0, 5.0) for sdr ...
Optimizing sdr:
    R²:            97.8%
Applying affine registration ...
Applying SDR warp ...
[done]
</pre></div>
</div>
<p>Finally, we’ll apply the registrations to the electrode contact coordinates.
The brain image is warped to the template but the goal was to warp the
positions of the electrode contacts. To do that, we’ll make an image that is
a lookup table of the electrode contacts. In this image, the background will
be <code class="docutils literal notranslate"><span class="pre">0</span></code> s all the bright voxels near the location of the first contact will
be <code class="docutils literal notranslate"><span class="pre">1</span></code> s, the second <code class="docutils literal notranslate"><span class="pre">2</span></code> s and so on. This image can then be warped by
the SDR transform. We can finally recover a position by averaging the
positions of all the voxels that had the contact’s lookup number in
the warped image.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># first we need our montage but it needs to be converted to &quot;mri&quot; coordinates</span>
<span class="c1"># using our ``subj_trans``</span>
<a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.get_montage" title="mne.io.Raw.get_montage" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">get_montage</span></a><span class="p">()</span>
<a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage.apply_trans" title="mne.channels.DigMontage.apply_trans" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">montage</span><span class="o">.</span><span class="n">apply_trans</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subj_trans</span></a><span class="p">)</span>

<span class="c1"># warp the montage</span>
<a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage_warped</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.preprocessing.ieeg.warp_montage.html#mne.preprocessing.ieeg.warp_montage" title="mne.preprocessing.ieeg.warp_montage" class="sphx-glr-backref-module-mne-preprocessing-ieeg sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">ieeg</span><span class="o">.</span><span class="n">warp_montage</span></a><span class="p">(</span>
    <a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a><span class="p">,</span> <span class="n">subject_brain</span><span class="p">,</span> <span class="n">template_brain</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <a href="https://dipy.org/documentation/latest/reference/dipy.align/#dipy.align.imwarp.DiffeomorphicMap" title="dipy.align.imwarp.DiffeomorphicMap" class="sphx-glr-backref-module-dipy-align-imwarp sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sdr_morph</span></a>
<span class="p">)</span>

<span class="c1"># visualize using an image of the electrode contacts to see their sizes</span>
<a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">elec_image</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.preprocessing.ieeg.make_montage_volume.html#mne.preprocessing.ieeg.make_montage_volume" title="mne.preprocessing.ieeg.make_montage_volume" class="sphx-glr-backref-module-mne-preprocessing-ieeg sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">ieeg</span><span class="o">.</span><span class="n">make_montage_volume</span></a><span class="p">(</span>
    <a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a><span class="p">,</span> <span class="n">CT_aligned</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.25</span>
<span class="p">)</span>

<span class="c1"># warp image using transforms</span>
<a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">warped_elec_image</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.transforms.apply_volume_registration.html#mne.transforms.apply_volume_registration" title="mne.transforms.apply_volume_registration" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">apply_volume_registration</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">elec_image</span></a><span class="p">,</span> <span class="n">template_brain</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">reg_affine</span></a><span class="p">,</span> <a href="https://dipy.org/documentation/latest/reference/dipy.align/#dipy.align.imwarp.DiffeomorphicMap" title="dipy.align.imwarp.DiffeomorphicMap" class="sphx-glr-backref-module-dipy-align-imwarp sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sdr_morph</span></a><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span>
<span class="p">)</span>

<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">nilearn</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_glass_brain</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">elec_image</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Dark2&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.text" title="matplotlib.figure.Figure.text" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">text</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="s2">&quot;Subject T1&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
<span class="n">nilearn</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_glass_brain</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage" title="nibabel.spatialimages.SpatialImage" class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">warped_elec_image</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">axes</span></a><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Dark2&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.text" title="matplotlib.figure.Figure.text" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">text</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">&quot;fsaverage&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.suptitle" title="matplotlib.figure.Figure.suptitle" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span></a><span class="p">(</span><span class="s2">&quot;Electrodes warped to fsaverage&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">CT_aligned</span><span class="p">,</span> <span class="n">subject_brain</span><span class="p">,</span> <span class="n">template_brain</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_012.png" srcset="../_images/sphx_glr_ieeg_locate_012.png" alt="Electrodes warped to fsaverage" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Applying affine registration ...
Applying SDR warp ...
[done]
</pre></div>
</div>
<p>We can now plot the result. You can compare this to the plot in
<a class="reference external" href="https://mne.tools/stable/auto_tutorials/clinical/20_seeg.html#tut-working-with-seeg" title="(in MNE v1.5)"><span>Working with sEEG data</span></a> to see the difference between this morph, which
is more complex, and the less-complex, linear Talairach transformation.
By accounting for the shape of this particular subject’s brain using the
SDR to warp the positions of the electrode contacts, the position in the
template brain is able to be more accurately estimated.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The accuracy of warping to the template has been degraded by
using <code class="docutils literal notranslate"><span class="pre">zooms</span></code> to downsample the image before registration
which makes some of the contacts inaccurately appear outside
the brain.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># first we need to add fiducials so that we can define the &quot;head&quot; coordinate</span>
<span class="c1"># frame in terms of them (with the origin at the center between LPA and RPA)</span>
<a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage.add_estimated_fiducials" title="mne.channels.DigMontage.add_estimated_fiducials" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-method"><span class="n">montage_warped</span><span class="o">.</span><span class="n">add_estimated_fiducials</span></a><span class="p">(</span><span class="s2">&quot;fsaverage&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">)</span>

<span class="c1"># compute the head&lt;-&gt;mri ``trans`` now using the fiducials</span>
<a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">template_trans</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.channels.compute_native_head_t.html#mne.channels.compute_native_head_t" title="mne.channels.compute_native_head_t" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">compute_native_head_t</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage_warped</span></a><span class="p">)</span>

<span class="c1"># now we can set the montage and, because there are fiducials in the montage,</span>
<span class="c1"># the montage will be properly transformed to &quot;head&quot; coordinates when we do</span>
<span class="c1"># (this step uses ``template_trans`` but it is recomputed behind the scenes)</span>
<a href="https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.set_montage" title="mne.io.Raw.set_montage" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">raw</span><span class="o">.</span><span class="n">set_montage</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage_warped</span></a><span class="p">)</span>

<span class="c1"># plot the resulting alignment</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain" title="mne.viz.Brain" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-class"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">Brain</span></a><span class="p">(</span><span class="s2">&quot;fsaverage&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subjects_dir</span></a><span class="p">,</span> <span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">brain_kwargs</span></a><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.add_sensors" title="mne.viz.Brain.add_sensors" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">add_sensors</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne.Info" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><a href="https://mne.tools/stable/generated/mne.transforms.Transform.html#mne.transforms.Transform" title="mne.transforms.Transform" class="sphx-glr-backref-module-mne-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">template_trans</span></a><span class="p">)</span>
<a href="https://mne.tools/stable/generated/mne.viz.Brain.html#mne.viz.Brain.show_view" title="mne.viz.Brain.show_view" class="sphx-glr-backref-module-mne-viz sphx-glr-backref-type-py-method"><span class="n">brain</span><span class="o">.</span><span class="n">show_view</span></a><span class="p">(</span><span class="o">**</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">view_kwargs</span></a><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_ieeg_locate_013.png" srcset="../_images/sphx_glr_ieeg_locate_013.png" alt="ieeg locate" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
For automatic theme detection, &quot;darkdetect&quot; has to be installed! You can install it with `pip install darkdetect`
Channel types:: seeg: 119
</pre></div>
</div>
<p>This pipeline was developed based on previous work
<a class="footnote-reference brackets" href="#footcite-hamiltonetal2017" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id4">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-rockhilletal2022" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Alexander P. Rockhill, Eric Larson, Brittany Stedelin, Alessandra Mantovani, Ahmed M. Raslan, Alexandre Gramfort, and Nicole C. Swann. Intracranial electrode location and analysis in mne-python. <em>Journal of Open Source Software</em>, 7(70):3897, 2022. <a class="reference external" href="https://doi.org/10.21105/joss.03897">doi:10.21105/joss.03897</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-hamiltonetal2017" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>Liberty S. Hamilton, David L. Chang, Morgan B. Lee, and Edward F. Chang. Semi-automated anatomical labeling and inter-subject warping of high-density intracranial recording electrodes in electrocorticography. <em>Frontiers in Neuroinformatics</em>, October 2017. <a class="reference external" href="https://doi.org/10.3389/fninf.2017.00062">doi:10.3389/fninf.2017.00062</a>.</p>
</aside>
</aside>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (1 minutes 53.270 seconds)</p>
<p><strong>Estimated memory usage:</strong>  781 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-ieeg-locate-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/08b5414465f3987d65266e292ba10801/ieeg_locate.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">ieeg_locate.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e8b509e5bea8fdaec2b6adf200ecb872/ieeg_locate.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">ieeg_locate.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="evoked_ers_source_power.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Compute evoked ERS source power using DICS, LCMV beamformer, and dSPM</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aligning-the-t1-to-acpc">Aligning the T1 to ACPC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#freesurfer-recon-all">Freesurfer recon-all</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aligning-the-ct-to-the-mr">Aligning the CT to the MR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#marking-the-location-of-each-electrode-contact">Marking the Location of Each Electrode Contact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warping-to-a-common-atlas">Warping to a Common Atlas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>