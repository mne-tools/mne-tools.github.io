{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Locating micro-scale intracranial electrode contacts\n\nWhen intracranial electrode contacts are very small, sometimes\nthe computed tomography (CT) scan is higher resolution than the\nmagnetic resonance (MR) image and so you want to find the contacts\non the CT without downsampling to the MR resolution. This example\nshows how to do this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Alex Rockhill <aprockhill@mailbox.org>\n#\n# License: BSD-3-Clause\n\nimport numpy as np\nimport nibabel as nib\nimport mne\n\n# path to sample sEEG\nmisc_path = mne.datasets.misc.data_path()\nsubjects_dir = misc_path / \"seeg\"\n\n# GUI requires pyvista backend\nmne.viz.set_3d_backend(\"pyvistaqt\")\n\n# we need three things:\n# 1) The electrophysiology file which contains the channels names\n# that we would like to associate with positions in the brain\n# 2) The CT where the electrode contacts show up with high intensity\n# 3) The MR where the brain is best visible (low contrast in CT)\nraw = mne.io.read_raw(misc_path / \"seeg\" / \"sample_seeg_ieeg.fif\")\nCT_orig = nib.load(misc_path / \"seeg\" / \"sample_seeg_CT.mgz\")\nT1 = nib.load(misc_path / \"seeg\" / \"sample_seeg\" / \"mri\" / \"T1.mgz\")\n\n# we'll also need a head-CT surface RAS transform, this can be faked with an\n# identify matrix but we'll find the fiducials on the CT in freeview (be sure\n# to find them in surface RAS (TkReg RAS in freeview) and not scanner RAS\n# (RAS in freeview)) (also be sure to note left is generally on the right in\n# freeview) and reproduce them here:\nmontage = mne.channels.make_dig_montage(\n    nasion=[-28.97, -5.88, -76.40],\n    lpa=[-96.35, -16.26, 17.63],\n    rpa=[31.28, -52.95, -0.69],\n    coord_frame=\"mri\",\n)\nraw.set_montage(montage, on_missing=\"ignore\")  # haven't located yet!\nhead_ct_t = mne.transforms.invert_transform(mne.channels.compute_native_head_t(montage))\n\n# note: coord_frame = 'mri' is a bit of a misnormer, it is a reference to\n# the surface RAS coordinate frame, here it is of the CT\n\n\n# launch the viewer with only the CT (note, we won't be able to use\n# the MR in this case to help determine which brain area the contact is\n# in), and use the user interface to find the locations of the contacts\ngui = mne.gui.locate_ieeg(raw.info, head_ct_t, CT_orig)\n\n# we'll programmatically mark all the contacts on one electrode shaft\nfor i, pos in enumerate(\n    [\n        (-52.66, -40.84, -26.99),\n        (-55.47, -38.03, -27.92),\n        (-57.68, -36.27, -28.85),\n        (-59.89, -33.81, -29.32),\n        (-62.57, -31.35, -30.37),\n        (-65.13, -29.07, -31.30),\n        (-67.57, -26.26, -31.88),\n    ]\n):\n    gui.set_RAS(pos)\n    gui.mark_channel(f\"LENT {i + 1}\")\n\n# finally, the coordinates will be in \"head\" (unless the trans was faked\n# as the identity, in which case they will be in surface RAS of the CT already)\n# so we need to convert them to scanner RAS of the CT, apply the alignment so\n# that they are in scanner RAS of the MRI and from there to surface RAS\n# of the MRI for viewing using freesurfer recon-all surfaces--fortunately\n# that is done for us in `mne.transforms.apply_volume_registration_points`\n\n# note that since we didn't fake the head->CT surface RAS transform, we\n# could apply the head->mri transform directly but that relies of the\n# fiducial points being marked exactly the same on the CT as on the MRI--\n# the error from this is not precise enough for intracranial electrophysiology,\n# better is to rely on the precision of the CT-MR image registration\n\nreg_affine = np.array(\n    [  # CT-MR registration\n        [0.99270756, -0.03243313, 0.11610254, -133.094156],\n        [0.04374389, 0.99439665, -0.09623816, -97.58320673],\n        [-0.11233068, 0.10061512, 0.98856381, -84.45551601],\n        [0.0, 0.0, 0.0, 1.0],\n    ]\n)\n\nraw.info, head_mri_t = mne.transforms.apply_volume_registration_points(\n    raw.info, head_ct_t, CT_orig, T1, reg_affine\n)\n\nbrain = mne.viz.Brain(subject=\"sample_seeg\", subjects_dir=subjects_dir, alpha=0.5)\nbrain.add_sensors(raw.info, head_mri_t)\nbrain.show_view(azimuth=120, elevation=100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}