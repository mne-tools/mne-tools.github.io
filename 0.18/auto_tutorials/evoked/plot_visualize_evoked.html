<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Visualize Evoked data &#8212; MNE 0.18.2 documentation</title>
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" href="../../_static/reset-syntax.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap_divs.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <script type="text/javascript" src="../../_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="../../_static/style.css " type="text/css" />
    <link rel="stylesheet" href="../../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>



  </head><body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.18.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../getting_started.html">Install</a></li>
                <li><a href="../../documentation.html">Documentation</a></li>
                <li><a href="../../python_reference.html">API</a></li>
                <li><a href="../../glossary.html">Glossary</a></li>
                <li><a href="../../auto_examples/index.html">Examples</a></li>
                <li><a href="../../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.18.2
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.18 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Visualize Evoked data</a><ul>
<li><a class="reference internal" href="#visualizing-field-lines-in-3d">Visualizing field lines in 3D</a></li>
</ul>
</li>
</ul>

<form action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="body col-md-12 content" role="main">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-evoked-plot-visualize-evoked-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="visualize-evoked-data">
<span id="sphx-glr-auto-tutorials-evoked-plot-visualize-evoked-py"></span><h1>Visualize Evoked data<a class="headerlink" href="#visualize-evoked-data" title="Permalink to this headline">Â¶</a></h1>
<p>In this tutorial we focus on the plotting functions of <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Evoked</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">mne</span>

<span class="c1"># sphinx_gallery_thumbnail_number = 9</span>
</pre></div>
</div>
<p>First we read the evoked object from a file. Check out
<a class="reference internal" href="../intro/plot_epoching_and_averaging.html#tut-epoching-and-averaging"><span class="std std-ref">Epoching and averaging (ERP/ERF)</span></a> to get to this stage from raw data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="View documentation for mne.datasets.sample.data_path"><span class="n">mne</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>
<span class="n">fname</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;MEG&#39;</span><span class="p">,</span> <span class="s1">&#39;sample&#39;</span><span class="p">,</span> <span class="s1">&#39;sample_audvis-ave.fif&#39;</span><span class="p">)</span>
<span class="n">evoked</span> <span class="o">=</span> <a href="../../generated/mne.read_evokeds.html#mne.read_evokeds" title="View documentation for mne.read_evokeds"><span class="n">mne</span><span class="o">.</span><span class="n">read_evokeds</span></a><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evoked</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Left Auditory)
        0 CTF compensation matrices available
        nave = 55 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Right Auditory)
        0 CTF compensation matrices available
        nave = 61 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Left visual)
        0 CTF compensation matrices available
        nave = 67 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Right visual)
        0 CTF compensation matrices available
        nave = 58 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
[&lt;Evoked  |  &#39;Left Auditory&#39; (mean, N=55), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &lt;Evoked  |  &#39;Right Auditory&#39; (mean, N=61), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &lt;Evoked  |  &#39;Left visual&#39; (mean, N=67), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &lt;Evoked  |  &#39;Right visual&#39; (mean, N=58), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;]
</pre></div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">evoked</span></code> is a list of <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">evoked</span></code></a> instances.
You can read only one of the categories by passing the argument <code class="docutils literal notranslate"><span class="pre">condition</span></code>
to <a class="reference internal" href="../../generated/mne.read_evokeds.html#mne.read_evokeds" title="mne.read_evokeds"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.read_evokeds()</span></code></a>. To make things more simple for this tutorial, we
read each instance to a variable.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_l_aud</span> <span class="o">=</span> <span class="n">evoked</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">evoked_r_aud</span> <span class="o">=</span> <span class="n">evoked</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">evoked_l_vis</span> <span class="o">=</span> <span class="n">evoked</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">evoked_r_vis</span> <span class="o">=</span> <span class="n">evoked</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
<p>Letâs start with a simple one. We plot event related potentials / fields
(ERP/ERF). The bad channels are not plotted by default. Here we explicitly
set the <code class="docutils literal notranslate"><span class="pre">exclude</span></code> parameter to show the bad channels in red. All plotting
functions of MNE-python return a handle to the figure instance. When we have
the handle, we can customise the plots to our liking.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">(),</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_001.png" />
<p>All plotting functions of MNE-python return a handle to the figure instance.
When we have the handle, we can customise the plots to our liking. For
example, we can get rid of the empty space with a simple function call.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<p>Now we will make it a bit fancier and only use MEG channels. Many of the
MNE-functions include a <code class="docutils literal notranslate"><span class="pre">picks</span></code> parameter to include a selection of
channels. <code class="docutils literal notranslate"><span class="pre">picks</span></code> is simply a list of channel indices that you can easily
construct with <a class="reference internal" href="../../generated/mne.pick_types.html#mne.pick_types" title="mne.pick_types"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.pick_types()</span></code></a>, <a class="reference internal" href="../../generated/mne.pick_channels.html#mne.pick_channels" title="mne.pick_channels"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.pick_channels()</span></code></a>,
<a class="reference internal" href="../../generated/mne.pick_channels_regexp.html#mne.pick_channels_regexp" title="mne.pick_channels_regexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.pick_channels_regexp()</span></code></a>, or a list of strings that can be
interpreted as channel names or channel types.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">spatial_colors=True</span></code>, the individual channel lines are color coded
to show the sensor positions - specifically, the x, y, and z locations of
the sensors are transformed into R, G and B values.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">spatial_colors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">gfp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">picks</span><span class="o">=</span><span class="s1">&#39;meg&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_002.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_002.png" />
<p>Notice the legend on the left. The colors would suggest that there may be two
separate sources for the signals. This wasnât obvious from the first figure.
Try painting the slopes with left mouse button. It should open a new window
with topomaps (scalp plots) of the average over the painted area. There is
also a function for drawing topomaps separately.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_003.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_003.png" />
<p>By default the topomaps are drawn from evenly spread out points of time over
the evoked data. We can also define the times ourselves.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">times</span> <span class="o">=</span> <a href="https://www.numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.151</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">evoked_r_aud</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="n">times</span><span class="p">,</span> <span class="n">ch_type</span><span class="o">=</span><span class="s1">&#39;mag&#39;</span><span class="p">,</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_004.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_004.png" />
<p>Or we can select automatically the peaks.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_r_aud</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="s1">&#39;peaks&#39;</span><span class="p">,</span> <span class="n">ch_type</span><span class="o">=</span><span class="s1">&#39;mag&#39;</span><span class="p">,</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_005.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_005.png" />
<p>See <a class="reference internal" href="../../auto_examples/visualization/plot_evoked_topomap.html#ex-evoked-topomap"><span class="std std-ref">Plotting topographic maps of evoked data</span></a> for
more advanced topomap plotting options. You can also take a look at the
documentation of <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_topomap" title="mne.Evoked.plot_topomap"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.Evoked.plot_topomap()</span></code></a> or simply write
<code class="docutils literal notranslate"><span class="pre">evoked_r_aud.plot_topomap?</span></code> in your Python console to see the different
parameters you can pass to this function. Most of the plotting functions also
accept <code class="docutils literal notranslate"><span class="pre">axes</span></code> parameter. With that, you can customise your plots even
further. First we create a set of matplotlib axes in a single figure and plot
all of our evoked categories next to each other.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">300</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
<span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">evoked_r_aud</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">evoked_l_vis</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">evoked_r_vis</span><span class="o">.</span><span class="n">plot_topomap</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ax</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Aud/L&#39;</span><span class="p">,</span> <span class="s1">&#39;Aud/R&#39;</span><span class="p">,</span> <span class="s1">&#39;Vis/L&#39;</span><span class="p">,</span> <span class="s1">&#39;Vis/R&#39;</span><span class="p">]):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show" title="View documentation for matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_006.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_006.png" />
<p>Notice that we created five axes, but had only four categories. The fifth
axes was used for drawing the colorbar. You must provide room for it when you
create this kind of custom plots or turn the colorbar off with
<code class="docutils literal notranslate"><span class="pre">colorbar=False</span></code>. Thatâs what the warnings are trying to tell you. Also, we
used <code class="docutils literal notranslate"><span class="pre">show=False</span></code> for the three first function calls. This prevents the
showing of the figure prematurely. The behavior depends on the mode you are
using for your Python session. See <a class="reference external" href="https://matplotlib.org/users/shell.html">https://matplotlib.org/users/shell.html</a>
for more information.</p>
<p>We can combine the two kinds of plots in one figure using the
<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_joint" title="mne.Evoked.plot_joint"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.Evoked.plot_joint()</span></code></a> method of Evoked objects. Called as-is
(<code class="docutils literal notranslate"><span class="pre">evoked.plot_joint()</span></code>), this function should give an informative display
of spatio-temporal dynamics.
You can directly style the time series part and the topomap part of the plot
using the <code class="docutils literal notranslate"><span class="pre">topomap_args</span></code> and <code class="docutils literal notranslate"><span class="pre">ts_args</span></code> parameters. You can pass key-value
pairs as a Python dictionary. These are then passed as parameters to the
topomaps (<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot_topomap" title="mne.Evoked.plot_topomap"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.Evoked.plot_topomap()</span></code></a>) and time series
(<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked.plot" title="mne.Evoked.plot"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.Evoked.plot()</span></code></a>) of the joint plot.
For an example of specific styling using these <code class="docutils literal notranslate"><span class="pre">topomap_args</span></code> and
<code class="docutils literal notranslate"><span class="pre">ts_args</span></code> arguments, here, topomaps at specific time points
(90 and 200 ms) are shown, sensors are not plotted (via an argument
forwarded to <em class="xref py py-obj">plot_topomap</em>), and the Global Field Power is shown:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ts_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">gfp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
<span class="n">topomap_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">sensors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
<span class="n">evoked_r_aud</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;right auditory&#39;</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">09</span><span class="p">,</span> <span class="o">.</span><span class="mi">20</span><span class="p">],</span>
                        <span class="n">ts_args</span><span class="o">=</span><span class="n">ts_args</span><span class="p">,</span> <span class="n">topomap_args</span><span class="o">=</span><span class="n">topomap_args</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="../../_images/sphx_glr_plot_visualize_evoked_007.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_visualize_evoked_007.png" />
</li>
<li><img alt="../../_images/sphx_glr_plot_visualize_evoked_008.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_visualize_evoked_008.png" />
</li>
<li><img alt="../../_images/sphx_glr_plot_visualize_evoked_009.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_visualize_evoked_009.png" />
</li>
</ul>
<p>Sometimes, you may want to compare two or more conditions at a selection of
sensors, or e.g. for the Global Field Power. For this, you can use the
function <a class="reference internal" href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_compare_evokeds()</span></code></a>. The easiest way is to create
a  Python dictionary, where the keys are condition names and the values are
<a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Evoked</span></code></a> objects. If you provide lists of <a class="reference internal" href="../../generated/mne.Evoked.html#mne.Evoked" title="mne.Evoked"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.Evoked</span></code></a>
objects, such as those for multiple subjects, the grand average is plotted,
along with a confidence interval band - this can be used to contrast
conditions for a whole experiment.
First, we load in the evoked objects into a dictionary, setting the keys to
â/â-separated tags (as we can do with event_ids for epochs). Then, we plot
with <a class="reference internal" href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_compare_evokeds()</span></code></a>.
The plot is styled with dict arguments, again using â/â-separated tags.
We plot a MEG channel with a strong auditory response.</p>
<p>For move advanced plotting using <a class="reference internal" href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="mne.viz.plot_compare_evokeds"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.viz.plot_compare_evokeds()</span></code></a>.
See also <a class="reference internal" href="../epochs/plot_metadata_epochs.html#tut-epochs-metadata"><span class="std std-ref">Pandas querying and metadata with Epochs objects</span></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conditions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Left Auditory&quot;</span><span class="p">,</span> <span class="s2">&quot;Right Auditory&quot;</span><span class="p">,</span> <span class="s2">&quot;Left visual&quot;</span><span class="p">,</span> <span class="s2">&quot;Right visual&quot;</span><span class="p">]</span>
<span class="n">evoked_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">condition</span> <span class="ow">in</span> <span class="n">conditions</span><span class="p">:</span>
    <span class="n">evoked_dict</span><span class="p">[</span><span class="n">condition</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)]</span> <span class="o">=</span> <a href="../../generated/mne.read_evokeds.html#mne.read_evokeds" title="View documentation for mne.read_evokeds"><span class="n">mne</span><span class="o">.</span><span class="n">read_evokeds</span></a><span class="p">(</span>
        <span class="n">fname</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">condition</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evoked_dict</span><span class="p">)</span>

<span class="n">colors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">Left</span><span class="o">=</span><span class="s2">&quot;Crimson&quot;</span><span class="p">,</span> <span class="n">Right</span><span class="o">=</span><span class="s2">&quot;CornFlowerBlue&quot;</span><span class="p">)</span>
<span class="n">linestyles</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">Auditory</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">visual</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">pick</span> <span class="o">=</span> <span class="n">evoked_dict</span><span class="p">[</span><span class="s2">&quot;Left/Auditory&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">ch_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;MEG 1811&#39;</span><span class="p">)</span>

<a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="View documentation for mne.viz.plot_compare_evokeds"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_compare_evokeds</span></a><span class="p">(</span><span class="n">evoked_dict</span><span class="p">,</span> <span class="n">picks</span><span class="o">=</span><span class="n">pick</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                             <span class="n">linestyles</span><span class="o">=</span><span class="n">linestyles</span><span class="p">,</span> <span class="n">split_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_010.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_010.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Left Auditory)
        0 CTF compensation matrices available
        nave = 55 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Right Auditory)
        0 CTF compensation matrices available
        nave = 61 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Left visual)
        0 CTF compensation matrices available
        nave = 67 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
    Read a total of 4 projection items:
        PCA-v1 (1 x 102) active
        PCA-v2 (1 x 102) active
        PCA-v3 (1 x 102) active
        Average EEG reference (1 x 60) active
    Found the data of interest:
        t =    -199.80 ...     499.49 ms (Right visual)
        0 CTF compensation matrices available
        nave = 58 - aspect type = 100
Projections have already been applied. Setting proj attribute to True.
Applying baseline correction (mode: mean)
{&#39;Left/Auditory&#39;: &lt;Evoked  |  &#39;Left Auditory&#39; (mean, N=55), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &#39;Right/Auditory&#39;: &lt;Evoked  |  &#39;Right Auditory&#39; (mean, N=61), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &#39;Left/visual&#39;: &lt;Evoked  |  &#39;Left visual&#39; (mean, N=67), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;, &#39;Right/visual&#39;: &lt;Evoked  |  &#39;Right visual&#39; (mean, N=58), [-0.1998, 0.49949] sec, 376 ch, ~4.9 MB&gt;}
</pre></div>
</div>
<p>We can also plot the activations as images. The time runs along the x-axis
and the channels along the y-axis. The amplitudes are color coded so that
the amplitudes from negative to positive translates to shift from blue to
red. White means zero amplitude. You can use the <code class="docutils literal notranslate"><span class="pre">cmap</span></code> parameter to define
the color map yourself. The accepted values include all matplotlib colormaps.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_r_aud</span><span class="o">.</span><span class="n">plot_image</span><span class="p">(</span><span class="n">picks</span><span class="o">=</span><span class="s1">&#39;meg&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_011.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_011.png" />
<p>Finally we plot the sensor data as a topographical view. In the simple case
we plot only left auditory responses, and then we plot them all in the same
figure for comparison. Click on the individual plots to open them bigger.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;MNE sample data</span><span class="se">\n</span><span class="s1">(condition : </span><span class="si">%s</span><span class="s1">)&#39;</span>
<span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot_topo</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span> <span class="o">%</span> <span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">comment</span><span class="p">,</span>
                       <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;white&#39;</span><span class="p">])</span>
<a href="../../generated/mne.viz.plot_evoked_topo.html#mne.viz.plot_evoked_topo" title="View documentation for mne.viz.plot_evoked_topo"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_evoked_topo</span></a><span class="p">(</span><span class="n">evoked</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span> <span class="o">%</span> <span class="s1">&#39;Left/Right Auditory/Visual&#39;</span><span class="p">,</span>
                         <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="../../_images/sphx_glr_plot_visualize_evoked_012.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_visualize_evoked_012.png" />
</li>
<li><img alt="../../_images/sphx_glr_plot_visualize_evoked_013.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_visualize_evoked_013.png" />
</li>
</ul>
<p>For small numbers of sensors, it is also possible to create a more refined
topoplot. Again, clicking on a sensor opens a single-sensor plot.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../generated/mne.viz.plot_compare_evokeds.html#mne.viz.plot_compare_evokeds" title="View documentation for mne.viz.plot_compare_evokeds"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_compare_evokeds</span></a><span class="p">(</span><span class="n">evoked_dict</span><span class="p">,</span> <span class="n">picks</span><span class="o">=</span><span class="s2">&quot;eeg&quot;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
                             <span class="n">linestyles</span><span class="o">=</span><span class="n">linestyles</span><span class="p">,</span> <span class="n">split_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">axes</span><span class="o">=</span><span class="s2">&quot;topo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_014.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_014.png" />
<p>We can also plot the activations as arrow maps on top of the topoplot.
The arrows represent an estimation of the current flow underneath the MEG
sensors. Here, sample number 175 corresponds to the time of the maximum
sensor space activity.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">evoked_l_aud_mag</span> <span class="o">=</span> <span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">pick_types</span><span class="p">(</span><span class="n">meg</span><span class="o">=</span><span class="s1">&#39;mag&#39;</span><span class="p">)</span>
<a href="../../generated/mne.viz.plot_arrowmap.html#mne.viz.plot_arrowmap" title="View documentation for mne.viz.plot_arrowmap"><span class="n">mne</span><span class="o">.</span><span class="n">viz</span><span class="o">.</span><span class="n">plot_arrowmap</span></a><span class="p">(</span><span class="n">evoked_l_aud_mag</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">175</span><span class="p">],</span> <span class="n">evoked_l_aud_mag</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_015.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_015.png" />
<div class="section" id="visualizing-field-lines-in-3d">
<h2>Visualizing field lines in 3D<a class="headerlink" href="#visualizing-field-lines-in-3d" title="Permalink to this headline">Â¶</a></h2>
<p>We now compute the field maps to project MEG and EEG data to the MEG helmet
and scalp surface.</p>
<p>To do this, we need coregistration information. See
<a class="reference internal" href="../source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for more details. Here we just illustrate usage.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subjects_dir</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;/subjects&#39;</span>
<span class="n">trans_fname</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_raw-trans.fif&#39;</span>

<span class="n">maps</span> <span class="o">=</span> <a href="../../generated/mne.make_field_map.html#mne.make_field_map" title="View documentation for mne.make_field_map"><span class="n">mne</span><span class="o">.</span><span class="n">make_field_map</span></a><span class="p">(</span><span class="n">evoked_l_aud</span><span class="p">,</span> <span class="n">trans</span><span class="o">=</span><span class="n">trans_fname</span><span class="p">,</span> <span class="n">subject</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span><span class="p">,</span>
                          <span class="n">subjects_dir</span><span class="o">=</span><span class="n">subjects_dir</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Finally, explore several points in time</span>
<span class="n">field_map</span> <span class="o">=</span> <span class="n">evoked_l_aud</span><span class="o">.</span><span class="n">plot_field</span><span class="p">(</span><span class="n">maps</span><span class="p">,</span> <span class="n">time</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_visualize_evoked_016.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_visualize_evoked_016.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using surface from /home/circleci/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem.fif.
Getting helmet for system 306m
Prepare EEG mapping...
Computing dot products for 59 electrodes...
Computing dot products for 2562 surface locations...
Field mapping data ready
    Preparing the mapping matrix...
    Truncating at 21/59 components to omit less than 0.001 (0.00097)
    The map will have average electrode reference
Prepare MEG mapping...
Computing dot products for 305 coils...
Computing dot products for 304 surface locations...
Field mapping data ready
    Preparing the mapping matrix...
    Truncating at 210/305 components to omit less than 0.0001 (9.9e-05)
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If trans_fname is set to None then only MEG estimates can be visualized.</p>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  27.574 seconds)</p>
<p><strong>Estimated memory usage:</strong>  32 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-evoked-plot-visualize-evoked-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/91ce3dd3cad2dd42719a8350dbe58a3b/plot_visualize_evoked.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_visualize_evoked.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/db1991d3949b36cc336dce254c001fb0/plot_visualize_evoked.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_visualize_evoked.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container institutions">
    <a href="https://www.massgeneral.org/"><img class="institution_lg" src="../../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a>
    <a href="https://martinos.org/"><img class="institution_lg" src="../../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a>
    <a href="https://hms.harvard.edu/"><img class="institution_lg" src="../../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a>
    <a href="https://web.mit.edu/"><img class="institution_sm" src="../../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a>
    <a href="https://www.nyu.edu/"><img class="institution_md" src="../../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a>
    <a href="http://www.cea.fr/"><img class="institution_md" src="../../_static/institution_logos/CEA.png" title="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives" alt="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives"/></a>
    <a href="https://sci.aalto.fi/"><img class="institution_md" src="../../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a>
    <a href="https://www.telecom-paris.fr/"><img class="institution_md" src="../../_static/institution_logos/Telecom_Paris_Tech.png" title="TÃ©lÃ©com ParisTech" alt="TÃ©lÃ©com ParisTech"/></a>
    <a href="https://www.washington.edu/"><img class="institution_sm" src="../../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a>
    <a href="https://icm-institute.org/"><img class="institution_lg" src="../../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle Ã©piniÃ¨re" alt="Institut du Cerveau et de la Moelle Ã©piniÃ¨re"/></a>
    <a href="https://www.bu.edu/"><img class="institution_sm" src="../../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a>
    <a href="https://www.inserm.fr/"><img class="institution_xs" src="../../_static/institution_logos/Inserm.svg" title="Institut national de la santÃ© et de la recherche mÃ©dicale" alt="Institut national de la santÃ© et de la recherche mÃ©dicale"/></a>
    <a href="https://www.fz-juelich.de/"><img class="institution_sm" src="../../_static/institution_logos/Julich.svg" title="Forschungszentrum JÃ¼lich" alt="Forschungszentrum JÃ¼lich"/></a>
    <a href="https://www.tu-ilmenau.de/"><img class="institution_sm" src="../../_static/institution_logos/Ilmenau.gif" title="Technische UniversitÃ¤t Ilmenau" alt="Technische UniversitÃ¤t Ilmenau"/></a>
    <a href="https://bids.berkeley.edu/"><img class="institution_md" src="../../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a>
    <a href="https://www.inria.fr/"><img class="institution_sm" src="../../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a>
    <a href="https://www.au.dk/"><img class="institution_sm" src="../../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a>
    <a href="https://www.uni-graz.at/"><img class="institution_md" src="../../_static/institution_logos/Graz.jpg" title="Karl-Franzens-UniversitÃ¤t Graz" alt="Karl-Franzens-UniversitÃ¤t Graz"/></a>
  </div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>Â·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>Â·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>Â·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>Â·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2019, MNE Developers. Last updated on 2019-07-11.</p>
  </div>
</footer>
  </body>
</html>