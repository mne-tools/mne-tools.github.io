<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Decoding (MVPA) &#8212; MNE 0.18.2 documentation</title>
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap_divs.css" />
    <link rel="stylesheet" href="../../_static/reset-syntax.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap_divs.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <script type="text/javascript" src="../../_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="../../_static/style.css " type="text/css" />
    <link rel="stylesheet" href="../../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>



  </head><body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.18.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../getting_started.html">Install</a></li>
                <li><a href="../../documentation.html">Documentation</a></li>
                <li><a href="../../python_reference.html">API</a></li>
                <li><a href="../../glossary.html">Glossary</a></li>
                <li><a href="../../auto_examples/index.html">Examples</a></li>
                <li><a href="../../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.18.2
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.18 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Decoding (MVPA)</a><ul>
<li><a class="reference internal" href="#design-philosophy">Design philosophy</a></li>
<li><a class="reference internal" href="#transformation-classes">Transformation classes</a><ul>
<li><a class="reference internal" href="#scaler">Scaler</a></li>
<li><a class="reference internal" href="#vectorizer">Vectorizer</a></li>
<li><a class="reference internal" href="#psdestimator">PSDEstimator</a></li>
<li><a class="reference internal" href="#filterestimator">FilterEstimator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spatial-filters">Spatial filters</a><ul>
<li><a class="reference internal" href="#common-spatial-pattern">Common spatial pattern</a></li>
<li><a class="reference internal" href="#source-power-comodulation-spoc">Source power comodulation (SPoC)</a></li>
<li><a class="reference internal" href="#xdawn">xDAWN</a></li>
<li><a class="reference internal" href="#effect-matched-spatial-filtering">Effect-matched spatial filtering</a></li>
<li><a class="reference internal" href="#patterns-vs-filters">Patterns vs. filters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#decoding-over-time">Decoding over time</a><ul>
<li><a class="reference internal" href="#temporal-decoding">Temporal decoding</a></li>
<li><a class="reference internal" href="#temporal-generalization">Temporal generalization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#source-space-decoding">Source-space decoding</a></li>
<li><a class="reference internal" href="#exercise">Exercise</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<form action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="body col-md-12 content" role="main">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-machine-learning-plot-sensors-decoding-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="decoding-mvpa">
<span id="sphx-glr-auto-tutorials-machine-learning-plot-sensors-decoding-py"></span><h1>Decoding (MVPA)<a class="headerlink" href="#decoding-mvpa" title="Permalink to this headline">Â¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#design-philosophy" id="id15">Design philosophy</a></p></li>
<li><p><a class="reference internal" href="#transformation-classes" id="id16">Transformation classes</a></p>
<ul>
<li><p><a class="reference internal" href="#scaler" id="id17">Scaler</a></p></li>
<li><p><a class="reference internal" href="#vectorizer" id="id18">Vectorizer</a></p></li>
<li><p><a class="reference internal" href="#psdestimator" id="id19">PSDEstimator</a></p></li>
<li><p><a class="reference internal" href="#filterestimator" id="id20">FilterEstimator</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#spatial-filters" id="id21">Spatial filters</a></p>
<ul>
<li><p><a class="reference internal" href="#common-spatial-pattern" id="id22">Common spatial pattern</a></p></li>
<li><p><a class="reference internal" href="#source-power-comodulation-spoc" id="id23">Source power comodulation (SPoC)</a></p></li>
<li><p><a class="reference internal" href="#xdawn" id="id24">xDAWN</a></p></li>
<li><p><a class="reference internal" href="#effect-matched-spatial-filtering" id="id25">Effect-matched spatial filtering</a></p></li>
<li><p><a class="reference internal" href="#patterns-vs-filters" id="id26">Patterns vs. filters</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#decoding-over-time" id="id27">Decoding over time</a></p>
<ul>
<li><p><a class="reference internal" href="#temporal-decoding" id="id28">Temporal decoding</a></p></li>
<li><p><a class="reference internal" href="#temporal-generalization" id="id29">Temporal generalization</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#source-space-decoding" id="id30">Source-space decoding</a></p></li>
<li><p><a class="reference internal" href="#exercise" id="id31">Exercise</a></p></li>
<li><p><a class="reference internal" href="#references" id="id32">References</a></p></li>
</ul>
</div>
<div class="section" id="design-philosophy">
<h2><a class="toc-backref" href="#id15">Design philosophy</a><a class="headerlink" href="#design-philosophy" title="Permalink to this headline">Â¶</a></h2>
<p>Decoding (a.k.a. MVPA) in MNE largely follows the machine
learning API of the scikit-learn package.
Each estimator implements <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">transform</span></code>, <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>, and
(optionally) <code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code> methods. For more details on this design,
visit <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>. For additional theoretical insights into the decoding
framework in MNE, see <a class="footnote-reference brackets" href="#id8" id="id1">1</a>.</p>
<p>For ease of comprehension, we will denote instantiations of the class using
the same name as the class but in small caps instead of camel cases.</p>
<p>Letâs start by loading data for a simple two-class problem:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># sphinx_gallery_thumbnail_number = 6</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="View documentation for sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="View documentation for sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="View documentation for sklearn.linear_model.LogisticRegression"><span class="n">LogisticRegression</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="k">import</span> <span class="n">sample</span>
<span class="kn">from</span> <span class="nn">mne.decoding</span> <span class="k">import</span> <span class="p">(</span><a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="View documentation for mne.decoding.SlidingEstimator"><span class="n">SlidingEstimator</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="View documentation for mne.decoding.GeneralizingEstimator"><span class="n">GeneralizingEstimator</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="View documentation for mne.decoding.Scaler"><span class="n">Scaler</span></a><span class="p">,</span>
                          <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="View documentation for mne.decoding.cross_val_multiscore"><span class="n">cross_val_multiscore</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.LinearModel.html#mne.decoding.LinearModel" title="View documentation for mne.decoding.LinearModel"><span class="n">LinearModel</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.get_coef.html#mne.decoding.get_coef" title="View documentation for mne.decoding.get_coef"><span class="n">get_coef</span></a><span class="p">,</span>
                          <a href="../../generated/mne.decoding.Vectorizer.html#mne.decoding.Vectorizer" title="View documentation for mne.decoding.Vectorizer"><span class="n">Vectorizer</span></a><span class="p">,</span> <a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="View documentation for mne.decoding.CSP"><span class="n">CSP</span></a><span class="p">)</span>

<span class="n">data_path</span> <span class="o">=</span> <a href="../../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="View documentation for mne.datasets.sample.data_path"><span class="n">sample</span><span class="o">.</span><span class="n">data_path</span></a><span class="p">()</span>

<span class="n">raw_fname</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">+</span> <span class="s1">&#39;/MEG/sample/sample_audvis_raw.fif&#39;</span>
<span class="n">tmin</span><span class="p">,</span> <span class="n">tmax</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.200</span><span class="p">,</span> <span class="mf">0.500</span>
<span class="n">event_id</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Auditory/Left&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Visual/Left&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>  <span class="c1"># just use two</span>
<span class="n">raw</span> <span class="o">=</span> <a href="../../generated/mne.io.read_raw_fif.html#mne.io.read_raw_fif" title="View documentation for mne.io.read_raw_fif"><span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_raw_fif</span></a><span class="p">(</span><span class="n">raw_fname</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># The subsequent decoding analyses only capture evoked responses, so we can</span>
<span class="c1"># low-pass the MEG data. Usually a value more like 40 Hz would be used,</span>
<span class="c1"># but here low-pass at 20 so we can more heavily decimate, and allow</span>
<span class="c1"># the examlpe to run faster. The 2 Hz high-pass helps improve CSP.</span>
<span class="n">raw</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">events</span> <span class="o">=</span> <a href="../../generated/mne.find_events.html#mne.find_events" title="View documentation for mne.find_events"><span class="n">mne</span><span class="o">.</span><span class="n">find_events</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="s1">&#39;STI 014&#39;</span><span class="p">)</span>

<span class="c1"># Set up pick list: EEG + MEG - bad channels (modify to your needs)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;bads&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;MEG 2443&#39;</span><span class="p">,</span> <span class="s1">&#39;EEG 053&#39;</span><span class="p">]</span>  <span class="c1"># bads + 2 more</span>

<span class="c1"># Read epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <a href="../../generated/mne.Epochs.html#mne.Epochs" title="View documentation for mne.Epochs"><span class="n">mne</span><span class="o">.</span><span class="n">Epochs</span></a><span class="p">(</span><span class="n">raw</span><span class="p">,</span> <span class="n">events</span><span class="p">,</span> <span class="n">event_id</span><span class="p">,</span> <span class="n">tmin</span><span class="p">,</span> <span class="n">tmax</span><span class="p">,</span> <span class="n">proj</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">picks</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;grad&#39;</span><span class="p">,</span> <span class="s1">&#39;eog&#39;</span><span class="p">),</span> <span class="n">baseline</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mf">0.</span><span class="p">),</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">reject</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="mf">4000e-13</span><span class="p">,</span> <span class="n">eog</span><span class="o">=</span><span class="mf">150e-6</span><span class="p">),</span> <span class="n">decim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">epochs</span><span class="o">.</span><span class="n">pick_types</span><span class="p">(</span><span class="n">meg</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="s1">&#39;bads&#39;</span><span class="p">)</span>  <span class="c1"># remove stim and EOG</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>  <span class="c1"># MEG signals: n_epochs, n_meg_channels, n_times</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">epochs</span><span class="o">.</span><span class="n">events</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># target: Audio left or right</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
    Read a total of 3 projection items:
        PCA-v1 (1 x 102)  idle
        PCA-v2 (1 x 102)  idle
        PCA-v3 (1 x 102)  idle
    Range : 25800 ... 192599 =     42.956 ...   320.670 secs
Ready.
Current compensation grade : 0
Reading 0 ... 166799  =      0.000 ...   277.714 secs...
Filtering raw data in 1 contiguous segment
Setting up band-pass filter from 2 - 20 Hz

FIR filter parameters
---------------------
Designing a one-pass, zero-phase, non-causal bandpass filter:
- Windowed time-domain design (firwin) method
- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
- Lower passband edge: 2.00
- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)
- Upper passband edge: 20.00 Hz
- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)
- Filter length: 991 samples (1.650 sec)

320 events found
Event IDs: [ 1  2  3  4  5 32]
145 matching events found
Applying baseline correction (mode: mean)
Not setting metadata
3 projection items activated
Loading data for 145 events and 421 original time points ...
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
    Rejecting  epoch based on EOG : [&#39;EOG 061&#39;]
22 bad epochs dropped
</pre></div>
</div>
</div>
<div class="section" id="transformation-classes">
<h2><a class="toc-backref" href="#id16">Transformation classes</a><a class="headerlink" href="#transformation-classes" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="scaler">
<h3><a class="toc-backref" href="#id17">Scaler</a><a class="headerlink" href="#scaler" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.Scaler</span></code></a> will standardize the data based on channel
scales. In the simplest modes <code class="docutils literal notranslate"><span class="pre">scalings=None</span></code> or <code class="docutils literal notranslate"><span class="pre">scalings=dict(...)</span></code>,
each data channel type (e.g., mag, grad, eeg) is treated separately and
scaled by a constant. This is the approach used by e.g.,
<a class="reference internal" href="../../generated/mne.compute_covariance.html#mne.compute_covariance" title="mne.compute_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.compute_covariance()</span></code></a> to standardize channel scales.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">scalings='mean'</span></code> or <code class="docutils literal notranslate"><span class="pre">scalings='median'</span></code>, each channel is scaled using
empirical measures. Each channel is scaled independently by the mean and
standand deviation, or median and interquartile range, respectively, across
all epochs and time points during <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit" title="mne.decoding.Scaler.fit"><code class="xref py py-class docutils literal notranslate"><span class="pre">fit</span></code></a>
(during training). The <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.transform" title="mne.decoding.Scaler.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transform()</span></code></a> method is
called to transform data (training or test set) by scaling all time points
and epochs on a channel-by-channel basis. To perform both the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and
<code class="docutils literal notranslate"><span class="pre">transform</span></code> operations in a single call, the
<a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.fit_transform" title="mne.decoding.Scaler.fit_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit_transform()</span></code></a> method may be used. To invert the
transform, <a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler.inverse_transform" title="mne.decoding.Scaler.inverse_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">inverse_transform()</span></code></a> can be used. For
<code class="docutils literal notranslate"><span class="pre">scalings='median'</span></code>, <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> version 0.17+ is required.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Using this class is different from directly applying
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="(in scikit-learn v0.21.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.StandardScaler</span></code></a> or
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="(in scikit-learn v0.21.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.preprocessing.RobustScaler</span></code></a> offered by
<a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>. These scale each <em>classification feature</em>, e.g.
each time point for each channel, with mean and standard
deviation computed across epochs, whereas
<a class="reference internal" href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="mne.decoding.Scaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.Scaler</span></code></a> scales each <em>channel</em> using mean and
standard deviation computed across all of its time points
and epochs.</p>
</div>
</div>
<div class="section" id="vectorizer">
<h3><a class="toc-backref" href="#id18">Vectorizer</a><a class="headerlink" href="#vectorizer" title="Permalink to this headline">Â¶</a></h3>
<p>Scikit-learn API provides functionality to chain transformers and estimators
by using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.21.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a>. We can construct decoding
pipelines and perform cross-validation and grid-search. However scikit-learn
transformers and estimators generally expect 2D data
(n_samples * n_features), whereas MNE transformers typically output data
with a higher dimensionality
(e.g. n_samples * n_channels * n_frequencies * n_times). A Vectorizer
therefore needs to be applied between the MNE and the scikit-learn steps
like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uses all MEG sensors and time points as separate classification</span>
<span class="c1"># features, so the resulting filters used are spatio-temporal</span>
<span class="n">clf</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="View documentation for sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="../../generated/mne.decoding.Scaler.html#mne.decoding.Scaler" title="View documentation for mne.decoding.Scaler"><span class="n">Scaler</span></a><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">),</span>
                    <a href="../../generated/mne.decoding.Vectorizer.html#mne.decoding.Vectorizer" title="View documentation for mne.decoding.Vectorizer"><span class="n">Vectorizer</span></a><span class="p">(),</span>
                    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="View documentation for sklearn.linear_model.LogisticRegression"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>

<span class="n">scores</span> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="View documentation for mne.decoding.cross_val_multiscore"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<span class="n">score</span> <span class="o">=</span> <a href="https://www.numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="View documentation for numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Spatio-temporal: </span><span class="si">%0.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">score</span><span class="p">,))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Spatio-temporal: 99.2%
</pre></div>
</div>
</div>
<div class="section" id="psdestimator">
<h3><a class="toc-backref" href="#id19">PSDEstimator</a><a class="headerlink" href="#psdestimator" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.PSDEstimator.html#mne.decoding.PSDEstimator" title="mne.decoding.PSDEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.PSDEstimator</span></code></a>
computes the power spectral density (PSD) using the multitaper
method. It takes a 3D array as input, converts it into 2D and computes the
PSD.</p>
</div>
<div class="section" id="filterestimator">
<h3><a class="toc-backref" href="#id20">FilterEstimator</a><a class="headerlink" href="#filterestimator" title="Permalink to this headline">Â¶</a></h3>
<p>The <a class="reference internal" href="../../generated/mne.decoding.FilterEstimator.html#mne.decoding.FilterEstimator" title="mne.decoding.FilterEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.FilterEstimator</span></code></a> filters the 3D epochs data.</p>
</div>
</div>
<div class="section" id="spatial-filters">
<h2><a class="toc-backref" href="#id21">Spatial filters</a><a class="headerlink" href="#spatial-filters" title="Permalink to this headline">Â¶</a></h2>
<p>Just like temporal filters, spatial filters provide weights to modify the
data along the sensor dimension. They are popular in the BCI community
because of their simplicity and ability to distinguish spatially-separated
neural activity.</p>
<div class="section" id="common-spatial-pattern">
<h3><a class="toc-backref" href="#id22">Common spatial pattern</a><a class="headerlink" href="#common-spatial-pattern" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.CSP</span></code></a> is a technique to analyze multichannel data based
on recordings from two classes <a class="footnote-reference brackets" href="#id9" id="id2">2</a> (see also
<a class="reference external" href="https://en.wikipedia.org/wiki/Common_spatial_pattern">https://en.wikipedia.org/wiki/Common_spatial_pattern</a>).</p>
<p>Let <span class="math notranslate nohighlight">\(X \in R^{C\times T}\)</span> be a segment of data with
<span class="math notranslate nohighlight">\(C\)</span> channels and <span class="math notranslate nohighlight">\(T\)</span> time points. The data at a single time point
is denoted by <span class="math notranslate nohighlight">\(x(t)\)</span> such that <span class="math notranslate nohighlight">\(X=[x(t), x(t+1), ..., x(t+T-1)]\)</span>.
Common spatial pattern (CSP) finds a decomposition that projects the signal
in the original sensor space to CSP space using the following transformation:</p>
<div class="math notranslate nohighlight" id="equation-csp">
<span class="eqno">(1)<a class="headerlink" href="#equation-csp" title="Permalink to this equation">Â¶</a></span>\[x_{CSP}(t) = W^{T}x(t)\]</div>
<p>where each column of <span class="math notranslate nohighlight">\(W \in R^{C\times C}\)</span> is a spatial filter and each
row of <span class="math notranslate nohighlight">\(x_{CSP}\)</span> is a CSP component. The matrix <span class="math notranslate nohighlight">\(W\)</span> is also
called the de-mixing matrix in other contexts. Let
<span class="math notranslate nohighlight">\(\Sigma^{+} \in R^{C\times C}\)</span> and <span class="math notranslate nohighlight">\(\Sigma^{-} \in R^{C\times C}\)</span>
be the estimates of the covariance matrices of the two conditions.
CSP analysis is given by the simultaneous diagonalization of the two
covariance matrices</p>
<div class="math notranslate nohighlight" id="equation-diagonalize-p">
<span class="eqno">(2)<a class="headerlink" href="#equation-diagonalize-p" title="Permalink to this equation">Â¶</a></span>\[W^{T}\Sigma^{+}W = \lambda^{+}\]</div>
<div class="math notranslate nohighlight" id="equation-diagonalize-n">
<span class="eqno">(3)<a class="headerlink" href="#equation-diagonalize-n" title="Permalink to this equation">Â¶</a></span>\[W^{T}\Sigma^{-}W = \lambda^{-}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda^{C}\)</span> is a diagonal matrix whose entries are the
eigenvalues of the following generalized eigenvalue problem</p>
<div class="math notranslate nohighlight" id="equation-eigen-problem">
<span class="eqno">(4)<a class="headerlink" href="#equation-eigen-problem" title="Permalink to this equation">Â¶</a></span>\[\Sigma^{+}w = \lambda \Sigma^{-}w\]</div>
<p>Large entries in the diagonal matrix corresponds to a spatial filter which
gives high variance in one class but low variance in the other. Thus, the
filter facilitates discrimination between the two classes.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_decoding_csp_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-eeg-py"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></p></li>
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_decoding_csp_timefreq.html#sphx-glr-auto-examples-decoding-plot-decoding-csp-timefreq-py"><span class="std std-ref">Decoding in time-frequency space data using the Common Spatial Pattern (CSP)</span></a></p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The winning entry of the Grasp-and-lift EEG competition in Kaggle used
the <a class="reference internal" href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="mne.decoding.CSP"><code class="xref py py-class docutils literal notranslate"><span class="pre">CSP</span></code></a> implementation in MNE and was featured as
a <a class="reference external" href="http://blog.kaggle.com/2015/08/12/july-2015-scripts-of-the-week/">script of the week</a>.</p>
</div>
<p>We can use CSP with these data with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">csp</span> <span class="o">=</span> <a href="../../generated/mne.decoding.CSP.html#mne.decoding.CSP" title="View documentation for mne.decoding.CSP"><span class="n">CSP</span></a><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">norm_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="View documentation for sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span><span class="n">csp</span><span class="p">,</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="View documentation for sklearn.linear_model.LogisticRegression"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>
<span class="n">scores</span> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="View documentation for mne.decoding.cross_val_multiscore"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CSP: </span><span class="si">%0.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing data rank from raw with rank=None
    Using tolerance 4.3e-11 (2.2e-16 eps * 203 dim * 9.6e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.3e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.2e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 4.3e-11 (2.2e-16 eps * 203 dim * 9.5e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.4e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 4.2e-11 (2.2e-16 eps * 203 dim * 9.3e+02  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5.2e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
CSP: 86.4%
</pre></div>
</div>
</div>
<div class="section" id="source-power-comodulation-spoc">
<h3><a class="toc-backref" href="#id23">Source power comodulation (SPoC)</a><a class="headerlink" href="#source-power-comodulation-spoc" title="Permalink to this headline">Â¶</a></h3>
<p>Source Power Comodulation (<a class="reference internal" href="../../generated/mne.decoding.SPoC.html#mne.decoding.SPoC" title="mne.decoding.SPoC"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.SPoC</span></code></a>) <a class="footnote-reference brackets" href="#id10" id="id3">3</a>
identifies the composition of
orthogonal spatial filters that maximally correlate with a continuous target.</p>
<p>SPoC can be seen as an extension of the CSP where the target is driven by a
continuous variable rather than a discrete variable. Typical applications
include extraction of motor patterns using EMG power or audio patterns using
sound envelope.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_decoding_spoc_CMC.html#sphx-glr-auto-examples-decoding-plot-decoding-spoc-cmc-py"><span class="std std-ref">Continuous Target Decoding with SPoC</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="xdawn">
<h3><a class="toc-backref" href="#id24">xDAWN</a><a class="headerlink" href="#xdawn" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../../generated/mne.preprocessing.Xdawn.html#mne.preprocessing.Xdawn" title="mne.preprocessing.Xdawn"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.preprocessing.Xdawn</span></code></a> is a spatial filtering method designed to
improve the signal to signal + noise ratio (SSNR) of the ERP responses <a class="footnote-reference brackets" href="#id11" id="id4">4</a>.
Xdawn was originally
designed for P300 evoked potential by enhancing the target response with
respect to the non-target response. The implementation in MNE-Python is a
generalization to any type of ERP.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/preprocessing/plot_xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-plot-xdawn-denoising-py"><span class="std std-ref">XDAWN Denoising</span></a></p></li>
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_decoding_xdawn_eeg.html#sphx-glr-auto-examples-decoding-plot-decoding-xdawn-eeg-py"><span class="std std-ref">XDAWN Decoding From EEG data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="effect-matched-spatial-filtering">
<h3><a class="toc-backref" href="#id25">Effect-matched spatial filtering</a><a class="headerlink" href="#effect-matched-spatial-filtering" title="Permalink to this headline">Â¶</a></h3>
<p>The result of <a class="reference internal" href="../../generated/mne.decoding.EMS.html#mne.decoding.EMS" title="mne.decoding.EMS"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.EMS</span></code></a> is a spatial filter at each time
point and a corresponding time course <a class="footnote-reference brackets" href="#id12" id="id5">5</a>.
Intuitively, the result gives the similarity between the filter at
each time point and the data vector (sensors) at that time point.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_ems_filtering.html#sphx-glr-auto-examples-decoding-plot-ems-filtering-py"><span class="std std-ref">Compute effect-matched-spatial filtering (EMS)</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="patterns-vs-filters">
<h3><a class="toc-backref" href="#id26">Patterns vs. filters</a><a class="headerlink" href="#patterns-vs-filters" title="Permalink to this headline">Â¶</a></h3>
<p>When interpreting the components of the CSP (or spatial filters in general),
it is often more intuitive to think about how <span class="math notranslate nohighlight">\(x(t)\)</span> is composed of
the different CSP components <span class="math notranslate nohighlight">\(x_{CSP}(t)\)</span>. In other words, we can
rewrite Equation <a class="reference internal" href="#equation-csp">(1)</a> as follows:</p>
<div class="math notranslate nohighlight" id="equation-patterns">
<span class="eqno">(5)<a class="headerlink" href="#equation-patterns" title="Permalink to this equation">Â¶</a></span>\[x(t) = (W^{-1})^{T}x_{CSP}(t)\]</div>
<p>The columns of the matrix <span class="math notranslate nohighlight">\((W^{-1})^T\)</span> are called spatial patterns.
This is also called the mixing matrix. The example
<a class="reference internal" href="../../auto_examples/decoding/plot_linear_model_patterns.html#sphx-glr-auto-examples-decoding-plot-linear-model-patterns-py"><span class="std std-ref">Linear classifier on sensor data with plot patterns and filters</span></a>
discusses the difference between patterns and filters.</p>
<p>These can be plotted with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit CSP on full data and plot</span>
<span class="n">csp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">csp</span><span class="o">.</span><span class="n">plot_patterns</span><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
<span class="n">csp</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> <span class="n">scalings</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="../../_images/sphx_glr_plot_sensors_decoding_001.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_sensors_decoding_001.png" />
</li>
<li><img alt="../../_images/sphx_glr_plot_sensors_decoding_002.png" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_sensors_decoding_002.png" />
</li>
</ul>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing data rank from raw with rank=None
    Using tolerance 4.8e-11 (2.2e-16 eps * 203 dim * 1.1e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
Computing data rank from raw with rank=None
    Using tolerance 5.7e-11 (2.2e-16 eps * 203 dim * 1.3e+03  max singular value)
    Estimated rank (mag): 203
    MAG: rank 203 computed from 203 data channels with 0 projectors
Reducing data rank from 203 -&gt; 203
Estimating covariance using EMPIRICAL
Done.
</pre></div>
</div>
</div>
</div>
<div class="section" id="decoding-over-time">
<h2><a class="toc-backref" href="#id27">Decoding over time</a><a class="headerlink" href="#decoding-over-time" title="Permalink to this headline">Â¶</a></h2>
<p>This strategy consists in fitting a multivariate predictive model on each
time instant and evaluating its performance at the same instant on new
epochs. The <a class="reference internal" href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.SlidingEstimator</span></code></a> will take as input a
pair of features <span class="math notranslate nohighlight">\(X\)</span> and targets <span class="math notranslate nohighlight">\(y\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> has
more than 2 dimensions. For decoding over time the data <span class="math notranslate nohighlight">\(X\)</span>
is the epochs data of shape n_epochs x n_channels x n_times. As the
last dimension of <span class="math notranslate nohighlight">\(X\)</span> is the time, an estimator will be fit
on every time instant.</p>
<p>This approach is analogous to SlidingEstimator-based approaches in fMRI,
where here we are interested in when one can discriminate experimental
conditions and therefore figure out when the effect of interest happens.</p>
<p>When working with linear models as estimators, this approach boils
down to estimating a discriminative spatial filter for each time instant.</p>
<div class="section" id="temporal-decoding">
<h3><a class="toc-backref" href="#id28">Temporal decoding</a><a class="headerlink" href="#temporal-decoding" title="Permalink to this headline">Â¶</a></h3>
<p>Weâll use a Logistic Regression for a binary classification as machine
learning model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We will train the classifier on all left visual vs auditory trials on MEG</span>

<span class="n">clf</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="View documentation for sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="View documentation for sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a><span class="p">(),</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="View documentation for sklearn.linear_model.LogisticRegression"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>

<span class="n">time_decod</span> <span class="o">=</span> <a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="View documentation for mne.decoding.SlidingEstimator"><span class="n">SlidingEstimator</span></a><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="View documentation for mne.decoding.cross_val_multiscore"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><span class="n">time_decod</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<span class="n">scores</span> <span class="o">=</span> <a href="https://www.numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="View documentation for numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;score&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Times&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;AUC&#39;</span><span class="p">)</span>  <span class="c1"># Area Under the Curve</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Sensor space decoding&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_sensors_decoding_003.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_sensors_decoding_003.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>You can retrieve the spatial filters and spatial patterns if you explicitly
use a LinearModel</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline" title="View documentation for sklearn.pipeline.make_pipeline"><span class="n">make_pipeline</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="View documentation for sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a><span class="p">(),</span>
                    <a href="../../generated/mne.decoding.LinearModel.html#mne.decoding.LinearModel" title="View documentation for mne.decoding.LinearModel"><span class="n">LinearModel</span></a><span class="p">(</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="View documentation for sklearn.linear_model.LogisticRegression"><span class="n">LogisticRegression</span></a><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)))</span>
<span class="n">time_decod</span> <span class="o">=</span> <a href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="View documentation for mne.decoding.SlidingEstimator"><span class="n">SlidingEstimator</span></a><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">time_decod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">coef</span> <span class="o">=</span> <a href="../../generated/mne.decoding.get_coef.html#mne.decoding.get_coef" title="View documentation for mne.decoding.get_coef"><span class="n">get_coef</span></a><span class="p">(</span><span class="n">time_decod</span><span class="p">,</span> <span class="s1">&#39;patterns_&#39;</span><span class="p">,</span> <span class="n">inverse_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">evoked</span> <span class="o">=</span> <a href="../../generated/mne.EvokedArray.html#mne.EvokedArray" title="View documentation for mne.EvokedArray"><span class="n">mne</span><span class="o">.</span><span class="n">EvokedArray</span></a><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="n">epochs</span><span class="o">.</span><span class="n">info</span><span class="p">,</span> <span class="n">tmin</span><span class="o">=</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">joint_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">ts_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">),</span>
                    <span class="n">topomap_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">time_unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">))</span>
<span class="n">evoked</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">times</span><span class="o">=</span><a href="https://www.numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="View documentation for numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="o">.</span><span class="mi">500</span><span class="p">,</span> <span class="o">.</span><span class="mi">100</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;patterns&#39;</span><span class="p">,</span>
                  <span class="o">**</span><span class="n">joint_kwargs</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_sensors_decoding_004.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_sensors_decoding_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
<div class="section" id="temporal-generalization">
<h3><a class="toc-backref" href="#id29">Temporal generalization</a><a class="headerlink" href="#temporal-generalization" title="Permalink to this headline">Â¶</a></h3>
<p>Temporal generalization is an extension of the decoding over time approach.
It consists in evaluating whether the model estimated at a particular
time instant accurately predicts any other time instant. It is analogous to
transferring a trained model to a distinct learning problem, where the
problems correspond to decoding the patterns of brain activity recorded at
distinct time instants.</p>
<p>The object to for Temporal generalization is
<a class="reference internal" href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.decoding.GeneralizingEstimator</span></code></a>. It expects as input <span class="math notranslate nohighlight">\(X\)</span>
and <span class="math notranslate nohighlight">\(y\)</span> (similarly to <a class="reference internal" href="../../generated/mne.decoding.SlidingEstimator.html#mne.decoding.SlidingEstimator" title="mne.decoding.SlidingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">SlidingEstimator</span></code></a>) but
generates predictions from each model for all time instants. The class
<a class="reference internal" href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="mne.decoding.GeneralizingEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">GeneralizingEstimator</span></code></a> is generic and will treat the
last dimension as the one to be used for generalization testing. For
convenience, here, we refer to it as different tasks. If <span class="math notranslate nohighlight">\(X\)</span>
corresponds to epochs data then the last dimension is time.</p>
<p>This runs the analysis used in <a class="footnote-reference brackets" href="#id13" id="id6">6</a> and further detailed in <a class="footnote-reference brackets" href="#id14" id="id7">7</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the Temporal generalization object</span>
<span class="n">time_gen</span> <span class="o">=</span> <a href="../../generated/mne.decoding.GeneralizingEstimator.html#mne.decoding.GeneralizingEstimator" title="View documentation for mne.decoding.GeneralizingEstimator"><span class="n">GeneralizingEstimator</span></a><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <a href="../../generated/mne.decoding.cross_val_multiscore.html#mne.decoding.cross_val_multiscore" title="View documentation for mne.decoding.cross_val_multiscore"><span class="n">cross_val_multiscore</span></a><span class="p">(</span><span class="n">time_gen</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Mean scores across cross-validation splits</span>
<span class="n">scores</span> <span class="o">=</span> <a href="https://www.numpy.org/devdocs/reference/generated/numpy.mean.html#numpy.mean" title="View documentation for numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot the diagonal (it&#39;s exactly the same as the time-by-time decoding above)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">,</span> <a href="https://www.numpy.org/devdocs/reference/generated/numpy.diag.html#numpy.diag" title="View documentation for numpy.diag"><span class="n">np</span><span class="o">.</span><span class="n">diag</span></a><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;score&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;chance&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Times&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;AUC&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">.</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Decoding MEG sensors over time&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_sensors_decoding_005.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_sensors_decoding_005.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>Plot the full (generalization) matrix:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="View documentation for matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;lanczos&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span>
               <span class="n">extent</span><span class="o">=</span><span class="n">epochs</span><span class="o">.</span><span class="n">times</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Testing Time (s)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Training Time (s)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Temporal generalization&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.colorbar.html#matplotlib.pyplot.colorbar" title="View documentation for matplotlib.pyplot.colorbar"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span></a><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_sensors_decoding_006.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_sensors_decoding_006.png" />
</div>
</div>
<div class="section" id="source-space-decoding">
<h2><a class="toc-backref" href="#id30">Source-space decoding</a><a class="headerlink" href="#source-space-decoding" title="Permalink to this headline">Â¶</a></h2>
<p>Source space decoding is also possible, but because the number of features
can be much larger than in the sensor space, univariate feature selection
using ANOVA f-test (or some other metric) can be done to reduce the feature
dimension. Interpreting decoding results might be easier in source space as
compared to sensor space.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/decoding/plot_decoding_spatio_temporal_source.html#tut-dec-st-source"><span class="std std-ref">Decoding source space data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="exercise">
<h2><a class="toc-backref" href="#id31">Exercise</a><a class="headerlink" href="#exercise" title="Permalink to this headline">Â¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Explore other datasets from MNE (e.g. Face dataset from SPM to predict
Face vs. Scrambled)</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id32">References</a><a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Jean-RÃ©mi King et al. (2018) âEncoding and Decoding Neuronal Dynamics:
Methodological Framework to Uncover the Algorithms of Cognitionâ,
2018. The Cognitive Neurosciences VI.
<a class="reference external" href="https://hal.archives-ouvertes.fr/hal-01848442/">https://hal.archives-ouvertes.fr/hal-01848442/</a></p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Zoltan J. Koles. The quantitative extraction and topographic mapping
of the abnormal components in the clinical EEG. Electroencephalography
and Clinical Neurophysiology, 79(6):440â447, December 1991.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Dahne, S., Meinecke, F. C., Haufe, S., Hohne, J., Tangermann, M.,
Muller, K. R., &amp; Nikulin, V. V. (2014). SPoC: a novel framework for
relating the amplitude of neuronal oscillations to behaviorally
relevant parameters. NeuroImage, 86, 111-122.</p>
</dd>
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Rivet, B., Souloumiac, A., Attina, V., &amp; Gibert, G. (2009). xDAWN
algorithm to enhance evoked potentials: application to
brain-computer interface. Biomedical Engineering, IEEE Transactions
on, 56(8), 2035-2043.</p>
</dd>
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Aaron Schurger, Sebastien Marti, and Stanislas Dehaene, âReducing
multi-sensor data to a single time course that reveals experimental
effectsâ, BMC Neuroscience 2013, 14:122</p>
</dd>
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Jean-Remi King, Alexandre Gramfort, Aaron Schurger, Lionel Naccache
and Stanislas Dehaene, âTwo distinct dynamic modes subtend the
detection of unexpected soundsâ, PLOS ONE, 2013,
<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/24475052">https://www.ncbi.nlm.nih.gov/pubmed/24475052</a></p>
</dd>
<dt class="label" id="id14"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p>King &amp; Dehaene (2014) âCharacterizing the dynamics of mental
representations: the temporal generalization methodâ, Trends In
Cognitive Sciences, 18(4), 203-210.
<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/24593982">https://www.ncbi.nlm.nih.gov/pubmed/24593982</a></p>
</dd>
</dl>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  23.624 seconds)</p>
<p><strong>Estimated memory usage:</strong>  487 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-machine-learning-plot-sensors-decoding-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e9da0c1f80863ce55775f8c349b7ce39/plot_sensors_decoding.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_sensors_decoding.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/7b57fca16e7c12b88411529a749018d6/plot_sensors_decoding.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_sensors_decoding.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container institutions">
    <a href="https://www.massgeneral.org/"><img class="institution_lg" src="../../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a>
    <a href="https://martinos.org/"><img class="institution_lg" src="../../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a>
    <a href="https://hms.harvard.edu/"><img class="institution_lg" src="../../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a>
    <a href="https://web.mit.edu/"><img class="institution_sm" src="../../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a>
    <a href="https://www.nyu.edu/"><img class="institution_md" src="../../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a>
    <a href="http://www.cea.fr/"><img class="institution_md" src="../../_static/institution_logos/CEA.png" title="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives" alt="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives"/></a>
    <a href="https://sci.aalto.fi/"><img class="institution_md" src="../../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a>
    <a href="https://www.telecom-paris.fr/"><img class="institution_md" src="../../_static/institution_logos/Telecom_Paris_Tech.png" title="TÃ©lÃ©com ParisTech" alt="TÃ©lÃ©com ParisTech"/></a>
    <a href="https://www.washington.edu/"><img class="institution_sm" src="../../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a>
    <a href="https://icm-institute.org/"><img class="institution_lg" src="../../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle Ã©piniÃ¨re" alt="Institut du Cerveau et de la Moelle Ã©piniÃ¨re"/></a>
    <a href="https://www.bu.edu/"><img class="institution_sm" src="../../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a>
    <a href="https://www.inserm.fr/"><img class="institution_xs" src="../../_static/institution_logos/Inserm.svg" title="Institut national de la santÃ© et de la recherche mÃ©dicale" alt="Institut national de la santÃ© et de la recherche mÃ©dicale"/></a>
    <a href="https://www.fz-juelich.de/"><img class="institution_sm" src="../../_static/institution_logos/Julich.svg" title="Forschungszentrum JÃ¼lich" alt="Forschungszentrum JÃ¼lich"/></a>
    <a href="https://www.tu-ilmenau.de/"><img class="institution_sm" src="../../_static/institution_logos/Ilmenau.gif" title="Technische UniversitÃ¤t Ilmenau" alt="Technische UniversitÃ¤t Ilmenau"/></a>
    <a href="https://bids.berkeley.edu/"><img class="institution_md" src="../../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a>
    <a href="https://www.inria.fr/"><img class="institution_sm" src="../../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a>
    <a href="https://www.au.dk/"><img class="institution_sm" src="../../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a>
    <a href="https://www.uni-graz.at/"><img class="institution_md" src="../../_static/institution_logos/Graz.jpg" title="Karl-Franzens-UniversitÃ¤t Graz" alt="Karl-Franzens-UniversitÃ¤t Graz"/></a>
  </div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>Â·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>Â·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>Â·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>Â·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2019, MNE Developers. Last updated on 2019-07-11.</p>
  </div>
</footer>
  </body>
</html>