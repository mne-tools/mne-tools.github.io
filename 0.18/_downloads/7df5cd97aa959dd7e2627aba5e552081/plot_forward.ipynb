{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nHead model and forward computation\n==================================\n\nThe aim of this tutorial is to be a getting started for forward\ncomputation.\n\nFor more extensive details and presentation of the general\nconcepts for forward modeling. See `ch_forward`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport mne\nfrom mne.datasets import sample\ndata_path = sample.data_path()\n\n# the raw file containing the channel location + types\nraw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\n# The paths to Freesurfer reconstructions\nsubjects_dir = data_path + '/subjects'\nsubject = 'sample'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing the forward operator\n------------------------------\n\nTo compute a forward operator we need:\n\n   - a ``-trans.fif`` file that contains the coregistration info.\n   - a source space\n   - the :term:`BEM` surfaces\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute and visualize BEM surfaces\n----------------------------------\n\nThe :term:`BEM` surfaces are the triangulations of the interfaces between\ndifferent tissues needed for forward computation. These surfaces are for\nexample the inner skull surface, the outer skull surface and the outer skin\nsurface, a.k.a. scalp surface.\n\nComputing the BEM surfaces requires FreeSurfer and makes use of either of\nthe two following command line tools:\n\n  - `gen_mne_watershed_bem`\n  - `gen_mne_flash_bem`\n\nOr by calling in a Python script one of the functions\n:func:`mne.bem.make_watershed_bem` or :func:`mne.bem.make_flash_bem`.\n\nHere we'll assume it's already computed. It takes a few minutes per subject.\n\nFor EEG we use 3 layers (inner skull, outer skull, and skin) while for\nMEG 1 layer (inner skull) is enough.\n\nLet's look at these surfaces. The function :func:`mne.viz.plot_bem`\nassumes that you have the the *bem* folder of your subject FreeSurfer\nreconstruction the necessary files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_bem(subject=subject, subjects_dir=subjects_dir,\n                 brain_surfaces='white', orientation='coronal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization the coregistration\n--------------------------------\n\nThe coregistration is operation that allows to position the head and the\nsensors in a common coordinate system. In the MNE software the transformation\nto align the head and the sensors in stored in a so-called **trans file**.\nIt is a FIF file that ends with ``-trans.fif``. It can be obtained with\n:func:`mne.gui.coregistration` (or its convenient command line\nequivalent `gen_mne_coreg`), or mrilab if you're using a Neuromag\nsystem.\n\nFor the Python version see :func:`mne.gui.coregistration`\n\nHere we assume the coregistration is done, so we just visually check the\nalignment with the following code.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The transformation file obtained by coregistration\ntrans = data_path + '/MEG/sample/sample_audvis_raw-trans.fif'\n\ninfo = mne.io.read_info(raw_fname)\n# Here we look at the dense head, which isn't used for BEM computations but\n# is useful for coregistration.\nmne.viz.plot_alignment(info, trans, subject=subject, dig=True,\n                       meg=['helmet', 'sensors'], subjects_dir=subjects_dir,\n                       surfaces='head-dense')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompute Source Space\n--------------------\n\nThe source space defines the position and orientation of the candidate source\nlocations. There are two types of source spaces:\n\n- **source-based** source space when the candidates are confined to a\n  surface.\n\n- **volumetric or discrete** source space when the candidates are discrete,\n  arbitrarily located source points bounded by the surface.\n\n**Source-based** source space is computed using\n:func:`mne.setup_source_space`, while **volumetric** source space is computed\nusing :func:`mne.setup_volume_source_space`.\n\nWe will now compute a source-based source space with an OCT-6 resolution.\nSee `setting_up_source_space` for details on source space definition\nand spacing parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src = mne.setup_source_space(subject, spacing='oct6',\n                             subjects_dir=subjects_dir, add_dist=False)\nprint(src)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The surface based source space ``src`` contains two parts, one for the left\nhemisphere (4098 locations) and one for the right hemisphere\n(4098 locations). Sources can be visualized on top of the BEM surfaces\nin purple.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne.viz.plot_bem(subject=subject, subjects_dir=subjects_dir,\n                 brain_surfaces='white', src=src, orientation='coronal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compute a volume based source space defined with a grid of candidate\ndipoles inside a sphere of radius 90mm centered at (0.0, 0.0, 40.0)\nyou can use the following code.\nObviously here, the sphere is not perfect. It is not restricted to the\nbrain and it can miss some parts of the cortex.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sphere = (0.0, 0.0, 40.0, 90.0)\nvol_src = mne.setup_volume_source_space(subject, subjects_dir=subjects_dir,\n                                        sphere=sphere)\nprint(vol_src)\n\nmne.viz.plot_bem(subject=subject, subjects_dir=subjects_dir,\n                 brain_surfaces='white', src=vol_src, orientation='coronal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compute a volume based source space defined with a grid of candidate\ndipoles inside the brain (requires the :term:`BEM` surfaces) you can use the\nfollowing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "surface = op.join(subjects_dir, subject, 'bem', 'inner_skull.surf')\nvol_src = mne.setup_volume_source_space(subject, subjects_dir=subjects_dir,\n                                        surface=surface)\nprint(vol_src)\n\nmne.viz.plot_bem(subject=subject, subjects_dir=subjects_dir,\n                 brain_surfaces='white', src=vol_src, orientation='coronal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the surface-based source space only sources that lie in the plotted MRI\nslices are shown. Let's write a few lines of mayavi to see all sources in 3D.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np  # noqa\nfrom mayavi import mlab  # noqa\nfrom surfer import Brain  # noqa\n\nbrain = Brain('sample', 'lh', 'inflated', subjects_dir=subjects_dir)\nsurf = brain.geo['lh']\n\nvertidx = np.where(src[0]['inuse'])[0]\n\nmlab.points3d(surf.x[vertidx], surf.y[vertidx],\n              surf.z[vertidx], color=(1, 1, 0), scale_factor=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompute forward solution\n------------------------\n\nWe can now compute the forward solution.\nTo reduce computation we'll just compute a single layer BEM (just inner\nskull) that can then be used for MEG (not EEG).\n\nWe specify if we want a one-layer or a three-layer BEM using the\nconductivity parameter.\n\nThe BEM solution requires a BEM model which describes the geometry\nof the head the conductivities of the different tissues.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conductivity = (0.3,)  # for single layer\n# conductivity = (0.3, 0.006, 0.3)  # for three layers\nmodel = mne.make_bem_model(subject='sample', ico=4,\n                           conductivity=conductivity,\n                           subjects_dir=subjects_dir)\nbem = mne.make_bem_solution(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the :term:`BEM` does not involve any use of the trans file. The BEM\nonly depends on the head geometry and conductivities.\nIt is therefore independent from the MEG data and the head position.\n\nLet's now compute the forward operator, commonly referred to as the\ngain or leadfield matrix.\n\nSee :func:`mne.make_forward_solution` for details on parameters meaning.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fwd = mne.make_forward_solution(raw_fname, trans=trans, src=src, bem=bem,\n                                meg=True, eeg=False, mindist=5.0, n_jobs=2)\nprint(fwd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can explore the content of fwd to access the numpy array that contains\nthe gain matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "leadfield = fwd['sol']['data']\nprint(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To extract the numpy array containing the forward operator corresponding to\nthe source space `fwd['src']` with cortical orientation constraint\nwe can use the following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fwd_fixed = mne.convert_forward_solution(fwd, surf_ori=True, force_fixed=True,\n                                         use_cps=True)\nleadfield = fwd_fixed['sol']['data']\nprint(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is equivalent to the following code that explicitly applies the\nforward operator to a source estimate composed of the identity operator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_dipoles = leadfield.shape[1]\nvertices = [src_hemi['vertno'] for src_hemi in fwd_fixed['src']]\nstc = mne.SourceEstimate(1e-9 * np.eye(n_dipoles), vertices, tmin=0., tstep=1)\nleadfield = mne.apply_forward(fwd_fixed, stc, info).data / 1e-9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To save to disk a forward solution you can use\n:func:`mne.write_forward_solution` and to read it back from disk\n:func:`mne.read_forward_solution`. Don't forget that FIF files containing\nforward solution should end with *-fwd.fif*.\n\nTo get a fixed-orientation forward solution, use\n:func:`mne.convert_forward_solution` to convert the free-orientation\nsolution to (surface-oriented) fixed orientation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exercise\n--------\n\nBy looking at\n`sphx_glr_auto_examples_forward_plot_forward_sensitivity_maps.py`\nplot the sensitivity maps for EEG and compare it with the MEG, can you\njustify the claims that:\n\n  - MEG is not sensitive to radial sources\n  - EEG is more sensitive to deep sources\n\nHow will the MEG sensitivity maps and histograms change if you use a free\ninstead if a fixed/surface oriented orientation?\n\nTry this changing the mode parameter in :func:`mne.sensitivity_map`\naccordingly. Why don't we see any dipoles on the gyri?\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}