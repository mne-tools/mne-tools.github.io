{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simulate raw data using subject anatomy\n\n\nThis example illustrates how to generate source estimates and simulate raw data\nusing subject anatomy with the :class:`mne.simulation.SourceSimulator` class.\nOnce the raw data is simulated, generated source estimates are reconstructed\nusing dynamic statistical parametric mapping (dSPM) inverse operator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Ivana Kojcic <ivana.kojcic@gmail.com>\n#         Eric Larson <larson.eric.d@gmail.com>\n#         Kostiantyn Maksymenko <kostiantyn.maksymenko@gmail.com>\n#         Samuel Deslauriers-Gauthier <sam.deslauriers@gmail.com>\n\n# License: BSD (3-clause)\n\nimport os.path as op\n\nimport numpy as np\n\nimport mne\nfrom mne.datasets import sample\n\nprint(__doc__)\n\n# To simulate the sample dataset, information of the sample subject needs to be\n# loaded. This step will download the data if it not already on your machine.\n# Subjects directory is also set so it doesn't need to be given to functions.\ndata_path = sample.data_path()\nsubjects_dir = op.join(data_path, 'subjects')\nsubject = 'sample'\nmeg_path = op.join(data_path, 'MEG', subject)\n\n# First, we get an info structure from the sample subject.\nfname_info = op.join(meg_path, 'sample_audvis_raw.fif')\ninfo = mne.io.read_info(fname_info)\ntstep = 1 / info['sfreq']\n\n# To simulate sources, we also need a source space. It can be obtained from the\n# forward solution of the sample subject.\nfwd_fname = op.join(meg_path, 'sample_audvis-meg-eeg-oct-6-fwd.fif')\nfwd = mne.read_forward_solution(fwd_fname)\nsrc = fwd['src']\n\n# To simulate raw data, we need to define when the activity occurs using events\n# matrix and specify the IDs of each event.\n# Noise covariance matrix also needs to be defined.\n# Here, both are loaded from the sample dataset, but they can also be specified\n# by the user.\n\nfname_event = op.join(meg_path, 'sample_audvis_raw-eve.fif')\nfname_cov = op.join(meg_path, 'sample_audvis-cov.fif')\n\nevents = mne.read_events(fname_event)\nnoise_cov = mne.read_cov(fname_cov)\n\n# Standard sample event IDs. These values will correspond to the third column\n# in the events matrix.\nevent_id = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,\n            'visual/right': 4, 'smiley': 5, 'button': 32}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to simulate source time courses, labels of desired active regions\nneed to be specified for each of the 4 simulation conditions.\nMake a dictionary that maps conditions to activation strengths within\naparc.a2009s [1]_ labels. In the aparc.a2009s parcellation:\n\n- 'G_temp_sup-G_T_transv' is the label for primary auditory area\n- 'S_calcarine' is the label for primary visual area\n\nIn each of the 4 conditions, only the primary area is activated. This means\nthat during the activations of auditory areas, there are no activations in\nvisual areas and vice versa.\nMoreover, for each condition, contralateral region is more active (here, 2\ntimes more) than the ipsilateral.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "activations = {\n    'auditory/left':\n        [('G_temp_sup-G_T_transv-lh', 100),          # label, activation (nAm)\n         ('G_temp_sup-G_T_transv-rh', 200)],\n    'auditory/right':\n        [('G_temp_sup-G_T_transv-lh', 200),\n         ('G_temp_sup-G_T_transv-rh', 100)],\n    'visual/left':\n        [('S_calcarine-lh', 100),\n         ('S_calcarine-rh', 200)],\n    'visual/right':\n        [('S_calcarine-lh', 200),\n         ('S_calcarine-rh', 100)],\n}\n\nannot = 'aparc.a2009s'\n\n# Load the 4 necessary label names.\nlabel_names = sorted(set(activation[0]\n                         for activation_list in activations.values()\n                         for activation in activation_list))\nregion_names = list(activations.keys())\n\n#  Define the time course of the activity for each region to activate. We use a\n#  sine wave and it will be the same for all 4 regions.\nsource_time_series = np.sin(np.linspace(0, 4 * np.pi, 100)) * 10e-9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create simulated source activity\n--------------------------------\n\nHere, :class:`~mne.simulation.SourceSimulator` is used, which allows to\nspecify where (label), what (source_time_series), and when (events) event\ntype will occur.\n\nWe will add data for 4 areas, each of which contains 2 labels. Since add_data\nmethod accepts 1 label per call, it will be called 2 times per area.\nAll activations will contain the same waveform, but the amplitude will be 2\ntimes higher in the contralateral label, as explained before.\n\nWhen the activity occurs is defined using events. In this case, they are\ntaken from the original raw data. The first column is the sample of the\nevent, the second is not used. The third one is the event id, which is\ndifferent for each of the 4 areas.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "source_simulator = mne.simulation.SourceSimulator(src, tstep=tstep)\nfor region_id, region_name in enumerate(region_names, 1):\n    events_tmp = events[np.where(events[:, 2] == region_id)[0], :]\n    for i in range(2):\n        label_name = activations[region_name][i][0]\n        label_tmp = mne.read_labels_from_annot(subject, annot,\n                                               subjects_dir=subjects_dir,\n                                               regexp=label_name,\n                                               verbose=False)\n        label_tmp = label_tmp[0]\n        amplitude_tmp = activations[region_name][i][1]\n        source_simulator.add_data(label_tmp,\n                                  amplitude_tmp * source_time_series,\n                                  events_tmp)\n\n# To obtain a SourceEstimate object, we need to use `get_stc()` method of\n# SourceSimulator class.\nstc_data = source_simulator.get_stc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulate raw data\n-----------------\n\nProject the source time series to sensor space. Three types of noise will be\nadded to the simulated raw data:\n\n- multivariate Gaussian noise obtained from the noise covariance from the\n  sample data\n- blink (EOG) noise\n- ECG noise\n\nThe :class:`~mne.simulation.SourceSimulator` can be given directly to the\n:func:`~mne.simulation.simulate_raw` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_sim = mne.simulation.simulate_raw(info, source_simulator, forward=fwd,\n                                      cov=None)\nraw_sim.set_eeg_reference(projection=True).crop(0, 60)  # for speed\n\nmne.simulation.add_noise(raw_sim, cov=noise_cov, random_state=0)\nmne.simulation.add_eog(raw_sim, random_state=0)\nmne.simulation.add_ecg(raw_sim, random_state=0)\n\n# Plot original and simulated raw data.\nraw_sim.plot(title='Simulated raw data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct simulated source time courses using dSPM inverse operator\n---------------------------------------------------------------------\n\nHere, source time courses for auditory and visual areas are reconstructed\nseparately and their difference is shown. This was done merely for better\nvisual representation of source reconstruction.\nAs expected, when high activations appear in primary auditory areas, primary\nvisual areas will have low activations and vice versa.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "method, lambda2 = 'dSPM', 1. / 9.\nepochs = mne.Epochs(raw_sim, events, event_id)\ninv = mne.minimum_norm.make_inverse_operator(epochs.info, fwd, noise_cov)\nstc_aud = mne.minimum_norm.apply_inverse(\n    epochs['auditory/left'].average(), inv, lambda2, method)\nstc_vis = mne.minimum_norm.apply_inverse(\n    epochs['visual/right'].average(), inv, lambda2, method)\nstc_diff = stc_aud - stc_vis\n\nbrain = stc_diff.plot(subjects_dir=subjects_dir, initial_time=0.1,\n                      hemi='split', views=['lat', 'med'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n.. [1] Destrieux C, Fischl B, Dale A, Halgren E (2010). Automatic\n       parcellation of human cortical gyri and sulci using standard\n       anatomical nomenclature, vol. 53(1), 1-15, NeuroImage.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}