{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute LCMV beamformer on evoked data\n\n\nCompute LCMV beamformer on an evoked dataset for three different choices of\nsource orientation and store the solutions in stc files for visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 3\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.beamformer import make_lcmv, apply_lcmv\n\nprint(__doc__)\n\ndata_path = sample.data_path()\nraw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_raw-eve.fif'\nfname_fwd = data_path + '/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif'\nlabel_name = 'Aud-lh'\nfname_label = data_path + '/MEG/sample/labels/%s.label' % label_name\nsubjects_dir = data_path + '/subjects'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get epochs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_id, tmin, tmax = 1, -0.2, 0.5\n\n# Setup for reading the raw data\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\nraw.info['bads'] = ['MEG 2443', 'EEG 053']  # 2 bads channels\nevents = mne.read_events(event_fname)\n\n# Set up pick list: EEG + MEG - bad channels (modify to your needs)\npicks = mne.pick_types(raw.info, meg=True, eeg=False, stim=True, eog=True,\n                       exclude='bads')\n\n# Pick the channels of interest\nraw.pick_channels([raw.ch_names[pick] for pick in picks])\n# Re-normalize our empty-room projectors, so they are fine after subselection\nraw.info.normalize_proj()\n\n# Read epochs\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n                    baseline=(None, 0), preload=True, proj=True,\n                    reject=dict(grad=4000e-13, mag=4e-12, eog=150e-6))\nevoked = epochs.average()\n\nforward = mne.read_forward_solution(fname_fwd)\nforward = mne.convert_forward_solution(forward, surf_ori=True)\n\n# Compute regularized noise and data covariances\nnoise_cov = mne.compute_covariance(epochs, tmin=tmin, tmax=0, method='shrunk',\n                                   rank=None)\ndata_cov = mne.compute_covariance(epochs, tmin=0.04, tmax=0.15,\n                                  method='shrunk', rank=None)\nevoked.plot(time_unit='s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run beamformers and look at maximum outputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pick_oris = [None, 'normal', 'max-power', None]\ndescriptions = ['Free', 'Normal', 'Max-power', 'Fixed']\n\nfig, ax = plt.subplots(1)\nmax_voxs = list()\ncolors = list()\nfor pick_ori, desc in zip(pick_oris, descriptions):\n    # compute unit-noise-gain beamformer with whitening of the leadfield and\n    # data (enabled by passing a noise covariance matrix)\n    if desc == 'Fixed':\n        use_forward = mne.convert_forward_solution(forward, force_fixed=True)\n    else:\n        use_forward = forward\n    filters = make_lcmv(evoked.info, use_forward, data_cov, reg=0.05,\n                        noise_cov=noise_cov, pick_ori=pick_ori,\n                        weight_norm='unit-noise-gain', rank=None)\n    print(filters)\n    # apply this spatial filter to source-reconstruct the evoked data\n    stc = apply_lcmv(evoked, filters, max_ori_out='signed')\n\n    # View activation time-series in maximum voxel at 100 ms:\n    time_idx = stc.time_as_index(0.1)\n    max_idx = np.argmax(np.abs(stc.data[:, time_idx]))\n    # we know these are all left hemi, so we can just use vertices[0]\n    max_voxs.append(stc.vertices[0][max_idx])\n    h = ax.plot(stc.times, stc.data[max_idx, :],\n                label='%s, voxel: %i' % (desc, max_idx))[0]\n    colors.append(h.get_color())\n    if pick_ori == 'max-power':\n        max_stc = stc\nax.axhline(0, color='k')\n\nax.set(xlabel='Time (ms)', ylabel='LCMV value',\n       title='LCMV in maximum voxel')\nax.legend(loc='lower right')\nmne.viz.utils.plt_show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also look at the spatial distribution\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot last stc in the brain in 3D with PySurfer if available\nbrain = max_stc.plot(hemi='lh', views='lat', subjects_dir=subjects_dir,\n                     initial_time=0.1, time_unit='s', smoothing_steps=5)\nfor color, vertex in zip(colors, max_voxs):\n    brain.add_foci([vertex], coords_as_verts=True, scale_factor=0.5,\n                   hemi='lh', color=color)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}