<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Datasets &#8212; MNE 0.18.2 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bootstrap_divs.css" />
    <link rel="stylesheet" href="../_static/reset-syntax.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/bootstrap_divs.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <script type="text/javascript" src="../_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="../_static/style.css " type="text/css" />
    <link rel="stylesheet" href="../_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="../_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>



  </head><body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.18.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../getting_started.html">Install</a></li>
                <li><a href="../documentation.html">Documentation</a></li>
                <li><a href="../python_reference.html">API</a></li>
                <li><a href="../glossary.html">Glossary</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.18.2
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.18 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Datasets</a><ul>
<li><a class="reference internal" href="#sample">Sample</a></li>
<li><a class="reference internal" href="#fsaverage">fsaverage</a></li>
<li><a class="reference internal" href="#brainstorm">Brainstorm</a><ul>
<li><a class="reference internal" href="#auditory">Auditory</a></li>
<li><a class="reference internal" href="#resting-state">Resting state</a></li>
<li><a class="reference internal" href="#median-nerve">Median nerve</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spm-faces">SPM faces</a></li>
<li><a class="reference internal" href="#eegbci-motor-imagery">EEGBCI motor imagery</a></li>
<li><a class="reference internal" href="#somatosensory">Somatosensory</a></li>
<li><a class="reference internal" href="#multimodal">Multimodal</a></li>
<li><a class="reference internal" href="#high-frequency-sef">High frequency SEF</a></li>
<li><a class="reference internal" href="#visual-92-object-categories">Visual 92 object categories</a></li>
<li><a class="reference internal" href="#mtrf-dataset">mTRF Dataset</a></li>
<li><a class="reference internal" href="#miscellaneous-datasets">Miscellaneous Datasets</a><ul>
<li><a class="reference internal" href="#ecog-dataset">ECoG Dataset</a></li>
</ul>
</li>
<li><a class="reference internal" href="#kiloword-dataset">Kiloword dataset</a></li>
<li><a class="reference internal" href="#d-neuroimaging-bti-dataset">4D Neuroimaging / BTi dataset</a></li>
<li><a class="reference internal" href="#opm">OPM</a></li>
<li><a class="reference internal" href="#the-sleep-polysomnographic-database">The Sleep PolySomnoGraphic Database</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="datasets">
<span id="id1"></span><h1>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">Â¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#sample" id="id16">Sample</a></p></li>
<li><p><a class="reference internal" href="#fsaverage" id="id17">fsaverage</a></p></li>
<li><p><a class="reference internal" href="#brainstorm" id="id18">Brainstorm</a></p>
<ul>
<li><p><a class="reference internal" href="#auditory" id="id19">Auditory</a></p></li>
<li><p><a class="reference internal" href="#resting-state" id="id20">Resting state</a></p></li>
<li><p><a class="reference internal" href="#median-nerve" id="id21">Median nerve</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#spm-faces" id="id22">SPM faces</a></p></li>
<li><p><a class="reference internal" href="#eegbci-motor-imagery" id="id23">EEGBCI motor imagery</a></p></li>
<li><p><a class="reference internal" href="#somatosensory" id="id24">Somatosensory</a></p></li>
<li><p><a class="reference internal" href="#multimodal" id="id25">Multimodal</a></p></li>
<li><p><a class="reference internal" href="#high-frequency-sef" id="id26">High frequency SEF</a></p></li>
<li><p><a class="reference internal" href="#visual-92-object-categories" id="id27">Visual 92 object categories</a></p></li>
<li><p><a class="reference internal" href="#mtrf-dataset" id="id28">mTRF Dataset</a></p></li>
<li><p><a class="reference internal" href="#miscellaneous-datasets" id="id29">Miscellaneous Datasets</a></p>
<ul>
<li><p><a class="reference internal" href="#ecog-dataset" id="id30">ECoG Dataset</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#kiloword-dataset" id="id31">Kiloword dataset</a></p></li>
<li><p><a class="reference internal" href="#d-neuroimaging-bti-dataset" id="id32">4D Neuroimaging / BTi dataset</a></p></li>
<li><p><a class="reference internal" href="#opm" id="id33">OPM</a></p></li>
<li><p><a class="reference internal" href="#the-sleep-polysomnographic-database" id="id34">The Sleep PolySomnoGraphic Database</a></p></li>
<li><p><a class="reference internal" href="#references" id="id35">References</a></p></li>
</ul>
</div>
<p>All the dataset fetchers are available in <a class="reference internal" href="../python_reference.html#module-mne.datasets" title="mne.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mne.datasets</span></code></a>. To download any of the datasets,
use the <code class="docutils literal notranslate"><span class="pre">data_path</span></code> (fetches full dataset) or the <code class="docutils literal notranslate"><span class="pre">load_data</span></code> (fetches dataset partially) functions.</p>
<div class="section" id="sample">
<span id="sample-dataset"></span><h2><a class="toc-backref" href="#id16">Sample</a><a class="headerlink" href="#sample" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path" title="mne.datasets.sample.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sample.data_path()</span></code></a></p>
<p><a class="reference internal" href="sample_dataset.html#ch-sample-data"><span class="std std-ref">The sample data set</span></a> is recorded using a 306-channel Neuromag vectorview system.</p>
<p>In this experiment, checkerboard patterns were presented to the subject
into the left and right visual field, interspersed by tones to the
left or right ear. The interval between the stimuli was 750 ms. Occasionally
a smiley face was presented at the center of the visual field.
The subject was asked to press a key with the right index finger
as soon as possible after the appearance of the face.</p>
<p>Once the <code class="docutils literal notranslate"><span class="pre">data_path</span></code> is known, its contents can be examined using <a class="reference internal" href="io.html#ch-convert"><span class="std std-ref">IO functions</span></a>.</p>
</div>
<div class="section" id="fsaverage">
<h2><a class="toc-backref" href="#id17">fsaverage</a><a class="headerlink" href="#fsaverage" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.fetch_fsaverage.html#mne.datasets.fetch_fsaverage" title="mne.datasets.fetch_fsaverage"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.fetch_fsaverage()</span></code></a></p>
<p>For convenience, we provide a function to separately download and extract the
(or update an existing) fsaverage subject.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<p><a class="reference internal" href="../auto_tutorials/source-modeling/plot_eeg_no_mri.html#tut-eeg-fsaverage-source-modeling"><span class="std std-ref">EEG forward operator with a template MRI</span></a></p>
</div>
</div>
<div class="section" id="brainstorm">
<h2><a class="toc-backref" href="#id18">Brainstorm</a><a class="headerlink" href="#brainstorm" title="Permalink to this headline">Â¶</a></h2>
<p>Dataset fetchers for three Brainstorm tutorials are available. Users must agree to the
license terms of these datasets before downloading them. These files are recorded in a CTF 275 system
and are provided in native CTF format (.ds files).</p>
<div class="section" id="auditory">
<h3><a class="toc-backref" href="#id19">Auditory</a><a class="headerlink" href="#auditory" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a>.</p>
<p>Details about the data can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetAuditory">auditory dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/sample-datasets/plot_brainstorm_auditory.html#tut-brainstorm-auditory"><span class="std std-ref">Brainstorm auditory tutorial dataset</span></a>: Partially replicates the original Brainstorm tutorial.</p></li>
</ul>
</div>
</div>
<div class="section" id="resting-state">
<h3><a class="toc-backref" href="#id20">Resting state</a><a class="headerlink" href="#resting-state" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_resting.data_path.html#mne.datasets.brainstorm.bst_resting.data_path" title="mne.datasets.brainstorm.bst_resting.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_resting.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetResting">resting state dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/connectivity/plot_mne_inverse_envelope_correlation.html#ex-envelope-correlation"><span class="std std-ref">Compute envelope correlations in source space</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="median-nerve">
<h3><a class="toc-backref" href="#id21">Median nerve</a><a class="headerlink" href="#median-nerve" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.brainstorm.bst_raw.data_path.html#mne.datasets.brainstorm.bst_raw.data_path" title="mne.datasets.brainstorm.bst_raw.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.brainstorm.bst_raw.data_path()</span></code></a></p>
<p>Details can be found at the Brainstorm <a class="reference external" href="https://neuroimage.usc.edu/brainstorm/DatasetMedianNerveCtf">median nerve dataset tutorial</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_brainstorm_data.html#ex-brainstorm-raw"><span class="std std-ref">Brainstorm raw (median nerve) dataset</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="spm-faces">
<h2><a class="toc-backref" href="#id22">SPM faces</a><a class="headerlink" href="#spm-faces" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.spm_face.data_path.html#mne.datasets.spm_face.data_path" title="mne.datasets.spm_face.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.spm_face.data_path()</span></code></a></p>
<p>The <a class="reference external" href="https://www.fil.ion.ucl.ac.uk/spm/data/mmfaces/">SPM faces dataset</a> contains EEG, MEG and fMRI recordings on face perception.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/spm_faces_dataset.html#ex-spm-faces"><span class="std std-ref">From raw data to dSPM on SPM Faces dataset</span></a> Full pipeline including artifact removal, epochs averaging, forward model computation and source reconstruction using dSPM on the contrast: âfaces - scrambledâ.</p></li>
</ul>
</div>
</div>
<div class="section" id="eegbci-motor-imagery">
<h2><a class="toc-backref" href="#id23">EEGBCI motor imagery</a><a class="headerlink" href="#eegbci-motor-imagery" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.eegbci.load_data.html#mne.datasets.eegbci.load_data" title="mne.datasets.eegbci.load_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.eegbci.load_data()</span></code></a></p>
<p>The EEGBCI dataset is documented in <a class="footnote-reference brackets" href="#id9" id="id2">2</a>. The data set is available at PhysioNet <a class="footnote-reference brackets" href="#id10" id="id3">3</a>.
The dataset contains 64-channel EEG recordings from 109 subjects and 14 runs on each subject in EDF+ format.
The recordings were made using the BCI2000 system. To load a subject, do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mne.io</span> <span class="k">import</span> <span class="n">concatenate_raws</span><span class="p">,</span> <span class="n">read_raw_edf</span>
<span class="kn">from</span> <span class="nn">mne.datasets</span> <span class="k">import</span> <span class="n">eegbci</span>
<span class="n">raw_fnames</span> <span class="o">=</span> <span class="n">eegbci</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">runs</span><span class="p">)</span>
<span class="n">raws</span> <span class="o">=</span> <span class="p">[</span><span class="n">read_raw_edf</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">raw_fnames</span><span class="p">]</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">concatenate_raws</span><span class="p">(</span><span class="n">raws</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/plot_decoding_csp_eeg.html#ex-decoding-csp-eeg"><span class="std std-ref">Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)</span></a></p></li>
</ul>
</div>
<p>Do not hesitate to contact MNE-Python developers on the
<a class="reference external" href="http://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">MNE mailing list</a>
to discuss the possibility to add more publicly available datasets.</p>
</div>
<div class="section" id="somatosensory">
<h2><a class="toc-backref" href="#id24">Somatosensory</a><a class="headerlink" href="#somatosensory" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.somato.data_path.html#mne.datasets.somato.data_path" title="mne.datasets.somato.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.somato.data_path()</span></code></a></p>
<p>This dataset contains somatosensory data with event-related synchronizations
(ERS) and desynchronizations (ERD).</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/time-freq/plot_sensors_time_frequency.html#tut-sensors-time-freq"><span class="std std-ref">Frequency and time-frequency sensors analysis</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="multimodal">
<h2><a class="toc-backref" href="#id25">Multimodal</a><a class="headerlink" href="#multimodal" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.multimodal.data_path.html#mne.datasets.multimodal.data_path" title="mne.datasets.multimodal.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.multimodal.data_path()</span></code></a></p>
<p>This dataset contains a single subject recorded at Otaniemi (Aalto University)
with auditory, visual, and somatosensory stimuli.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/io/plot_elekta_epochs.html#ex-io-ave-fiff"><span class="std std-ref">Getting averaging info from .fif files</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="high-frequency-sef">
<h2><a class="toc-backref" href="#id26">High frequency SEF</a><a class="headerlink" href="#high-frequency-sef" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.hf_sef.data_path.html#mne.datasets.hf_sef.data_path" title="mne.datasets.hf_sef.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.hf_sef.data_path()</span></code></a></p>
<p>This dataset contains somatosensory evoked fields (median nerve stimulation)
with thousands of epochs. It was recorded with an Elekta TRIUX MEG device at
a sampling frequency of 3 kHz. The dataset is suitable for investigating
high-frequency somatosensory responses. Data from two subjects are included
with MRI images in DICOM format and FreeSurfer reconstructions.</p>
</div>
<div class="section" id="visual-92-object-categories">
<h2><a class="toc-backref" href="#id27">Visual 92 object categories</a><a class="headerlink" href="#visual-92-object-categories" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.visual_92_categories.data_path.html#mne.datasets.visual_92_categories.data_path" title="mne.datasets.visual_92_categories.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.visual_92_categories.data_path()</span></code></a>.</p>
<p>This dataset is recorded using a 306-channel Neuromag vectorview system.</p>
<p>Experiment consisted in the visual presentation of 92 images of human, animal
and inanimate objects either natural or artificial <a class="footnote-reference brackets" href="#id11" id="id4">4</a>. Given the high number
of conditions this dataset is well adapted to an approach based on
Representational Similarity Analysis (RSA).</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/decoding_rsa.html#ex-rsa-noplot"><span class="std std-ref">Representational Similarity Analysis (RSA)</span></a>: Partially replicates the results from Cichy et al. (2014).</p></li>
</ul>
</div>
</div>
<div class="section" id="mtrf-dataset">
<h2><a class="toc-backref" href="#id28">mTRF Dataset</a><a class="headerlink" href="#mtrf-dataset" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.mtrf.data_path.html#mne.datasets.mtrf.data_path" title="mne.datasets.mtrf.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.mtrf.data_path()</span></code></a>.</p>
<p>This dataset contains 128 channel EEG as well as natural speech stimulus features,
which is also available <a class="reference external" href="https://sourceforge.net/projects/aespa/files/">here</a>.</p>
<p>The experiment consisted of subjects listening to natural speech.
The dataset contains several feature representations of the speech stimulus,
suitable for using to fit continuous regression models of neural activity.
More details and a description of the package can be found in <a class="footnote-reference brackets" href="#id12" id="id5">5</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/decoding/plot_receptive_field_mtrf.html#ex-receptive-field-mtrf"><span class="std std-ref">Receptive Field Estimation and Prediction</span></a>: Partially replicates the results from Crosse et al. (2016).</p></li>
</ul>
</div>
</div>
<div class="section" id="miscellaneous-datasets">
<h2><a class="toc-backref" href="#id29">Miscellaneous Datasets</a><a class="headerlink" href="#miscellaneous-datasets" title="Permalink to this headline">Â¶</a></h2>
<p>These datasets are used for specific purposes in the documentation and in
general are not useful for separate analyses.</p>
<div class="section" id="ecog-dataset">
<h3><a class="toc-backref" href="#id30">ECoG Dataset</a><a class="headerlink" href="#ecog-dataset" title="Permalink to this headline">Â¶</a></h3>
<p><a class="reference internal" href="../generated/mne.datasets.misc.data_path.html#mne.datasets.misc.data_path" title="mne.datasets.misc.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.misc.data_path()</span></code></a>. Data exists at <code class="docutils literal notranslate"><span class="pre">/ecog/sample_ecog.mat</span></code>.</p>
<p>This dataset contains a sample Electrocorticography (ECoG) dataset. It includes
a single grid of electrodes placed over the temporal lobe during an auditory
listening task. This dataset is primarily used to demonstrate visualization
functions in MNE and does not contain useful metadata for analysis.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/visualization/plot_3d_to_2d.html#ex-electrode-pos-2d"><span class="std std-ref">How to convert 3D electrode positions to a 2D image.</span></a>: Demonstrates
how to project a 3D electrode location onto a 2D image, a common procedure
in electrocorticography.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="kiloword-dataset">
<h2><a class="toc-backref" href="#id31">Kiloword dataset</a><a class="headerlink" href="#kiloword-dataset" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.kiloword.data_path.html#mne.datasets.kiloword.data_path" title="mne.datasets.kiloword.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.kiloword.data_path()</span></code></a>.</p>
<p>This dataset consists of averaged EEG data from 75 subjects performing a lexical decision
task on 960 English words <a class="footnote-reference brackets" href="#id13" id="id6">6</a>. The words are richly annotated, and can be used for e.g.
multiple regression estimation of EEG correlates of printed word processing.</p>
</div>
<div class="section" id="d-neuroimaging-bti-dataset">
<h2><a class="toc-backref" href="#id32">4D Neuroimaging / BTi dataset</a><a class="headerlink" href="#d-neuroimaging-bti-dataset" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.phantom_4dbti.data_path.html#mne.datasets.phantom_4dbti.data_path" title="mne.datasets.phantom_4dbti.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.phantom_4dbti.data_path()</span></code></a>.</p>
<p>This dataset was obtained with a phantom on a 4D Neuroimaging / BTi system at the MEG
center in La Timone hospital in Marseille.</p>
</div>
<div class="section" id="opm">
<h2><a class="toc-backref" href="#id33">OPM</a><a class="headerlink" href="#opm" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.opm.data_path.html#mne.datasets.opm.data_path" title="mne.datasets.opm.data_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.opm.data_path()</span></code></a></p>
<p>OPM data acquired using an Elekta DACQ, simply piping the data into Elekta
magnetometer channels. The FIF files thus appear to come from a TRIUX system
that is only acquiring a small number of magnetometer channels instead of the
whole array.</p>
<p>The OPM <code class="docutils literal notranslate"><span class="pre">coil_type</span></code> is custom, requiring a custom <code class="docutils literal notranslate"><span class="pre">coil_def.dat</span></code>.
The new <code class="docutils literal notranslate"><span class="pre">coil_type</span></code> is 9999.</p>
<p>OPM co-registration differs a bit from the typical SQUID-MEG workflow.
No <code class="docutils literal notranslate"><span class="pre">-trans.fif</span></code> file is needed for the OPMs, the FIF files include proper
sensor locations in MRI coordinates and no digitization of RPA/LPA/Nasion.
Thus the MEG&lt;-&gt;Head coordinate transform is taken to be an identity matrix
(i.e., everything is in MRI coordinates), even though this mis-identifies
the head coordinate frame (which is defined by the relationship of the
LPA, RPA, and Nasion).</p>
<p>Triggers include:</p>
<ul class="simple">
<li><p>Median nerve stimulation: trigger value 257.</p></li>
<li><p>Magnetic trigger (in OPM measurement only): trigger value 260.
1 second before the median nerve stimulation, a magnetic trigger is piped into the MSR.
This was to be able to check the synchronization between OPMs retrospectively, as each
sensor runs on an indepent clock. Synchronization turned out to be satisfactory</p></li>
</ul>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_opm_data.html#ex-opm-somatosensory"><span class="std std-ref">Optically pumped magnetometer (OPM) data</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/datasets/plot_opm_rest_data.html#ex-opm-resting-state"><span class="std std-ref">VectorView and OPM resting state datasets</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="the-sleep-polysomnographic-database">
<h2><a class="toc-backref" href="#id34">The Sleep PolySomnoGraphic Database</a><a class="headerlink" href="#the-sleep-polysomnographic-database" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference internal" href="../generated/mne.datasets.sleep_physionet.age.fetch_data.html#mne.datasets.sleep_physionet.age.fetch_data" title="mne.datasets.sleep_physionet.age.fetch_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sleep_physionet.age.fetch_data()</span></code></a>
<a class="reference internal" href="../generated/mne.datasets.sleep_physionet.temazepam.fetch_data.html#mne.datasets.sleep_physionet.temazepam.fetch_data" title="mne.datasets.sleep_physionet.temazepam.fetch_data"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.datasets.sleep_physionet.temazepam.fetch_data()</span></code></a></p>
<p>The sleep PhysioNet database contains 197 whole-night PolySomnoGraphic sleep
recordings, containing EEG, EOG, chin EMG, and event markers. Some records also
contain respiration and body temperature. Corresponding hypnograms (sleep
patterns) were manually scored by well-trained technicians according to the
Rechtschaffen and Kales manual, and are also available. If you use these
data please cite <a class="footnote-reference brackets" href="#id14" id="id7">7</a> and <a class="footnote-reference brackets" href="#id15" id="id8">8</a>.</p>
<div class="topic">
<p class="topic-title first">Examples</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_tutorials/sample-datasets/plot_sleep.html#tut-sleep-stage-classif"><span class="std std-ref">Sleep stage classification from polysomnography (PSG) data</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id35">References</a><a class="headerlink" href="#references" title="Permalink to this headline">Â¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220</p>
</dd>
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Cichy, R. M., Pantazis, D., &amp; Oliva, A. Resolving human object recognition in space and time. Nature Neuroscience (2014): 17(3), 455-462</p>
</dd>
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Crosse, M. J., Di Liberto, G. M., Bednar, A., &amp; Lalor, E. C. The Multivariate Temporal Response Function (mTRF) Toolbox: A MATLAB Toolbox for Relating Neural Signals to Continuous Stimuli. Frontiers in Human Neuroscience (2016): 10.</p>
</dd>
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Dufau, S., Grainger, J., Midgley, KJ., Holcomb, PJ. A thousand words are worth a picture: Snapshots of printed-word processing in an event-related potential megastudy. Psychological science, 2015</p>
</dd>
<dt class="label" id="id14"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p>B Kemp, AH Zwinderman, B Tuk, HAC Kamphuisen, JJL OberyÃ©. Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG. IEEE-BME 47(9):1185-1194 (2000). <a class="reference external" href="https://ieeexplore.ieee.org/document/867928">https://ieeexplore.ieee.org/document/867928</a></p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id8">8</a></span></dt>
<dd><p>Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220 [Circulation Electronic Pages; <a class="reference external" href="http://circ.ahajournals.org/cgi/content/full/101/23/e215">http://circ.ahajournals.org/cgi/content/full/101/23/e215</a>]; 2000 (June 13).</p>
</dd>
</dl>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container institutions">
    <a href="https://www.massgeneral.org/"><img class="institution_lg" src="../_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a>
    <a href="https://martinos.org/"><img class="institution_lg" src="../_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a>
    <a href="https://hms.harvard.edu/"><img class="institution_lg" src="../_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a>
    <a href="https://web.mit.edu/"><img class="institution_sm" src="../_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a>
    <a href="https://www.nyu.edu/"><img class="institution_md" src="../_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a>
    <a href="http://www.cea.fr/"><img class="institution_md" src="../_static/institution_logos/CEA.png" title="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives" alt="Commissariat Ã  lÂ´Ã©nergie atomique et aux Ã©nergies alternatives"/></a>
    <a href="https://sci.aalto.fi/"><img class="institution_md" src="../_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a>
    <a href="https://www.telecom-paris.fr/"><img class="institution_md" src="../_static/institution_logos/Telecom_Paris_Tech.png" title="TÃ©lÃ©com ParisTech" alt="TÃ©lÃ©com ParisTech"/></a>
    <a href="https://www.washington.edu/"><img class="institution_sm" src="../_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a>
    <a href="https://icm-institute.org/"><img class="institution_lg" src="../_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle Ã©piniÃ¨re" alt="Institut du Cerveau et de la Moelle Ã©piniÃ¨re"/></a>
    <a href="https://www.bu.edu/"><img class="institution_sm" src="../_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a>
    <a href="https://www.inserm.fr/"><img class="institution_xs" src="../_static/institution_logos/Inserm.svg" title="Institut national de la santÃ© et de la recherche mÃ©dicale" alt="Institut national de la santÃ© et de la recherche mÃ©dicale"/></a>
    <a href="https://www.fz-juelich.de/"><img class="institution_sm" src="../_static/institution_logos/Julich.svg" title="Forschungszentrum JÃ¼lich" alt="Forschungszentrum JÃ¼lich"/></a>
    <a href="https://www.tu-ilmenau.de/"><img class="institution_sm" src="../_static/institution_logos/Ilmenau.gif" title="Technische UniversitÃ¤t Ilmenau" alt="Technische UniversitÃ¤t Ilmenau"/></a>
    <a href="https://bids.berkeley.edu/"><img class="institution_md" src="../_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a>
    <a href="https://www.inria.fr/"><img class="institution_sm" src="../_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a>
    <a href="https://www.au.dk/"><img class="institution_sm" src="../_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a>
    <a href="https://www.uni-graz.at/"><img class="institution_md" src="../_static/institution_logos/Graz.jpg" title="Karl-Franzens-UniversitÃ¤t Graz" alt="Karl-Franzens-UniversitÃ¤t Graz"/></a>
  </div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>Â·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>Â·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>Â·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>Â·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2019, MNE Developers. Last updated on 2019-07-11.</p>
  </div>
</footer>
  </body>
</html>