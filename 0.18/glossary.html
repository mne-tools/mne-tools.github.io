<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Glossary &#8212; MNE 0.18.2 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap_divs.css" />
    <link rel="stylesheet" href="_static/reset-syntax.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script type="text/javascript" src="_static/bootstrap_divs.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />

    <script type="text/javascript" src="_static/copybutton.js"></script>


    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37225609-1']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>


    <link rel="stylesheet" href="_static/style.css " type="text/css" />
    <link rel="stylesheet" href="_static/font-awesome.css" type="text/css" />
    <link rel="stylesheet" href="_static/flag-icon.css" type="text/css" />



    <script type="text/javascript">
    !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);
    js.id=id;js.src="https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
    </script>



    <script type="text/javascript">
    (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
    </script>



<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>



  </head><body>





  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/mne_logo_small.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b>0.18.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="getting_started.html">Install</a></li>
                <li><a href="documentation.html">Documentation</a></li>
                <li><a href="python_reference.html">API</a></li>
                <li><a href="#">Glossary</a></li>
                <li><a href="auto_examples/index.html">Examples</a></li>
                <li><a href="contributing.html">Contribute</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
<div class="navbar-form navbar-right navbar-btn dropdown btn-group-sm" style="margin-left: 20px; margin-top: 5px; margin-bottom: 5px">
  <button type="button" class="btn btn-primary navbar-btn dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown">
    v0.18.2
    <span class="caret"></span>
  </button>
  <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
    <li><a href="https://mne-tools.github.io/dev/index.html">Development</a></li>
    <li><a href="https://mne-tools.github.io/stable/index.html">v0.18 (stable)</a></li>
    <li><a href="https://mne-tools.github.io/0.17/index.html">v0.17</a></li>
    <li><a href="https://mne-tools.github.io/0.16/index.html">v0.16</a></li>
    <li><a href="https://mne-tools.github.io/0.15/index.html">v0.15</a></li>
    <li><a href="https://mne-tools.github.io/0.14/index.html">v0.14</a></li>
    <li><a href="https://mne-tools.github.io/0.13/index.html">v0.13</a></li>
    <li><a href="https://mne-tools.github.io/0.12/index.html">v0.12</a></li>
    <li><a href="https://mne-tools.github.io/0.11/index.html">v0.11</a></li>
  </ul>
</div>


            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/mne_logo_small.png" alt="Logo"/>
            </a></p><ul>
<li><a class="reference internal" href="#">Glossary</a><ul>
<li><a class="reference internal" href="#mne-python-core-terminology-and-general-concepts">MNE-Python core terminology and general concepts</a></li>
</ul>
</li>
</ul>

<form action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="glossary">
<span id="id1"></span><h1>Glossary<a class="headerlink" href="#glossary" title="Permalink to this headline">¶</a></h1>
<div class="section" id="mne-python-core-terminology-and-general-concepts">
<h2>MNE-Python core terminology and general concepts<a class="headerlink" href="#mne-python-core-terminology-and-general-concepts" title="Permalink to this headline">¶</a></h2>
<dl class="glossary simple">
<dt id="term-annotations">annotations</dt><dd><p>An annotation is defined by an onset, a duration, and a string
description. It can contain information about the experiments, but
also details on signals marked by a human: bad data segments,
sleep scores, sleep events (spindles, K-complex) etc.
An <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> object is a container of multiple annotations.
See <a class="reference internal" href="generated/mne.Annotations.html#mne.Annotations" title="mne.Annotations"><code class="xref py py-class docutils literal notranslate"><span class="pre">Annotations</span></code></a> page for the API of the corresponding
object class and <a class="reference internal" href="auto_tutorials/intro/plot_object_annotations.html#tut-annotations"><span class="std std-ref">The Events and Annotations data structures</span></a>
for a tutorial on how to manipulate such objects.</p>
</dd>
<dt id="term-channels">channels</dt><dd><p>Channels refer to MEG sensors, EEG electrodes or any extra electrode
or sensor such as EOG, ECG or sEEG, ECoG etc. Channels have typically
a type, such as gradiometer, and a unit, such as Tesla/Meter that
is used in the code base, e.g. for plotting.</p>
</dd>
<dt id="term-bem">BEM</dt><dd><p>BEM is the acronym for boundary element method or boundary element
model. Both are related to the forward model computation and more
specifically the definion of the conductor model. The
boundary element model consists of surfaces such as the inner skull,
outer skull and outer skiln (a.k.a. scalp) that define compartments
of tissues of the head. You can compute the BEM surfaces with
<a class="reference internal" href="generated/mne.bem.make_watershed_bem.html#mne.bem.make_watershed_bem" title="mne.bem.make_watershed_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_watershed_bem()</span></code></a> or <a class="reference internal" href="generated/mne.bem.make_flash_bem.html#mne.bem.make_flash_bem" title="mne.bem.make_flash_bem"><code class="xref py py-func docutils literal notranslate"><span class="pre">mne.bem.make_flash_bem()</span></code></a>.
See <a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> for usage demo.</p>
</dd>
<dt id="term-dipole">dipole</dt><dd><p>See <a class="reference internal" href="#term-equivalent-current-dipole"><span class="xref std std-term">equivalent current dipole</span></a>.</p>
</dd>
<dt id="term-equivalent-current-dipole">equivalent current dipole</dt><dd><p>An equivalent current dipole (ECD) is an approximate representation of
post-synaptic activity in a small region of cortex. The intracellular
currents that give rise to measurable EEG/MEG signals are thought to
originate in populations of cortical pyramidal neurons aligned
perpendicularly to the cortical surface. Because the length of such
current sources is very small relative to the distance between the
cortex and the EEG/MEG sensors, the fields measured by the techniques
are well-approximated by (i.e., “equivalent” to) fields generated by
idealized point sources (dipoles) located on the cortical surface.</p>
</dd>
<dt id="term-epochs">epochs</dt><dd><p>Epochs are chunks of data extracted from raw continuous data. Typically,
they correspond to the trials of an experimental design.
See <a class="reference internal" href="generated/mne.Epochs.html#mne.Epochs" title="mne.Epochs"><code class="xref py py-class docutils literal notranslate"><span class="pre">Epochs</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/epochs/plot_object_epochs.html#tut-epochs-class"><span class="std std-ref">The Epochs data structure: epoched data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-evoked">evoked</dt><dd><p>Evoked data are obtained by averaging epochs. Typically, an evoked object
is constructed for each subject and each condition, but it can also be
obtained by averaging a list of evoked over different subjects.
See <a class="reference internal" href="generated/mne.EvokedArray.html#mne.EvokedArray" title="mne.EvokedArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">EvokedArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/evoked/plot_object_evoked.html#tut-evoked-class"><span class="std std-ref">The Evoked data structure: evoked/averaged data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-events">events</dt><dd><p>Events correspond to specific time points in raw data; e.g.,
triggers, experimental condition events, etc. MNE represents events with
integers that are stored in numpy arrays of shape (n_events, 3). Such arrays
are classically obtained from a trigger channel, also referred to as
stim channel.</p>
</dd>
<dt id="term-first-samp">first_samp</dt><dd><p>The attribute of raw objects called <code class="docutils literal notranslate"><span class="pre">first_samp</span></code> is an integer that
refers to the number of time samples passed between the onset of the
acquisition system and the time when data started to be written
on disk. This is a specificity of the Vectorview MEG systems (fif files)
but for consistency it is available for all file formats in MNE.
One benefit of this system is that croppping data only boils
down to a change of the <code class="docutils literal notranslate"><span class="pre">first_samp</span></code> attribute to know when cropped data
was acquired.</p>
</dd>
<dt id="term-forward-solution">forward solution</dt><dd><p>The forward solution (abbr. <code class="docutils literal notranslate"><span class="pre">fwd</span></code>) is a linear operator capturing the
relationship between each dipole location in the <a class="reference internal" href="#term-source-space"><span class="xref std std-term">source space</span></a>
and the corresponding field distribution measured by the sensors (AKA,
the “lead field matrix”). Calculating a forward solution requires a
conductivity model of the head, encapsulating the geometry and
electrical conductivity of the different tissue compartments (see
<a class="reference internal" href="#term-bem"><span class="xref std std-term">boundary element model</span></a> and
<a class="reference internal" href="generated/mne.bem.ConductorModel.html#mne.bem.ConductorModel" title="mne.bem.ConductorModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">mne.bem.ConductorModel</span></code></a>).</p>
</dd>
<dt id="term-info">info</dt><dd><p>Also called <code class="docutils literal notranslate"><span class="pre">measurement</span> <span class="pre">info</span></code>, it is a collection of metadata regarding
a Raw, Epochs or Evoked object; e.g.,
channel locations and types, sampling frequency,
preprocessing history such as filters …
See <a class="reference internal" href="auto_tutorials/intro/plot_info.html#tut-info-class"><span class="std std-ref">The Info data structure</span></a> for a narrative overview.</p>
</dd>
<dt id="term-inverse-operator">inverse operator</dt><dd><p>The inverse operator is an <span class="math notranslate nohighlight">\(M \times N\)</span> matrix (<span class="math notranslate nohighlight">\(M\)</span> source
locations by <span class="math notranslate nohighlight">\(N\)</span> sensors) that, when applied to the sensor
signals, yields estimates of the brain activity that gave rise to the
observed sensor signals. Inverse operators are available for the linear
inverse methods MNE, dSPM, sLORETA and eLORETA.</p>
</dd>
<dt id="term-label">label</dt><dd><p>A <a class="reference internal" href="generated/mne.Label.html#mne.Label" title="mne.Label"><code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code></a> refers to a region in the cortex, also often called
a region of interest (ROI) in the literature.</p>
</dd>
<dt id="term-montage">montage</dt><dd><p>EEG channel names and the relative positions of the sensor w.r.t. the scalp.
See <a class="reference internal" href="generated/mne.channels.Montage.html#mne.channels.Montage" title="mne.channels.Montage"><code class="xref py py-class docutils literal notranslate"><span class="pre">Montage</span></code></a> for the API of the corresponding object
class.</p>
</dd>
<dt id="term-morphing">morphing</dt><dd><p>Morphing refers to the operation of transferring source estimates from
one anatomy to another. It is commonly referred as realignment in fMRI
literature. This operation is necessary for group studies.
See <a class="reference internal" href="manual/source_localization/morph_stc.html#ch-morph"><span class="std std-ref">Morphing source estimates: Moving data from one brain to another</span></a> for more details.</p>
</dd>
<dt id="term-pick">pick</dt><dd><p>An integer that is the index of a channel in the measurement info.
It allows to obtain the information on a channel in the list of channels
available in <code class="docutils literal notranslate"><span class="pre">info['chs']</span></code>.</p>
</dd>
<dt id="term-projector">projector</dt><dd><p>A projector (abbr. <code class="docutils literal notranslate"><span class="pre">proj</span></code>), also referred to as Signal Space
Projection (SSP), defines
a linear operation applied spatially to EEG or MEG data. You can see
this as a matrix multiplication that reduces the rank of the data by
projecting it to a lower dimensional subspace. Such a projection
operator is applied to both the data and the forward operator for
source localization. Note that EEG average referencing can be done
using such a projection operator. It is stored in the measurement
info in <code class="docutils literal notranslate"><span class="pre">info['projs']</span></code>.</p>
</dd>
<dt id="term-raw">raw</dt><dd><p>It corresponds to continuous data (preprocessed or not). One typically
manipulates raw data when reading recordings in a file on disk.
See <a class="reference internal" href="generated/mne.io.RawArray.html#mne.io.RawArray" title="mne.io.RawArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">RawArray</span></code></a> for the API of the corresponding
object class, and <a class="reference internal" href="auto_tutorials/raw/plot_object_raw.html#tut-raw-class"><span class="std std-ref">The Raw data structure: continuous data</span></a> for a narrative overview.</p>
</dd>
<dt id="term-source-space">source space</dt><dd><p>A source space (abbr. <code class="docutils literal notranslate"><span class="pre">src</span></code>) specifies where in the brain one wants
to estimate the
source amplitudes. It corresponds to locations of a set of
candidate equivalent current dipoles (ECD). MNE mostly works
with source spaces defined on the cortical surfaces estimated
by FreeSurfer from a T1-weighted MRI image. See
<a class="reference internal" href="auto_tutorials/source-modeling/plot_forward.html#tut-forward"><span class="std std-ref">Head model and forward computation</span></a> to read on
how to compute a forward operator on a source space.
See <a class="reference internal" href="generated/mne.SourceSpaces.html#mne.SourceSpaces" title="mne.SourceSpaces"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceSpaces</span></code></a> for the API of the corresponding
object class.</p>
</dd>
<dt id="term-source-estimates-abbr-stc">source estimates (abbr. <code class="docutils literal notranslate"><span class="pre">stc</span></code>)</dt><dd><p>Source estimates, commonly referred to as STC (Source Time Courses),
are obtained from source localization methods,
such as dSPM, sLORETA, LCMV or MxNE.
It contains the amplitudes of the sources over time.
An STC object only stores the amplitudes of activations but
not the locations of the sources. To get access to the locations
you need to have the source space used to compute the forward
operator.
See <a class="reference internal" href="generated/mne.SourceEstimate.html#mne.SourceEstimate" title="mne.SourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">SourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.VolSourceEstimate.html#mne.VolSourceEstimate" title="mne.VolSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VolSourceEstimate</span></code></a>
<a class="reference internal" href="generated/mne.VectorSourceEstimate.html#mne.VectorSourceEstimate" title="mne.VectorSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorSourceEstimate</span></code></a>, <a class="reference internal" href="generated/mne.MixedSourceEstimate.html#mne.MixedSourceEstimate" title="mne.MixedSourceEstimate"><code class="xref py py-class docutils literal notranslate"><span class="pre">MixedSourceEstimate</span></code></a>,
for the API of the corresponding object classes.</p>
</dd>
<dt id="term-selection-abbr-sel">selection (abbr. sel)</dt><dd><p>A set of picks. E.g., all sensors included in a Region of Interest.</p>
</dd>
<dt id="term-stim-channel">stim channel</dt><dd><p>A stim channel, a.k.a. trigger channel, is a channel that encodes events
during the recording. It is typically a channel that is always zero and that
takes positive values when something happens such as the onset of a stimulus.
Classical names for stim channels is <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">014</span></code> or <code class="docutils literal notranslate"><span class="pre">STI</span> <span class="pre">101</span></code>.
So-called events arrays are obtained from stim channels.</p>
</dd>
<dt id="term-trans">trans</dt><dd><p>A coordinate frame affine transformation, usually between the Neuromag head
coordinate frame and the MRI Surface RAS coordinate frame used by Freesurfer.</p>
</dd>
</dl>
</div>
</div>


    </div>
    
  </div>
</div>
<footer class="footer">
  <div class="container institutions">
    <a href="https://www.massgeneral.org/"><img class="institution_lg" src="_static/institution_logos/MGH.svg" title="Massachusetts General Hospital" alt="Massachusetts General Hospital"/></a>
    <a href="https://martinos.org/"><img class="institution_lg" src="_static/institution_logos/Martinos.png" title="Athinoula A. Martinos Center for Biomedical Imaging" alt="Athinoula A. Martinos Center for Biomedical Imaging"/></a>
    <a href="https://hms.harvard.edu/"><img class="institution_lg" src="_static/institution_logos/Harvard.png" title="Harvard Medical School" alt="Harvard Medical School"/></a>
    <a href="https://web.mit.edu/"><img class="institution_sm" src="_static/institution_logos/MIT.svg" title="Massachusetts Institute of Technology" alt="Massachusetts Institute of Technology"/></a>
    <a href="https://www.nyu.edu/"><img class="institution_md" src="_static/institution_logos/NYU.png" title="New York University" alt="New York University"/></a>
    <a href="http://www.cea.fr/"><img class="institution_md" src="_static/institution_logos/CEA.png" title="Commissariat à l´énergie atomique et aux énergies alternatives" alt="Commissariat à l´énergie atomique et aux énergies alternatives"/></a>
    <a href="https://sci.aalto.fi/"><img class="institution_md" src="_static/institution_logos/Aalto.svg" title="Aalto-yliopiston perustieteiden korkeakoulu" alt="Aalto-yliopiston perustieteiden korkeakoulu"/></a>
    <a href="https://www.telecom-paris.fr/"><img class="institution_md" src="_static/institution_logos/Telecom_Paris_Tech.png" title="Télécom ParisTech" alt="Télécom ParisTech"/></a>
    <a href="https://www.washington.edu/"><img class="institution_sm" src="_static/institution_logos/Washington.png" title="University of Washington" alt="University of Washington"/></a>
    <a href="https://icm-institute.org/"><img class="institution_lg" src="_static/institution_logos/ICM.jpg" title="Institut du Cerveau et de la Moelle épinière" alt="Institut du Cerveau et de la Moelle épinière"/></a>
    <a href="https://www.bu.edu/"><img class="institution_sm" src="_static/institution_logos/BU.svg" title="Boston University" alt="Boston University"/></a>
    <a href="https://www.inserm.fr/"><img class="institution_xs" src="_static/institution_logos/Inserm.svg" title="Institut national de la santé et de la recherche médicale" alt="Institut national de la santé et de la recherche médicale"/></a>
    <a href="https://www.fz-juelich.de/"><img class="institution_sm" src="_static/institution_logos/Julich.svg" title="Forschungszentrum Jülich" alt="Forschungszentrum Jülich"/></a>
    <a href="https://www.tu-ilmenau.de/"><img class="institution_sm" src="_static/institution_logos/Ilmenau.gif" title="Technische Universität Ilmenau" alt="Technische Universität Ilmenau"/></a>
    <a href="https://bids.berkeley.edu/"><img class="institution_md" src="_static/institution_logos/BIDS.png" title="Berkeley Institute for Data Science" alt="Berkeley Institute for Data Science"/></a>
    <a href="https://www.inria.fr/"><img class="institution_sm" src="_static/institution_logos/inria.png" title="Institut national de recherche en informatique et en automatique" alt="Institut national de recherche en informatique et en automatique"/></a>
    <a href="https://www.au.dk/"><img class="institution_sm" src="_static/institution_logos/Aarhus.png" title="Aarhus Universitet" alt="Aarhus Universitet"/></a>
    <a href="https://www.uni-graz.at/"><img class="institution_md" src="_static/institution_logos/Graz.jpg" title="Karl-Franzens-Universität Graz" alt="Karl-Franzens-Universität Graz"/></a>
  </div>
  <div class="container">
    <ul class="list-inline">
      <li><a href="https://github.com/mne-tools/mne-python">GitHub</a></li>
      <li>·</li>
      <li><a href="https://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis">Mailing list</a></li>
      <li>·</li>
      <li><a href="https://gitter.im/mne-tools/mne-python">Gitter</a></li>
      <li>·</li>
      <li><a href="whats_new.html">What's new</a></li>
      <li>·</li>
      <li><a href="faq.html#cite">Cite MNE</a></li>
      <li class="pull-right"><a href="#">Back to top</a></li>
    </ul>
    <p>&copy; Copyright 2012-2019, MNE Developers. Last updated on 2019-07-11.</p>
  </div>
</footer>
  </body>
</html>